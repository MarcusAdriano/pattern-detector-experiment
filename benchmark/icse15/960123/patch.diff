diff --git a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/Cassandra.java b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/Cassandra.java
index 2f3808b1..3544469c 100644
--- a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/Cassandra.java
+++ b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/Cassandra.java
@@ -5681,14 +5681,14 @@ public void read(TProtocol iprot) throws TException {
           case 0: // SUCCESS
             if (field.type == TType.LIST) {
               {
-                TList _list29 = iprot.readListBegin();
-                this.success = new ArrayList<ColumnOrSuperColumn>(_list29.size);
-                for (int _i30 = 0; _i30 < _list29.size; ++_i30)
+                TList _list33 = iprot.readListBegin();
+                this.success = new ArrayList<ColumnOrSuperColumn>(_list33.size);
+                for (int _i34 = 0; _i34 < _list33.size; ++_i34)
                 {
-                  ColumnOrSuperColumn _elem31;
-                  _elem31 = new ColumnOrSuperColumn();
-                  _elem31.read(iprot);
-                  this.success.add(_elem31);
+                  ColumnOrSuperColumn _elem35;
+                  _elem35 = new ColumnOrSuperColumn();
+                  _elem35.read(iprot);
+                  this.success.add(_elem35);
                 }
                 iprot.readListEnd();
               }
@@ -5738,9 +5738,9 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
         {
           oprot.writeListBegin(new TList(TType.STRUCT, this.success.size()));
-          for (ColumnOrSuperColumn _iter32 : this.success)
+          for (ColumnOrSuperColumn _iter36 : this.success)
           {
-            _iter32.write(oprot);
+            _iter36.write(oprot);
           }
           oprot.writeListEnd();
         }
@@ -6274,13 +6274,13 @@ public void read(TProtocol iprot) throws TException {
           case 1: // KEYS
             if (field.type == TType.LIST) {
               {
-                TList _list33 = iprot.readListBegin();
-                this.keys = new ArrayList<byte[]>(_list33.size);
-                for (int _i34 = 0; _i34 < _list33.size; ++_i34)
+                TList _list37 = iprot.readListBegin();
+                this.keys = new ArrayList<byte[]>(_list37.size);
+                for (int _i38 = 0; _i38 < _list37.size; ++_i38)
                 {
-                  byte[] _elem35;
-                  _elem35 = iprot.readBinary();
-                  this.keys.add(_elem35);
+                  byte[] _elem39;
+                  _elem39 = iprot.readBinary();
+                  this.keys.add(_elem39);
                 }
                 iprot.readListEnd();
               }
@@ -6330,9 +6330,9 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(KEYS_FIELD_DESC);
         {
           oprot.writeListBegin(new TList(TType.STRING, this.keys.size()));
-          for (byte[] _iter36 : this.keys)
+          for (byte[] _iter40 : this.keys)
           {
-            oprot.writeBinary(_iter36);
+            oprot.writeBinary(_iter40);
           }
           oprot.writeListEnd();
         }
@@ -6824,26 +6824,26 @@ public void read(TProtocol iprot) throws TException {
           case 0: // SUCCESS
             if (field.type == TType.MAP) {
               {
-                TMap _map37 = iprot.readMapBegin();
-                this.success = new HashMap<byte[],List<ColumnOrSuperColumn>>(2*_map37.size);
-                for (int _i38 = 0; _i38 < _map37.size; ++_i38)
+                TMap _map41 = iprot.readMapBegin();
+                this.success = new HashMap<byte[],List<ColumnOrSuperColumn>>(2*_map41.size);
+                for (int _i42 = 0; _i42 < _map41.size; ++_i42)
                 {
-                  byte[] _key39;
-                  List<ColumnOrSuperColumn> _val40;
-                  _key39 = iprot.readBinary();
+                  byte[] _key43;
+                  List<ColumnOrSuperColumn> _val44;
+                  _key43 = iprot.readBinary();
                   {
-                    TList _list41 = iprot.readListBegin();
-                    _val40 = new ArrayList<ColumnOrSuperColumn>(_list41.size);
-                    for (int _i42 = 0; _i42 < _list41.size; ++_i42)
+                    TList _list45 = iprot.readListBegin();
+                    _val44 = new ArrayList<ColumnOrSuperColumn>(_list45.size);
+                    for (int _i46 = 0; _i46 < _list45.size; ++_i46)
                     {
-                      ColumnOrSuperColumn _elem43;
-                      _elem43 = new ColumnOrSuperColumn();
-                      _elem43.read(iprot);
-                      _val40.add(_elem43);
+                      ColumnOrSuperColumn _elem47;
+                      _elem47 = new ColumnOrSuperColumn();
+                      _elem47.read(iprot);
+                      _val44.add(_elem47);
                     }
                     iprot.readListEnd();
                   }
-                  this.success.put(_key39, _val40);
+                  this.success.put(_key43, _val44);
                 }
                 iprot.readMapEnd();
               }
@@ -6893,14 +6893,14 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
         {
           oprot.writeMapBegin(new TMap(TType.STRING, TType.LIST, this.success.size()));
-          for (Map.Entry<byte[], List<ColumnOrSuperColumn>> _iter44 : this.success.entrySet())
+          for (Map.Entry<byte[], List<ColumnOrSuperColumn>> _iter48 : this.success.entrySet())
           {
-            oprot.writeBinary(_iter44.getKey());
+            oprot.writeBinary(_iter48.getKey());
             {
-              oprot.writeListBegin(new TList(TType.STRUCT, _iter44.getValue().size()));
-              for (ColumnOrSuperColumn _iter45 : _iter44.getValue())
+              oprot.writeListBegin(new TList(TType.STRUCT, _iter48.getValue().size()));
+              for (ColumnOrSuperColumn _iter49 : _iter48.getValue())
               {
-                _iter45.write(oprot);
+                _iter49.write(oprot);
               }
               oprot.writeListEnd();
             }
@@ -8617,13 +8617,13 @@ public void read(TProtocol iprot) throws TException {
           case 2: // KEYS
             if (field.type == TType.LIST) {
               {
-                TList _list46 = iprot.readListBegin();
-                this.keys = new ArrayList<byte[]>(_list46.size);
-                for (int _i47 = 0; _i47 < _list46.size; ++_i47)
+                TList _list50 = iprot.readListBegin();
+                this.keys = new ArrayList<byte[]>(_list50.size);
+                for (int _i51 = 0; _i51 < _list50.size; ++_i51)
                 {
-                  byte[] _elem48;
-                  _elem48 = iprot.readBinary();
-                  this.keys.add(_elem48);
+                  byte[] _elem52;
+                  _elem52 = iprot.readBinary();
+                  this.keys.add(_elem52);
                 }
                 iprot.readListEnd();
               }
@@ -8678,9 +8678,9 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(KEYS_FIELD_DESC);
         {
           oprot.writeListBegin(new TList(TType.STRING, this.keys.size()));
-          for (byte[] _iter49 : this.keys)
+          for (byte[] _iter53 : this.keys)
           {
-            oprot.writeBinary(_iter49);
+            oprot.writeBinary(_iter53);
           }
           oprot.writeListEnd();
         }
@@ -9179,15 +9179,15 @@ public void read(TProtocol iprot) throws TException {
           case 0: // SUCCESS
             if (field.type == TType.MAP) {
               {
-                TMap _map50 = iprot.readMapBegin();
-                this.success = new HashMap<byte[],Integer>(2*_map50.size);
-                for (int _i51 = 0; _i51 < _map50.size; ++_i51)
+                TMap _map54 = iprot.readMapBegin();
+                this.success = new HashMap<byte[],Integer>(2*_map54.size);
+                for (int _i55 = 0; _i55 < _map54.size; ++_i55)
                 {
-                  byte[] _key52;
-                  int _val53;
-                  _key52 = iprot.readBinary();
-                  _val53 = iprot.readI32();
-                  this.success.put(_key52, _val53);
+                  byte[] _key56;
+                  int _val57;
+                  _key56 = iprot.readBinary();
+                  _val57 = iprot.readI32();
+                  this.success.put(_key56, _val57);
                 }
                 iprot.readMapEnd();
               }
@@ -9237,10 +9237,10 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
         {
           oprot.writeMapBegin(new TMap(TType.STRING, TType.I32, this.success.size()));
-          for (Map.Entry<byte[], Integer> _iter54 : this.success.entrySet())
+          for (Map.Entry<byte[], Integer> _iter58 : this.success.entrySet())
           {
-            oprot.writeBinary(_iter54.getKey());
-            oprot.writeI32(_iter54.getValue());
+            oprot.writeBinary(_iter58.getKey());
+            oprot.writeI32(_iter58.getValue());
           }
           oprot.writeMapEnd();
         }
@@ -10323,14 +10323,14 @@ public void read(TProtocol iprot) throws TException {
           case 0: // SUCCESS
             if (field.type == TType.LIST) {
               {
-                TList _list55 = iprot.readListBegin();
-                this.success = new ArrayList<KeySlice>(_list55.size);
-                for (int _i56 = 0; _i56 < _list55.size; ++_i56)
+                TList _list59 = iprot.readListBegin();
+                this.success = new ArrayList<KeySlice>(_list59.size);
+                for (int _i60 = 0; _i60 < _list59.size; ++_i60)
                 {
-                  KeySlice _elem57;
-                  _elem57 = new KeySlice();
-                  _elem57.read(iprot);
-                  this.success.add(_elem57);
+                  KeySlice _elem61;
+                  _elem61 = new KeySlice();
+                  _elem61.read(iprot);
+                  this.success.add(_elem61);
                 }
                 iprot.readListEnd();
               }
@@ -10380,9 +10380,9 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
         {
           oprot.writeListBegin(new TList(TType.STRUCT, this.success.size()));
-          for (KeySlice _iter58 : this.success)
+          for (KeySlice _iter62 : this.success)
           {
-            _iter58.write(oprot);
+            _iter62.write(oprot);
           }
           oprot.writeListEnd();
         }
@@ -12825,38 +12825,38 @@ public void read(TProtocol iprot) throws TException {
           case 1: // MUTATION_MAP
             if (field.type == TType.MAP) {
               {
-                TMap _map59 = iprot.readMapBegin();
-                this.mutation_map = new HashMap<byte[],Map<String,List<Mutation>>>(2*_map59.size);
-                for (int _i60 = 0; _i60 < _map59.size; ++_i60)
-                {
-                  byte[] _key61;
-                  Map<String,List<Mutation>> _val62;
-                  _key61 = iprot.readBinary();
-                  {
                     TMap _map63 = iprot.readMapBegin();
-                    _val62 = new HashMap<String,List<Mutation>>(2*_map63.size);
+                this.mutation_map = new HashMap<byte[],Map<String,List<Mutation>>>(2*_map63.size);
                     for (int _i64 = 0; _i64 < _map63.size; ++_i64)
                     {
-                      String _key65;
-                      List<Mutation> _val66;
-                      _key65 = iprot.readString();
+                  byte[] _key65;
+                  Map<String,List<Mutation>> _val66;
+                  _key65 = iprot.readBinary();
+                  {
+                    TMap _map67 = iprot.readMapBegin();
+                    _val66 = new HashMap<String,List<Mutation>>(2*_map67.size);
+                    for (int _i68 = 0; _i68 < _map67.size; ++_i68)
+                    {
+                      String _key69;
+                      List<Mutation> _val70;
+                      _key69 = iprot.readString();
                       {
-                        TList _list67 = iprot.readListBegin();
-                        _val66 = new ArrayList<Mutation>(_list67.size);
-                        for (int _i68 = 0; _i68 < _list67.size; ++_i68)
+                        TList _list71 = iprot.readListBegin();
+                        _val70 = new ArrayList<Mutation>(_list71.size);
+                        for (int _i72 = 0; _i72 < _list71.size; ++_i72)
                         {
-                          Mutation _elem69;
-                          _elem69 = new Mutation();
-                          _elem69.read(iprot);
-                          _val66.add(_elem69);
+                          Mutation _elem73;
+                          _elem73 = new Mutation();
+                          _elem73.read(iprot);
+                          _val70.add(_elem73);
                         }
                         iprot.readListEnd();
                       }
-                      _val62.put(_key65, _val66);
+                      _val66.put(_key69, _val70);
                     }
                     iprot.readMapEnd();
                   }
-                  this.mutation_map.put(_key61, _val62);
+                  this.mutation_map.put(_key65, _val66);
                 }
                 iprot.readMapEnd();
               }
@@ -12890,19 +12890,19 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(MUTATION_MAP_FIELD_DESC);
         {
           oprot.writeMapBegin(new TMap(TType.STRING, TType.MAP, this.mutation_map.size()));
-          for (Map.Entry<byte[], Map<String,List<Mutation>>> _iter70 : this.mutation_map.entrySet())
+          for (Map.Entry<byte[], Map<String,List<Mutation>>> _iter74 : this.mutation_map.entrySet())
           {
-            oprot.writeBinary(_iter70.getKey());
+            oprot.writeBinary(_iter74.getKey());
             {
-              oprot.writeMapBegin(new TMap(TType.STRING, TType.LIST, _iter70.getValue().size()));
-              for (Map.Entry<String, List<Mutation>> _iter71 : _iter70.getValue().entrySet())
+              oprot.writeMapBegin(new TMap(TType.STRING, TType.LIST, _iter74.getValue().size()));
+              for (Map.Entry<String, List<Mutation>> _iter75 : _iter74.getValue().entrySet())
               {
-                oprot.writeString(_iter71.getKey());
+                oprot.writeString(_iter75.getKey());
                 {
-                  oprot.writeListBegin(new TList(TType.STRUCT, _iter71.getValue().size()));
-                  for (Mutation _iter72 : _iter71.getValue())
+                  oprot.writeListBegin(new TList(TType.STRUCT, _iter75.getValue().size()));
+                  for (Mutation _iter76 : _iter75.getValue())
                   {
-                    _iter72.write(oprot);
+                    _iter76.write(oprot);
                   }
                   oprot.writeListEnd();
                 }
@@ -14546,25 +14546,25 @@ public void read(TProtocol iprot) throws TException {
           case 0: // SUCCESS
             if (field.type == TType.MAP) {
               {
-                TMap _map73 = iprot.readMapBegin();
-                this.success = new HashMap<String,List<String>>(2*_map73.size);
-                for (int _i74 = 0; _i74 < _map73.size; ++_i74)
+                TMap _map77 = iprot.readMapBegin();
+                this.success = new HashMap<String,List<String>>(2*_map77.size);
+                for (int _i78 = 0; _i78 < _map77.size; ++_i78)
                 {
-                  String _key75;
-                  List<String> _val76;
-                  _key75 = iprot.readString();
+                  String _key79;
+                  List<String> _val80;
+                  _key79 = iprot.readString();
                   {
-                    TList _list77 = iprot.readListBegin();
-                    _val76 = new ArrayList<String>(_list77.size);
-                    for (int _i78 = 0; _i78 < _list77.size; ++_i78)
+                    TList _list81 = iprot.readListBegin();
+                    _val80 = new ArrayList<String>(_list81.size);
+                    for (int _i82 = 0; _i82 < _list81.size; ++_i82)
                     {
-                      String _elem79;
-                      _elem79 = iprot.readString();
-                      _val76.add(_elem79);
+                      String _elem83;
+                      _elem83 = iprot.readString();
+                      _val80.add(_elem83);
                     }
                     iprot.readListEnd();
                   }
-                  this.success.put(_key75, _val76);
+                  this.success.put(_key79, _val80);
                 }
                 iprot.readMapEnd();
               }
@@ -14598,14 +14598,14 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
         {
           oprot.writeMapBegin(new TMap(TType.STRING, TType.LIST, this.success.size()));
-          for (Map.Entry<String, List<String>> _iter80 : this.success.entrySet())
+          for (Map.Entry<String, List<String>> _iter84 : this.success.entrySet())
           {
-            oprot.writeString(_iter80.getKey());
+            oprot.writeString(_iter84.getKey());
             {
-              oprot.writeListBegin(new TList(TType.STRING, _iter80.getValue().size()));
-              for (String _iter81 : _iter80.getValue())
+              oprot.writeListBegin(new TList(TType.STRING, _iter84.getValue().size()));
+              for (String _iter85 : _iter84.getValue())
               {
-                oprot.writeString(_iter81);
+                oprot.writeString(_iter85);
               }
               oprot.writeListEnd();
             }
@@ -15073,13 +15073,13 @@ public void read(TProtocol iprot) throws TException {
           case 0: // SUCCESS
             if (field.type == TType.SET) {
               {
-                TSet _set82 = iprot.readSetBegin();
-                this.success = new HashSet<String>(2*_set82.size);
-                for (int _i83 = 0; _i83 < _set82.size; ++_i83)
+                TSet _set86 = iprot.readSetBegin();
+                this.success = new HashSet<String>(2*_set86.size);
+                for (int _i87 = 0; _i87 < _set86.size; ++_i87)
                 {
-                  String _elem84;
-                  _elem84 = iprot.readString();
-                  this.success.add(_elem84);
+                  String _elem88;
+                  _elem88 = iprot.readString();
+                  this.success.add(_elem88);
                 }
                 iprot.readSetEnd();
               }
@@ -15105,9 +15105,9 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
         {
           oprot.writeSetBegin(new TSet(TType.STRING, this.success.size()));
-          for (String _iter85 : this.success)
+          for (String _iter89 : this.success)
           {
-            oprot.writeString(_iter85);
+            oprot.writeString(_iter89);
           }
           oprot.writeSetEnd();
         }
@@ -16679,14 +16679,14 @@ public void read(TProtocol iprot) throws TException {
           case 0: // SUCCESS
             if (field.type == TType.LIST) {
               {
-                TList _list86 = iprot.readListBegin();
-                this.success = new ArrayList<TokenRange>(_list86.size);
-                for (int _i87 = 0; _i87 < _list86.size; ++_i87)
+                TList _list90 = iprot.readListBegin();
+                this.success = new ArrayList<TokenRange>(_list90.size);
+                for (int _i91 = 0; _i91 < _list90.size; ++_i91)
                 {
-                  TokenRange _elem88;
-                  _elem88 = new TokenRange();
-                  _elem88.read(iprot);
-                  this.success.add(_elem88);
+                  TokenRange _elem92;
+                  _elem92 = new TokenRange();
+                  _elem92.read(iprot);
+                  this.success.add(_elem92);
                 }
                 iprot.readListEnd();
               }
@@ -16720,9 +16720,9 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
         {
           oprot.writeListBegin(new TList(TType.STRUCT, this.success.size()));
-          for (TokenRange _iter89 : this.success)
+          for (TokenRange _iter93 : this.success)
           {
-            _iter89.write(oprot);
+            _iter93.write(oprot);
           }
           oprot.writeListEnd();
         }
@@ -17355,27 +17355,27 @@ public void read(TProtocol iprot) throws TException {
           case 0: // SUCCESS
             if (field.type == TType.MAP) {
               {
-                TMap _map90 = iprot.readMapBegin();
-                this.success = new HashMap<String,Map<String,String>>(2*_map90.size);
-                for (int _i91 = 0; _i91 < _map90.size; ++_i91)
-                {
-                  String _key92;
-                  Map<String,String> _val93;
-                  _key92 = iprot.readString();
-                  {
                     TMap _map94 = iprot.readMapBegin();
-                    _val93 = new HashMap<String,String>(2*_map94.size);
+                this.success = new HashMap<String,Map<String,String>>(2*_map94.size);
                     for (int _i95 = 0; _i95 < _map94.size; ++_i95)
                     {
                       String _key96;
-                      String _val97;
+                  Map<String,String> _val97;
                       _key96 = iprot.readString();
-                      _val97 = iprot.readString();
-                      _val93.put(_key96, _val97);
+                  {
+                    TMap _map98 = iprot.readMapBegin();
+                    _val97 = new HashMap<String,String>(2*_map98.size);
+                    for (int _i99 = 0; _i99 < _map98.size; ++_i99)
+                    {
+                      String _key100;
+                      String _val101;
+                      _key100 = iprot.readString();
+                      _val101 = iprot.readString();
+                      _val97.put(_key100, _val101);
                     }
                     iprot.readMapEnd();
                   }
-                  this.success.put(_key92, _val93);
+                  this.success.put(_key96, _val97);
                 }
                 iprot.readMapEnd();
               }
@@ -17409,15 +17409,15 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
         {
           oprot.writeMapBegin(new TMap(TType.STRING, TType.MAP, this.success.size()));
-          for (Map.Entry<String, Map<String,String>> _iter98 : this.success.entrySet())
+          for (Map.Entry<String, Map<String,String>> _iter102 : this.success.entrySet())
           {
-            oprot.writeString(_iter98.getKey());
+            oprot.writeString(_iter102.getKey());
             {
-              oprot.writeMapBegin(new TMap(TType.STRING, TType.STRING, _iter98.getValue().size()));
-              for (Map.Entry<String, String> _iter99 : _iter98.getValue().entrySet())
+              oprot.writeMapBegin(new TMap(TType.STRING, TType.STRING, _iter102.getValue().size()));
+              for (Map.Entry<String, String> _iter103 : _iter102.getValue().entrySet())
               {
-                oprot.writeString(_iter99.getKey());
-                oprot.writeString(_iter99.getValue());
+                oprot.writeString(_iter103.getKey());
+                oprot.writeString(_iter103.getValue());
               }
               oprot.writeMapEnd();
             }
@@ -18349,13 +18349,13 @@ public void read(TProtocol iprot) throws TException {
           case 0: // SUCCESS
             if (field.type == TType.LIST) {
               {
-                TList _list100 = iprot.readListBegin();
-                this.success = new ArrayList<String>(_list100.size);
-                for (int _i101 = 0; _i101 < _list100.size; ++_i101)
+                TList _list104 = iprot.readListBegin();
+                this.success = new ArrayList<String>(_list104.size);
+                for (int _i105 = 0; _i105 < _list104.size; ++_i105)
                 {
-                  String _elem102;
-                  _elem102 = iprot.readString();
-                  this.success.add(_elem102);
+                  String _elem106;
+                  _elem106 = iprot.readString();
+                  this.success.add(_elem106);
                 }
                 iprot.readListEnd();
               }
@@ -18381,9 +18381,9 @@ public void write(TProtocol oprot) throws TException {
         oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
         {
           oprot.writeListBegin(new TList(TType.STRING, this.success.size()));
-          for (String _iter103 : this.success)
+          for (String _iter107 : this.success)
           {
-            oprot.writeString(_iter103);
+            oprot.writeString(_iter107);
           }
           oprot.writeListEnd();
         }
diff --git a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/CfDef.java b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/CfDef.java
index ec56b5fc..36c17ef5 100644
--- a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/CfDef.java
+++ b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/CfDef.java
@@ -59,6 +59,7 @@
   private static final TField PRELOAD_ROW_CACHE_FIELD_DESC = new TField("preload_row_cache", TType.BOOL, (short)10);
   private static final TField KEY_CACHE_SIZE_FIELD_DESC = new TField("key_cache_size", TType.DOUBLE, (short)11);
   private static final TField READ_REPAIR_CHANCE_FIELD_DESC = new TField("read_repair_chance", TType.DOUBLE, (short)12);
+  private static final TField COLUMN_METADATA_FIELD_DESC = new TField("column_metadata", TType.LIST, (short)13);
 
   public String table;
   public String name;
@@ -72,6 +73,7 @@
   public boolean preload_row_cache;
   public double key_cache_size;
   public double read_repair_chance;
+  public List<ColumnDef> column_metadata;
 
   /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
   public enum _Fields implements TFieldIdEnum {
@@ -86,7 +88,8 @@
     ROW_CACHE_SIZE((short)9, "row_cache_size"),
     PRELOAD_ROW_CACHE((short)10, "preload_row_cache"),
     KEY_CACHE_SIZE((short)11, "key_cache_size"),
-    READ_REPAIR_CHANCE((short)12, "read_repair_chance");
+    READ_REPAIR_CHANCE((short)12, "read_repair_chance"),
+    COLUMN_METADATA((short)13, "column_metadata");
 
     private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
     private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
@@ -171,6 +174,9 @@ public String getFieldName() {
         new FieldValueMetaData(TType.DOUBLE)));
     put(_Fields.READ_REPAIR_CHANCE, new FieldMetaData("read_repair_chance", TFieldRequirementType.OPTIONAL, 
         new FieldValueMetaData(TType.DOUBLE)));
+    put(_Fields.COLUMN_METADATA, new FieldMetaData("column_metadata", TFieldRequirementType.OPTIONAL, 
+        new ListMetaData(TType.LIST, 
+            new StructMetaData(TType.STRUCT, ColumnDef.class))));
   }});
 
   static {
@@ -243,6 +249,13 @@ public CfDef(CfDef other) {
     this.preload_row_cache = other.preload_row_cache;
     this.key_cache_size = other.key_cache_size;
     this.read_repair_chance = other.read_repair_chance;
+    if (other.isSetColumn_metadata()) {
+      List<ColumnDef> __this__column_metadata = new ArrayList<ColumnDef>();
+      for (ColumnDef other_element : other.column_metadata) {
+        __this__column_metadata.add(new ColumnDef(other_element));
+      }
+      this.column_metadata = __this__column_metadata;
+    }
   }
 
   public CfDef deepCopy() {
@@ -538,6 +551,45 @@ public void setRead_repair_chanceIsSet(boolean value) {
     __isset_bit_vector.set(__READ_REPAIR_CHANCE_ISSET_ID, value);
   }
 
+  public int getColumn_metadataSize() {
+    return (this.column_metadata == null) ? 0 : this.column_metadata.size();
+  }
+
+  public java.util.Iterator<ColumnDef> getColumn_metadataIterator() {
+    return (this.column_metadata == null) ? null : this.column_metadata.iterator();
+  }
+
+  public void addToColumn_metadata(ColumnDef elem) {
+    if (this.column_metadata == null) {
+      this.column_metadata = new ArrayList<ColumnDef>();
+    }
+    this.column_metadata.add(elem);
+  }
+
+  public List<ColumnDef> getColumn_metadata() {
+    return this.column_metadata;
+  }
+
+  public CfDef setColumn_metadata(List<ColumnDef> column_metadata) {
+    this.column_metadata = column_metadata;
+    return this;
+  }
+
+  public void unsetColumn_metadata() {
+    this.column_metadata = null;
+  }
+
+  /** Returns true if field column_metadata is set (has been asigned a value) and false otherwise */
+  public boolean isSetColumn_metadata() {
+    return this.column_metadata != null;
+  }
+
+  public void setColumn_metadataIsSet(boolean value) {
+    if (!value) {
+      this.column_metadata = null;
+    }
+  }
+
   public void setFieldValue(_Fields field, Object value) {
     switch (field) {
     case TABLE:
@@ -636,6 +688,14 @@ public void setFieldValue(_Fields field, Object value) {
       }
       break;
 
+    case COLUMN_METADATA:
+      if (value == null) {
+        unsetColumn_metadata();
+      } else {
+        setColumn_metadata((List<ColumnDef>)value);
+      }
+      break;
+
     }
   }
 
@@ -681,6 +741,9 @@ public Object getFieldValue(_Fields field) {
     case READ_REPAIR_CHANCE:
       return new Double(getRead_repair_chance());
 
+    case COLUMN_METADATA:
+      return getColumn_metadata();
+
     }
     throw new IllegalStateException();
   }
@@ -716,6 +779,8 @@ public boolean isSet(_Fields field) {
       return isSetKey_cache_size();
     case READ_REPAIR_CHANCE:
       return isSetRead_repair_chance();
+    case COLUMN_METADATA:
+      return isSetColumn_metadata();
     }
     throw new IllegalStateException();
   }
@@ -845,6 +910,15 @@ public boolean equals(CfDef that) {
         return false;
     }
 
+    boolean this_present_column_metadata = true && this.isSetColumn_metadata();
+    boolean that_present_column_metadata = true && that.isSetColumn_metadata();
+    if (this_present_column_metadata || that_present_column_metadata) {
+      if (!(this_present_column_metadata && that_present_column_metadata))
+        return false;
+      if (!this.column_metadata.equals(that.column_metadata))
+        return false;
+    }
+
     return true;
   }
 
@@ -969,6 +1043,15 @@ public int compareTo(CfDef other) {
         return lastComparison;
       }
     }
+    lastComparison = Boolean.valueOf(isSetColumn_metadata()).compareTo(typedOther.isSetColumn_metadata());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetColumn_metadata()) {      lastComparison = TBaseHelper.compareTo(column_metadata, typedOther.column_metadata);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
     return 0;
   }
 
@@ -1070,6 +1153,24 @@ public void read(TProtocol iprot) throws TException {
             TProtocolUtil.skip(iprot, field.type);
           }
           break;
+        case 13: // COLUMN_METADATA
+          if (field.type == TType.LIST) {
+            {
+              TList _list25 = iprot.readListBegin();
+              this.column_metadata = new ArrayList<ColumnDef>(_list25.size);
+              for (int _i26 = 0; _i26 < _list25.size; ++_i26)
+              {
+                ColumnDef _elem27;
+                _elem27 = new ColumnDef();
+                _elem27.read(iprot);
+                this.column_metadata.add(_elem27);
+              }
+              iprot.readListEnd();
+            }
+          } else { 
+            TProtocolUtil.skip(iprot, field.type);
+          }
+          break;
         default:
           TProtocolUtil.skip(iprot, field.type);
       }
@@ -1157,6 +1258,20 @@ public void write(TProtocol oprot) throws TException {
       oprot.writeDouble(this.read_repair_chance);
       oprot.writeFieldEnd();
     }
+    if (this.column_metadata != null) {
+      if (isSetColumn_metadata()) {
+        oprot.writeFieldBegin(COLUMN_METADATA_FIELD_DESC);
+        {
+          oprot.writeListBegin(new TList(TType.STRUCT, this.column_metadata.size()));
+          for (ColumnDef _iter28 : this.column_metadata)
+          {
+            _iter28.write(oprot);
+          }
+          oprot.writeListEnd();
+        }
+        oprot.writeFieldEnd();
+      }
+    }
     oprot.writeFieldStop();
     oprot.writeStructEnd();
   }
@@ -1265,6 +1380,16 @@ public String toString() {
       sb.append(this.read_repair_chance);
       first = false;
     }
+    if (isSetColumn_metadata()) {
+      if (!first) sb.append(", ");
+      sb.append("column_metadata:");
+      if (this.column_metadata == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.column_metadata);
+      }
+      first = false;
+    }
     sb.append(")");
     return sb.toString();
   }
diff --git a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/ColumnDef.java b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/ColumnDef.java
index e69de29b..0ad08b9e 100644
--- a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/ColumnDef.java
+++ b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/ColumnDef.java
@@ -0,0 +1,598 @@
+/**
+ * Autogenerated by Thrift
+ *
+ * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
+ */
+package org.apache.cassandra.thrift;
+/*
+ * 
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ * 
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ * 
+ */
+
+
+import java.util.List;
+import java.util.ArrayList;
+import java.util.Map;
+import java.util.HashMap;
+import java.util.EnumMap;
+import java.util.Set;
+import java.util.HashSet;
+import java.util.EnumSet;
+import java.util.Collections;
+import java.util.BitSet;
+import java.util.Arrays;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import org.apache.thrift.*;
+import org.apache.thrift.meta_data.*;
+import org.apache.thrift.protocol.*;
+
+public class ColumnDef implements TBase<ColumnDef._Fields>, java.io.Serializable, Cloneable, Comparable<ColumnDef> {
+  private static final TStruct STRUCT_DESC = new TStruct("ColumnDef");
+
+  private static final TField NAME_FIELD_DESC = new TField("name", TType.STRING, (short)1);
+  private static final TField VALIDATION_CLASS_FIELD_DESC = new TField("validation_class", TType.STRING, (short)2);
+  private static final TField INDEX_TYPE_FIELD_DESC = new TField("index_type", TType.STRING, (short)3);
+  private static final TField INDEX_NAME_FIELD_DESC = new TField("index_name", TType.STRING, (short)4);
+
+  public byte[] name;
+  public String validation_class;
+  public String index_type;
+  public String index_name;
+
+  /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
+  public enum _Fields implements TFieldIdEnum {
+    NAME((short)1, "name"),
+    VALIDATION_CLASS((short)2, "validation_class"),
+    INDEX_TYPE((short)3, "index_type"),
+    INDEX_NAME((short)4, "index_name");
+
+    private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
+    private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();
+
+    static {
+      for (_Fields field : EnumSet.allOf(_Fields.class)) {
+        byId.put((int)field._thriftId, field);
+        byName.put(field.getFieldName(), field);
+      }
+    }
+
+    /**
+     * Find the _Fields constant that matches fieldId, or null if its not found.
+     */
+    public static _Fields findByThriftId(int fieldId) {
+      return byId.get(fieldId);
+    }
+
+    /**
+     * Find the _Fields constant that matches fieldId, throwing an exception
+     * if it is not found.
+     */
+    public static _Fields findByThriftIdOrThrow(int fieldId) {
+      _Fields fields = findByThriftId(fieldId);
+      if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
+      return fields;
+    }
+
+    /**
+     * Find the _Fields constant that matches name, or null if its not found.
+     */
+    public static _Fields findByName(String name) {
+      return byName.get(name);
+    }
+
+    private final short _thriftId;
+    private final String _fieldName;
+
+    _Fields(short thriftId, String fieldName) {
+      _thriftId = thriftId;
+      _fieldName = fieldName;
+    }
+
+    public short getThriftFieldId() {
+      return _thriftId;
+    }
+
+    public String getFieldName() {
+      return _fieldName;
+    }
+  }
+
+  // isset id assignments
+
+  public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
+    put(_Fields.NAME, new FieldMetaData("name", TFieldRequirementType.REQUIRED, 
+        new FieldValueMetaData(TType.STRING)));
+    put(_Fields.VALIDATION_CLASS, new FieldMetaData("validation_class", TFieldRequirementType.REQUIRED, 
+        new FieldValueMetaData(TType.STRING)));
+    put(_Fields.INDEX_TYPE, new FieldMetaData("index_type", TFieldRequirementType.OPTIONAL, 
+        new FieldValueMetaData(TType.STRING)));
+    put(_Fields.INDEX_NAME, new FieldMetaData("index_name", TFieldRequirementType.OPTIONAL, 
+        new FieldValueMetaData(TType.STRING)));
+  }});
+
+  static {
+    FieldMetaData.addStructMetaDataMap(ColumnDef.class, metaDataMap);
+  }
+
+  public ColumnDef() {
+  }
+
+  public ColumnDef(
+    byte[] name,
+    String validation_class)
+  {
+    this();
+    this.name = name;
+    this.validation_class = validation_class;
+  }
+
+  /**
+   * Performs a deep copy on <i>other</i>.
+   */
+  public ColumnDef(ColumnDef other) {
+    if (other.isSetName()) {
+      this.name = new byte[other.name.length];
+      System.arraycopy(other.name, 0, name, 0, other.name.length);
+    }
+    if (other.isSetValidation_class()) {
+      this.validation_class = other.validation_class;
+    }
+    if (other.isSetIndex_type()) {
+      this.index_type = other.index_type;
+    }
+    if (other.isSetIndex_name()) {
+      this.index_name = other.index_name;
+    }
+  }
+
+  public ColumnDef deepCopy() {
+    return new ColumnDef(this);
+  }
+
+  @Deprecated
+  public ColumnDef clone() {
+    return new ColumnDef(this);
+  }
+
+  public byte[] getName() {
+    return this.name;
+  }
+
+  public ColumnDef setName(byte[] name) {
+    this.name = name;
+    return this;
+  }
+
+  public void unsetName() {
+    this.name = null;
+  }
+
+  /** Returns true if field name is set (has been asigned a value) and false otherwise */
+  public boolean isSetName() {
+    return this.name != null;
+  }
+
+  public void setNameIsSet(boolean value) {
+    if (!value) {
+      this.name = null;
+    }
+  }
+
+  public String getValidation_class() {
+    return this.validation_class;
+  }
+
+  public ColumnDef setValidation_class(String validation_class) {
+    this.validation_class = validation_class;
+    return this;
+  }
+
+  public void unsetValidation_class() {
+    this.validation_class = null;
+  }
+
+  /** Returns true if field validation_class is set (has been asigned a value) and false otherwise */
+  public boolean isSetValidation_class() {
+    return this.validation_class != null;
+  }
+
+  public void setValidation_classIsSet(boolean value) {
+    if (!value) {
+      this.validation_class = null;
+    }
+  }
+
+  public String getIndex_type() {
+    return this.index_type;
+  }
+
+  public ColumnDef setIndex_type(String index_type) {
+    this.index_type = index_type;
+    return this;
+  }
+
+  public void unsetIndex_type() {
+    this.index_type = null;
+  }
+
+  /** Returns true if field index_type is set (has been asigned a value) and false otherwise */
+  public boolean isSetIndex_type() {
+    return this.index_type != null;
+  }
+
+  public void setIndex_typeIsSet(boolean value) {
+    if (!value) {
+      this.index_type = null;
+    }
+  }
+
+  public String getIndex_name() {
+    return this.index_name;
+  }
+
+  public ColumnDef setIndex_name(String index_name) {
+    this.index_name = index_name;
+    return this;
+  }
+
+  public void unsetIndex_name() {
+    this.index_name = null;
+  }
+
+  /** Returns true if field index_name is set (has been asigned a value) and false otherwise */
+  public boolean isSetIndex_name() {
+    return this.index_name != null;
+  }
+
+  public void setIndex_nameIsSet(boolean value) {
+    if (!value) {
+      this.index_name = null;
+    }
+  }
+
+  public void setFieldValue(_Fields field, Object value) {
+    switch (field) {
+    case NAME:
+      if (value == null) {
+        unsetName();
+      } else {
+        setName((byte[])value);
+      }
+      break;
+
+    case VALIDATION_CLASS:
+      if (value == null) {
+        unsetValidation_class();
+      } else {
+        setValidation_class((String)value);
+      }
+      break;
+
+    case INDEX_TYPE:
+      if (value == null) {
+        unsetIndex_type();
+      } else {
+        setIndex_type((String)value);
+      }
+      break;
+
+    case INDEX_NAME:
+      if (value == null) {
+        unsetIndex_name();
+      } else {
+        setIndex_name((String)value);
+      }
+      break;
+
+    }
+  }
+
+  public void setFieldValue(int fieldID, Object value) {
+    setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
+  }
+
+  public Object getFieldValue(_Fields field) {
+    switch (field) {
+    case NAME:
+      return getName();
+
+    case VALIDATION_CLASS:
+      return getValidation_class();
+
+    case INDEX_TYPE:
+      return getIndex_type();
+
+    case INDEX_NAME:
+      return getIndex_name();
+
+    }
+    throw new IllegalStateException();
+  }
+
+  public Object getFieldValue(int fieldId) {
+    return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
+  }
+
+  /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
+  public boolean isSet(_Fields field) {
+    switch (field) {
+    case NAME:
+      return isSetName();
+    case VALIDATION_CLASS:
+      return isSetValidation_class();
+    case INDEX_TYPE:
+      return isSetIndex_type();
+    case INDEX_NAME:
+      return isSetIndex_name();
+    }
+    throw new IllegalStateException();
+  }
+
+  public boolean isSet(int fieldID) {
+    return isSet(_Fields.findByThriftIdOrThrow(fieldID));
+  }
+
+  @Override
+  public boolean equals(Object that) {
+    if (that == null)
+      return false;
+    if (that instanceof ColumnDef)
+      return this.equals((ColumnDef)that);
+    return false;
+  }
+
+  public boolean equals(ColumnDef that) {
+    if (that == null)
+      return false;
+
+    boolean this_present_name = true && this.isSetName();
+    boolean that_present_name = true && that.isSetName();
+    if (this_present_name || that_present_name) {
+      if (!(this_present_name && that_present_name))
+        return false;
+      if (!java.util.Arrays.equals(this.name, that.name))
+        return false;
+    }
+
+    boolean this_present_validation_class = true && this.isSetValidation_class();
+    boolean that_present_validation_class = true && that.isSetValidation_class();
+    if (this_present_validation_class || that_present_validation_class) {
+      if (!(this_present_validation_class && that_present_validation_class))
+        return false;
+      if (!this.validation_class.equals(that.validation_class))
+        return false;
+    }
+
+    boolean this_present_index_type = true && this.isSetIndex_type();
+    boolean that_present_index_type = true && that.isSetIndex_type();
+    if (this_present_index_type || that_present_index_type) {
+      if (!(this_present_index_type && that_present_index_type))
+        return false;
+      if (!this.index_type.equals(that.index_type))
+        return false;
+    }
+
+    boolean this_present_index_name = true && this.isSetIndex_name();
+    boolean that_present_index_name = true && that.isSetIndex_name();
+    if (this_present_index_name || that_present_index_name) {
+      if (!(this_present_index_name && that_present_index_name))
+        return false;
+      if (!this.index_name.equals(that.index_name))
+        return false;
+    }
+
+    return true;
+  }
+
+  @Override
+  public int hashCode() {
+    return 0;
+  }
+
+  public int compareTo(ColumnDef other) {
+    if (!getClass().equals(other.getClass())) {
+      return getClass().getName().compareTo(other.getClass().getName());
+    }
+
+    int lastComparison = 0;
+    ColumnDef typedOther = (ColumnDef)other;
+
+    lastComparison = Boolean.valueOf(isSetName()).compareTo(typedOther.isSetName());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetName()) {      lastComparison = TBaseHelper.compareTo(name, typedOther.name);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = Boolean.valueOf(isSetValidation_class()).compareTo(typedOther.isSetValidation_class());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetValidation_class()) {      lastComparison = TBaseHelper.compareTo(validation_class, typedOther.validation_class);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = Boolean.valueOf(isSetIndex_type()).compareTo(typedOther.isSetIndex_type());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetIndex_type()) {      lastComparison = TBaseHelper.compareTo(index_type, typedOther.index_type);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    lastComparison = Boolean.valueOf(isSetIndex_name()).compareTo(typedOther.isSetIndex_name());
+    if (lastComparison != 0) {
+      return lastComparison;
+    }
+    if (isSetIndex_name()) {      lastComparison = TBaseHelper.compareTo(index_name, typedOther.index_name);
+      if (lastComparison != 0) {
+        return lastComparison;
+      }
+    }
+    return 0;
+  }
+
+  public void read(TProtocol iprot) throws TException {
+    TField field;
+    iprot.readStructBegin();
+    while (true)
+    {
+      field = iprot.readFieldBegin();
+      if (field.type == TType.STOP) { 
+        break;
+      }
+      switch (field.id) {
+        case 1: // NAME
+          if (field.type == TType.STRING) {
+            this.name = iprot.readBinary();
+          } else { 
+            TProtocolUtil.skip(iprot, field.type);
+          }
+          break;
+        case 2: // VALIDATION_CLASS
+          if (field.type == TType.STRING) {
+            this.validation_class = iprot.readString();
+          } else { 
+            TProtocolUtil.skip(iprot, field.type);
+          }
+          break;
+        case 3: // INDEX_TYPE
+          if (field.type == TType.STRING) {
+            this.index_type = iprot.readString();
+          } else { 
+            TProtocolUtil.skip(iprot, field.type);
+          }
+          break;
+        case 4: // INDEX_NAME
+          if (field.type == TType.STRING) {
+            this.index_name = iprot.readString();
+          } else { 
+            TProtocolUtil.skip(iprot, field.type);
+          }
+          break;
+        default:
+          TProtocolUtil.skip(iprot, field.type);
+      }
+      iprot.readFieldEnd();
+    }
+    iprot.readStructEnd();
+
+    // check for required fields of primitive type, which can't be checked in the validate method
+    validate();
+  }
+
+  public void write(TProtocol oprot) throws TException {
+    validate();
+
+    oprot.writeStructBegin(STRUCT_DESC);
+    if (this.name != null) {
+      oprot.writeFieldBegin(NAME_FIELD_DESC);
+      oprot.writeBinary(this.name);
+      oprot.writeFieldEnd();
+    }
+    if (this.validation_class != null) {
+      oprot.writeFieldBegin(VALIDATION_CLASS_FIELD_DESC);
+      oprot.writeString(this.validation_class);
+      oprot.writeFieldEnd();
+    }
+    if (this.index_type != null) {
+      if (isSetIndex_type()) {
+        oprot.writeFieldBegin(INDEX_TYPE_FIELD_DESC);
+        oprot.writeString(this.index_type);
+        oprot.writeFieldEnd();
+      }
+    }
+    if (this.index_name != null) {
+      if (isSetIndex_name()) {
+        oprot.writeFieldBegin(INDEX_NAME_FIELD_DESC);
+        oprot.writeString(this.index_name);
+        oprot.writeFieldEnd();
+      }
+    }
+    oprot.writeFieldStop();
+    oprot.writeStructEnd();
+  }
+
+  @Override
+  public String toString() {
+    StringBuilder sb = new StringBuilder("ColumnDef(");
+    boolean first = true;
+
+    sb.append("name:");
+    if (this.name == null) {
+      sb.append("null");
+    } else {
+        int __name_size = Math.min(this.name.length, 128);
+        for (int i = 0; i < __name_size; i++) {
+          if (i != 0) sb.append(" ");
+          sb.append(Integer.toHexString(this.name[i]).length() > 1 ? Integer.toHexString(this.name[i]).substring(Integer.toHexString(this.name[i]).length() - 2).toUpperCase() : "0" + Integer.toHexString(this.name[i]).toUpperCase());
+        }
+        if (this.name.length > 128) sb.append(" ...");
+    }
+    first = false;
+    if (!first) sb.append(", ");
+    sb.append("validation_class:");
+    if (this.validation_class == null) {
+      sb.append("null");
+    } else {
+      sb.append(this.validation_class);
+    }
+    first = false;
+    if (isSetIndex_type()) {
+      if (!first) sb.append(", ");
+      sb.append("index_type:");
+      if (this.index_type == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.index_type);
+      }
+      first = false;
+    }
+    if (isSetIndex_name()) {
+      if (!first) sb.append(", ");
+      sb.append("index_name:");
+      if (this.index_name == null) {
+        sb.append("null");
+      } else {
+        sb.append(this.index_name);
+      }
+      first = false;
+    }
+    sb.append(")");
+    return sb.toString();
+  }
+
+  public void validate() throws TException {
+    // check for required fields
+    if (name == null) {
+      throw new TProtocolException("Required field 'name' was not present! Struct: " + toString());
+    }
+    if (validation_class == null) {
+      throw new TProtocolException("Required field 'validation_class' was not present! Struct: " + toString());
+    }
+  }
+
+}
+
diff --git a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/Constants.java b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/Constants.java
index a17fd47b..d1fde4c9 100644
--- a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/Constants.java
+++ b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/Constants.java
@@ -42,6 +42,6 @@
 
 public class Constants {
 
-  public static final String VERSION = "8.1.0";
+  public static final String VERSION = "8.2.0";
 
 }
diff --git a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/KsDef.java b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/KsDef.java
index 1882a1b6..65c7cde0 100644
--- a/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/KsDef.java
+++ b/cassandra/trunk/interface/thrift/gen-java/org/apache/cassandra/thrift/KsDef.java
@@ -514,14 +514,14 @@ public void read(TProtocol iprot) throws TException {
         case 5: // CF_DEFS
           if (field.type == TType.LIST) {
             {
-              TList _list25 = iprot.readListBegin();
-              this.cf_defs = new ArrayList<CfDef>(_list25.size);
-              for (int _i26 = 0; _i26 < _list25.size; ++_i26)
+              TList _list29 = iprot.readListBegin();
+              this.cf_defs = new ArrayList<CfDef>(_list29.size);
+              for (int _i30 = 0; _i30 < _list29.size; ++_i30)
               {
-                CfDef _elem27;
-                _elem27 = new CfDef();
-                _elem27.read(iprot);
-                this.cf_defs.add(_elem27);
+                CfDef _elem31;
+                _elem31 = new CfDef();
+                _elem31.read(iprot);
+                this.cf_defs.add(_elem31);
               }
               iprot.readListEnd();
             }
@@ -564,9 +564,9 @@ public void write(TProtocol oprot) throws TException {
       oprot.writeFieldBegin(CF_DEFS_FIELD_DESC);
       {
         oprot.writeListBegin(new TList(TType.STRUCT, this.cf_defs.size()));
-        for (CfDef _iter28 : this.cf_defs)
+        for (CfDef _iter32 : this.cf_defs)
         {
-          _iter28.write(oprot);
+          _iter32.write(oprot);
         }
         oprot.writeListEnd();
       }
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/avro/CassandraServer.java b/cassandra/trunk/src/java/org/apache/cassandra/avro/CassandraServer.java
index a3daf6bf..e81c7e08 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/avro/CassandraServer.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/avro/CassandraServer.java
@@ -42,6 +42,7 @@
 
 import org.apache.cassandra.concurrent.StageManager;
 import org.apache.cassandra.config.CFMetaData;
+import org.apache.cassandra.config.ColumnDefinition;
 import org.apache.cassandra.config.ConfigurationException;
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.KSMetaData;
@@ -54,6 +55,7 @@
 import org.apache.cassandra.locator.AbstractReplicationStrategy;
 import org.apache.cassandra.service.StorageProxy;
 import org.apache.cassandra.service.StorageService;
+import org.apache.cassandra.utils.ByteArrayKey;
 
 import static org.apache.cassandra.avro.AvroRecordFactory.*;
 import static org.apache.cassandra.avro.ErrorFactory.*;
@@ -596,7 +598,8 @@ public Void system_add_keyspace(KsDef ksDef) throws AvroRemoteException, Invalid
                         cfDef.row_cache_size == null ? CFMetaData.DEFAULT_ROW_CACHE_SIZE : cfDef.row_cache_size,
                         cfDef.preload_row_cache == null ? CFMetaData.DEFAULT_PRELOAD_ROW_CACHE : cfDef.preload_row_cache,
                         cfDef.key_cache_size == null ? CFMetaData.DEFAULT_KEY_CACHE_SIZE : cfDef.key_cache_size,
-                        cfDef.read_repair_chance == null ? CFMetaData.DEFAULT_READ_REPAIR_CHANCE : cfDef.read_repair_chance);
+                        cfDef.read_repair_chance == null ? CFMetaData.DEFAULT_READ_REPAIR_CHANCE : cfDef.read_repair_chance,
+                        Collections.<ByteArrayKey, ColumnDefinition>emptyMap());
                 cfDefs.add(cfmeta);
             }
             
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/config/CFMetaData.java b/cassandra/trunk/src/java/org/apache/cassandra/config/CFMetaData.java
index be114876..7044762d 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/config/CFMetaData.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/config/CFMetaData.java
@@ -24,24 +24,24 @@
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicInteger;
 
-import org.apache.cassandra.db.HintedHandOffManager;
-import org.apache.cassandra.db.SystemTable;
-import org.apache.cassandra.db.Table;
-import org.apache.cassandra.db.marshal.BytesType;
-import org.apache.cassandra.db.marshal.TimeUUIDType;
-import org.apache.cassandra.db.marshal.UTF8Type;
-import org.apache.cassandra.db.migration.Migration;
 import org.apache.commons.lang.builder.EqualsBuilder;
 import org.apache.commons.lang.builder.HashCodeBuilder;
 
-import org.apache.cassandra.db.ColumnFamilyType;
-import org.apache.cassandra.db.ClockType;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.collect.BiMap;
+import com.google.common.collect.HashBiMap;
+import org.apache.cassandra.db.*;
 import org.apache.cassandra.db.clock.AbstractReconciler;
 import org.apache.cassandra.db.clock.TimestampReconciler;
-import org.apache.cassandra.db.marshal.AbstractType;
+import org.apache.cassandra.db.marshal.*;
+import org.apache.cassandra.db.migration.Migration;
+import org.apache.cassandra.locator.DatacenterShardStrategy;
+import org.apache.cassandra.service.ColumnValidator;
+import org.apache.cassandra.utils.ByteArrayKey;
 import org.apache.cassandra.utils.Pair;
 
-import com.google.common.collect.*;
 
 public final class CFMetaData
 {
@@ -51,16 +51,18 @@
     public final static boolean DEFAULT_PRELOAD_ROW_CACHE = false;
     private static final int MIN_CF_ID = 1000;
 
+    private static final Logger logger = LoggerFactory.getLogger(DatacenterShardStrategy.class);
+
     private static final AtomicInteger idGen = new AtomicInteger(MIN_CF_ID);
     
     private static final Map<Integer, String> currentCfNames = new HashMap<Integer, String>();
     
     private static final BiMap<Pair<String, String>, Integer> cfIdMap = HashBiMap.<Pair<String, String>, Integer>create();
     
-    public static final CFMetaData StatusCf = new CFMetaData(Table.SYSTEM_TABLE, SystemTable.STATUS_CF, ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "persistent metadata for the local node", 0, false, 0.01, 0);
-    public static final CFMetaData HintsCf = new CFMetaData(Table.SYSTEM_TABLE, HintedHandOffManager.HINTS_CF, ColumnFamilyType.Super, ClockType.Timestamp, UTF8Type.instance, BytesType.instance, new TimestampReconciler(), "hinted handoff data", 0, false, 0.01, 1);
-    public static final CFMetaData MigrationsCf = new CFMetaData(Table.SYSTEM_TABLE, Migration.MIGRATIONS_CF, ColumnFamilyType.Standard, ClockType.Timestamp, TimeUUIDType.instance, null, new TimestampReconciler(), "individual schema mutations", 0, false, 0.01, 2);
-    public static final CFMetaData SchemaCf = new CFMetaData(Table.SYSTEM_TABLE, Migration.SCHEMA_CF, ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "current state of the schema", 0, false, 0.01, 3);
+    public static final CFMetaData StatusCf = new CFMetaData(Table.SYSTEM_TABLE, SystemTable.STATUS_CF, ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "persistent metadata for the local node", 0, false, 0.01, 0, Collections.<ByteArrayKey,ColumnDefinition>emptyMap());
+    public static final CFMetaData HintsCf = new CFMetaData(Table.SYSTEM_TABLE, HintedHandOffManager.HINTS_CF, ColumnFamilyType.Super, ClockType.Timestamp, UTF8Type.instance, BytesType.instance, new TimestampReconciler(), "hinted handoff data", 0, false, 0.01, 1, Collections.<ByteArrayKey, ColumnDefinition>emptyMap());
+    public static final CFMetaData MigrationsCf = new CFMetaData(Table.SYSTEM_TABLE, Migration.MIGRATIONS_CF, ColumnFamilyType.Standard, ClockType.Timestamp, TimeUUIDType.instance, null, new TimestampReconciler(), "individual schema mutations", 0, false, 0.01, 2, Collections.<ByteArrayKey, ColumnDefinition>emptyMap());
+    public static final CFMetaData SchemaCf = new CFMetaData(Table.SYSTEM_TABLE, Migration.SCHEMA_CF, ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "current state of the schema", 0, false, 0.01, 3, Collections. <ByteArrayKey, ColumnDefinition>emptyMap());
 
     /**
      * @return An immutable mapping of (ksname,cfname) to id.
@@ -115,9 +117,12 @@ public static final void fixMaxId()
     public final int cfId;
     public boolean preloadRowCache;
 
+    // BytesToken because byte[].hashCode|equals is inherited from Object.  gggrrr...
+    public final Map<ByteArrayKey, ColumnDefinition> column_metadata;
 
-    private CFMetaData(String tableName, String cfName, ColumnFamilyType cfType, ClockType clockType, AbstractType comparator, AbstractType subcolumnComparator, AbstractReconciler reconciler, String comment, double rowCacheSize, boolean preloadRowCache, double keyCacheSize, double readRepairChance, int cfId)
+    private CFMetaData(String tableName, String cfName, ColumnFamilyType cfType, ClockType clockType, AbstractType comparator, AbstractType subcolumnComparator, AbstractReconciler reconciler, String comment, double rowCacheSize, boolean preloadRowCache, double keyCacheSize, double readRepairChance, int cfId, Map<ByteArrayKey, ColumnDefinition> column_metadata)
     {
+        assert column_metadata != null;
         this.tableName = tableName;
         this.cfName = cfName;
         this.cfType = cfType;
@@ -133,6 +138,7 @@ private CFMetaData(String tableName, String cfName, ColumnFamilyType cfType, Clo
         this.keyCacheSize = keyCacheSize;
         this.readRepairChance = readRepairChance;
         this.cfId = cfId;        
+        this.column_metadata = Collections.unmodifiableMap(column_metadata);
     }
     
     /** adds this cfm to the map. */
@@ -148,22 +154,22 @@ public static void map(CFMetaData cfm) throws ConfigurationException
         }
     }
 
-    public CFMetaData(String tableName, String cfName, ColumnFamilyType cfType, ClockType clockType, AbstractType comparator, AbstractType subcolumnComparator, AbstractReconciler reconciler, String comment, double rowCacheSize, boolean preloadRowCache, double keyCacheSize, double readRepairChance)
+    public CFMetaData(String tableName, String cfName, ColumnFamilyType cfType, ClockType clockType, AbstractType comparator, AbstractType subcolumnComparator, AbstractReconciler reconciler, String comment, double rowCacheSize, boolean preloadRowCache, double keyCacheSize, double readRepairChance, Map<ByteArrayKey, ColumnDefinition> column_metadata)
     {
-        this(tableName, cfName, cfType, clockType, comparator, subcolumnComparator, reconciler, comment, rowCacheSize, preloadRowCache, keyCacheSize, readRepairChance, nextId());
+        this(tableName, cfName, cfType, clockType, comparator, subcolumnComparator, reconciler, comment, rowCacheSize, preloadRowCache, keyCacheSize, readRepairChance, nextId(), column_metadata);
     }
 
     /** clones an existing CFMetaData using the same id. */
     public static CFMetaData rename(CFMetaData cfm, String newName)
     {
-        CFMetaData newCfm = new CFMetaData(cfm.tableName, newName, cfm.cfType, cfm.clockType, cfm.comparator, cfm.subcolumnComparator, cfm.reconciler, cfm.comment, cfm.rowCacheSize, cfm.preloadRowCache, cfm.keyCacheSize, cfm.readRepairChance, cfm.cfId);
+        CFMetaData newCfm = new CFMetaData(cfm.tableName, newName, cfm.cfType, cfm.clockType, cfm.comparator, cfm.subcolumnComparator, cfm.reconciler, cfm.comment, cfm.rowCacheSize, cfm.preloadRowCache, cfm.keyCacheSize, cfm.readRepairChance, cfm.cfId, cfm.column_metadata);
         return newCfm;
     }
     
     /** clones existing CFMetaData. keeps the id but changes the table name.*/
     public static CFMetaData renameTable(CFMetaData cfm, String tableName)
     {
-        return new CFMetaData(tableName, cfm.cfName, cfm.cfType, cfm.clockType, cfm.comparator, cfm.subcolumnComparator, cfm.reconciler, cfm.comment, cfm.rowCacheSize, cfm.preloadRowCache, cfm.keyCacheSize, cfm.readRepairChance, cfm.cfId);
+        return new CFMetaData(tableName, cfm.cfName, cfm.cfType, cfm.clockType, cfm.comparator, cfm.subcolumnComparator, cfm.reconciler, cfm.comment, cfm.rowCacheSize, cfm.preloadRowCache, cfm.keyCacheSize, cfm.readRepairChance, cfm.cfId, cfm.column_metadata);
     }
     
     /** used for evicting cf data out of static tracking collections. */
@@ -203,6 +209,13 @@ public String pretty()
         dout.writeDouble(cfm.keyCacheSize);
         dout.writeDouble(cfm.readRepairChance);
         dout.writeInt(cfm.cfId);
+        dout.writeInt(cfm.column_metadata.size());
+        for (ColumnDefinition cd : cfm.column_metadata.values())
+        {
+            byte[] cdBytes = ColumnDefinition.serialize(cd);
+            dout.writeInt(cdBytes.length);
+            dout.write(cdBytes);
+        }
         dout.close();
         return bout.toByteArray();
     }
@@ -232,9 +245,19 @@ public static CFMetaData deserialize(InputStream in) throws IOException, Configu
         double keyCacheSize = din.readDouble();
         double readRepairChance = din.readDouble();
         int cfId = din.readInt();
-        return new CFMetaData(tableName, cfName, cfType, clockType, comparator, subcolumnComparator, reconciler, comment, rowCacheSize, preloadRowCache, keyCacheSize, readRepairChance, cfId);
+        int columnMetadataSize = din.readInt();
+        Map<ByteArrayKey, ColumnDefinition> column_metadata = new HashMap<ByteArrayKey, ColumnDefinition>(columnMetadataSize);
+        while (columnMetadataSize > 0)
+        {
+            int cdSize = din.readInt();
+            byte[] cdBytes = new byte[cdSize];
+            if (in.read(cdBytes) != cdSize)
+                throw new IOException("short read of ColumnDefinition");
+            ColumnDefinition cd = ColumnDefinition.deserialize(cdBytes);
+            column_metadata.put(new ByteArrayKey(cd.name), cd);
+        }
+        return new CFMetaData(tableName, cfName, cfType, clockType, comparator, subcolumnComparator, reconciler, comment, rowCacheSize, preloadRowCache, keyCacheSize, readRepairChance, cfId, column_metadata);
     }
-    
 
     public boolean equals(Object obj) 
     {
@@ -261,6 +284,7 @@ else if (obj == null || obj.getClass() != getClass())
             .append(keyCacheSize, rhs.keyCacheSize)
             .append(readRepairChance, rhs.readRepairChance)
             .append(cfId, rhs.cfId)
+            .append(column_metadata, rhs.column_metadata)
             .isEquals();
     }
 
@@ -279,6 +303,7 @@ public int hashCode()
             .append(keyCacheSize)
             .append(readRepairChance)
             .append(cfId)
+            .append(column_metadata)
             .toHashCode();
     }
 
@@ -286,4 +311,35 @@ private static int nextId()
     {
         return idGen.getAndIncrement();
     }
+
+    public ColumnValidator getColumnValidator(byte[] column)
+    {
+        ColumnValidator validator = null;
+        ColumnDefinition columnDefinition = column_metadata.get(new ByteArrayKey(column));
+
+        if (columnDefinition != null)
+        {
+            String className = columnDefinition.validation_class;
+            if (className != null && className.trim().length() > 0)
+            {
+                try
+                {
+                    validator = (ColumnValidator) Class.forName(className).newInstance();
+                }
+                catch (ClassNotFoundException cnfe)
+                {
+                    throw new MarshalException("could not find validation class + " + className, cnfe);
+                }
+                catch (InstantiationException ie)
+                {
+                    throw new MarshalException("could not instantiate validation class " + className, ie);
+                }
+                catch (IllegalAccessException iae)
+                {
+                    throw new MarshalException("IllegalAccessException instantiating validation class " + className, iae);
+                }
+            }
+        }
+        return validator;
+    }
 }
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/config/ColumnDefinition.java b/cassandra/trunk/src/java/org/apache/cassandra/config/ColumnDefinition.java
index e69de29b..79fe7506 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/config/ColumnDefinition.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/config/ColumnDefinition.java
@@ -0,0 +1,141 @@
+package org.apache.cassandra.config;
+
+import java.io.*;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import org.apache.commons.lang.builder.EqualsBuilder;
+import org.apache.commons.lang.builder.HashCodeBuilder;
+
+import org.apache.cassandra.thrift.ColumnDef;
+import org.apache.cassandra.utils.ByteArrayKey;
+
+public class ColumnDefinition {
+    public byte[] name;
+    public String validation_class;
+    public String index_type;
+    public String index_name;
+
+    public ColumnDefinition()
+    {
+        this(null, null, null, null);
+    }
+
+    public ColumnDefinition(byte[] name, String validation_class, String index_type, String index_name)
+    {
+        this.name = name;
+        this.validation_class = validation_class;
+        this.index_type = index_type;
+        this.index_name = index_name;
+    }
+
+    @Override
+    public int hashCode()
+    {
+        return new HashCodeBuilder()
+                .append(name)
+                .append(validation_class)
+                .append(index_type)
+                .append(index_name)
+                .toHashCode();
+    }
+
+    @Override
+    public boolean equals(Object obj)
+    {
+        if (obj == this)
+        {
+            return true;
+        }
+        else if (obj == null || obj.getClass() != getClass())
+        {
+            return false;
+        }
+
+        ColumnDefinition rhs = (ColumnDefinition) obj;
+        return new EqualsBuilder()
+                .append(name, rhs.name)
+                .append(validation_class, rhs.validation_class)
+                .append(index_name, rhs.index_name)
+                .append(index_type, rhs.index_type)
+                .isEquals();
+    }
+
+    public static byte[] serialize(ColumnDefinition cd) throws IOException
+    {
+        ByteArrayOutputStream bout = new ByteArrayOutputStream();
+        DataOutputStream out = new DataOutputStream(bout);
+        out.writeInt(cd.name.length);
+        out.write(cd.name);
+
+        out.writeBoolean(cd.validation_class != null);
+        if (cd.validation_class != null)
+        {
+            out.writeUTF(cd.validation_class);
+        }
+
+        out.writeBoolean(cd.index_type != null);
+        if (cd.index_type != null)
+        {
+            out.writeUTF(cd.index_type);
+        }
+
+        out.writeBoolean(cd.index_name != null);
+        if (cd.index_name != null)
+        {
+            out.writeUTF(cd.index_name);
+        }
+
+        out.close();
+        return bout.toByteArray();
+    }
+
+    public static ColumnDefinition deserialize(byte[] bytes) throws IOException
+    {
+        ColumnDefinition cd = new ColumnDefinition();
+        DataInputStream in = new DataInputStream(new ByteArrayInputStream(bytes));
+        int nameSize = in.readInt();
+        cd.name = new byte[nameSize];
+        if (in.read(cd.name, 0, nameSize) != nameSize)
+            throw new IOException("short read of ColumnDefinition name");
+
+        if (in.readBoolean())
+            cd.validation_class = in.readUTF();
+
+        if (in.readBoolean())
+            cd.index_type = in.readUTF();
+
+        if (in.readBoolean())
+            cd.index_name = in.readUTF();
+
+        return cd;
+    }
+
+    public static ColumnDefinition fromColumnDef(ColumnDef thriftColumnDef)
+    {
+        assert thriftColumnDef != null;
+        ColumnDefinition cd = new ColumnDefinition();
+        cd.name = thriftColumnDef.name;
+        cd.validation_class = thriftColumnDef.validation_class;
+        cd.index_type = thriftColumnDef.index_type;
+        cd.index_name = thriftColumnDef.index_name;
+        return cd;
+    }
+
+    public static Map<ByteArrayKey, ColumnDefinition> fromColumnDef(List<ColumnDef> thriftDefs)
+    {
+        if (thriftDefs == null)
+            return Collections.<ByteArrayKey, ColumnDefinition>emptyMap();
+
+        //where are my simple map/reduce/lambda constructs!? gggrrr...
+        Map<ByteArrayKey, ColumnDefinition> cds = new HashMap<ByteArrayKey, ColumnDefinition>();
+        for (ColumnDef thriftColumnDef : thriftDefs)
+        {
+            cds.put(new ByteArrayKey(thriftColumnDef.name), fromColumnDef(thriftColumnDef));
+        }
+
+        return Collections.<ByteArrayKey, ColumnDefinition>unmodifiableMap(cds);
+    }
+}
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/config/ColumnFamily.java b/cassandra/trunk/src/java/org/apache/cassandra/config/ColumnFamily.java
index 6d5115d7..dd8eca18 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/config/ColumnFamily.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/config/ColumnFamily.java
@@ -1,7 +1,11 @@
 package org.apache.cassandra.config;
 
+import java.util.Collections;
+import java.util.Map;
+
 import org.apache.cassandra.db.ClockType;
 import org.apache.cassandra.db.ColumnFamilyType;
+import org.apache.cassandra.utils.ByteArrayKey;
 
 public class ColumnFamily {
     public String name;            
@@ -15,4 +19,5 @@
     public double keys_cached = CFMetaData.DEFAULT_KEY_CACHE_SIZE; 
     public double read_repair_chance = CFMetaData.DEFAULT_READ_REPAIR_CHANCE;
     public boolean preload_row_cache = CFMetaData.DEFAULT_PRELOAD_ROW_CACHE;
+    public Map<ByteArrayKey, ColumnDefinition> column_metata = Collections.<ByteArrayKey, ColumnDefinition>emptyMap();
 }
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java b/cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
index 05f9d769..06296d3e 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
@@ -18,9 +18,24 @@
 
 package org.apache.cassandra.config;
 
+import java.io.*;
+import java.lang.reflect.Constructor;
+import java.lang.reflect.Field;
+import java.lang.reflect.InvocationTargetException;
+import java.net.InetAddress;
+import java.net.URL;
+import java.net.UnknownHostException;
+import java.util.*;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import org.apache.cassandra.auth.AllowAllAuthenticator;
 import org.apache.cassandra.auth.IAuthenticator;
-import org.apache.cassandra.db.*;
+import org.apache.cassandra.db.ClockType;
+import org.apache.cassandra.db.ColumnFamilyType;
+import org.apache.cassandra.db.DefsTable;
+import org.apache.cassandra.db.Table;
 import org.apache.cassandra.db.clock.AbstractReconciler;
 import org.apache.cassandra.db.clock.TimestampReconciler;
 import org.apache.cassandra.db.commitlog.CommitLog;
@@ -28,34 +43,18 @@
 import org.apache.cassandra.db.marshal.BytesType;
 import org.apache.cassandra.db.migration.Migration;
 import org.apache.cassandra.dht.IPartitioner;
-import org.apache.cassandra.locator.AbstractReplicationStrategy;
 import org.apache.cassandra.io.util.FileUtils;
+import org.apache.cassandra.locator.AbstractReplicationStrategy;
+import org.apache.cassandra.locator.IEndpointSnitch;
+import org.apache.cassandra.service.ColumnValidator;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.FBUtilities;
 import org.apache.cassandra.utils.Pair;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.apache.cassandra.locator.IEndpointSnitch;
-
 import org.yaml.snakeyaml.Loader;
 import org.yaml.snakeyaml.TypeDescription;
 import org.yaml.snakeyaml.Yaml;
 import org.yaml.snakeyaml.error.YAMLException;
 
-import java.io.File;
-import java.io.FileFilter;
-import java.io.FileInputStream;
-import java.io.IOError;
-import java.io.IOException;
-import java.io.InputStream;
-import java.lang.reflect.Constructor;
-import java.lang.reflect.Field;
-import java.lang.reflect.InvocationTargetException;
-import java.util.*;
-import java.net.InetAddress;
-import java.net.UnknownHostException;
-import java.net.URL;
-
 public class DatabaseDescriptor
 {
     private static Logger logger = LoggerFactory.getLogger(DatabaseDescriptor.class);
@@ -538,7 +537,7 @@ else if (cf.compare_subcolumns_with != null)
                 {                        
                     throw new ConfigurationException("read_repair_chance must be between 0.0 and 1.0");
                 }
-                cfDefs[j++] = new CFMetaData(keyspace.name, cf.name, cfType, cf.clock_type, comparator, subcolumnComparator, reconciler, cf.comment, cf.rows_cached, cf.preload_row_cache, cf.keys_cached, cf.read_repair_chance);
+                cfDefs[j++] = new CFMetaData(keyspace.name, cf.name, cfType, cf.clock_type, comparator, subcolumnComparator, reconciler, cf.comment, cf.rows_cached, cf.preload_row_cache, cf.keys_cached, cf.read_repair_chance, cf.column_metata);
             }
             defs.add(new KSMetaData(keyspace.name, strategyClass, keyspace.replication_factor, cfDefs));
             
@@ -1081,4 +1080,9 @@ public static boolean hintedHandoffEnabled()
     {
         return conf.hinted_handoff_enabled;
     }
+
+    public static ColumnValidator getColumnValidator(String keyspace, String cf, byte[] column)
+    {
+        return getCFMetaData(keyspace, cf).getColumnValidator(column);
+    }
 }
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/db/marshal/MarshalException.java b/cassandra/trunk/src/java/org/apache/cassandra/db/marshal/MarshalException.java
index e7c7a199..279f45d2 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/db/marshal/MarshalException.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/db/marshal/MarshalException.java
@@ -27,4 +27,9 @@ public MarshalException(String message)
     {
         super(message);
     }
+
+    public MarshalException(String message, Throwable cause)
+    {
+        super(message, cause);
+    }
 }
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/service/ColumnValidator.java b/cassandra/trunk/src/java/org/apache/cassandra/service/ColumnValidator.java
index e69de29b..a19f25f0 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/service/ColumnValidator.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/service/ColumnValidator.java
@@ -0,0 +1,9 @@
+package org.apache.cassandra.service;
+
+import org.apache.cassandra.thrift.Column;
+import org.apache.cassandra.thrift.ColumnParent;
+
+public interface ColumnValidator
+{
+    public void validate(String keyspace, ColumnParent column_parent, Column column);
+}
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/service/ExampleColumnValidator.java b/cassandra/trunk/src/java/org/apache/cassandra/service/ExampleColumnValidator.java
index e69de29b..df6a93da 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/service/ExampleColumnValidator.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/service/ExampleColumnValidator.java
@@ -0,0 +1,15 @@
+package org.apache.cassandra.service;
+
+import org.apache.cassandra.db.marshal.MarshalException;
+import org.apache.cassandra.thrift.Column;
+import org.apache.cassandra.thrift.ColumnParent;
+
+public class ExampleColumnValidator implements ColumnValidator
+{
+    @Override
+    public void validate(String keyspace, ColumnParent column_parent, Column column)
+    {
+        if (column.value.length % 2 == 0)
+            throw new MarshalException("column.value.length is even");
+    }
+}
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/thrift/CassandraServer.java b/cassandra/trunk/src/java/org/apache/cassandra/thrift/CassandraServer.java
index 91e62880..4d1dbef8 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/thrift/CassandraServer.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/thrift/CassandraServer.java
@@ -22,32 +22,21 @@
 import java.util.*;
 import java.util.concurrent.TimeoutException;
 
-import org.apache.cassandra.auth.AllowAllAuthenticator;
-import org.apache.cassandra.concurrent.StageManager;
-import org.apache.cassandra.config.ConfigurationException;
-import org.apache.cassandra.config.KSMetaData;
-import org.apache.cassandra.db.migration.AddColumnFamily;
-import org.apache.cassandra.db.migration.AddKeyspace;
-import org.apache.cassandra.db.migration.DropColumnFamily;
-import org.apache.cassandra.db.migration.DropKeyspace;
-import org.apache.cassandra.db.migration.RenameColumnFamily;
-import org.apache.cassandra.db.migration.RenameKeyspace;
-import org.apache.cassandra.locator.AbstractReplicationStrategy;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import org.apache.cassandra.config.CFMetaData;
-import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.auth.AllowAllAuthenticator;
+import org.apache.cassandra.concurrent.StageManager;
+import org.apache.cassandra.config.*;
 import org.apache.cassandra.db.*;
+import org.apache.cassandra.db.ColumnFamily;
 import org.apache.cassandra.db.clock.AbstractReconciler;
 import org.apache.cassandra.db.clock.TimestampReconciler;
 import org.apache.cassandra.db.filter.QueryPath;
 import org.apache.cassandra.db.marshal.MarshalException;
-import org.apache.cassandra.dht.AbstractBounds;
-import org.apache.cassandra.dht.Bounds;
-import org.apache.cassandra.dht.IPartitioner;
-import org.apache.cassandra.dht.Range;
-import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.db.migration.*;
+import org.apache.cassandra.dht.*;
+import org.apache.cassandra.locator.AbstractReplicationStrategy;
 import org.apache.cassandra.service.StorageProxy;
 import org.apache.cassandra.service.StorageService;
 import org.apache.thrift.TException;
@@ -858,7 +847,8 @@ private CFMetaData convertToCFMetaData(CfDef cf_def) throws InvalidRequestExcept
                     cf_def.row_cache_size,
                     cf_def.preload_row_cache,
                     cf_def.key_cache_size,
-                    cf_def.read_repair_chance);
+                    cf_def.read_repair_chance,
+                    ColumnDefinition.fromColumnDef(cf_def.column_metadata));
     }
 
     public void truncate(String cfname) throws InvalidRequestException, UnavailableException, TException
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/thrift/ThriftValidation.java b/cassandra/trunk/src/java/org/apache/cassandra/thrift/ThriftValidation.java
index 301a27b1..3a51b168 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/thrift/ThriftValidation.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/thrift/ThriftValidation.java
@@ -20,28 +20,28 @@
  * 
  */
 
-import java.util.Comparator;
 import java.util.Arrays;
-import org.apache.commons.lang.ArrayUtils;
-
-import org.apache.cassandra.db.KeyspaceNotDefinedException;
-import org.apache.cassandra.db.ColumnFamily;
-import org.apache.cassandra.db.IColumn;
-import org.apache.cassandra.db.ColumnFamilyType;
-import org.apache.cassandra.db.IClock;
-import org.apache.cassandra.db.TimestampClock;
-import org.apache.cassandra.db.marshal.AbstractType;
-import org.apache.cassandra.db.marshal.MarshalException;
+import java.util.Comparator;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.db.*;
+import org.apache.cassandra.db.marshal.AbstractType;
+import org.apache.cassandra.db.marshal.MarshalException;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.RandomPartitioner;
 import org.apache.cassandra.dht.Token;
+import org.apache.cassandra.locator.DatacenterShardStrategy;
+import org.apache.cassandra.service.ColumnValidator;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.FBUtilities;
 
 public class ThriftValidation
 {
+    private static final Logger logger = LoggerFactory.getLogger(DatacenterShardStrategy.class);
+
     static void validateKey(byte[] key) throws InvalidRequestException
     {
         if (key == null || key.length == 0)
@@ -302,10 +302,31 @@ public static void validateSlicePredicate(String keyspace, String cfName, byte[]
             validateColumns(keyspace, cfName, scName, predicate.column_names);
     }
 
+    public static void runExternalColumnVerifier(String keyspace, ColumnParent column_parent, Column column) throws InvalidRequestException
+    {
+        try
+        {
+            ColumnValidator validator = null;
+            validator = DatabaseDescriptor.getColumnValidator(keyspace, column_parent.column_family, column.name);
+            if (validator != null)
+                validator.validate(keyspace, column_parent, column);
+        }
+        catch (MarshalException me)
+        {
+            String msg = String.format("[%s][%s][md5(byte[])=%s] = [md5(byte[])=%s] failed validation (%s)",
+                    keyspace, column_parent.getColumn_family(),
+                    FBUtilities.hexHash("MD5", column.name),
+                    FBUtilities.hexHash("MD5", column.value),
+                    me.getMessage());
+            throw new InvalidRequestException(msg); //why doesn't IRE except a caused_by argument?
+        }
+    }
+
     public static void validateColumn(String keyspace, ColumnParent column_parent, Column column) throws InvalidRequestException
     {
         validateTtl(column);
         validateColumns(keyspace, column_parent, Arrays.asList(column.name));
+        runExternalColumnVerifier(keyspace, column_parent, column);
     }
 
     public static void validatePredicate(String keyspace, ColumnParent column_parent, SlicePredicate predicate)
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/utils/ByteArrayKey.java b/cassandra/trunk/src/java/org/apache/cassandra/utils/ByteArrayKey.java
index e69de29b..069fc9c0 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/utils/ByteArrayKey.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/utils/ByteArrayKey.java
@@ -0,0 +1,38 @@
+package org.apache.cassandra.utils;
+
+import java.util.Arrays;
+
+/**
+ * A wrapper class for making a byte[] suitable for use as keys (i.e. hashCode/equals)
+ */
+public class ByteArrayKey
+{
+    private final byte[] bytes;
+
+    public ByteArrayKey(byte[] bytes)
+    {
+        this.bytes = bytes;
+    }
+
+    @Override
+    public int hashCode()
+    {
+        return Arrays.hashCode(this.bytes);
+    }
+
+    @Override
+    public boolean equals(Object obj)
+    {
+        if (obj == this)
+        {
+            return true;
+        }
+        else if (obj == null || obj.getClass() != getClass())
+        {
+            return false;
+        }
+
+        return Arrays.equals(this.bytes, ((ByteArrayKey) obj).bytes);
+    }
+}
+
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java b/cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java
index 73d9c3e9..218d1b7e 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java
@@ -229,6 +229,11 @@ public static BigInteger md5hash(byte[] data)
         return hash.abs();        
     }
 
+    public static String hexHash(String type, byte[]... data)
+    {
+        return bytesToHex(hash(type, data));
+    }
+
     public static byte[] hash(String type, byte[]... data)
     {
     	byte[] result;
diff --git a/cassandra/trunk/test/unit/org/apache/cassandra/db/DefsTest.java b/cassandra/trunk/test/unit/org/apache/cassandra/db/DefsTest.java
index d26ef4e6..74886640 100644
--- a/cassandra/trunk/test/unit/org/apache/cassandra/db/DefsTest.java
+++ b/cassandra/trunk/test/unit/org/apache/cassandra/db/DefsTest.java
@@ -17,45 +17,32 @@
  */
 
 package org.apache.cassandra.db;
+import org.apache.cassandra.utils.ByteArrayKey;
+
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.util.*;
+import java.util.concurrent.ExecutionException;
+
+import org.junit.Test;
 
 import org.apache.cassandra.CleanupHelper;
 import org.apache.cassandra.Util;
-
-import org.apache.cassandra.config.CFMetaData;
-import org.apache.cassandra.config.ConfigurationException;
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.config.KSMetaData;
+import org.apache.cassandra.config.*;
 import org.apache.cassandra.db.clock.TimestampReconciler;
 import org.apache.cassandra.db.filter.QueryFilter;
 import org.apache.cassandra.db.filter.QueryPath;
 import org.apache.cassandra.db.marshal.BytesType;
-import org.apache.cassandra.db.migration.AddColumnFamily;
-import org.apache.cassandra.db.migration.AddKeyspace;
-import org.apache.cassandra.db.migration.DropColumnFamily;
-import org.apache.cassandra.db.migration.DropKeyspace;
-import org.apache.cassandra.db.migration.Migration;
-import org.apache.cassandra.db.migration.RenameColumnFamily;
-import org.apache.cassandra.db.migration.RenameKeyspace;
+import org.apache.cassandra.db.marshal.UTF8Type;
+import org.apache.cassandra.db.migration.*;
+import org.apache.cassandra.dht.BytesToken;
 import org.apache.cassandra.locator.RackUnawareStrategy;
+import org.apache.cassandra.utils.ByteArrayKey;
 import org.apache.cassandra.utils.FBUtilities;
-import org.apache.cassandra.db.marshal.UTF8Type;
 import org.apache.cassandra.utils.UUIDGen;
 
-import org.junit.Test;
-
-import java.io.ByteArrayInputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.List;
-import java.util.SortedSet;
-import java.util.TreeSet;
-import java.util.UUID;
-import java.util.concurrent.ExecutionException;
-
 public class DefsTest extends CleanupHelper
 {   
     @Test
@@ -78,7 +65,7 @@ public void saveAndRestore() throws IOException
     @Test
     public void addNewCfToBogusTable() throws InterruptedException
     {
-        CFMetaData newCf = new CFMetaData("MadeUpKeyspace", "NewCF", ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "new cf", 0, false, 1.0, 0);
+        CFMetaData newCf = new CFMetaData("MadeUpKeyspace", "NewCF", ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "new cf", 0, false, 1.0, 0, Collections.<ByteArrayKey, ColumnDefinition>emptyMap());
         try
         {
             new AddColumnFamily(newCf).apply();
@@ -103,7 +90,7 @@ public void testMigrations() throws IOException, ConfigurationException
         assert DatabaseDescriptor.getDefsVersion().equals(prior);
         
         // add a cf.
-        CFMetaData newCf1 = new CFMetaData("Keyspace1", "MigrationCf_1", ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "Migration CF ", 0, false, 1.0, 0);
+        CFMetaData newCf1 = new CFMetaData("Keyspace1", "MigrationCf_1", ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "Migration CF ", 0, false, 1.0, 0, Collections.<ByteArrayKey, ColumnDefinition>emptyMap());
         Migration m1 = new AddColumnFamily(newCf1);
         m1.apply();
         UUID ver1 = m1.getVersion();
@@ -162,7 +149,7 @@ public void addNewCF() throws ConfigurationException, IOException, ExecutionExce
         final String cf = "BrandNewCf";
         KSMetaData original = DatabaseDescriptor.getTableDefinition(ks);
 
-        CFMetaData newCf = new CFMetaData(original.name, cf, ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "A New Column Family", 0, false, 1.0, 0);
+        CFMetaData newCf = new CFMetaData(original.name, cf, ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "A New Column Family", 0, false, 1.0, 0, Collections.<ByteArrayKey, ColumnDefinition>emptyMap());
         assert !DatabaseDescriptor.getTableDefinition(ks).cfMetaData().containsKey(newCf.cfName);
         new AddColumnFamily(newCf).apply();
 
@@ -184,6 +171,43 @@ public void addNewCF() throws ConfigurationException, IOException, ExecutionExce
         assert Arrays.equals("value0".getBytes(), col.value());
     }
 
+    @Test
+    public void testCanAddColumnDefinitionsInColumnMetaData() throws Exception
+    {
+        String ks = "Keyspace1";
+        String cf = "ValidatorColumnFamily";
+        KSMetaData original = DatabaseDescriptor.getTableDefinition(ks);
+
+        Map<ByteArrayKey, ColumnDefinition> column_metadata = new HashMap<ByteArrayKey, ColumnDefinition>();
+
+        ColumnDefinition cd0 = new ColumnDefinition();
+        cd0.name = "TestColumn1".getBytes("UTF8");
+        cd0.validation_class = "random class one";
+        cd0.index_name = null;
+        cd0.index_type = null;
+
+        ColumnDefinition cd1 = new ColumnDefinition();
+        cd1.name = "*".getBytes("UTF8");
+        cd1.validation_class = "random class two";
+        cd1.index_name = "some name";
+        cd1.index_type = "some type";
+
+        column_metadata.put(new ByteArrayKey(cd0.name), cd0);
+        column_metadata.put(new ByteArrayKey(cd1.name), cd1);
+
+        CFMetaData newCf = new CFMetaData(original.name, cf, ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "A New Column Family", 0, false, 1.0, 0, column_metadata);
+        assert !DatabaseDescriptor.getTableDefinition(ks).cfMetaData().containsKey(newCf.cfName);
+        new AddColumnFamily(newCf).apply();
+
+        assert DatabaseDescriptor.getTableDefinition(ks).cfMetaData().containsKey(newCf.cfName);
+        assert DatabaseDescriptor.getTableDefinition(ks).cfMetaData().get(newCf.cfName).equals(newCf);
+
+        ColumnFamilyStore store = Table.open(ks).getColumnFamilyStore(cf);
+        assert store != null;
+        store.forceBlockingFlush();
+    }
+
+
     @Test
     public void dropCf() throws ConfigurationException, IOException, ExecutionException, InterruptedException
     {
@@ -276,7 +300,7 @@ public void renameCf() throws ConfigurationException, IOException, ExecutionExce
     public void addNewKS() throws ConfigurationException, IOException, ExecutionException, InterruptedException
     {
         DecoratedKey dk = Util.dk("key0");
-        CFMetaData newCf = new CFMetaData("NewKeyspace1", "AddedStandard1", ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "A new cf for a new ks", 0, false, 1.0, 0);
+        CFMetaData newCf = new CFMetaData("NewKeyspace1", "AddedStandard1", ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "A new cf for a new ks", 0, false, 1.0, 0, Collections.<ByteArrayKey, ColumnDefinition>emptyMap());
         KSMetaData newKs = new KSMetaData(newCf.tableName, RackUnawareStrategy.class, 5, newCf);
         
         new AddKeyspace(newKs).apply();
@@ -432,7 +456,7 @@ public void createEmptyKsAddNewCf() throws ConfigurationException, IOException,
         new AddKeyspace(newKs).apply();
         assert DatabaseDescriptor.getTableDefinition("EmptyKeyspace") != null;
 
-        CFMetaData newCf = new CFMetaData("EmptyKeyspace", "AddedLater", ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "A new CF to add to an empty KS", 0, false, 1.0, 0);
+        CFMetaData newCf = new CFMetaData("EmptyKeyspace", "AddedLater", ColumnFamilyType.Standard, ClockType.Timestamp, UTF8Type.instance, null, new TimestampReconciler(), "A new CF to add to an empty KS", 0, false, 1.0, 0, Collections.<ByteArrayKey, ColumnDefinition>emptyMap());
 
         //should not exist until apply
         assert !DatabaseDescriptor.getTableDefinition(newKs.name).cfMetaData().containsKey(newCf.cfName);
