diff --git a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/index/TestTermsEnum.java b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/index/TestTermsEnum.java
index 6d7d1dc4..0fb06fad 100644
--- a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/index/TestTermsEnum.java
+++ b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/index/TestTermsEnum.java
@@ -1,471 +1 @@
   Merged /lucene/dev/trunk/lucene/backwards/src/test-framework:r1206143
-package org.apache.lucene.index;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.LineFileDocs;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
-
-public class TestTermsEnum extends LuceneTestCase {
-
-  public void test() throws Exception {
-    final LineFileDocs docs = new LineFileDocs(random);
-    final Directory d = newDirectory();
-    final RandomIndexWriter w = new RandomIndexWriter(random, d);
-    final int numDocs = atLeast(10);
-    for(int docCount=0;docCount<numDocs;docCount++) {
-      w.addDocument(docs.nextDoc());
-    }
-    final IndexReader r = w.getReader();
-    w.close();
-
-    final List<Term> terms = new ArrayList<Term>();
-    TermEnum termEnum = r.terms(new Term("body"));
-    do {
-      Term term = termEnum.term();
-      if (term == null || !"body".equals(term.field())) {
-        break;
-      }
-      terms.add(term);
-    } while (termEnum.next());
-
-    if (VERBOSE) {
-      System.out.println("TEST: " + terms.size() + " terms");
-    }
-
-    int upto = -1;
-    final int iters = atLeast(200);
-    for(int iter=0;iter<iters;iter++) {
-      final boolean isEnd;
-      if (upto != -1 && random.nextBoolean()) {
-        // next
-        if (VERBOSE) {
-          System.out.println("TEST: iter next");
-        }
-        termEnum.next();
-        isEnd = termEnum.term() == null || !"body".equals(termEnum.term().field());
-        upto++;
-        if (isEnd) {
-          if (VERBOSE) {
-            System.out.println("  end");
-          }
-          assertEquals(upto, terms.size());
-          upto = -1;
-        } else {
-          if (VERBOSE) {
-            System.out.println("  got term=" + termEnum.term() + " expected=" + terms.get(upto));
-          }
-          assertTrue(upto < terms.size());
-          assertEquals(terms.get(upto), termEnum.term());
-        }
-      } else {
-
-        final Term target;
-        final String exists;
-        if (random.nextBoolean()) {
-          // likely fake term
-          if (random.nextBoolean()) {
-            target = new Term("body",
-                              _TestUtil.randomSimpleString(random));
-          } else {
-            target = new Term("body",
-                              _TestUtil.randomRealisticUnicodeString(random));
-          }
-          exists = "likely not";
-        } else {
-          // real term 
-          target = terms.get(random.nextInt(terms.size()));
-          exists = "yes";
-        }
-
-        upto = Collections.binarySearch(terms, target);
-
-        if (VERBOSE) {
-          System.out.println("TEST: iter seekCeil target=" + target + " exists=" + exists);
-        }
-        termEnum = r.terms(target);
-        final Term actualTerm = termEnum.term();
-
-        if (VERBOSE) {
-          System.out.println("  got term=" + actualTerm);
-        }
-          
-        if (upto < 0) {
-          upto = -(upto+1);
-          if (upto >= terms.size()) {
-            assertTrue(actualTerm == null || !"body".equals(actualTerm.field()));
-            upto = -1;
-          } else {
-            assertTrue(actualTerm != null && "body".equals(actualTerm.field()));
-            assertEquals(terms.get(upto), actualTerm);
-          }
-        } else {
-          assertEquals(terms.get(upto), actualTerm);
-        }
-      }
-    }
-
-    r.close();
-    d.close();
-  }
-
-  private Directory d;
-  private IndexReader r;
-
-  private final String FIELD = "field";
-
-  private IndexReader makeIndex(String... terms) throws Exception {
-    d = newDirectory();
-    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));
-
-    /*
-    CoreCodecProvider cp = new CoreCodecProvider();    
-    cp.unregister(cp.lookup("Standard"));
-    cp.register(new StandardCodec(minTermsInBlock, maxTermsInBlock));
-    cp.setDefaultFieldCodec("Standard");
-    iwc.setCodecProvider(cp);
-    */
-
-    final RandomIndexWriter w = new RandomIndexWriter(random, d, iwc);
-    w.w.setInfoStream(VERBOSE ? System.out : null);
-    for(String term : terms) {
-      Document doc = new Document();
-      Field f = newField(FIELD, term, Field.Store.NO, Field.Index.NOT_ANALYZED);
-      doc.add(f);
-      w.addDocument(doc);
-    }
-    if (r != null) {
-      close();
-    }
-    r = w.getReader();
-    w.close();
-    return r;
-  }
-
-  private void close() throws Exception {
-    final Directory d = ((SegmentReader) r.getSequentialSubReaders()[0]).directory();
-    r.close();
-    d.close();
-  }
-
-  private int docFreq(IndexReader r, String term) throws Exception {
-    return r.docFreq(new Term(FIELD, term));
-  }
-
-  public void testEasy() throws Exception {
-    // No floor arcs:
-    r = makeIndex("aa0", "aa1", "aa2", "aa3", "bb0", "bb1", "bb2", "bb3", "aa");
-
-    // First term in block:
-    assertEquals(1, docFreq(r, "aa0"));
-
-    // Scan forward to another term in same block
-    assertEquals(1, docFreq(r, "aa2"));
-
-    assertEquals(1, docFreq(r, "aa"));
-
-    // Reset same block then scan forwards
-    assertEquals(1, docFreq(r, "aa1"));
-
-    // Not found, in same block
-    assertEquals(0, docFreq(r, "aa5"));
-
-    // Found, in same block
-    assertEquals(1, docFreq(r, "aa2"));
-
-    // Not found in index:
-    assertEquals(0, docFreq(r, "b0"));
-
-    // Found:
-    assertEquals(1, docFreq(r, "aa2"));
-
-    // Found, rewind:
-    assertEquals(1, docFreq(r, "aa0"));
-
-
-    // First term in block:
-    assertEquals(1, docFreq(r, "bb0"));
-
-    // Scan forward to another term in same block
-    assertEquals(1, docFreq(r, "bb2"));
-
-    // Reset same block then scan forwards
-    assertEquals(1, docFreq(r, "bb1"));
-
-    // Not found, in same block
-    assertEquals(0, docFreq(r, "bb5"));
-
-    // Found, in same block
-    assertEquals(1, docFreq(r, "bb2"));
-
-    // Not found in index:
-    assertEquals(0, docFreq(r, "b0"));
-
-    // Found:
-    assertEquals(1, docFreq(r, "bb2"));
-
-    // Found, rewind:
-    assertEquals(1, docFreq(r, "bb0"));
-
-    close();
-  }
-
-  // tests:
-  //   - test same prefix has non-floor block and floor block (ie, has 2 long outputs on same term prefix)
-  //   - term that's entirely in the index
-
-  public void testFloorBlocks() throws Exception {
-    final String[] terms = new String[] {"aa0", "aa1", "aa2", "aa3", "aa4", "aa5", "aa6", "aa7", "aa8", "aa9", "aa", "xx"};
-    r = makeIndex(terms);
-    //r = makeIndex("aa0", "aa1", "aa2", "aa3", "aa4", "aa5", "aa6", "aa7", "aa8", "aa9");
-
-    // First term in first block:
-    assertEquals(1, docFreq(r, "aa0"));
-    assertEquals(1, docFreq(r, "aa4"));
-
-    // No block
-    assertEquals(0, docFreq(r, "bb0"));
-
-    // Second block
-    assertEquals(1, docFreq(r, "aa4"));
-
-    // Backwards to prior floor block:
-    assertEquals(1, docFreq(r, "aa0"));
-
-    // Forwards to last floor block:
-    assertEquals(1, docFreq(r, "aa9"));
-
-    assertEquals(0, docFreq(r, "a"));
-    assertEquals(1, docFreq(r, "aa"));
-    assertEquals(0, docFreq(r, "a"));
-    assertEquals(1, docFreq(r, "aa"));
-
-    // Forwards to last floor block:
-    assertEquals(1, docFreq(r, "xx"));
-    assertEquals(1, docFreq(r, "aa1"));
-    assertEquals(0, docFreq(r, "yy"));
-
-    assertEquals(1, docFreq(r, "xx"));
-    assertEquals(1, docFreq(r, "aa9"));
-
-    assertEquals(1, docFreq(r, "xx"));
-    assertEquals(1, docFreq(r, "aa4"));
-
-    final TermEnum te = r.terms(new Term(FIELD));
-    while(te.next()) {
-      //System.out.println("TEST: next term=" + te.term().utf8ToString());
-    }
-
-    testRandomSeeks(r, terms);
-    close();
-  }
-
-  public void testZeroTerms() throws Exception {
-    d = newDirectory();
-    final RandomIndexWriter w = new RandomIndexWriter(random, d);
-    w.w.setInfoStream(VERBOSE ? System.out : null);
-    Document doc = new Document();
-    doc.add(newField("field", "one two three", Field.Store.NO, Field.Index.ANALYZED));
-    doc = new Document();
-    doc.add(newField("field2", "one two three", Field.Store.NO, Field.Index.ANALYZED));
-    w.addDocument(doc);
-    w.commit();
-    w.deleteDocuments(new Term("field", "one"));
-    w.forceMerge(1);
-    IndexReader r = w.getReader();
-    w.close();
-    assertEquals(1, r.numDocs());
-    assertEquals(1, r.maxDoc());
-    TermEnum terms = r.terms(new Term("field"));
-    if (terms != null) {
-      assertTrue(!terms.next() || !"field".equals(terms.term().field()));
-    }
-    r.close();
-    d.close();
-  }
-
-  private String getRandomString() {
-    //return _TestUtil.randomSimpleString(random);
-    return _TestUtil.randomRealisticUnicodeString(random);
-  }
-
-  public void testRandomTerms() throws Exception {
-    final String[] terms = new String[_TestUtil.nextInt(random, 1, atLeast(1000))];
-    final Set<String> seen = new HashSet<String>();
-
-    final boolean allowEmptyString = random.nextBoolean();
-
-    if (random.nextInt(10) == 7 && terms.length > 2) {
-      // Sometimes add a bunch of terms sharing a longish common prefix:
-      final int numTermsSamePrefix = random.nextInt(terms.length/2);
-      if (numTermsSamePrefix > 0) {
-        String prefix;
-        while(true) {
-          prefix = getRandomString();
-          if (prefix.length() < 5) {
-            continue;
-          } else {
-            break;
-          }
-        }
-        while(seen.size() < numTermsSamePrefix) {
-          final String t = prefix + getRandomString();
-          if (!seen.contains(t)) {
-            terms[seen.size()] = t;
-            seen.add(t);
-          }
-        }
-      }
-    }
-
-    while(seen.size() < terms.length) {
-      final String t = getRandomString();
-      if (!seen.contains(t) && (allowEmptyString || t.length() != 0)) {
-        terms[seen.size()] = t;
-        seen.add(t);
-      }
-    }
-    r = makeIndex(terms);
-    testRandomSeeks(r, terms);
-    close();
-  }
-
-  private BytesRef getNonExistTerm(BytesRef[] terms) {
-    BytesRef t = null;
-    while(true) {
-      final String ts = getRandomString();
-      t = new BytesRef(ts);
-      if (Arrays.binarySearch(terms, t) < 0) {
-        return t;
-      }
-    }
-  }
-
-  private void testRandomSeeks(IndexReader r, String... validTermStrings) throws IOException {
-    final BytesRef[] validTerms = new BytesRef[validTermStrings.length];
-    for(int termIDX=0;termIDX<validTermStrings.length;termIDX++) {
-      validTerms[termIDX] = new BytesRef(validTermStrings[termIDX]);
-    }
-    Arrays.sort(validTerms, BytesRef.getUTF8SortedAsUTF16Comparator());
-    if (VERBOSE) {
-      System.out.println("TEST: " + validTerms.length + " terms:");
-      for(int idx=0;idx<validTerms.length;idx++) {
-        System.out.println("  " + idx + ": " + validTerms[idx]);
-      }
-    }
-
-    final int END_LOC = -validTerms.length-1;
-    
-    for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
-
-      final BytesRef t;
-      int loc;
-      if (random.nextInt(6) == 4) {
-        // pick term that doens't exist:
-        t = getNonExistTerm(validTerms);
-        if (VERBOSE) {
-          System.out.println("\nTEST: invalid term=" + t.utf8ToString());
-        }
-        loc = Arrays.binarySearch(validTerms, t, BytesRef.getUTF8SortedAsUTF16Comparator());
-      } else {
-        // pick valid term
-        loc = random.nextInt(validTerms.length);
-        t = new BytesRef(validTerms[loc]);
-        if (VERBOSE) {
-          System.out.println("\nTEST: valid term=" + t.utf8ToString());
-        }
-      }
-      final Term targetTerm = new Term(FIELD, t.utf8ToString());
-
-      if (VERBOSE) {
-        System.out.println("  seek term=" + targetTerm);
-      }
-
-      final TermEnum te = r.terms(targetTerm);
-      Term actualTerm = te.term();
-      if (VERBOSE) {
-        System.out.println("  got " + actualTerm);
-      }
-
-      if (loc >= 0) {
-        // assertEquals(TermsEnum.SeekStatus.FOUND, result);
-      } else if (loc == END_LOC) {
-        assertTrue(actualTerm == null || !FIELD.equals(actualTerm.field()));
-      } else {
-        assert loc >= -validTerms.length;
-        assertTrue(actualTerm != null && FIELD.equals(actualTerm.field()));
-        //assertEquals(TermsEnum.SeekStatus.NOT_FOUND, result);
-      }
-
-      if (loc >= 0) {
-        assertEquals(targetTerm, actualTerm);
-      } else if (loc == END_LOC) {
-        continue;
-      } else {
-        loc = -loc-1;
-        assertEquals(new Term(FIELD, validTerms[loc].utf8ToString()), actualTerm);
-      }
-
-      // Do a bunch of next's after the seek
-      final int numNext = random.nextInt(validTerms.length);
-
-      if (VERBOSE) {
-        System.out.println("\nTEST: numNext=" + numNext);
-      }
-
-      for(int nextCount=0;nextCount<numNext;nextCount++) {
-        if (VERBOSE) {
-          System.out.println("\nTEST: next loc=" + loc + " of " + validTerms.length);
-        }
-        boolean result = te.next();
-        actualTerm = te.term();
-        loc++;
-
-        if (loc == validTerms.length) {
-          if (VERBOSE) {
-            System.out.println("  actual=null");
-          }
-          assertFalse(result);
-          assertTrue(actualTerm == null || !FIELD.equals(actualTerm.field()));
-          break;
-        } else {
-          if (VERBOSE) {
-            System.out.println("  actual=" + new BytesRef(actualTerm.text()));
-          }
-          assertTrue(result);
-          assertTrue(actualTerm != null && FIELD.equals(actualTerm.field()));
-          assertEquals(validTerms[loc], new BytesRef(actualTerm.text()));
-        }
-      }
-    }
-  }
-}
diff --git a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestByteBlockPool.java b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestByteBlockPool.java
index ef12523f..e69de29b 100644
--- a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestByteBlockPool.java
+++ b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestByteBlockPool.java
@@ -1,67 +0,0 @@
-package org.apache.lucene.util;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.store.IndexOutput;
-import org.apache.lucene.store.RAMDirectory;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements. See the NOTICE file distributed with this
- * work for additional information regarding copyright ownership. The ASF
- * licenses this file to You under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- * 
- * http://www.apache.org/licenses/LICENSE-2.0
- * 
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
- * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
- * License for the specific language governing permissions and limitations under
- * the License.
- */
-public class TestByteBlockPool extends LuceneTestCase {
-
-  public void testCopyRefAndWrite() throws IOException {
-    List<String> list = new ArrayList<String>();
-    int maxLength = atLeast(500);
-    ByteBlockPool pool = new ByteBlockPool(new ByteBlockPool.DirectAllocator());
-    pool.nextBuffer();
-    final int numValues = atLeast(100);
-    BytesRef ref = new BytesRef();
-    for (int i = 0; i < numValues; i++) {
-      final String value = _TestUtil.randomRealisticUnicodeString(random,
-          maxLength);
-      list.add(value);
-      ref.copy(value);
-      pool.copy(ref);
-    }
-    RAMDirectory dir = new RAMDirectory();
-    IndexOutput stream = dir.createOutput("foo.txt");
-    pool.writePool(stream);
-    stream.flush();
-    stream.close();
-    IndexInput input = dir.openInput("foo.txt");
-    assertEquals(pool.byteOffset + pool.byteUpto, stream.length());
-    BytesRef expected = new BytesRef();
-    BytesRef actual = new BytesRef();
-    for (String string : list) {
-      expected.copy(string);
-      actual.grow(expected.length);
-      actual.length = expected.length;
-      input.readBytes(actual.bytes, 0, actual.length);
-      assertEquals(expected, actual);
-    }
-    try {
-      input.readByte();
-      fail("must be EOF");
-    } catch (IOException e) {
-      // expected - read past EOF
-    }
-    dir.close();
-  }
-}
diff --git a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestBytesRefHash.java b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestBytesRefHash.java
index b677ff9d..e69de29b 100644
--- a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestBytesRefHash.java
+++ b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestBytesRefHash.java
@@ -1,347 +0,0 @@
-package org.apache.lucene.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.BitSet;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-import java.util.SortedSet;
-import java.util.TreeSet;
-import java.util.Map.Entry;
-
-import org.apache.lucene.util.BytesRefHash.MaxBytesLengthExceededException;
-import org.junit.Before;
-import org.junit.Test;
-
-/**
- *
- */
-public class TestBytesRefHash extends LuceneTestCase {
-
-  BytesRefHash hash;
-  ByteBlockPool pool;
-  
-  /**
-   */
-  @Override
-  @Before
-  public void setUp() throws Exception {
-    super.setUp();
-    pool = newPool();
-    hash = newHash(pool);
-  }
-  
-  private ByteBlockPool newPool(){
-    return  random.nextBoolean() && pool != null ? pool
-        : new ByteBlockPool(new RecyclingByteBlockAllocator(ByteBlockPool.BYTE_BLOCK_SIZE, random.nextInt(25)));
-  }
-  
-  private BytesRefHash newHash(ByteBlockPool blockPool) {
-    final int initSize = 2 << 1 + random.nextInt(5);
-    return random.nextBoolean() ? new BytesRefHash(blockPool) : new BytesRefHash(
-        blockPool, initSize, new BytesRefHash.DirectBytesStartArray(initSize));
-  }
-
-  /**
-   * Test method for {@link org.apache.lucene.util.BytesRefHash#size()}.
-   */
-  @Test
-  public void testSize() {
-    BytesRef ref = new BytesRef();
-    int num = atLeast(2);
-    for (int j = 0; j < num; j++) {
-      final int mod = 1+random.nextInt(39);
-      for (int i = 0; i < 797; i++) {
-        String str;
-        do {
-          str = _TestUtil.randomRealisticUnicodeString(random, 1000);
-        } while (str.length() == 0);
-        ref.copy(str);
-        int count = hash.size();
-        int key = hash.add(ref);
-        if (key < 0)
-          assertEquals(hash.size(), count);
-        else
-          assertEquals(hash.size(), count + 1);
-        if(i % mod == 0) {
-          hash.clear();
-          assertEquals(0, hash.size());
-          hash.reinit();
-        }
-      }
-    }
-  }
-
-  /**
-   * Test method for
-   * {@link org.apache.lucene.util.BytesRefHash#get(org.apache.lucene.util.BytesRefHash.Entry)}
-   * .
-   */
-  @Test
-  public void testGet() {
-    BytesRef ref = new BytesRef();
-    BytesRef scratch = new BytesRef();
-    int num = atLeast(2);
-    for (int j = 0; j < num; j++) {
-      Map<String, Integer> strings = new HashMap<String, Integer>();
-      int uniqueCount = 0;
-      for (int i = 0; i < 797; i++) {
-        String str;
-        do {
-          str = _TestUtil.randomRealisticUnicodeString(random, 1000);
-        } while (str.length() == 0);
-        ref.copy(str);
-        int count = hash.size();
-        int key = hash.add(ref);
-        if (key >= 0) {
-          assertNull(strings.put(str, Integer.valueOf(key)));
-          assertEquals(uniqueCount, key);
-          uniqueCount++;
-          assertEquals(hash.size(), count + 1);
-        } else {
-          assertTrue((-key)-1 < count);
-          assertEquals(hash.size(), count);
-        }
-      }
-      for (Entry<String, Integer> entry : strings.entrySet()) {
-        ref.copy(entry.getKey());
-        assertEquals(ref, hash.get(entry.getValue().intValue(), scratch));
-      }
-      hash.clear();
-      assertEquals(0, hash.size());
-      hash.reinit();
-    }
-  }
-
-  /**
-   * Test method for {@link org.apache.lucene.util.BytesRefHash#compact()}.
-   */
-  @Test
-  public void testCompact() {
-    BytesRef ref = new BytesRef();
-    int num = atLeast(2);
-    for (int j = 0; j < num; j++) {
-      int numEntries = 0;
-      final int size = 797;
-      BitSet bits = new BitSet(size);
-      for (int i = 0; i < size; i++) {
-        String str;
-        do {
-          str = _TestUtil.randomRealisticUnicodeString(random, 1000);
-        } while (str.length() == 0);
-        ref.copy(str);
-        final int key = hash.add(ref);
-        if (key < 0) {
-          assertTrue(bits.get((-key)-1));
-        } else {
-          assertFalse(bits.get(key));
-          bits.set(key);
-          numEntries++;
-        }
-      }
-      assertEquals(hash.size(), bits.cardinality());
-      assertEquals(numEntries, bits.cardinality());
-      assertEquals(numEntries, hash.size());
-      int[] compact = hash.compact();
-      assertTrue(numEntries < compact.length);
-      for (int i = 0; i < numEntries; i++) {
-        bits.set(compact[i], false);
-      }
-      assertEquals(0, bits.cardinality());
-      hash.clear();
-      assertEquals(0, hash.size());
-      hash.reinit();
-    }
-  }
-
-  /**
-   * Test method for
-   * {@link org.apache.lucene.util.BytesRefHash#sort(java.util.Comparator)}.
-   */
-  @Test
-  public void testSort() {
-    BytesRef ref = new BytesRef();
-    int num = atLeast(2);
-    for (int j = 0; j < num; j++) {
-      SortedSet<String> strings = new TreeSet<String>();
-      for (int i = 0; i < 797; i++) {
-        String str;
-        do {
-          str = _TestUtil.randomRealisticUnicodeString(random, 1000);
-        } while (str.length() == 0);
-        ref.copy(str);
-        hash.add(ref);
-        strings.add(str);
-      }
-      // We use the UTF-16 comparator here, because we need to be able to
-      // compare to native String.compareTo() [UTF-16]:
-      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUTF16Comparator());
-      assertTrue(strings.size() < sort.length);
-      int i = 0;
-      BytesRef scratch = new BytesRef();
-      for (String string : strings) {
-        ref.copy(string);
-        assertEquals(ref, hash.get(sort[i++], scratch));
-      }
-      hash.clear();
-      assertEquals(0, hash.size());
-      hash.reinit();
-
-    }
-  }
-
-  /**
-   * Test method for
-   * {@link org.apache.lucene.util.BytesRefHash#add(org.apache.lucene.util.BytesRef)}
-   * .
-   */
-  @Test
-  public void testAdd() {
-    BytesRef ref = new BytesRef();
-    BytesRef scratch = new BytesRef();
-    int num = atLeast(2);
-    for (int j = 0; j < num; j++) {
-      Set<String> strings = new HashSet<String>();
-      int uniqueCount = 0;
-      for (int i = 0; i < 797; i++) {
-        String str;
-        do {
-          str = _TestUtil.randomRealisticUnicodeString(random, 1000);
-        } while (str.length() == 0);
-        ref.copy(str);
-        int count = hash.size();
-        int key = hash.add(ref);
-
-        if (key >=0) {
-          assertTrue(strings.add(str));
-          assertEquals(uniqueCount, key);
-          assertEquals(hash.size(), count + 1);
-          uniqueCount++;
-        } else {
-          assertFalse(strings.add(str));
-          assertTrue((-key)-1 < count);
-          assertEquals(str, hash.get((-key)-1, scratch).utf8ToString());
-          assertEquals(count, hash.size());
-        }
-      }
-      
-      assertAllIn(strings, hash);
-      hash.clear();
-      assertEquals(0, hash.size());
-      hash.reinit();
-    }
-  }
-
-  @Test(expected = MaxBytesLengthExceededException.class)
-  public void testLargeValue() {
-    int[] sizes = new int[] { random.nextInt(5),
-        ByteBlockPool.BYTE_BLOCK_SIZE - 33 + random.nextInt(31),
-        ByteBlockPool.BYTE_BLOCK_SIZE - 1 + random.nextInt(37) };
-    BytesRef ref = new BytesRef();
-    for (int i = 0; i < sizes.length; i++) {
-      ref.bytes = new byte[sizes[i]];
-      ref.offset = 0;
-      ref.length = sizes[i];
-      try {
-        assertEquals(i, hash.add(ref));
-      } catch (MaxBytesLengthExceededException e) {
-        if (i < sizes.length - 1)
-          fail("unexpected exception at size: " + sizes[i]);
-        throw e;
-      }
-    }
-  }
-  
-  /**
-   * Test method for
-   * {@link org.apache.lucene.util.BytesRefHash#addByPoolOffset(int)}
-   * .
-   */
-  @Test
-  public void testAddByPoolOffset() {
-    BytesRef ref = new BytesRef();
-    BytesRef scratch = new BytesRef();
-    BytesRefHash offsetHash = newHash(pool);
-    int num = atLeast(2);
-    for (int j = 0; j < num; j++) {
-      Set<String> strings = new HashSet<String>();
-      int uniqueCount = 0;
-      for (int i = 0; i < 797; i++) {
-        String str;
-        do {
-          str = _TestUtil.randomRealisticUnicodeString(random, 1000);
-        } while (str.length() == 0);
-        ref.copy(str);
-        int count = hash.size();
-        int key = hash.add(ref);
-
-        if (key >= 0) {
-          assertTrue(strings.add(str));
-          assertEquals(uniqueCount, key);
-          assertEquals(hash.size(), count + 1);
-          int offsetKey = offsetHash.addByPoolOffset(hash.byteStart(key));
-          assertEquals(uniqueCount, offsetKey);
-          assertEquals(offsetHash.size(), count + 1);
-          uniqueCount++;
-        } else {
-          assertFalse(strings.add(str));
-          assertTrue((-key)-1 < count);
-          assertEquals(str, hash.get((-key)-1, scratch).utf8ToString());
-          assertEquals(count, hash.size());
-          int offsetKey = offsetHash.addByPoolOffset(hash.byteStart((-key)-1));
-          assertTrue((-offsetKey)-1 < count);
-          assertEquals(str, hash.get((-offsetKey)-1, scratch).utf8ToString());
-          assertEquals(count, hash.size());
-        }
-      }
-      
-      assertAllIn(strings, hash);
-      for (String string : strings) {
-        ref.copy(string);
-        int key = hash.add(ref);
-        BytesRef bytesRef = offsetHash.get((-key)-1, scratch);
-        assertEquals(ref, bytesRef);
-      }
-
-      hash.clear();
-      assertEquals(0, hash.size());
-      offsetHash.clear();
-      assertEquals(0, offsetHash.size());
-      hash.reinit(); // init for the next round
-      offsetHash.reinit();
-    }
-  }
-  
-  private void assertAllIn(Set<String> strings, BytesRefHash hash) {
-    BytesRef ref = new BytesRef();
-    BytesRef scratch = new BytesRef();
-    int count = hash.size();
-    for (String string : strings) {
-      ref.copy(string);
-      int key  =  hash.add(ref); // add again to check duplicates
-      assertEquals(string, hash.get((-key)-1, scratch).utf8ToString());
-      assertEquals(count, hash.size());
-      assertTrue("key: " + key + " count: " + count + " string: " + string,
-          key < count);
-    }
-  }
-
-
-}
diff --git a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestCharsRef.java b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestCharsRef.java
index 84b968d2..e69de29b 100644
--- a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestCharsRef.java
+++ b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/TestCharsRef.java
@@ -1,70 +0,0 @@
-package org.apache.lucene.util;
-
-import java.util.Arrays;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestCharsRef extends LuceneTestCase {
-  public void testUTF16InUTF8Order() {
-    final int numStrings = atLeast(1000);
-    BytesRef utf8[] = new BytesRef[numStrings];
-    CharsRef utf16[] = new CharsRef[numStrings];
-    
-    for (int i = 0; i < numStrings; i++) {
-      String s = _TestUtil.randomUnicodeString(random);
-      utf8[i] = new BytesRef(s);
-      utf16[i] = new CharsRef(s);
-    }
-    
-    Arrays.sort(utf8);
-    Arrays.sort(utf16, CharsRef.getUTF16SortedAsUTF8Comparator());
-    
-    for (int i = 0; i < numStrings; i++) {
-      assertEquals(utf8[i].utf8ToString(), utf16[i].toString());
-    }
-  }
-  
-  public void testAppend() {
-    CharsRef ref = new CharsRef();
-    StringBuilder builder = new StringBuilder();
-    int numStrings = atLeast(10);
-    for (int i = 0; i < numStrings; i++) {
-      char[] charArray = _TestUtil.randomRealisticUnicodeString(random, 1, 100).toCharArray();
-      int offset = random.nextInt(charArray.length);
-      int length = charArray.length - offset;
-      builder.append(charArray, offset, length);
-      ref.append(charArray, offset, length);  
-    }
-    
-    assertEquals(builder.toString(), ref.toString());
-  }
-  
-  public void testCopy() {
-    int numIters = atLeast(10);
-    for (int i = 0; i < numIters; i++) {
-      CharsRef ref = new CharsRef();
-      char[] charArray = _TestUtil.randomRealisticUnicodeString(random, 1, 100).toCharArray();
-      int offset = random.nextInt(charArray.length);
-      int length = charArray.length - offset;
-      String str = new String(charArray, offset, length);
-      ref.copy(charArray, offset, length);
-      assertEquals(str, ref.toString());  
-    }
-    
-  }
-}
diff --git a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/fst/TestFSTs.java b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/fst/TestFSTs.java
index 8308f1b3..e69de29b 100644
--- a/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/fst/TestFSTs.java
+++ b/lucene/dev/branches/branch_3x/lucene/backwards/src/test/org/apache/lucene/util/fst/TestFSTs.java
@@ -1,1765 +0,0 @@
-package org.apache.lucene.util.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedReader;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InputStreamReader;
-import java.io.OutputStreamWriter;
-import java.io.Writer;
-import java.util.*;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TermEnum;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.FSDirectory;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.store.IndexOutput;
-import org.apache.lucene.store.MockDirectoryWrapper;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.LineFileDocs;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
-import org.apache.lucene.util.fst.FST.Arc;
-
-public class TestFSTs extends LuceneTestCase {
-
-  private MockDirectoryWrapper dir;
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    dir = newDirectory();
-    dir.setPreventDoubleWrite(false);
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    dir.close();
-    super.tearDown();
-  }
-
-  private static BytesRef toBytesRef(IntsRef ir) {
-    BytesRef br = new BytesRef(ir.length);
-    for(int i=0;i<ir.length;i++) {
-      int x = ir.ints[ir.offset+i];
-      assert x >= 0 && x <= 255;
-      br.bytes[i] = (byte) x;
-    }
-    br.length = ir.length;
-    return br;
-  }
-
-  private static IntsRef toIntsRef(String s, int inputMode) {
-    return toIntsRef(s, inputMode, new IntsRef(10));
-  }
-
-  private static IntsRef toIntsRef(String s, int inputMode, IntsRef ir) {
-    if (inputMode == 0) {
-      // utf8
-      return toIntsRef(new BytesRef(s), ir);
-    } else {
-      // utf32
-      return toIntsRefUTF32(s, ir);
-    }
-  }
-
-  private static IntsRef toIntsRefUTF32(String s, IntsRef ir) {
-    final int charLength = s.length();
-    int charIdx = 0;
-    int intIdx = 0;
-    while(charIdx < charLength) {
-      if (intIdx == ir.ints.length) {
-        ir.grow(intIdx+1);
-      }
-      final int utf32 = s.codePointAt(charIdx);
-      ir.ints[intIdx] = utf32;
-      charIdx += Character.charCount(utf32);
-      intIdx++;
-    }
-    ir.length = intIdx;
-    return ir;
-  }
-
-  private static IntsRef toIntsRef(BytesRef br, IntsRef ir) {
-    if (br.length > ir.ints.length) {
-      ir.grow(br.length);
-    }
-    for(int i=0;i<br.length;i++) {
-      ir.ints[i] = br.bytes[br.offset+i]&0xFF;
-    }
-    ir.length = br.length;
-    return ir;
-  }
-
-  public void testBasicFSA() throws IOException {
-    String[] strings = new String[] {"station", "commotion", "elation", "elastic", "plastic", "stop", "ftop", "ftation", "stat"};
-    String[] strings2 = new String[] {"station", "commotion", "elation", "elastic", "plastic", "stop", "ftop", "ftation"};
-    IntsRef[] terms = new IntsRef[strings.length];
-    IntsRef[] terms2 = new IntsRef[strings2.length];
-    for(int inputMode=0;inputMode<2;inputMode++) {
-      if (VERBOSE) {
-        System.out.println("TEST: inputMode=" + inputModeToString(inputMode));
-      }
-
-      for(int idx=0;idx<strings.length;idx++) {
-        terms[idx] = toIntsRef(strings[idx], inputMode);
-      }
-      for(int idx=0;idx<strings2.length;idx++) {
-        terms2[idx] = toIntsRef(strings2[idx], inputMode);
-      }
-      Arrays.sort(terms2);
-
-      doTest(inputMode, terms);
-    
-      // Test pre-determined FST sizes to make sure we haven't lost minimality (at least on this trivial set of terms):
-
-      // FSA
-      {
-        final Outputs<Object> outputs = NoOutputs.getSingleton();
-        final Object NO_OUTPUT = outputs.getNoOutput();      
-        final List<FSTTester.InputOutput<Object>> pairs = new ArrayList<FSTTester.InputOutput<Object>>(terms2.length);
-        for(IntsRef term : terms2) {
-          pairs.add(new FSTTester.InputOutput<Object>(term, NO_OUTPUT));
-        }
-        FST<Object> fst = new FSTTester<Object>(random, dir, inputMode, pairs, outputs).doTest(0, 0, false);
-        assertNotNull(fst);
-        assertEquals(22, fst.getNodeCount());
-        assertEquals(27, fst.getArcCount());
-      }
-
-      // FST ord pos int
-      {
-        final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-        final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms2.length);
-        for(int idx=0;idx<terms2.length;idx++) {
-          pairs.add(new FSTTester.InputOutput<Long>(terms2[idx], outputs.get(idx)));
-        }
-        final FST<Long> fst = new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest(0, 0, false);
-        assertNotNull(fst);
-        assertEquals(22, fst.getNodeCount());
-        assertEquals(27, fst.getArcCount());
-      }
-
-      // FST byte sequence ord
-      {
-        final ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();
-        final BytesRef NO_OUTPUT = outputs.getNoOutput();      
-        final List<FSTTester.InputOutput<BytesRef>> pairs = new ArrayList<FSTTester.InputOutput<BytesRef>>(terms2.length);
-        for(int idx=0;idx<terms2.length;idx++) {
-          final BytesRef output = random.nextInt(30) == 17 ? NO_OUTPUT : new BytesRef(Integer.toString(idx));
-          pairs.add(new FSTTester.InputOutput<BytesRef>(terms2[idx], output));
-        }
-        final FST<BytesRef> fst = new FSTTester<BytesRef>(random, dir, inputMode, pairs, outputs).doTest(0, 0, false);
-        assertNotNull(fst);
-        assertEquals(24, fst.getNodeCount());
-        assertEquals(30, fst.getArcCount());
-      }
-    }
-  }
-
-  private static String simpleRandomString(Random r) {
-    final int end = r.nextInt(10);
-    if (end == 0) {
-      // allow 0 length
-      return "";
-    }
-    final char[] buffer = new char[end];
-    for (int i = 0; i < end; i++) {
-      buffer[i] = (char) _TestUtil.nextInt(r, 97, 102);
-    }
-    return new String(buffer, 0, end);
-  }
-
-  // given set of terms, test the different outputs for them
-  private void doTest(int inputMode, IntsRef[] terms) throws IOException {
-    Arrays.sort(terms);
-
-    // NoOutputs (simple FSA)
-    {
-      final Outputs<Object> outputs = NoOutputs.getSingleton();
-      final Object NO_OUTPUT = outputs.getNoOutput();      
-      final List<FSTTester.InputOutput<Object>> pairs = new ArrayList<FSTTester.InputOutput<Object>>(terms.length);
-      for(IntsRef term : terms) {
-        pairs.add(new FSTTester.InputOutput<Object>(term, NO_OUTPUT));
-      }
-      new FSTTester<Object>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // PositiveIntOutput (ord)
-    {
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-      final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
-      for(int idx=0;idx<terms.length;idx++) {
-        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], outputs.get(idx)));
-      }
-      new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // PositiveIntOutput (random monotonically increasing positive number)
-    {
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(random.nextBoolean());
-      final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
-      long lastOutput = 0;
-      for(int idx=0;idx<terms.length;idx++) {
-        final long value = lastOutput + _TestUtil.nextInt(random, 1, 1000);
-        lastOutput = value;
-        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], outputs.get(value)));
-      }
-      new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // PositiveIntOutput (random positive number)
-    {
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(random.nextBoolean());
-      final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
-      for(int idx=0;idx<terms.length;idx++) {
-        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], outputs.get(random.nextLong()) & Long.MAX_VALUE));
-      }
-      new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // Pair<ord, (random monotonically increasing positive number>
-    {
-      final PositiveIntOutputs o1 = PositiveIntOutputs.getSingleton(random.nextBoolean());
-      final PositiveIntOutputs o2 = PositiveIntOutputs.getSingleton(random.nextBoolean());
-      final PairOutputs<Long,Long> outputs = new PairOutputs<Long,Long>(o1, o2);
-      final List<FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>> pairs = new ArrayList<FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>>(terms.length);
-      long lastOutput = 0;
-      for(int idx=0;idx<terms.length;idx++) {
-        final long value = lastOutput + _TestUtil.nextInt(random, 1, 1000);
-        lastOutput = value;
-        pairs.add(new FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>(terms[idx],
-                                                                         outputs.get(o1.get(idx),
-                                                                                     o2.get(value))));
-      }
-      new FSTTester<PairOutputs.Pair<Long,Long>>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // Sequence-of-bytes
-    {
-      final ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();
-      final BytesRef NO_OUTPUT = outputs.getNoOutput();      
-      final List<FSTTester.InputOutput<BytesRef>> pairs = new ArrayList<FSTTester.InputOutput<BytesRef>>(terms.length);
-      for(int idx=0;idx<terms.length;idx++) {
-        final BytesRef output = random.nextInt(30) == 17 ? NO_OUTPUT : new BytesRef(Integer.toString(idx));
-        pairs.add(new FSTTester.InputOutput<BytesRef>(terms[idx], output));
-      }
-      new FSTTester<BytesRef>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // Sequence-of-ints
-    {
-      final IntSequenceOutputs outputs = IntSequenceOutputs.getSingleton();
-      final List<FSTTester.InputOutput<IntsRef>> pairs = new ArrayList<FSTTester.InputOutput<IntsRef>>(terms.length);
-      for(int idx=0;idx<terms.length;idx++) {
-        final String s = Integer.toString(idx);
-        final IntsRef output = new IntsRef(s.length());
-        output.length = s.length();
-        for(int idx2=0;idx2<output.length;idx2++) {
-          output.ints[idx2] = s.charAt(idx2);
-        }
-        pairs.add(new FSTTester.InputOutput<IntsRef>(terms[idx], output));
-      }
-      new FSTTester<IntsRef>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // Up to two positive ints, shared, generally but not
-    // monotonically increasing
-    {
-      if (VERBOSE) {
-        System.out.println("TEST: now test UpToTwoPositiveIntOutputs");
-      }
-      final UpToTwoPositiveIntOutputs outputs = UpToTwoPositiveIntOutputs.getSingleton(true);
-      final List<FSTTester.InputOutput<Object>> pairs = new ArrayList<FSTTester.InputOutput<Object>>(terms.length);
-      long lastOutput = 0;
-      for(int idx=0;idx<terms.length;idx++) {
-        // Sometimes go backwards
-        long value = lastOutput + _TestUtil.nextInt(random, -100, 1000);
-        while(value < 0) {
-          value = lastOutput + _TestUtil.nextInt(random, -100, 1000);
-        }
-        final Object output;
-        if (random.nextInt(5) == 3) {
-          long value2 = lastOutput + _TestUtil.nextInt(random, -100, 1000);
-          while(value2 < 0) {
-            value2 = lastOutput + _TestUtil.nextInt(random, -100, 1000);
-          }
-          output = outputs.get(value, value2);
-        } else {
-          output = outputs.get(value);
-        }
-        pairs.add(new FSTTester.InputOutput<Object>(terms[idx], output));
-      }
-      new FSTTester<Object>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-  }
-
-  private static class FSTTester<T> {
-
-    final Random random;
-    final List<InputOutput<T>> pairs;
-    final int inputMode;
-    final Outputs<T> outputs;
-    final Directory dir;
-
-    public FSTTester(Random random, Directory dir, int inputMode, List<InputOutput<T>> pairs, Outputs<T> outputs) {
-      this.random = random;
-      this.dir = dir;
-      this.inputMode = inputMode;
-      this.pairs = pairs;
-      this.outputs = outputs;
-    }
-
-    private static class InputOutput<T> implements Comparable<InputOutput<T>> {
-      public final IntsRef input;
-      public final T output;
-
-      public InputOutput(IntsRef input, T output) {
-        this.input = input;
-        this.output = output;
-      }
-
-      public int compareTo(InputOutput<T> other) {
-        if (other instanceof InputOutput) {
-          return input.compareTo((other).input);
-        } else {
-          throw new IllegalArgumentException();
-        }
-      }
-    }
-
-    public void doTest() throws IOException {
-      // no pruning
-      doTest(0, 0, true);
-
-      if (!(outputs instanceof UpToTwoPositiveIntOutputs)) {
-        // simple pruning
-        doTest(_TestUtil.nextInt(random, 1, 1+pairs.size()), 0, true);
-        
-        // leafy pruning
-        doTest(0, _TestUtil.nextInt(random, 1, 1+pairs.size()), true);
-      }
-    }
-
-    // runs the term, returning the output, or null if term
-    // isn't accepted.  if prefixLength is non-null it must be
-    // length 1 int array; prefixLength[0] is set to the length
-    // of the term prefix that matches
-    private T run(FST<T> fst, IntsRef term, int[] prefixLength) throws IOException {
-      assert prefixLength == null || prefixLength.length == 1;
-      final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
-      final T NO_OUTPUT = fst.outputs.getNoOutput();
-      T output = NO_OUTPUT;
-
-      for(int i=0;i<=term.length;i++) {
-        final int label;
-        if (i == term.length) {
-          label = FST.END_LABEL;
-        } else {
-          label = term.ints[term.offset+i];
-        }
-        //System.out.println("   loop i=" + i + " label=" + label + " output=" + fst.outputs.outputToString(output) + " curArc: target=" + arc.target + " isFinal?=" + arc.isFinal());
-        if (fst.findTargetArc(label, arc, arc) == null) {
-          if (prefixLength != null) {
-            prefixLength[0] = i;
-            return output;
-          } else {
-            return null;
-          }
-        }
-        output = fst.outputs.add(output, arc.output);
-      }
-
-      if (prefixLength != null) {
-        prefixLength[0] = term.length;
-      }
-
-      return output;
-    }
-
-    private T randomAcceptedWord(FST<T> fst, IntsRef in) throws IOException {
-      FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
-
-      final List<FST.Arc<T>> arcs = new ArrayList<FST.Arc<T>>();
-      in.length = 0;
-      in.offset = 0;
-      final T NO_OUTPUT = fst.outputs.getNoOutput();
-      T output = NO_OUTPUT;
-
-      while(true) {
-        // read all arcs:
-        fst.readFirstTargetArc(arc, arc);
-        arcs.add(new FST.Arc<T>().copyFrom(arc));
-        while(!arc.isLast()) {
-          fst.readNextArc(arc);
-          arcs.add(new FST.Arc<T>().copyFrom(arc));
-        }
-      
-        // pick one
-        arc = arcs.get(random.nextInt(arcs.size()));
-        arcs.clear();
-
-        // accumulate output
-        output = fst.outputs.add(output, arc.output);
-
-        // append label
-        if (arc.label == FST.END_LABEL) {
-          break;
-        }
-
-        if (in.ints.length == in.length) {
-          in.grow(1+in.length);
-        }
-        in.ints[in.length++] = arc.label;
-      }
-
-      return output;
-    }
-
-
-    FST<T> doTest(int prune1, int prune2, boolean allowRandomSuffixSharing) throws IOException {
-      if (VERBOSE) {
-        System.out.println("TEST: prune1=" + prune1 + " prune2=" + prune2);
-      }
-
-      final Builder<T> builder = new Builder<T>(inputMode == 0 ? FST.INPUT_TYPE.BYTE1 : FST.INPUT_TYPE.BYTE4,
-                                                prune1, prune2,
-                                                prune1==0 && prune2==0,
-                                                allowRandomSuffixSharing ? random.nextBoolean() : true,
-                                                allowRandomSuffixSharing ? _TestUtil.nextInt(random, 1, 10) : Integer.MAX_VALUE,
-                                                outputs);
-
-      for(InputOutput<T> pair : pairs) {
-        if (pair.output instanceof UpToTwoPositiveIntOutputs.TwoLongs) {
-          final UpToTwoPositiveIntOutputs _outputs = (UpToTwoPositiveIntOutputs) outputs;
-          final UpToTwoPositiveIntOutputs.TwoLongs twoLongs = (UpToTwoPositiveIntOutputs.TwoLongs) pair.output;
-          @SuppressWarnings("unchecked") final Builder<Object> builderObject = (Builder<Object>) builder;
-          builderObject.add(pair.input, _outputs.get(twoLongs.first));
-          builderObject.add(pair.input, _outputs.get(twoLongs.second));
-        } else {
-          builder.add(pair.input, pair.output);
-        }
-      }
-      FST<T> fst = builder.finish();
-
-      if (random.nextBoolean() && fst != null) {
-        IndexOutput out = dir.createOutput("fst.bin");
-        fst.save(out);
-        out.close();
-        IndexInput in = dir.openInput("fst.bin");
-        try {
-          fst = new FST<T>(in, outputs);
-        } finally {
-          in.close();
-          dir.deleteFile("fst.bin");
-        }
-      }
-
-      if (VERBOSE && pairs.size() <= 20 && fst != null) {
-        Writer w = new OutputStreamWriter(new FileOutputStream("out.dot"), "UTF-8");
-        Util.toDot(fst, w, false, false);
-        w.close();
-        System.out.println("SAVED out.dot");
-      }
-
-      if (VERBOSE) {
-        if (fst == null) {
-          System.out.println("  fst has 0 nodes (fully pruned)");
-        } else {
-          System.out.println("  fst has " + fst.getNodeCount() + " nodes and " + fst.getArcCount() + " arcs");
-        }
-      }
-
-      if (prune1 == 0 && prune2 == 0) {
-        verifyUnPruned(inputMode, fst);
-      } else {
-        verifyPruned(inputMode, fst, prune1, prune2);
-      }
-
-      return fst;
-    }
-
-    // FST is complete
-    private void verifyUnPruned(int inputMode, FST<T> fst) throws IOException {
-
-      if (pairs.size() == 0) {
-        assertNull(fst);
-        return;
-      }
-
-      if (VERBOSE) {
-        System.out.println("TEST: now verify " + pairs.size() + " terms");
-        for(InputOutput<T> pair : pairs) {
-          assertNotNull(pair);
-          assertNotNull(pair.input);
-          assertNotNull(pair.output);
-          System.out.println("  " + inputToString(inputMode, pair.input) + ": " + outputs.outputToString(pair.output));
-        }
-      }
-
-      assertNotNull(fst);
-
-      // visit valid paris in order -- make sure all words
-      // are accepted, and FSTEnum's next() steps through
-      // them correctly
-      if (VERBOSE) {
-        System.out.println("TEST: check valid terms/next()");
-      }
-      {
-        IntsRefFSTEnum<T> fstEnum = new IntsRefFSTEnum<T>(fst);
-        for(InputOutput<T> pair : pairs) {
-          IntsRef term = pair.input;
-          if (VERBOSE) {
-            System.out.println("TEST: check term=" + inputToString(inputMode, term) + " output=" + fst.outputs.outputToString(pair.output));
-          }
-          Object output = run(fst, term, null);
-
-          assertNotNull("term " + inputToString(inputMode, term) + " is not accepted", output);
-          assertEquals(pair.output, output);
-
-          // verify enum's next
-          IntsRefFSTEnum.InputOutput<T> t = fstEnum.next();
-          assertNotNull(t);
-          assertEquals("expected input=" + inputToString(inputMode, term) + " but fstEnum returned " + inputToString(inputMode, t.input), term, t.input);
-          assertEquals(pair.output, t.output);
-        }
-        assertNull(fstEnum.next());
-      }
-
-      final Map<IntsRef,T> termsMap = new HashMap<IntsRef,T>();
-      for(InputOutput<T> pair : pairs) {
-        termsMap.put(pair.input, pair.output);
-      }
-
-      // find random matching word and make sure it's valid
-      if (VERBOSE) {
-        System.out.println("TEST: verify random accepted terms");
-      }
-      final IntsRef scratch = new IntsRef(10);
-      int num = atLeast(500);
-      for(int iter=0;iter<num;iter++) {
-        T output = randomAcceptedWord(fst, scratch);
-        assertTrue("accepted word " + inputToString(inputMode, scratch) + " is not valid", termsMap.containsKey(scratch));
-        assertEquals(termsMap.get(scratch), output);
-      }
-    
-      // test IntsRefFSTEnum.seek:
-      if (VERBOSE) {
-        System.out.println("TEST: verify seek");
-      }
-      IntsRefFSTEnum<T> fstEnum = new IntsRefFSTEnum<T>(fst);
-      num = atLeast(100);
-      for(int iter=0;iter<num;iter++) {
-        if (VERBOSE) {
-          System.out.println("TEST: iter=" + iter);
-        }
-        if (random.nextBoolean()) {
-          // seek to term that doesn't exist:
-          while(true) {
-            final IntsRef term = toIntsRef(getRandomString(), inputMode);
-            int pos = Collections.binarySearch(pairs, new InputOutput<T>(term, null));
-            if (pos < 0) {
-              pos = -(pos+1);
-              // ok doesn't exist
-              //System.out.println("  seek " + inputToString(inputMode, term));
-              final IntsRefFSTEnum.InputOutput<T> seekResult;
-              if (random.nextBoolean()) {
-                if (VERBOSE) {
-                  System.out.println("  do non-exist seekFloor term=" + inputToString(inputMode, term));
-                }
-                seekResult = fstEnum.seekFloor(term);
-                pos--;
-              } else {
-                if (VERBOSE) {
-                  System.out.println("  do non-exist seekCeil term=" + inputToString(inputMode, term));
-                }
-                seekResult = fstEnum.seekCeil(term);
-              }
-
-              if (pos != -1 && pos < pairs.size()) {
-                //System.out.println("    got " + inputToString(inputMode,seekResult.input) + " output=" + fst.outputs.outputToString(seekResult.output));
-                assertNotNull("got null but expected term=" + inputToString(inputMode, pairs.get(pos).input), seekResult);
-                if (VERBOSE) {
-                  System.out.println("    got " + inputToString(inputMode, seekResult.input));
-                }
-                assertEquals("expected " + inputToString(inputMode, pairs.get(pos).input) + " but got " + inputToString(inputMode, seekResult.input), pairs.get(pos).input, seekResult.input);
-                assertEquals(pairs.get(pos).output, seekResult.output);
-              } else {
-                // seeked before start or beyond end
-                //System.out.println("seek=" + seekTerm);
-                assertNull("expected null but got " + (seekResult==null ? "null" : inputToString(inputMode, seekResult.input)), seekResult);
-                if (VERBOSE) {
-                  System.out.println("    got null");
-                }
-              }
-
-              break;
-            }
-          }
-        } else {
-          // seek to term that does exist:
-          InputOutput<T> pair = pairs.get(random.nextInt(pairs.size()));
-          final IntsRefFSTEnum.InputOutput<T> seekResult;
-          if (random.nextBoolean()) {
-            if (VERBOSE) {
-              System.out.println("  do exists seekFloor " + inputToString(inputMode, pair.input));
-            }
-            seekResult = fstEnum.seekFloor(pair.input);
-          } else {
-            if (VERBOSE) {
-              System.out.println("  do exists seekCeil " + inputToString(inputMode, pair.input));
-            }
-            seekResult = fstEnum.seekCeil(pair.input);
-          }
-          assertNotNull(seekResult);
-          assertEquals("got " + inputToString(inputMode, seekResult.input) + " but expected " + inputToString(inputMode, pair.input), pair.input, seekResult.input);
-          assertEquals(pair.output, seekResult.output);
-        }
-      }
-
-      if (VERBOSE) {
-        System.out.println("TEST: mixed next/seek");
-      }
-
-      // test mixed next/seek
-      num = atLeast(100);
-      for(int iter=0;iter<num;iter++) {
-        if (VERBOSE) {
-          System.out.println("TEST: iter " + iter);
-        }
-        // reset:
-        fstEnum = new IntsRefFSTEnum<T>(fst);
-        int upto = -1;
-        while(true) {
-          boolean isDone = false;
-          if (upto == pairs.size()-1 || random.nextBoolean()) {
-            // next
-            upto++;
-            if (VERBOSE) {
-              System.out.println("  do next");
-            }
-            isDone = fstEnum.next() == null;
-          } else if (upto != -1 && upto < 0.75 * pairs.size() && random.nextBoolean()) {
-            int attempt = 0;
-            for(;attempt<10;attempt++) {
-              IntsRef term = toIntsRef(getRandomString(), inputMode);
-              if (!termsMap.containsKey(term) && term.compareTo(pairs.get(upto).input) > 0) {
-                int pos = Collections.binarySearch(pairs, new InputOutput<T>(term, null));
-                assert pos < 0;
-                upto = -(pos+1);
-
-                if (random.nextBoolean()) {
-                  upto--;
-                  assertTrue(upto != -1);
-                  if (VERBOSE) {
-                    System.out.println("  do non-exist seekFloor(" + inputToString(inputMode, term) + ")");
-                  }
-                  isDone = fstEnum.seekFloor(term) == null;
-                } else {
-                  if (VERBOSE) {
-                    System.out.println("  do non-exist seekCeil(" + inputToString(inputMode, term) + ")");
-                  }
-                  isDone = fstEnum.seekCeil(term) == null;
-                }
-
-                break;
-              }
-            }
-            if (attempt == 10) {
-              continue;
-            }
-            
-          } else {
-            final int inc = random.nextInt(pairs.size() - upto - 1);
-            upto += inc;
-            if (upto == -1) {
-              upto = 0;
-            }
-
-            if (random.nextBoolean()) {
-              if (VERBOSE) {
-                System.out.println("  do advanceCeil(" + inputToString(inputMode, pairs.get(upto).input) + ")");
-              }
-              isDone = fstEnum.seekCeil(pairs.get(upto).input) == null;
-            } else {
-              if (VERBOSE) {
-                System.out.println("  do advanceFloor(" + inputToString(inputMode, pairs.get(upto).input) + ")");
-              }
-              isDone = fstEnum.seekFloor(pairs.get(upto).input) == null;
-            }
-          }
-          if (VERBOSE) {
-            if (!isDone) {
-              System.out.println("    got " + inputToString(inputMode, fstEnum.current().input));
-            } else {
-              System.out.println("    got null");
-            }
-          }
-
-          if (upto == pairs.size()) {
-            assertTrue(isDone);
-            break;
-          } else {
-            assertFalse(isDone);
-            assertEquals(pairs.get(upto).input, fstEnum.current().input);
-            assertEquals(pairs.get(upto).output, fstEnum.current().output);
-
-            /*
-            if (upto < pairs.size()-1) {
-              int tryCount = 0;
-              while(tryCount < 10) {
-                final IntsRef t = toIntsRef(getRandomString(), inputMode);
-                if (pairs.get(upto).input.compareTo(t) < 0) {
-                  final boolean expected = t.compareTo(pairs.get(upto+1).input) < 0;
-                  if (VERBOSE) {
-                    System.out.println("TEST: call beforeNext(" + inputToString(inputMode, t) + "); current=" + inputToString(inputMode, pairs.get(upto).input) + " next=" + inputToString(inputMode, pairs.get(upto+1).input) + " expected=" + expected);
-                  }
-                  assertEquals(expected, fstEnum.beforeNext(t));
-                  break;
-                }
-                tryCount++;
-              }
-            }
-            */
-          }
-        }
-      }
-    }
-
-    private static class CountMinOutput<T> {
-      int count;
-      T output;
-      T finalOutput;
-      boolean isLeaf = true;
-      boolean isFinal;
-    }
-
-    // FST is pruned
-    private void verifyPruned(int inputMode, FST<T> fst, int prune1, int prune2) throws IOException {
-
-      if (VERBOSE) {
-        System.out.println("TEST: now verify pruned " + pairs.size() + " terms; outputs=" + outputs);
-        for(InputOutput<T> pair : pairs) {
-          System.out.println("  " + inputToString(inputMode, pair.input) + ": " + outputs.outputToString(pair.output));
-        }
-      }
-
-      // To validate the FST, we brute-force compute all prefixes
-      // in the terms, matched to their "common" outputs, prune that
-      // set according to the prune thresholds, then assert the FST
-      // matches that same set.
-
-      // NOTE: Crazy RAM intensive!!
-
-      //System.out.println("TEST: tally prefixes");
-
-      // build all prefixes
-      final Map<IntsRef,CountMinOutput<T>> prefixes = new HashMap<IntsRef,CountMinOutput<T>>();
-      final IntsRef scratch = new IntsRef(10);
-      for(InputOutput<T> pair: pairs) {
-        scratch.copy(pair.input);
-        for(int idx=0;idx<=pair.input.length;idx++) {
-          scratch.length = idx;
-          CountMinOutput<T> cmo = prefixes.get(scratch);
-          if (cmo == null) {
-            cmo = new CountMinOutput<T>();
-            cmo.count = 1;
-            cmo.output = pair.output;
-            prefixes.put(new IntsRef(scratch), cmo);
-          } else {
-            cmo.count++;
-            cmo.output = outputs.common(cmo.output, pair.output);
-          }
-          if (idx == pair.input.length) {
-            cmo.isFinal = true;
-            cmo.finalOutput = cmo.output;
-          }
-        }
-      }
-
-      if (VERBOSE) {
-        System.out.println("TEST: now prune");
-      }
-
-      // prune 'em
-      final Iterator<Map.Entry<IntsRef,CountMinOutput<T>>> it = prefixes.entrySet().iterator();
-      while(it.hasNext()) {
-        Map.Entry<IntsRef,CountMinOutput<T>> ent = it.next();
-        final IntsRef prefix = ent.getKey();
-        final CountMinOutput<T> cmo = ent.getValue();
-        if (VERBOSE) {
-          System.out.println("  term prefix=" + inputToString(inputMode, prefix, false) + " count=" + cmo.count + " isLeaf=" + cmo.isLeaf + " output=" + outputs.outputToString(cmo.output) + " isFinal=" + cmo.isFinal);
-        }
-        final boolean keep;
-        if (prune1 > 0) {
-          keep = cmo.count >= prune1;
-        } else {
-          assert prune2 > 0;
-          if (prune2 > 1 && cmo.count >= prune2) {
-            keep = true;
-          } else if (prefix.length > 0) {
-            // consult our parent
-            scratch.length = prefix.length-1;
-            System.arraycopy(prefix.ints, prefix.offset, scratch.ints, 0, scratch.length);
-            final CountMinOutput<T> cmo2 = prefixes.get(scratch);
-            //System.out.println("    parent count = " + (cmo2 == null ? -1 : cmo2.count));
-            keep = cmo2 != null && ((prune2 > 1 && cmo2.count >= prune2) || (prune2 == 1 && (cmo2.count >= 2 || prefix.length <= 1)));
-          } else if (cmo.count >= prune2) {
-            keep = true;
-          } else {
-            keep = false;
-          }
-        }
-
-        if (!keep) {
-          it.remove();
-          //System.out.println("    remove");
-        } else {
-          // clear isLeaf for all ancestors
-          //System.out.println("    keep");
-          scratch.copy(prefix);
-          scratch.length--;
-          while(scratch.length >= 0) {
-            final CountMinOutput<T> cmo2 = prefixes.get(scratch);
-            if (cmo2 != null) {
-              //System.out.println("    clear isLeaf " + inputToString(inputMode, scratch));
-              cmo2.isLeaf = false;
-            }
-            scratch.length--;
-          }
-        }
-      }
-
-      //System.out.println("TEST: after prune");
-      /*
-        for(Map.Entry<BytesRef,CountMinOutput> ent : prefixes.entrySet()) {
-        System.out.println("  " + inputToString(inputMode, ent.getKey()) + ": isLeaf=" + ent.getValue().isLeaf + " isFinal=" + ent.getValue().isFinal);
-        if (ent.getValue().isFinal) {
-        System.out.println("    finalOutput=" + outputs.outputToString(ent.getValue().finalOutput));
-        }
-        }
-      */
-
-      if (prefixes.size() <= 1) {
-        assertNull(fst);
-        return;
-      }
-
-      assertNotNull(fst);
-
-      // make sure FST only enums valid prefixes
-      if (VERBOSE) {
-        System.out.println("TEST: check pruned enum");
-      }
-      IntsRefFSTEnum<T> fstEnum = new IntsRefFSTEnum<T>(fst);
-      IntsRefFSTEnum.InputOutput<T> current;
-      while((current = fstEnum.next()) != null) {
-        if (VERBOSE) {
-          System.out.println("  fstEnum.next prefix=" + inputToString(inputMode, current.input, false) + " output=" + outputs.outputToString(current.output));
-        }
-        final CountMinOutput cmo = prefixes.get(current.input);
-        assertNotNull(cmo);
-        assertTrue(cmo.isLeaf || cmo.isFinal);
-        //if (cmo.isFinal && !cmo.isLeaf) {
-        if (cmo.isFinal) {
-          assertEquals(cmo.finalOutput, current.output);
-        } else {
-          assertEquals(cmo.output, current.output);
-        }
-      }
-
-      // make sure all non-pruned prefixes are present in the FST
-      if (VERBOSE) {
-        System.out.println("TEST: verify all prefixes");
-      }
-      final int[] stopNode = new int[1];
-      for(Map.Entry<IntsRef,CountMinOutput<T>> ent : prefixes.entrySet()) {
-        if (ent.getKey().length > 0) {
-          final CountMinOutput<T> cmo = ent.getValue();
-          final T output = run(fst, ent.getKey(), stopNode);
-          if (VERBOSE) {
-            System.out.println("TEST: verify prefix=" + inputToString(inputMode, ent.getKey(), false) + " output=" + outputs.outputToString(cmo.output));
-          }
-          // if (cmo.isFinal && !cmo.isLeaf) {
-          if (cmo.isFinal) {
-            assertEquals(cmo.finalOutput, output);
-          } else {
-            assertEquals(cmo.output, output);
-          }
-          assertEquals(ent.getKey().length, stopNode[0]);
-        }
-      }
-    }
-  }
-
-  public void testRandomWords() throws IOException {
-    testRandomWords(1000, atLeast(2));
-    //testRandomWords(20, 100);
-  }
-
-  private String inputModeToString(int mode) {
-    if (mode == 0) {
-      return "utf8";
-    } else {
-      return "utf32";
-    }
-  }
-
-  private void testRandomWords(int maxNumWords, int numIter) throws IOException {
-    for(int iter=0;iter<numIter;iter++) {
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter " + iter);
-      }
-      for(int inputMode=0;inputMode<2;inputMode++) {
-        final int numWords = random.nextInt(maxNumWords+1);
-        Set<IntsRef> termsSet = new HashSet<IntsRef>();
-        IntsRef[] terms = new IntsRef[numWords];
-        while(termsSet.size() < numWords) {
-          final String term = getRandomString();
-          termsSet.add(toIntsRef(term, inputMode));
-        }
-        doTest(inputMode, termsSet.toArray(new IntsRef[termsSet.size()]));
-      }
-    }
-  }
-
-  static String getRandomString() {
-    final String term;
-    if (random.nextBoolean()) {
-      term = _TestUtil.randomRealisticUnicodeString(random);
-    } else {
-      // we want to mix in limited-alphabet symbols so
-      // we get more sharing of the nodes given how few
-      // terms we are testing...
-      term = simpleRandomString(random);
-    }
-    return term;
-  }
-
-  @Nightly
-  public void testBigSet() throws IOException {
-    testRandomWords(_TestUtil.nextInt(random, 50000, 60000), 1);
-  }
-  
-  private static String inputToString(int inputMode, IntsRef term) {
-    return inputToString(inputMode, term, true);
-  }
-
-  private static String inputToString(int inputMode, IntsRef term, boolean isValidUnicode) {
-    if (!isValidUnicode) {
-      return term.toString();
-    } else if (inputMode == 0) {
-      // utf8
-      return toBytesRef(term).utf8ToString() + " " + term;
-    } else {
-      // utf32
-      return UnicodeUtil.newString(term.ints, term.offset, term.length) + " " + term;
-    }
-  }
-
-  private static IntsRef toIntsRef(String s) {
-    final int charCount = s.length();
-    IntsRef ir = new IntsRef(charCount);
-    for(int charIDX=0;charIDX<charCount;charIDX++) {
-      ir.ints[charIDX] = s.charAt(charIDX);
-    }
-    ir.length = charCount;
-    return ir;
-  }
-
-  private static String toString(IntsRef ints) {
-    char[] chars = new char[ints.length];
-    for(int charIDX=0;charIDX<ints.length;charIDX++) {
-      final int ch = ints.ints[ints.offset+charIDX];
-      assertTrue(ch >= 0 && ch < 65536);
-      chars[charIDX] = (char) ch;
-    }
-    return new String(chars);
-  }
-
-  // Build FST for all unique terms in the test line docs
-  // file, up until a time limit
-  public void testRealTerms() throws Exception {
-
-    /*
-    if (CodecProvider.getDefault().getDefaultFieldCodec().equals("SimpleText")) {
-      // no
-      CodecProvider.getDefault().setDefaultFieldCodec("Standard");
-    }
-    */
-
-    final LineFileDocs docs = new LineFileDocs(random);
-    final int RUN_TIME_MSEC = atLeast(500);
-    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(-1).setRAMBufferSizeMB(64);
-    final File tempDir = _TestUtil.getTempDir("fstlines");
-    final MockDirectoryWrapper dir = newFSDirectory(tempDir);
-    final IndexWriter writer = new IndexWriter(dir, conf);
-    writer.setInfoStream(VERBOSE ? System.out : null);
-    final long stopTime = System.currentTimeMillis() + RUN_TIME_MSEC;
-    Document doc;
-    int docCount = 0;
-    while((doc = docs.nextDoc()) != null && System.currentTimeMillis() < stopTime) {
-      writer.addDocument(doc);
-      docCount++;
-    }
-    IndexReader r = IndexReader.open(writer, true);
-    writer.close();
-    final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(random.nextBoolean());
-    Builder<Long> builder = new Builder<Long>(FST.INPUT_TYPE.BYTE2, outputs);
-
-    boolean storeOrd = false;
-    if (VERBOSE) {
-      if (storeOrd) {
-        System.out.println("FST stores ord");
-      } else {
-        System.out.println("FST stores docFreq");
-      }
-    }
-    TermEnum termEnum = r.terms(new Term("body", ""));
-    if (VERBOSE) {
-      System.out.println("TEST: got termEnum=" + termEnum);
-    }
-    int ord = 0;
-    while(true) {
-      final Term term = termEnum.term();
-      if (term == null || !"body".equals(term.field())) {
-        break;
-      }
-
-      // No ord in 3.x:
-      /*
-      if (ord == 0) {
-        try {
-          termsEnum.ord();
-        } catch (UnsupportedOperationException uoe) {
-          if (VERBOSE) {
-            System.out.println("TEST: codec doesn't support ord; FST stores docFreq");
-          }
-          storeOrd = false;
-        }
-      }
-      */
-      final int output;
-      if (storeOrd) {
-        output = ord;
-      } else {
-        output = termEnum.docFreq();
-      }
-      //System.out.println("ADD: " + term.text() + " ch[0]=" + (term.text().length() == 0 ? -1 : term.text().charAt(0)));
-      builder.add(toIntsRef(term.text()), outputs.get(output));
-      ord++;
-      if (VERBOSE && ord % 100000 == 0 && LuceneTestCase.TEST_NIGHTLY) {
-        System.out.println(ord + " terms...");
-      }
-      termEnum.next();
-    }
-    final FST<Long> fst = builder.finish();
-    if (VERBOSE) {
-      System.out.println("FST: " + docCount + " docs; " + ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs;" + " " + fst.sizeInBytes() + " bytes");
-    }
-
-    if (ord > 0) {
-      // Now confirm BytesRefFSTEnum and TermEnum act the
-      // same:
-      final IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<Long>(fst);
-      int num = atLeast(1000);
-      for(int iter=0;iter<num;iter++) {
-        final String randomTerm = getRandomString();
-
-        if (VERBOSE) {
-          System.out.println("TEST: seek " + randomTerm + " ch[0]=" + (randomTerm.length() == 0 ? -1 : randomTerm.charAt(0)));
-        }
-
-        termEnum = r.terms(new Term("body", randomTerm));
-        final IntsRefFSTEnum.InputOutput fstSeekResult = fstEnum.seekCeil(toIntsRef(randomTerm));
-
-        if (termEnum.term() == null || !"body".equals(termEnum.term().field())) {
-          assertNull("got " + (fstSeekResult == null ? "null" : toString(fstSeekResult.input) + " but expected null"), fstSeekResult);
-        } else {
-          assertSame(termEnum, fstEnum, storeOrd);
-          for(int nextIter=0;nextIter<10;nextIter++) {
-            if (VERBOSE) {
-              System.out.println("TEST: next");
-              //if (storeOrd) {
-              //System.out.println("  ord=" + termEnum.ord());
-              //}
-            }
-            termEnum.next();
-            if (termEnum.term() != null && "body".equals(termEnum.term().field())) {
-              if (VERBOSE) {
-                System.out.println("  term=" + termEnum.term());
-              }
-              assertNotNull(fstEnum.next());
-              assertSame(termEnum, fstEnum, storeOrd);
-            } else {
-              if (VERBOSE) {
-                System.out.println("  end!");
-              }
-              IntsRefFSTEnum.InputOutput<Long> nextResult = fstEnum.next();
-              if (nextResult != null) {
-                System.out.println("expected null but got: input=" + toString(nextResult.input) + " output=" + outputs.outputToString(nextResult.output));
-                fail();
-              }
-              break;
-            }
-          }
-        }
-      }
-    }
-
-    r.close();
-    dir.close();
-  }
-
-  private void assertSame(TermEnum termEnum, IntsRefFSTEnum fstEnum, boolean storeOrd) throws Exception {
-    if (termEnum.term() == null || !"body".equals(termEnum.term().field())) {
-      if (fstEnum.current() != null) {
-        fail("fstEnum.current().input=" + toString(fstEnum.current().input));
-      }
-    } else {
-      assertNotNull(fstEnum.current());
-      assertEquals(termEnum.term() + " != " + toString(fstEnum.current().input), termEnum.term().text(), toString(fstEnum.current().input));
-      if (storeOrd) {
-        // fst stored the ord
-        // No ord in 3.x
-        // assertEquals(termEnum.ord(), ((Long) fstEnum.current().output).longValue());
-      } else {
-        // fst stored the docFreq
-        assertEquals(termEnum.docFreq(), (int) (((Long) fstEnum.current().output).longValue()));
-      }
-    }
-  }
-
-  private static abstract class VisitTerms<T> {
-    private final String dirOut;
-    private final String wordsFileIn;
-    private int inputMode;
-    private final Outputs<T> outputs;
-    private final Builder<T> builder;
-
-    public VisitTerms(String dirOut, String wordsFileIn, int inputMode, int prune, Outputs<T> outputs) {
-      this.dirOut = dirOut;
-      this.wordsFileIn = wordsFileIn;
-      this.inputMode = inputMode;
-      this.outputs = outputs;
-      
-      builder = new Builder<T>(inputMode == 0 ? FST.INPUT_TYPE.BYTE1 : FST.INPUT_TYPE.BYTE4, 0, prune, prune == 0, true, Integer.MAX_VALUE, outputs);
-    }
-
-    protected abstract T getOutput(IntsRef input, int ord) throws IOException;
-
-    public void run(int limit, boolean verify) throws IOException {
-      BufferedReader is = new BufferedReader(new InputStreamReader(new FileInputStream(wordsFileIn), "UTF-8"), 65536);
-      try {
-        final IntsRef intsRef = new IntsRef(10);
-        long tStart = System.currentTimeMillis();
-        int ord = 0;
-        while(true) {
-          String w = is.readLine();
-          if (w == null) {
-            break;
-          }
-          toIntsRef(w, inputMode, intsRef);
-          builder.add(intsRef,
-                      getOutput(intsRef, ord));
-
-          ord++;
-          if (ord % 500000 == 0) {
-            System.out.println(
-                String.format(Locale.ENGLISH, 
-                    "%6.2fs: %9d...", ((System.currentTimeMillis() - tStart) / 1000.0), ord));
-          }
-          if (ord >= limit) {
-            break;
-          }
-        }
-
-        assert builder.getTermCount() == ord;
-        final FST<T> fst = builder.finish();
-        if (fst == null) {
-          System.out.println("FST was fully pruned!");
-          System.exit(0);
-        }
-
-        if (dirOut == null)
-          return;
-
-        System.out.println(ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs; " + fst.getArcWithOutputCount() + " arcs w/ output; tot size " + fst.sizeInBytes());
-        if (fst.getNodeCount() < 100) {
-          Writer w = new OutputStreamWriter(new FileOutputStream("out.dot"), "UTF-8");
-          Util.toDot(fst, w, false, false);
-          w.close();
-          System.out.println("Wrote FST to out.dot");
-        }
-
-        Directory dir = FSDirectory.open(new File(dirOut));
-        IndexOutput out = dir.createOutput("fst.bin");
-        fst.save(out);
-        out.close();
-
-        System.out.println("Saved FST to fst.bin.");
-
-        if (!verify) {
-          return;
-        }
-
-        System.out.println("\nNow verify...");
-
-        is.close();
-        is = new BufferedReader(new InputStreamReader(new FileInputStream(wordsFileIn), "UTF-8"), 65536);
-
-        ord = 0;
-        tStart = System.currentTimeMillis();
-        while(true) {
-          String w = is.readLine();
-          if (w == null) {
-            break;
-          }
-          toIntsRef(w, inputMode, intsRef);
-          T expected = getOutput(intsRef, ord);
-          T actual = Util.get(fst, intsRef);
-          if (actual == null) {
-            throw new RuntimeException("unexpected null output on input=" + w);
-          }
-          if (!actual.equals(expected)) {
-            throw new RuntimeException("wrong output (got " + outputs.outputToString(actual) + " but expected " + outputs.outputToString(expected) + ") on input=" + w);
-          }
-
-          ord++;
-          if (ord % 500000 == 0) {
-            System.out.println(((System.currentTimeMillis()-tStart)/1000.0) + "s: " + ord + "...");
-          }
-          if (ord >= limit) {
-            break;
-          }
-        }
-
-        double totSec = ((System.currentTimeMillis() - tStart)/1000.0);
-        System.out.println("Verify took " + totSec + " sec + (" + (int) ((totSec*1000000000/ord)) + " nsec per lookup)");
-
-      } finally {
-        is.close();
-      }
-    }
-  }
-
-  // java -cp build/classes/test:build/classes/java:build/classes/test-framework:lib/junit-4.7.jar org.apache.lucene.util.fst.TestFSTs /x/tmp/allTerms3.txt out
-  public static void main(String[] args) throws IOException {
-    int prune = 0;
-    int limit = Integer.MAX_VALUE;
-    int inputMode = 0;                             // utf8
-    boolean storeOrds = false;
-    boolean storeDocFreqs = false;
-    boolean verify = true;
-    
-    String wordsFileIn = null;
-    String dirOut = null;
-
-    int idx = 0;
-    while (idx < args.length) {
-      if (args[idx].equals("-prune")) {
-        prune = Integer.valueOf(args[1 + idx]);
-        idx++;
-      } else if (args[idx].equals("-limit")) {
-        limit = Integer.valueOf(args[1 + idx]);
-        idx++;
-      } else if (args[idx].equals("-utf8")) {
-        inputMode = 0;
-      } else if (args[idx].equals("-utf32")) {
-        inputMode = 1;
-      } else if (args[idx].equals("-docFreq")) {
-        storeDocFreqs = true;
-      } else if (args[idx].equals("-ords")) {
-        storeOrds = true;
-      } else if (args[idx].equals("-noverify")) {
-        verify = false;
-      } else if (args[idx].startsWith("-")) {
-        System.err.println("Unrecognized option: " + args[idx]);
-        System.exit(-1);
-      } else {
-        if (wordsFileIn == null) {
-          wordsFileIn = args[idx];
-        } else if (dirOut == null) {
-          dirOut = args[idx];
-        } else {
-          System.err.println("Too many arguments, expected: input [output]");
-          System.exit(-1);
-        }
-      }
-      idx++;
-    }
-    
-    if (wordsFileIn == null) {
-      System.err.println("No input file.");
-      System.exit(-1);
-    }
-
-    // ord benefits from share, docFreqs don't:
-
-    if (storeOrds && storeDocFreqs) {
-      // Store both ord & docFreq:
-      final PositiveIntOutputs o1 = PositiveIntOutputs.getSingleton(true);
-      final PositiveIntOutputs o2 = PositiveIntOutputs.getSingleton(false);
-      final PairOutputs<Long,Long> outputs = new PairOutputs<Long,Long>(o1, o2);
-      new VisitTerms<PairOutputs.Pair<Long,Long>>(dirOut, wordsFileIn, inputMode, prune, outputs) {
-        Random rand;
-        @Override
-        public PairOutputs.Pair<Long,Long> getOutput(IntsRef input, int ord) {
-          if (ord == 0) {
-            rand = new Random(17);
-          }
-          return new PairOutputs.Pair<Long,Long>(o1.get(ord),
-                                                 o2.get(_TestUtil.nextInt(rand, 1, 5000)));
-        }
-      }.run(limit, verify);
-    } else if (storeOrds) {
-      // Store only ords
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-      new VisitTerms<Long>(dirOut, wordsFileIn, inputMode, prune, outputs) {
-        @Override
-        public Long getOutput(IntsRef input, int ord) {
-          return outputs.get(ord);
-        }
-      }.run(limit, verify);
-    } else if (storeDocFreqs) {
-      // Store only docFreq
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(false);
-      new VisitTerms<Long>(dirOut, wordsFileIn, inputMode, prune, outputs) {
-        Random rand;
-        @Override
-        public Long getOutput(IntsRef input, int ord) {
-          if (ord == 0) {
-            rand = new Random(17);
-          }
-          return outputs.get(_TestUtil.nextInt(rand, 1, 5000));
-        }
-      }.run(limit, verify);
-    } else {
-      // Store nothing
-      final NoOutputs outputs = NoOutputs.getSingleton();
-      final Object NO_OUTPUT = outputs.getNoOutput();
-      new VisitTerms<Object>(dirOut, wordsFileIn, inputMode, prune, outputs) {
-        @Override
-        public Object getOutput(IntsRef input, int ord) {
-          return NO_OUTPUT;
-        }
-      }.run(limit, verify);
-    }
-  }
-
-  public void testSingleString() throws Exception {
-    final Outputs<Object> outputs = NoOutputs.getSingleton();
-    final Builder<Object> b = new Builder<Object>(FST.INPUT_TYPE.BYTE1, outputs);
-    b.add(new BytesRef("foobar"), outputs.getNoOutput());
-    final BytesRefFSTEnum<Object> fstEnum = new BytesRefFSTEnum<Object>(b.finish());
-    assertNull(fstEnum.seekFloor(new BytesRef("foo")));
-    assertNull(fstEnum.seekCeil(new BytesRef("foobaz")));
-  }
-
-  public void testSimple() throws Exception {
-
-    // Get outputs -- passing true means FST will share
-    // (delta code) the outputs.  This should result in
-    // smaller FST if the outputs grow monotonically.  But
-    // if numbers are "random", false should give smaller
-    // final size:
-    final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-
-    // Build an FST mapping BytesRef -> Long
-    final Builder<Long> builder = new Builder<Long>(FST.INPUT_TYPE.BYTE1, outputs);
-
-    final BytesRef a = new BytesRef("a");
-    final BytesRef b = new BytesRef("b");
-    final BytesRef c = new BytesRef("c");
-
-    builder.add(a, outputs.get(17));
-    builder.add(b, outputs.get(42));
-    builder.add(c, outputs.get(13824324872317238L));
-
-    final FST<Long> fst = builder.finish();
-
-    assertEquals(13824324872317238L, (long) Util.get(fst, c));
-    assertEquals(42, (long) Util.get(fst, b));
-    assertEquals(17, (long) Util.get(fst, a));
-
-    BytesRefFSTEnum<Long> fstEnum = new BytesRefFSTEnum<Long>(fst);
-    BytesRefFSTEnum.InputOutput<Long> seekResult;
-    seekResult = fstEnum.seekFloor(a);
-    assertNotNull(seekResult);
-    assertEquals(17, (long) seekResult.output);
-
-    // goes to a
-    seekResult = fstEnum.seekFloor(new BytesRef("aa"));
-    assertNotNull(seekResult);
-    assertEquals(17, (long) seekResult.output);
-
-    // goes to b
-    seekResult = fstEnum.seekCeil(new BytesRef("aa"));
-    assertNotNull(seekResult);
-    assertEquals(b, seekResult.input);
-    assertEquals(42, (long) seekResult.output);
-  }
-
-  public void testPrimaryKeys() throws Exception {
-    Directory dir = newDirectory();
-
-    for(int cycle=0;cycle<2;cycle++) {
-      if (VERBOSE) {
-        System.out.println("TEST: cycle=" + cycle);
-      }
-      RandomIndexWriter w = new RandomIndexWriter(random, dir,
-                                                  newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE));
-      Document doc = new Document();
-      Field idField = newField("id", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
-      doc.add(idField);
-      
-      final int NUM_IDS = (int) (1000*RANDOM_MULTIPLIER*(1.0+random.nextDouble()));
-      //final int NUM_IDS = (int) (377 * (1.0+random.nextDouble()));
-      if (VERBOSE) {
-        System.out.println("TEST: NUM_IDS=" + NUM_IDS);
-      }
-      final Set<String> allIDs = new HashSet<String>();
-      for(int id=0;id<NUM_IDS;id++) {
-        String idString;
-        if (cycle == 0) {
-          // PKs are assigned sequentially
-          idString = String.format("%07d", id);
-        } else {
-          while(true) {
-            final String s = Long.toString(random.nextLong());
-            if (!allIDs.contains(s)) {
-              idString = s;
-              break;
-            }
-          }
-        }
-        allIDs.add(idString);
-        idField.setValue(idString);
-        w.addDocument(doc);
-      }
-
-      //w.forceMerge(1);
-
-      // turn writer into reader:
-      final IndexReader r = w.getReader();
-      final IndexSearcher s = new IndexSearcher(r);
-      w.close();
-
-      final List<String> allIDsList = new ArrayList<String>(allIDs);
-      final List<String> sortedAllIDsList = new ArrayList<String>(allIDsList);
-      Collections.sort(sortedAllIDsList);
-
-      // Sprinkle in some non-existent PKs:
-      Set<String> outOfBounds = new HashSet<String>();
-      for(int idx=0;idx<NUM_IDS/10;idx++) {
-        String idString;
-        if (cycle == 0) {
-          idString = String.format("%07d", (NUM_IDS + idx));
-        } else {
-          while(true) {
-            idString = Long.toString(random.nextLong());
-            if (!allIDs.contains(idString)) {
-              break;
-            }
-          }
-        }
-        outOfBounds.add(idString);
-        allIDsList.add(idString);
-      }
-
-      // Verify w/ TermQuery
-      for(int iter=0;iter<2*NUM_IDS;iter++) {
-        final String id = allIDsList.get(random.nextInt(allIDsList.size()));
-        final boolean exists = !outOfBounds.contains(id);
-        if (VERBOSE) {
-          System.out.println("TEST: TermQuery " + (exists ? "" : "non-exist ") + " id=" + id);
-        }
-        assertEquals((exists ? "" : "non-exist ") + "id=" + id, exists ? 1 : 0, s.search(new TermQuery(new Term("id", id)), 1).totalHits);
-      }
-
-      // Verify w/ MultiTermsEnum
-      for(int iter=0;iter<2*NUM_IDS;iter++) {
-        final String id;
-        final String nextID;
-        final boolean exists;
-
-        if (random.nextBoolean()) {
-          id = allIDsList.get(random.nextInt(allIDsList.size()));
-          exists = !outOfBounds.contains(id);
-          nextID = null;
-          if (VERBOSE) {
-            System.out.println("TEST: exactOnly " + (exists ? "" : "non-exist ") + "id=" + id);
-          }
-        } else {
-          // Pick ID between two IDs:
-          exists = false;
-          final int idv = random.nextInt(NUM_IDS-1);
-          if (cycle == 0) {
-            id = String.format("%07da", idv);
-            nextID = String.format("%07d", idv+1);
-          } else {
-            id = sortedAllIDsList.get(idv) + "a";
-            nextID = sortedAllIDsList.get(idv+1);
-          }
-          if (VERBOSE) {
-            System.out.println("TEST: not exactOnly id=" + id + " nextID=" + nextID);
-          }
-        }
-
-        final boolean useCache = random.nextBoolean();
-        if (VERBOSE) {
-          System.out.println("  useCache=" + useCache);
-        }
-
-        final Term idTerm = new Term("id", id);
-        final TermEnum termEnum = r.terms(idTerm);
-        final Term actual = termEnum.term();
-
-        if (nextID != null) {
-          assertNotNull(actual);
-          assertTrue(!actual.equals(idTerm));
-          assertEquals("expected=" + nextID + " actual=" + actual.text(), nextID, actual.text());
-        } else if (!exists) {
-          assertTrue(actual == null || !actual.equals(idTerm));
-        } else {
-          assertEquals(actual, idTerm);
-        }
-      }
-
-      r.close();
-    }
-    dir.close();
-  }
-
-  public void testRandomTermLookup() throws Exception {
-    Directory dir = newDirectory();
-
-    RandomIndexWriter w = new RandomIndexWriter(random, dir,
-                                                newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE));
-    w.w.setInfoStream(VERBOSE ? System.out : null);
-
-    Document doc = new Document();
-    Field f = newField("field", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
-    doc.add(f);
-      
-    final int NUM_TERMS = (int) (1000*RANDOM_MULTIPLIER * (1+random.nextDouble()));
-    if (VERBOSE) {
-      System.out.println("TEST: NUM_TERMS=" + NUM_TERMS);
-    }
-
-    final Set<String> allTerms = new HashSet<String>();
-    while(allTerms.size() < NUM_TERMS) {
-      allTerms.add(simpleRandomString(random));
-    }
-
-    for(String term : allTerms) {
-      f.setValue(term);
-      w.addDocument(doc);
-    }
-
-    // turn writer into reader:
-    if (VERBOSE) {
-      System.out.println("TEST: get reader");
-    }
-    IndexReader r = w.getReader();
-    if (VERBOSE) {
-      System.out.println("TEST: got reader=" + r);
-    }
-    IndexSearcher s = new IndexSearcher(r);
-    w.close();
-
-    final List<String> allTermsList = new ArrayList<String>(allTerms);
-    Collections.shuffle(allTermsList, random);
-
-    // verify exact lookup
-    for(String term : allTermsList) {
-      if (VERBOSE) {
-        System.out.println("TEST: term=" + term);
-      }
-      assertEquals("term=" + term, 1, s.search(new TermQuery(new Term("field", term)), 1).totalHits);
-    }
-
-    r.close();
-    dir.close();
-  }
-
-  /**
-   * Test state expansion (array format) on close-to-root states. Creates
-   * synthetic input that has one expanded state on each level.
-   * 
-   * @see "https://issues.apache.org/jira/browse/LUCENE-2933" 
-   */
-  public void testExpandedCloseToRoot() throws Exception {
-    class SyntheticData {
-      FST<Object> compile(String[] lines) throws IOException {
-        final NoOutputs outputs = NoOutputs.getSingleton();
-        final Object nothing = outputs.getNoOutput();
-        final Builder<Object> b = new Builder<Object>(FST.INPUT_TYPE.BYTE1, outputs);
-
-        int line = 0;
-        final BytesRef term = new BytesRef();
-        while (line < lines.length) {
-          String w = lines[line++];
-          if (w == null) {
-            break;
-          }
-          term.copy(w);
-          b.add(term, nothing);
-        }
-        
-        return b.finish();
-      }
-      
-      void generate(ArrayList<String> out, StringBuilder b, char from, char to,
-          int depth) {
-        if (depth == 0 || from == to) {
-          String seq = b.toString() + "_" + out.size() + "_end";
-          out.add(seq);
-        } else {
-          for (char c = from; c <= to; c++) {
-            b.append(c);
-            generate(out, b, from, c == to ? to : from, depth - 1);
-            b.deleteCharAt(b.length() - 1);
-          }
-        }
-      }
-
-      public int verifyStateAndBelow(FST<Object> fst, Arc<Object> arc, int depth) 
-        throws IOException {
-        if (fst.targetHasArcs(arc)) {
-          int childCount = 0;
-          for (arc = fst.readFirstTargetArc(arc, arc);; 
-               arc = fst.readNextArc(arc), childCount++)
-          {
-            boolean expanded = fst.isExpandedTarget(arc);
-            int children = verifyStateAndBelow(fst, new FST.Arc<Object>().copyFrom(arc), depth + 1);
-
-            assertEquals(
-                expanded,
-                (depth <= FST.FIXED_ARRAY_SHALLOW_DISTANCE && 
-                    children >= FST.FIXED_ARRAY_NUM_ARCS_SHALLOW) ||
-                 children >= FST.FIXED_ARRAY_NUM_ARCS_DEEP);
-            if (arc.isLast()) break;
-          }
-
-          return childCount;
-        }
-        return 0;
-      }
-    }
-
-    // Sanity check.
-    assertTrue(FST.FIXED_ARRAY_NUM_ARCS_SHALLOW < FST.FIXED_ARRAY_NUM_ARCS_DEEP);
-    assertTrue(FST.FIXED_ARRAY_SHALLOW_DISTANCE >= 0);
-
-    SyntheticData s = new SyntheticData();
-
-    ArrayList<String> out = new ArrayList<String>();
-    StringBuilder b = new StringBuilder();
-    s.generate(out, b, 'a', 'i', 10);
-    String[] input = out.toArray(new String[out.size()]);
-    Arrays.sort(input);
-    FST<Object> fst = s.compile(input);
-    FST.Arc<Object> arc = fst.getFirstArc(new FST.Arc<Object>());
-    s.verifyStateAndBelow(fst, arc, 1);
-  }
-
-  // Make sure raw FST can differentiate between final vs
-  // non-final end nodes
-  public void testNonFinalStopNodes() throws Exception {
-    final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-    final Long nothing = outputs.getNoOutput();
-    final Builder<Long> b = new Builder<Long>(FST.INPUT_TYPE.BYTE1, outputs);
-
-    final FST<Long> fst = new FST<Long>(FST.INPUT_TYPE.BYTE1, outputs);
-
-    final Builder.UnCompiledNode<Long> rootNode = new Builder.UnCompiledNode<Long>(b, 0);
-
-    // Add final stop node
-    {
-      final Builder.UnCompiledNode<Long> node = new Builder.UnCompiledNode<Long>(b, 0);
-      node.isFinal = true;
-      rootNode.addArc('a', node);
-      final Builder.CompiledNode frozen = new Builder.CompiledNode();
-      frozen.address = fst.addNode(node);
-      rootNode.arcs[0].nextFinalOutput = outputs.get(17);
-      rootNode.arcs[0].isFinal = true;
-      rootNode.arcs[0].output = nothing;
-      rootNode.arcs[0].target = frozen;
-    }
-
-    // Add non-final stop node
-    {
-      final Builder.UnCompiledNode<Long> node = new Builder.UnCompiledNode<Long>(b, 0);
-      rootNode.addArc('b', node);
-      final Builder.CompiledNode frozen = new Builder.CompiledNode();
-      frozen.address = fst.addNode(node);
-      rootNode.arcs[1].nextFinalOutput = nothing;
-      rootNode.arcs[1].output = outputs.get(42);
-      rootNode.arcs[1].target = frozen;
-    }
-
-    fst.finish(fst.addNode(rootNode));
-    
-    checkStopNodes(fst, outputs);
-
-    // Make sure it still works after save/load:
-    Directory dir = newDirectory();
-    IndexOutput out = dir.createOutput("fst");
-    fst.save(out);
-    out.close();
-
-    IndexInput in = dir.openInput("fst");
-    final FST<Long> fst2 = new FST<Long>(in, outputs);
-    checkStopNodes(fst2, outputs);
-    in.close();
-    dir.close();
-  }
-
-  private void checkStopNodes(FST<Long> fst, PositiveIntOutputs outputs) throws Exception {
-    final Long nothing = outputs.getNoOutput();
-    FST.Arc<Long> startArc = fst.getFirstArc(new FST.Arc<Long>());
-    assertEquals(nothing, startArc.output);
-    assertEquals(nothing, startArc.nextFinalOutput);
-
-    FST.Arc<Long> arc = fst.readFirstTargetArc(startArc, new FST.Arc<Long>());
-    assertEquals('a', arc.label);
-    assertEquals(17, arc.nextFinalOutput.longValue());
-    assertTrue(arc.isFinal());
-
-    arc = fst.readNextArc(arc);
-    assertEquals('b', arc.label);
-    assertFalse(arc.isFinal());
-    assertEquals(42, arc.output.longValue());
-  }
-}
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.java
index 9cb7513f..5b85780d 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.java
@@ -187,7 +187,7 @@ public void add(char[] output, int offset, int len) {
       if (outputs[count] == null) {
         outputs[count] = new CharsRef();
       }
-      outputs[count].copy(output, offset, len);
+      outputs[count].copyChars(output, offset, len);
       count++;
     }
   };
@@ -255,7 +255,7 @@ private void capture() {
 
     input.state = captureState();
     input.consumed = false;
-    input.term.copy(termAtt.buffer(), 0, termAtt.length());
+    input.term.copyChars(termAtt.buffer(), 0, termAtt.length());
 
     nextWrite = rollIncr(nextWrite);
 
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java
index 1cc22a4d..fd39cb89 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java
@@ -201,7 +201,7 @@ private void add(CharsRef input, int numInputWords, CharsRef output, int numOutp
       MapEntry e = workingSet.get(input);
       if (e == null) {
         e = new MapEntry();
-        workingSet.put(new CharsRef(input), e); // make a copy, since we will keep around in our map    
+        workingSet.put(CharsRef.deepCopyOf(input), e); // make a copy, since we will keep around in our map    
       }
       
       e.ords.add(ord);
@@ -307,7 +307,7 @@ public SynonymMap build() throws IOException {
         
         scratch.length = scratchOutput.getPosition() - scratch.offset;
         //System.out.println("  add input=" + input + " output=" + scratch + " offset=" + scratch.offset + " length=" + scratch.length + " count=" + count);
-        builder.add(input, new BytesRef(scratch));
+        builder.add(input, BytesRef.deepCopyOf(scratch));
       }
       
       FST<BytesRef> fst = builder.finish();
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/index/BufferedDeletesStream.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/index/BufferedDeletesStream.java
index a8bda0e7..52bb4401 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/index/BufferedDeletesStream.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/index/BufferedDeletesStream.java
@@ -31,7 +31,6 @@
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.util.BytesRef;
 
 /* Tracks the stream of {@link BuffereDeletes}.
  * When DocumensWriter flushes, its buffered
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/index/PrefixCodedTerms.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/index/PrefixCodedTerms.java
index ac539543..81ca3d44 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/index/PrefixCodedTerms.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/index/PrefixCodedTerms.java
@@ -103,7 +103,7 @@ public void remove() {
     public void add(Term term) {
       assert lastTerm.equals(new Term("")) || term.compareTo(lastTerm) > 0;
 
-      scratch.copy(term.text);
+      scratch.copyChars(term.text);
       try {
         int prefix = sharedPrefix(lastBytes, scratch);
         int suffix = scratch.length - prefix;
@@ -115,7 +115,7 @@ public void add(Term term) {
         }
         output.writeVInt(suffix);
         output.writeBytes(scratch.bytes, scratch.offset + prefix, suffix);
-        lastBytes.copy(scratch);
+        lastBytes.copyBytes(scratch);
         lastTerm.text = term.text;
         lastTerm.field = term.field;
       } catch (IOException e) {
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/BytesRef.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/BytesRef.java
index fd4aa5ae..d129abf2 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/BytesRef.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/BytesRef.java
@@ -24,7 +24,7 @@
  *  existing byte[].
  *
  *  @lucene.experimental */
-public final class BytesRef implements Comparable<BytesRef> {
+public final class BytesRef implements Comparable<BytesRef>,Cloneable {
 
   static final int HASH_PRIME = 31;
   public static final byte[] EMPTY_BYTES = new byte[0]; 
@@ -72,44 +72,16 @@ public BytesRef(int capacity) {
    */
   public BytesRef(CharSequence text) {
     this();
-    copy(text);
+    copyChars(text);
   }
   
-  /**
-   * @param text Initialize the byte[] from the UTF8 bytes
-   * for the provided array.  This must be well-formed
-   * unicode text, with no unpaired surrogates or U+FFFF.
-   */
-  public BytesRef(char text[], int offset, int length) {
-    this(length * 4);
-    copy(text, offset, length);
-  }
-
-  public BytesRef(BytesRef other) {
-    this();
-    copy(other);
-  }
-
-  /* // maybe?
-  public BytesRef(BytesRef other, boolean shallow) {
-    this();
-    if (shallow) {
-      offset = other.offset;
-      length = other.length;
-      bytes = other.bytes;
-    } else {
-      copy(other);
-    }
-  }
-  */
-
   /**
    * Copies the UTF8 bytes for this string.
    * 
    * @param text Must be well-formed unicode text, with no
    * unpaired surrogates or invalid UTF16 code units.
    */
-  public void copy(CharSequence text) {
+  public void copyChars(CharSequence text) {
     UnicodeUtil.UTF16toUTF8(text, 0, text.length(), this);
   }
 
@@ -119,7 +91,7 @@ public void copy(CharSequence text) {
    * @param text Must be well-formed unicode text, with no
    * unpaired surrogates or invalid UTF16 code units.
    */
-  public void copy(char text[], int offset, int length) {
+  public void copyChars(char text[], int offset, int length) {
     UnicodeUtil.UTF16toUTF8(text, offset, length, this);
   }
 
@@ -140,8 +112,8 @@ public boolean bytesEquals(BytesRef other) {
   }
 
   @Override
-  public Object clone() {
-    return new BytesRef(this);
+  public BytesRef clone() {
+    return new BytesRef(bytes, offset, length);
   }
 
   private boolean sliceEquals(BytesRef other, int pos) {
@@ -224,7 +196,13 @@ public String toString() {
     return sb.toString();
   }
 
-  public void copy(BytesRef other) {
+  /**
+   * Copies the bytes from the given {@link BytesRef}
+   * <p>
+   * NOTE: this method resets the offset to 0 and resizes the reference array
+   * if needed.
+   */
+  public void copyBytes(BytesRef other) {
     if (bytes.length < other.length) {
       bytes = new byte[other.length];
     }
@@ -365,4 +343,17 @@ public int compare(BytesRef a, BytesRef b) {
       return a.length - b.length;
     }
   }
+  
+  /**
+   * Creates a new BytesRef that points to a copy of the bytes from 
+   * <code>other</code>
+   * <p>
+   * The returned BytesRef will have a length of other.length
+   * and an offset of zero.
+   */
+  public static BytesRef deepCopyOf(BytesRef other) {
+    BytesRef copy = new BytesRef();
+    copy.copyBytes(other);
+    return copy;
+  }
 }
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/CharsRef.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/CharsRef.java
index 02a03a04..b8b0c801 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/CharsRef.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/CharsRef.java
@@ -25,7 +25,7 @@
  * {@link #EMPTY_ARRAY} if necessary.
  * @lucene.internal
  */
-public final class CharsRef implements Comparable<CharsRef>, CharSequence {
+public final class CharsRef implements Comparable<CharsRef>, CharSequence, Cloneable {
   private static final char[] EMPTY_ARRAY = new char[0];
   public char[] chars;
   public int offset;
@@ -68,18 +68,9 @@ public CharsRef(String string) {
     this.length = chars.length;
   }
 
-  /**
-   * Creates a new {@link CharsRef} and copies the contents of the source into
-   * the new instance.
-   * @see #copy(CharsRef)
-   */
-  public CharsRef(CharsRef other) {
-    copy(other);
-  }
-
   @Override
-  public Object clone() {
-    return new CharsRef(this);
+  public CharsRef clone() {
+    return new CharsRef(chars, offset, length);
   }
 
   @Override
@@ -168,7 +159,8 @@ public int compareTo(CharsRef other) {
    * @param other
    *          the {@link CharsRef} to copy
    */
-  public void copy(CharsRef other) {
+  // TODO: why does this behave differently/not invoke copyChars(char[], int, int) ???
+  public void copyChars(CharsRef other) {
     if (chars == null) {
       chars = new char[other.length];
     } else {
@@ -188,7 +180,7 @@ public void grow(int newLength) {
   /**
    * Copies the given array into this CharsRef starting at offset 0
    */
-  public void copy(char[] otherChars, int otherOffset, int otherLength) {
+  public void copyChars(char[] otherChars, int otherOffset, int otherLength) {
     grow(otherLength);
     System.arraycopy(otherChars, otherOffset, this.chars, 0,
         otherLength);
@@ -275,4 +267,17 @@ public int compare(CharsRef a, CharsRef b) {
       return a.length - b.length;
     }
   }
+  
+  /**
+   * Creates a new CharsRef that points to a copy of the chars from 
+   * <code>other</code>
+   * <p>
+   * The returned CharsRef will have a length of other.length
+   * and an offset of zero.
+   */
+  public static CharsRef deepCopyOf(CharsRef other) {
+    CharsRef clone = new CharsRef();
+    clone.copyChars(other);
+    return clone;
+  }
 }
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/IntsRef.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/IntsRef.java
index ee1bd2ed..eb2d4022 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/IntsRef.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/IntsRef.java
@@ -21,7 +21,7 @@
  *  existing int[].
  *
  *  @lucene.internal */
-public final class IntsRef implements Comparable<IntsRef> {
+public final class IntsRef implements Comparable<IntsRef>, Cloneable {
 
   public int[] ints;
   public int offset;
@@ -40,13 +40,9 @@ public IntsRef(int[] ints, int offset, int length) {
     this.length = length;
   }
 
-  public IntsRef(IntsRef other) {
-    copy(other);
-  }
-
   @Override
-  public Object clone() {
-    return new IntsRef(this);
+  public IntsRef clone() {
+    return new IntsRef(ints, offset, length);
   }
 
   @Override
@@ -106,7 +102,7 @@ public int compareTo(IntsRef other) {
     return this.length - other.length;
   }
 
-  public void copy(IntsRef other) {
+  public void copyInts(IntsRef other) {
     if (ints == null) {
       ints = new int[other.length];
     } else {
@@ -137,4 +133,17 @@ public String toString() {
     sb.append(']');
     return sb.toString();
   }
+  
+  /**
+   * Creates a new IntsRef that points to a copy of the ints from 
+   * <code>other</code>
+   * <p>
+   * The returned IntsRef will have a length of other.length
+   * and an offset of zero.
+   */
+  public static IntsRef deepCopyOf(IntsRef other) {
+    IntsRef clone = new IntsRef();
+    clone.copyInts(other);
+    return clone;
+  }
 }
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/fst/Builder.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/fst/Builder.java
index 02854e8d..dfc69a5b 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/fst/Builder.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/fst/Builder.java
@@ -413,7 +413,7 @@ public void add(IntsRef input, T output) throws IOException {
     }
 
     // save last input
-    lastInput.copy(input);
+    lastInput.copyInts(input);
 
     //System.out.println("  count[0]=" + frontier[0].inputCount);
   }
diff --git a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/TestTermsEnum.java b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/TestTermsEnum.java
index 61c33404..6c1e02f3 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/TestTermsEnum.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/TestTermsEnum.java
@@ -399,7 +399,7 @@ private void testRandomSeeks(IndexReader r, String... validTermStrings) throws I
       } else {
         // pick valid term
         loc = random.nextInt(validTerms.length);
-        t = new BytesRef(validTerms[loc]);
+        t = BytesRef.deepCopyOf(validTerms[loc]);
         if (VERBOSE) {
           System.out.println("\nTEST: valid term=" + t.utf8ToString());
         }
diff --git a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestByteBlockPool.java b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestByteBlockPool.java
index ef12523f..82932fe8 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestByteBlockPool.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestByteBlockPool.java
@@ -37,7 +37,7 @@ public void testCopyRefAndWrite() throws IOException {
       final String value = _TestUtil.randomRealisticUnicodeString(random,
           maxLength);
       list.add(value);
-      ref.copy(value);
+      ref.copyChars(value);
       pool.copy(ref);
     }
     RAMDirectory dir = new RAMDirectory();
@@ -50,7 +50,7 @@ public void testCopyRefAndWrite() throws IOException {
     BytesRef expected = new BytesRef();
     BytesRef actual = new BytesRef();
     for (String string : list) {
-      expected.copy(string);
+      expected.copyChars(string);
       actual.grow(expected.length);
       actual.length = expected.length;
       input.readBytes(actual.bytes, 0, actual.length);
diff --git a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestBytesRefHash.java b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestBytesRefHash.java
index b677ff9d..1e0ecd99 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestBytesRefHash.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestBytesRefHash.java
@@ -73,7 +73,7 @@ public void testSize() {
         do {
           str = _TestUtil.randomRealisticUnicodeString(random, 1000);
         } while (str.length() == 0);
-        ref.copy(str);
+        ref.copyChars(str);
         int count = hash.size();
         int key = hash.add(ref);
         if (key < 0)
@@ -107,7 +107,7 @@ public void testGet() {
         do {
           str = _TestUtil.randomRealisticUnicodeString(random, 1000);
         } while (str.length() == 0);
-        ref.copy(str);
+        ref.copyChars(str);
         int count = hash.size();
         int key = hash.add(ref);
         if (key >= 0) {
@@ -121,7 +121,7 @@ public void testGet() {
         }
       }
       for (Entry<String, Integer> entry : strings.entrySet()) {
-        ref.copy(entry.getKey());
+        ref.copyChars(entry.getKey());
         assertEquals(ref, hash.get(entry.getValue().intValue(), scratch));
       }
       hash.clear();
@@ -146,7 +146,7 @@ public void testCompact() {
         do {
           str = _TestUtil.randomRealisticUnicodeString(random, 1000);
         } while (str.length() == 0);
-        ref.copy(str);
+        ref.copyChars(str);
         final int key = hash.add(ref);
         if (key < 0) {
           assertTrue(bits.get((-key)-1));
@@ -186,7 +186,7 @@ public void testSort() {
         do {
           str = _TestUtil.randomRealisticUnicodeString(random, 1000);
         } while (str.length() == 0);
-        ref.copy(str);
+        ref.copyChars(str);
         hash.add(ref);
         strings.add(str);
       }
@@ -197,7 +197,7 @@ public void testSort() {
       int i = 0;
       BytesRef scratch = new BytesRef();
       for (String string : strings) {
-        ref.copy(string);
+        ref.copyChars(string);
         assertEquals(ref, hash.get(sort[i++], scratch));
       }
       hash.clear();
@@ -225,7 +225,7 @@ public void testAdd() {
         do {
           str = _TestUtil.randomRealisticUnicodeString(random, 1000);
         } while (str.length() == 0);
-        ref.copy(str);
+        ref.copyChars(str);
         int count = hash.size();
         int key = hash.add(ref);
 
@@ -288,7 +288,7 @@ public void testAddByPoolOffset() {
         do {
           str = _TestUtil.randomRealisticUnicodeString(random, 1000);
         } while (str.length() == 0);
-        ref.copy(str);
+        ref.copyChars(str);
         int count = hash.size();
         int key = hash.add(ref);
 
@@ -314,7 +314,7 @@ public void testAddByPoolOffset() {
       
       assertAllIn(strings, hash);
       for (String string : strings) {
-        ref.copy(string);
+        ref.copyChars(string);
         int key = hash.add(ref);
         BytesRef bytesRef = offsetHash.get((-key)-1, scratch);
         assertEquals(ref, bytesRef);
@@ -334,7 +334,7 @@ private void assertAllIn(Set<String> strings, BytesRefHash hash) {
     BytesRef scratch = new BytesRef();
     int count = hash.size();
     for (String string : strings) {
-      ref.copy(string);
+      ref.copyChars(string);
       int key  =  hash.add(ref); // add again to check duplicates
       assertEquals(string, hash.get((-key)-1, scratch).utf8ToString());
       assertEquals(count, hash.size());
diff --git a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestCharsRef.java b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestCharsRef.java
index 84b968d2..f6d25ceb 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestCharsRef.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/TestCharsRef.java
@@ -62,7 +62,7 @@ public void testCopy() {
       int offset = random.nextInt(charArray.length);
       int length = charArray.length - offset;
       String str = new String(charArray, offset, length);
-      ref.copy(charArray, offset, length);
+      ref.copyChars(charArray, offset, length);
       assertEquals(str, ref.toString());  
     }
     
diff --git a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/fst/TestFSTs.java b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/fst/TestFSTs.java
index 8308f1b3..7059e382 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/fst/TestFSTs.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/util/fst/TestFSTs.java
@@ -787,7 +787,7 @@ private void verifyPruned(int inputMode, FST<T> fst, int prune1, int prune2) thr
       final Map<IntsRef,CountMinOutput<T>> prefixes = new HashMap<IntsRef,CountMinOutput<T>>();
       final IntsRef scratch = new IntsRef(10);
       for(InputOutput<T> pair: pairs) {
-        scratch.copy(pair.input);
+        scratch.copyInts(pair.input);
         for(int idx=0;idx<=pair.input.length;idx++) {
           scratch.length = idx;
           CountMinOutput<T> cmo = prefixes.get(scratch);
@@ -795,7 +795,7 @@ private void verifyPruned(int inputMode, FST<T> fst, int prune1, int prune2) thr
             cmo = new CountMinOutput<T>();
             cmo.count = 1;
             cmo.output = pair.output;
-            prefixes.put(new IntsRef(scratch), cmo);
+            prefixes.put(IntsRef.deepCopyOf(scratch), cmo);
           } else {
             cmo.count++;
             cmo.output = outputs.common(cmo.output, pair.output);
@@ -847,7 +847,7 @@ private void verifyPruned(int inputMode, FST<T> fst, int prune1, int prune2) thr
         } else {
           // clear isLeaf for all ancestors
           //System.out.println("    keep");
-          scratch.copy(prefix);
+          scratch.copyInts(prefix);
           scratch.length--;
           while(scratch.length >= 0) {
             final CountMinOutput<T> cmo2 = prefixes.get(scratch);
@@ -1633,7 +1633,7 @@ public void testExpandedCloseToRoot() throws Exception {
           if (w == null) {
             break;
           }
-          term.copy(w);
+          term.copyChars(w);
           b.add(term, nothing);
         }
         
