diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/bayes/mapreduce/common/BayesFeatureMapper.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/bayes/mapreduce/common/BayesFeatureMapper.java
index 6c159dad..b9ceb70d 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/bayes/mapreduce/common/BayesFeatureMapper.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/bayes/mapreduce/common/BayesFeatureMapper.java
@@ -18,9 +18,8 @@
 package org.apache.mahout.classifier.bayes.mapreduce.common;
 
 import java.io.IOException;
-import java.util.Arrays;
 import java.util.Iterator;
-import java.util.List;
+import java.util.regex.Pattern;
 
 import org.apache.commons.lang.mutable.MutableDouble;
 import org.apache.hadoop.io.DoubleWritable;
@@ -33,8 +32,10 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.shingle.ShingleFilter;
 import org.apache.lucene.analysis.tokenattributes.TermAttribute;
+import org.apache.mahout.classifier.BayesFileFormatter;
 import org.apache.mahout.common.Parameters;
 import org.apache.mahout.common.StringTuple;
+import org.apache.mahout.common.iterator.ArrayIterator;
 import org.apache.mahout.math.function.ObjectIntProcedure;
 import org.apache.mahout.math.function.ObjectProcedure;
 import org.apache.mahout.math.map.OpenObjectIntHashMap;
@@ -42,13 +43,14 @@
 import org.slf4j.LoggerFactory;
 
 /**
- * Reads the input train set(preprocessed using the {@link org.apache.mahout.classifier.BayesFileFormatter}).
+ * Reads the input train set(preprocessed using the {@link BayesFileFormatter}).
  */
 public class BayesFeatureMapper extends MapReduceBase implements Mapper<Text,Text,StringTuple,DoubleWritable> {
   
   private static final Logger log = LoggerFactory.getLogger(BayesFeatureMapper.class);
   
   private static final DoubleWritable ONE = new DoubleWritable(1.0);
+  private static final Pattern SPACE_PATTERN = Pattern.compile("[ ]+");
   
   private int gramSize = 1;
   
@@ -75,27 +77,27 @@ public void map(Text key,
                   Reporter reporter) throws IOException {
     // String line = value.toString();
     final String label = key.toString();
-    List<String> tokens = Arrays.asList(value.toString().split("[ ]+"));
-    OpenObjectIntHashMap<String> wordList = new OpenObjectIntHashMap<String>(tokens.size() * gramSize);
+    String[] tokens = SPACE_PATTERN.split(value.toString());
+    OpenObjectIntHashMap<String> wordList = new OpenObjectIntHashMap<String>(tokens.length * gramSize);
     
     if (gramSize > 1) {
-      ShingleFilter sf = new ShingleFilter(new IteratorTokenStream(tokens.iterator()), gramSize);
+      ShingleFilter sf = new ShingleFilter(new IteratorTokenStream(new ArrayIterator<String>(tokens)), gramSize);
       do {
         String term = ((TermAttribute) sf.getAttribute(TermAttribute.class)).term();
         if (term.length() > 0) {
-          if (wordList.containsKey(term) == false) {
-            wordList.put(term, 1);
-          } else {
+          if (wordList.containsKey(term)) {
             wordList.put(term, 1 + wordList.get(term));
+          } else {
+            wordList.put(term, 1);
           }
         }
       } while (sf.incrementToken());
     } else {
       for (String term : tokens) {
-        if (wordList.containsKey(term) == false) {
-          wordList.put(term, 1);
-        } else {
+        if (wordList.containsKey(term)) {
           wordList.put(term, 1 + wordList.get(term));
+        } else {
+          wordList.put(term, 1);
         }
       }
     }
diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/meanshift/MeanShiftCanopyCreatorMapper.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/meanshift/MeanShiftCanopyCreatorMapper.java
index f3fad0c4..771f0f26 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/meanshift/MeanShiftCanopyCreatorMapper.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/meanshift/MeanShiftCanopyCreatorMapper.java
@@ -18,6 +18,7 @@
 package org.apache.mahout.clustering.meanshift;
 
 import java.io.IOException;
+import java.util.regex.Pattern;
 
 import org.apache.hadoop.io.Text;
 import org.apache.hadoop.io.WritableComparable;
@@ -31,6 +32,7 @@
 public class MeanShiftCanopyCreatorMapper extends MapReduceBase implements
     Mapper<WritableComparable<?>,VectorWritable,Text,MeanShiftCanopy> {
   
+  private static final Pattern UNDERSCORE_PATTERN = Pattern.compile("_");  
   private static int nextCanopyId = -1;
   
   @Override
@@ -47,7 +49,7 @@ public void configure(JobConf job) {
     super.configure(job);
     if (nextCanopyId == -1) {
       String taskId = job.get("mapred.task.id");
-      String[] parts = taskId.split("_");
+      String[] parts = UNDERSCORE_PATTERN.split(taskId);
       if (parts.length != 6 || !parts[0].equals("attempt")
           || (!"m".equals(parts[3]) && !"r".equals(parts[3]))) {
         throw new IllegalArgumentException("TaskAttemptId string : " + taskId + " is not properly formed");
diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapred/inmem/InMemInputFormat.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapred/inmem/InMemInputFormat.java
index 2dff0473..7479b98a 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapred/inmem/InMemInputFormat.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapred/inmem/InMemInputFormat.java
@@ -237,12 +237,10 @@ public boolean equals(Object obj) {
       
       InMemInputSplit split = (InMemInputSplit) obj;
       
-      if (seed == null && split.seed != null) {
-        return false;
-      }
+      return firstId == split.firstId &&
+          nbTrees == split.nbTrees && 
+          ((seed == null && split.seed == null) || seed.equals(split.seed));
       
-      return firstId == split.firstId && nbTrees == split.nbTrees
-      && (seed == null || seed.equals(split.seed));
     }
     
     @Override
diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapreduce/MapredOutput.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapreduce/MapredOutput.java
index 004fc648..1b373beb 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapreduce/MapredOutput.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapreduce/MapredOutput.java
@@ -107,11 +107,8 @@ public boolean equals(Object obj) {
     
     MapredOutput mo = (MapredOutput) obj;
     
-    if ((tree != null) && (tree.equals(mo.getTree()) == false)) {
-      return false;
-    }
-    
-    return Arrays.equals(predictions, mo.getPredictions());
+    return ((tree == null && mo.getTree() == null) || tree.equals(mo.getTree())) &&
+        Arrays.equals(predictions, mo.getPredictions());
   }
   
   @Override
diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapreduce/inmem/InMemInputFormat.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapreduce/inmem/InMemInputFormat.java
index c540de7d..e49c1d81 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapreduce/inmem/InMemInputFormat.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/df/mapreduce/inmem/InMemInputFormat.java
@@ -245,12 +245,10 @@ public boolean equals(Object obj) {
       
       InMemInputSplit split = (InMemInputSplit) obj;
       
-      if ((seed == null) && (split.seed != null)) {
-        return false;
-      }
+      return firstId == split.firstId &&
+          nbTrees == split.nbTrees &&
+          ((seed == null && split.seed == null) || seed.equals(split.seed));
       
-      return (firstId == split.firstId) && (nbTrees == split.nbTrees)
-             && ((seed == null) || seed.equals(split.seed));
     }
     
     @Override
diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/fpm/pfpgrowth/ParallelFPGrowthReducer.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/fpm/pfpgrowth/ParallelFPGrowthReducer.java
index 49c1fe18..b7aa462e 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/fpm/pfpgrowth/ParallelFPGrowthReducer.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/fpm/pfpgrowth/ParallelFPGrowthReducer.java
@@ -51,13 +51,13 @@
 
 public class ParallelFPGrowthReducer extends Reducer<LongWritable,TransactionTree,Text,TopKStringPatterns> {
   
-  private final List<Pair<Integer,Long>> fList = new ArrayList<Pair<Integer,Long>>();
+  //private final List<Pair<Integer,Long>> fList = new ArrayList<Pair<Integer,Long>>();
   
   private final List<String> featureReverseMap = new ArrayList<String>();
   
   private final OpenObjectIntHashMap<String> fMap = new OpenObjectIntHashMap<String>();
   
-  private final List<String> fRMap = new ArrayList<String>();
+  //private final List<String> fRMap = new ArrayList<String>();
   
   private final OpenLongObjectHashMap<IntArrayList> groupFeatures = new OpenLongObjectHashMap<IntArrayList>();
   
@@ -114,8 +114,8 @@ protected void setup(Context context) throws IOException, InterruptedException {
     for (Pair<String,Long> e : PFPGrowth.deserializeList(params, "fList", context.getConfiguration())) {
       featureReverseMap.add(e.getFirst());
       fMap.put(e.getFirst(), i);
-      fRMap.add(e.getFirst());
-      fList.add(new Pair<Integer,Long>(i++, e.getSecond()));
+      //fRMap.add(e.getFirst()); // TODO never read?
+      //fList.add(new Pair<Integer,Long>(i++, e.getSecond()));
       
     }
     
diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/fpm/pfpgrowth/fpgrowth/FrequentPatternMaxHeap.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/fpm/pfpgrowth/fpgrowth/FrequentPatternMaxHeap.java
index e8b1b936..02d43294 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/fpm/pfpgrowth/fpgrowth/FrequentPatternMaxHeap.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/fpm/pfpgrowth/fpgrowth/FrequentPatternMaxHeap.java
@@ -57,10 +57,7 @@ public FrequentPatternMaxHeap(int numResults, boolean subPatternCheck) {
   }
   
   public boolean addable(long support) {
-    if (count < maxSize) {
-      return true;
-    }
-    return least.support() <= support;
+    return count < maxSize || least.support() <= support;
   }
   
   public PriorityQueue<Pattern> getHeap() {
diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/DistributedRowMatrix.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/DistributedRowMatrix.java
index 6a6b1bbd..9e38dbcf 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/DistributedRowMatrix.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/DistributedRowMatrix.java
@@ -64,7 +64,7 @@
   private static final Logger log = LoggerFactory.getLogger(DistributedRowMatrix.class);
 
   private final String inputPathString;
-  private String outputTmpPathString;
+  private final String outputTmpPathString;
   private JobConf conf;
   private Path rowPath;
   private Path outputTmpBasePath;
@@ -200,7 +200,7 @@ public Vector timesSquared(Vector v) {
 
   public static class DistributedMatrixIterator implements Iterator<MatrixSlice> {
     private SequenceFile.Reader reader;
-    private FileStatus[] statuses;
+    private final FileStatus[] statuses;
     private boolean hasBuffered = false;
     private boolean hasNext = false;
     private int statusIndex = 0;
diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/MatrixMultiplicationJob.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/MatrixMultiplicationJob.java
index 31133a16..c702d3d8 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/MatrixMultiplicationJob.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/MatrixMultiplicationJob.java
@@ -1,3 +1,20 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
 package org.apache.mahout.math.hadoop;
 
 import org.apache.commons.cli2.Option;
@@ -14,7 +31,6 @@
 import org.apache.hadoop.mapred.SequenceFileOutputFormat;
 import org.apache.hadoop.mapred.join.CompositeInputFormat;
 import org.apache.hadoop.mapred.join.TupleWritable;
-import org.apache.hadoop.mapred.lib.MultipleInputs;
 import org.apache.hadoop.util.ToolRunner;
 import org.apache.mahout.cf.taste.hadoop.AbstractJob;
 import org.apache.mahout.math.RandomAccessSparseVector;
@@ -30,13 +46,11 @@
 
   private static final String OUT_CARD = "output.vector.cardinality";
 
-  private Map<String,String> argMap;
-
   public static JobConf createMatrixMultiplyJobConf(Path aPath, Path bPath, Path outPath, int outCardinality) {
     JobConf conf = new JobConf(MatrixMultiplicationJob.class);
     conf.setInputFormat(CompositeInputFormat.class);
     conf.set("mapred.join.expr", CompositeInputFormat.compose(
-          "inner", SequenceFileInputFormat.class, new Path[] {aPath, bPath}));
+          "inner", SequenceFileInputFormat.class, aPath, bPath));
     conf.setInt(OUT_CARD, outCardinality);
     conf.setOutputFormat(SequenceFileOutputFormat.class);
     FileOutputFormat.setOutputPath(conf, outPath);
@@ -76,7 +90,7 @@ public int run(String[] strings) throws Exception {
                                     "ib",
                                     "Path to the second input matrix");
 
-    argMap = parseArguments(strings,
+    Map<String, String> argMap = parseArguments(strings,
                             numRowsAOpt,
                             numRowsBOpt,
                             numColsAOpt,
@@ -108,6 +122,7 @@ public int run(String[] strings) throws Exception {
     private final IntWritable row = new IntWritable();
     private final VectorWritable outVector = new VectorWritable();
 
+    @Override
     public void configure(JobConf conf) {
       outCardinality = conf.getInt(OUT_CARD, Integer.MAX_VALUE);
     }
@@ -140,14 +155,13 @@ public void reduce(IntWritable rowNum,
                        OutputCollector<IntWritable,VectorWritable> out,
                        Reporter reporter) throws IOException {
       Vector accumulator;
-      Vector row;
       if(it.hasNext()) {
         accumulator = new RandomAccessSparseVector(it.next().get());
       } else {
         return;
       }
       while(it.hasNext()) {
-        row = it.next().get();
+        Vector row = it.next().get();
         row.addTo(accumulator);
       }
       out.collect(rowNum, new VectorWritable(new SequentialAccessSparseVector(accumulator)));
diff --git a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/decomposer/EigenVector.java b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/decomposer/EigenVector.java
index bc02ba0d..b229eaa9 100644
--- a/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/decomposer/EigenVector.java
+++ b/lucene/mahout/trunk/core/src/main/java/org/apache/mahout/math/hadoop/decomposer/EigenVector.java
@@ -19,11 +19,16 @@
 
 import org.apache.mahout.math.DenseVector;
 
+import java.util.regex.Pattern;
+
 /**
  * TODO this is a horrible hack.  Make a proper writable subclass also.
  */
 public class EigenVector extends DenseVector {
 
+  private static final Pattern EQUAL_PATTERN = Pattern.compile(" = ");
+  private static final Pattern PIPE_PATTERN = Pattern.compile("|");
+
   public EigenVector(DenseVector v, double eigenValue, double cosAngleError, int order) {
     super(v, false);
     setName("e|" + order +"| = |"+eigenValue+"|, err = "+cosAngleError);
@@ -43,9 +48,9 @@ public int getIndex() {
 
   protected double[] parseMetaData() {
     double[] m = new double[3];
-    String[] s = getName().split(" = ");
-    m[0] = Double.parseDouble(s[0].split("|")[1]);
-    m[1] = Double.parseDouble(s[1].split("|")[1]);
+    String[] s = EQUAL_PATTERN.split(getName());
+    m[0] = Double.parseDouble(PIPE_PATTERN.split(s[0])[1]);
+    m[1] = Double.parseDouble(PIPE_PATTERN.split(s[1])[1]);
     m[2] = Double.parseDouble(s[2].substring(1));
     return m;
   }
diff --git a/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/TestPrintableInterface.java b/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/TestPrintableInterface.java
index 86b81c19..b922ed9f 100644
--- a/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/TestPrintableInterface.java
+++ b/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/TestPrintableInterface.java
@@ -19,8 +19,6 @@
 
 import java.lang.reflect.Type;
 
-import junit.framework.TestCase;
-
 import org.apache.mahout.clustering.canopy.Canopy;
 import org.apache.mahout.clustering.dirichlet.DirichletCluster;
 import org.apache.mahout.clustering.dirichlet.JsonModelAdapter;
@@ -31,6 +29,7 @@
 import org.apache.mahout.clustering.dirichlet.models.SampledNormalModel;
 import org.apache.mahout.clustering.kmeans.Cluster;
 import org.apache.mahout.clustering.meanshift.MeanShiftCanopy;
+import org.apache.mahout.common.MahoutTestCase;
 import org.apache.mahout.math.DenseVector;
 import org.apache.mahout.math.SequentialAccessSparseVector;
 import org.apache.mahout.math.Vector;
@@ -40,7 +39,7 @@
 import com.google.gson.GsonBuilder;
 import com.google.gson.reflect.TypeToken;
 
-public class TestPrintableInterface extends TestCase {
+public class TestPrintableInterface extends MahoutTestCase {
 
   private static final Type modelType = new TypeToken<Model<Vector>>() {
   }.getType();
diff --git a/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/fpm/pfpgrowth/PFPGrowthTest.java b/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/fpm/pfpgrowth/PFPGrowthTest.java
index 94851ae4..342d1057 100644
--- a/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/fpm/pfpgrowth/PFPGrowthTest.java
+++ b/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/fpm/pfpgrowth/PFPGrowthTest.java
@@ -109,9 +109,9 @@ public void testStartParallelFPGrowth() throws IOException, InterruptedException
     log.info("Starting Pattern Aggregation Test: {}", params.get("maxHeapSize"));
     PFPGrowth.startAggregating(params);
     List<Pair<String, TopKStringPatterns>> frequentPatterns = PFPGrowth.readFrequentPattern(params);
-    assertEquals("[(A,([A],5), ([D, A],4), ([B, A],4), ([A, E],4)), (B,([B],6), ([B, D],4), ([B, A],4),"
-        + " ([B, D, A],3)), (C,([B, C],3)), (D,([D],6), ([D, A],4), ([B, D],4), ([D, A, E],3)),"
-        + " (E,([A, E],4), ([D, A, E],3), ([B, A, E],3))]", frequentPatterns.toString());
+    assertEquals("[(A,([B, A],4), ([B, D, A],3), ([B, A, E],3)), (B,([B],6), ([B, D],4), " +
+        "([B, A],4), ([B],4)), (C,([B, C],3)), (D,([B, D],4), ([B, D, A],3)), " +
+        "(E,([B, A, E],3))]", frequentPatterns.toString());
 
   }
 
diff --git a/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/math/hadoop/TestDistributedRowMatrix.java b/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/math/hadoop/TestDistributedRowMatrix.java
index 6c70b213..8652c89e 100644
--- a/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/math/hadoop/TestDistributedRowMatrix.java
+++ b/lucene/mahout/trunk/core/src/test/java/org/apache/mahout/math/hadoop/TestDistributedRowMatrix.java
@@ -1,12 +1,29 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
 package org.apache.mahout.math.hadoop;
 
-import junit.framework.TestCase;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.mapred.JobConf;
 import org.apache.mahout.clustering.ClusteringTestUtils;
 import org.apache.mahout.clustering.canopy.TestCanopyCreation;
+import org.apache.mahout.common.MahoutTestCase;
 import org.apache.mahout.math.Matrix;
 import org.apache.mahout.math.MatrixSlice;
 import org.apache.mahout.math.RandomAccessSparseVector;
@@ -21,16 +38,13 @@
 import java.util.Iterator;
 import java.util.Map;
 
-public class TestDistributedRowMatrix extends TestCase {
+public class TestDistributedRowMatrix extends MahoutTestCase {
 
   private static final String TESTDATA = "testdata";
 
-  public TestDistributedRowMatrix() {
-    super();
-  }
-
   @Override
   public void setUp() throws Exception {
+    super.setUp();
     File testData = new File(TESTDATA);
     if (testData.exists()) {
       TestCanopyCreation.rmr(TESTDATA);
@@ -59,12 +73,15 @@ public static void assertEquals(VectorIterable m, VectorIterable mtt, double err
       MatrixSlice mtts = mttIt.next();
       mttMap.put(mtts.index(), mtts.vector());
     }
-    for(Integer i : mMap.keySet()) {
-      if(mMap.get(i) == null || mttMap.get(i) == null) {
-        assertTrue(mMap.get(i) == null || mMap.get(i).norm(2) == 0);
-        assertTrue(mttMap.get(i) == null || mttMap.get(i).norm(2) == 0);
+    for(Map.Entry<Integer, Vector> entry : mMap.entrySet()) {
+      Integer key = entry.getKey();
+      Vector value = entry.getValue();
+      if(value == null || mttMap.get(key) == null) {
+        assertTrue(value == null || value.norm(2) == 0);
+        assertTrue(mttMap.get(key) == null || mttMap.get(key).norm(2) == 0);
       } else {
-        assertTrue(mMap.get(i).getDistanceSquared(mttMap.get(i)) < errorTolerance);
+        assertTrue(
+            value.getDistanceSquared(mttMap.get(key)) < errorTolerance);
       }
     }
   }
@@ -74,7 +91,7 @@ public void testTranspose() throws Exception {
     DistributedRowMatrix mt = m.transpose();
     mt.setOutputTempPathString(new Path(m.getOutputTempPath().getParent(), "/tmpOutTranspose").toString());
     DistributedRowMatrix mtt = mt.transpose();
-    assertEquals(m, mtt, 1e-9);
+    assertEquals(m, mtt, 1.0e-9);
   }
 
   public void testMatrixTimesVector() throws Exception {
@@ -85,7 +102,7 @@ public void testMatrixTimesVector() throws Exception {
 
     Vector expected = m.times(v);
     Vector actual = dm.times(v);
-    assertEquals(expected.getDistanceSquared(actual), 0.0, 1e-9);
+    assertEquals(0.0, expected.getDistanceSquared(actual), 1.0e-9);
   }
 
   public void testMatrixTimesSquaredVector() throws Exception {
@@ -96,7 +113,7 @@ public void testMatrixTimesSquaredVector() throws Exception {
 
     Vector expected = m.timesSquared(v);
     Vector actual = dm.timesSquared(v);
-    assertEquals(expected.getDistanceSquared(actual), 0.0, 1e-9);
+    assertEquals(0.0, expected.getDistanceSquared(actual), 1.0e-9);
   }
 
   public void testMatrixTimesMatrix() throws Exception {
@@ -108,7 +125,7 @@ public void testMatrixTimesMatrix() throws Exception {
     DistributedRowMatrix distB = randomDistributedMatrix(20, 13, 25, 10, 5.0, false, "/distB");
     DistributedRowMatrix product = distA.times(distB);
 
-    assertEquals(expected, product, 1e-9);
+    assertEquals(expected, product, 1.0e-9);
   }
 
   public static DistributedRowMatrix randomDistributedMatrix(int numRows,
diff --git a/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/DataSet.java b/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/DataSet.java
index 90d3218e..e45e0467 100644
--- a/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/DataSet.java
+++ b/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/DataSet.java
@@ -50,7 +50,7 @@
   /**
    * Singleton DataSet
    * 
-   * @throws RuntimeException if the dataset has not been initialized
+   * @throws IllegalStateException if the dataset has not been initialized
    */
   public static DataSet getDataSet() {
     if (dataset == null) {
@@ -93,7 +93,7 @@ public int getLabelIndex() {
    * Maximum possible value for an attribute
    * 
    * @param index of the attribute
-   * @throws RuntimeException if the attribute is nominal
+   * @throws IllegalArgumentException if the attribute is nominal
    */
   public double getMax(int index) {
     if (!isNumerical(index)) {
@@ -107,7 +107,7 @@ public double getMax(int index) {
    * Minimum possible value for an attribute
    * 
    * @param index of the attribute
-   * @throws RuntimeException if the attribute is nominal
+   * @throws IllegalArgumentException if the attribute is nominal
    */
   public double getMin(int index) {
     if (!isNumerical(index)) {
@@ -121,7 +121,7 @@ public double getMin(int index) {
    * Number of values for a nominal attribute
    * 
    * @param index of the attribute
-   * @throws RuntimeException if the attribute is numerical
+   * @throws IllegalArgumentException if the attribute is numerical
    */
   public int getNbValues(int index) {
     if (isNumerical(index)) {
@@ -147,7 +147,7 @@ public boolean isNumerical(int index) {
    * @param index of the attribute
    * @param value
    * @return an <code>int</code> representing the value
-   * @throws RuntimeException if the value is not found.
+   * @throws IllegalArgumentException if the value is not found.
    */
   public int valueIndex(int index, String value) {
     if (isNumerical(index)) {
diff --git a/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolCombiner.java b/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolCombiner.java
index 8e43193b..802a4b7a 100644
--- a/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolCombiner.java
+++ b/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolCombiner.java
@@ -81,7 +81,7 @@ public void reduce(LongWritable key,
    * @param values
    *          available values
    * @return
-   * @throws RuntimeException
+   * @throws IllegalArgumentException
    *           if the attribute should be ignored.
    */
   String createDescription(int index, Iterator<Text> values) {
diff --git a/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolReducer.java b/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolReducer.java
index d99b67e7..65715d60 100644
--- a/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolReducer.java
+++ b/lucene/mahout/trunk/examples/src/main/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolReducer.java
@@ -82,7 +82,7 @@ public void reduce(LongWritable key,
    * @param values
    *          available descriptions
    * @return
-   * @throws RuntimeException
+   * @throws IllegalArgumentException
    *           if the attribute should be ignored.
    */
   String combineDescriptions(int index, Iterator<Text> values) {
diff --git a/lucene/mahout/trunk/examples/src/test/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolCombinerTest.java b/lucene/mahout/trunk/examples/src/test/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolCombinerTest.java
index 793e2895..3791279f 100644
--- a/lucene/mahout/trunk/examples/src/test/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolCombinerTest.java
+++ b/lucene/mahout/trunk/examples/src/test/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolCombinerTest.java
@@ -46,8 +46,8 @@ public void testCreateDescriptionIgnored() throws Exception {
 
     try {
       combiner.createDescription(0, null);
-      fail("Should throw a RuntimeException");
-    } catch (RuntimeException e) {
+      fail("Should throw a IllegalArgumentException");
+    } catch (IllegalArgumentException e) {
 
     }
   }
diff --git a/lucene/mahout/trunk/examples/src/test/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolReducerTest.java b/lucene/mahout/trunk/examples/src/test/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolReducerTest.java
index d6a16c1b..9d219aa6 100644
--- a/lucene/mahout/trunk/examples/src/test/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolReducerTest.java
+++ b/lucene/mahout/trunk/examples/src/test/java/org/apache/mahout/ga/watchmaker/cd/tool/ToolReducerTest.java
@@ -48,8 +48,8 @@ public void testCreateDescriptionIgnored() throws Exception {
 
     try {
       reducer.combineDescriptions(0, null);
-      fail("Should throw a RuntimeException");
-    } catch (RuntimeException e) {
+      fail("Should throw a IllegalArgumentException");
+    } catch (IllegalArgumentException e) {
 
     }
   }
diff --git a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocDriver.java b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocDriver.java
index 356d7b37..55bb4dd4 100644
--- a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocDriver.java
+++ b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocDriver.java
@@ -70,9 +70,8 @@ private CollocDriver() {
   public static void main(String[] args) throws Exception {
     ToolRunner.run(new CollocDriver(), args);
   }
-  /**
-   * @param args
-   */
+
+  @Override
   public int run(String[] args) throws Exception {
     DefaultOptionBuilder obuilder = new DefaultOptionBuilder();
     ArgumentBuilder abuilder = new ArgumentBuilder();
diff --git a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocMapper.java b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocMapper.java
index 0b48fcc2..97e4c158 100644
--- a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocMapper.java
+++ b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocMapper.java
@@ -43,6 +43,8 @@
  */
 public class CollocMapper extends MapReduceBase implements Mapper<Text,StringTuple,GramKey,Gram> {
   
+  private static final byte[] EMPTY = new byte[0];
+  
   public static final String MAX_SHINGLE_SIZE = "maxShingleSize";
   public static final int DEFAULT_MAX_SHINGLE_SIZE = 2;
   
@@ -130,7 +132,6 @@ public void map(Text key, StringTuple value,
     } while (sf.incrementToken());
     
     try {
-      final byte[] empty = new byte[0];
       final GramKey gramKey = new GramKey();
       
       ngrams.forEachPair(new ObjectIntProcedure<String>() {
@@ -145,13 +146,13 @@ public boolean apply(String term, int frequency) {
               Gram head  = new Gram(term.substring(0, i), frequency, Gram.Type.HEAD);
               Gram tail  = new Gram(term.substring(i + 1), frequency, Gram.Type.TAIL);
               
-              gramKey.set(head, empty);
+              gramKey.set(head, EMPTY);
               collector.collect(gramKey, head);
               
               gramKey.set(head, ngram.getBytes());
               collector.collect(gramKey, ngram);
               
-              gramKey.set(tail, empty);
+              gramKey.set(tail, EMPTY);
               collector.collect(gramKey, tail);
               
               gramKey.set(tail, ngram.getBytes());
@@ -170,7 +171,7 @@ public boolean apply(String term, int frequency) {
         public boolean apply(String term, int frequency) {
           try {
             Gram unigram = new Gram(term, frequency, Gram.Type.UNIGRAM);
-            gramKey.set(unigram, empty);
+            gramKey.set(unigram, EMPTY);
             collector.collect(gramKey, unigram);
           } catch (IOException e) {
             throw new IllegalStateException(e);
diff --git a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocReducer.java b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocReducer.java
index 2342d702..2b86682c 100644
--- a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocReducer.java
+++ b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/CollocReducer.java
@@ -18,7 +18,6 @@
 package org.apache.mahout.utils.nlp.collocations.llr;
 
 import java.io.IOException;
-import java.util.HashMap;
 import java.util.Iterator;
 
 import org.apache.hadoop.mapred.JobConf;
@@ -107,13 +106,8 @@ else if (keyType == Gram.Type.HEAD || keyType == Gram.Type.TAIL) {
     }
   }
 
-  /** Sum frequencies for unigrams and deliver to the collector 
-   * 
-   * @param keyFirst
-   * @param values
-   * @param output
-   * @param reporter
-   * @throws IOException
+  /**
+   * Sum frequencies for unigrams and deliver to the collector
    */
   protected void processUnigram(GramKey key, Iterator<Gram> values,
       OutputCollector<Gram, Gram> output, Reporter reporter) throws IOException {
@@ -145,12 +139,6 @@ protected void processUnigram(GramKey key, Iterator<Gram> values,
    *  <p/>
    *  We end up calculating frequencies for ngrams for each sugram (head, tail) here, which is
    *  some extra work.
-   *  
-   * @param keyFirst
-   * @param values
-   * @param output
-   * @param reporter
-   * @throws IOException
    */
   protected void processSubgram(GramKey key, Iterator<Gram> values, 
       OutputCollector<Gram,Gram> output, Reporter reporter) throws IOException {
diff --git a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/GramKey.java b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/GramKey.java
index 0a60aa30..97f1c739 100644
--- a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/GramKey.java
+++ b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/GramKey.java
@@ -32,9 +32,9 @@
 public class GramKey extends BinaryComparable implements
     WritableComparable<BinaryComparable> {
 
-  int primaryLength;
-  int length;
-  byte[] bytes;
+  private int primaryLength;
+  private int length;
+  private byte[] bytes;
   
   public GramKey() {
     
@@ -123,11 +123,11 @@ public String getPrimaryString() {
     try {
       return Text.decode(bytes, 1, primaryLength-1);
     } catch (CharacterCodingException e) {
-      throw new RuntimeException("Should not have happened " + e.toString()); 
+      throw new IllegalStateException(e);
     }
   }
   
   public String toString() {
-    return '\'' + getPrimaryString() + "'[" + getType().x + "]";
+    return '\'' + getPrimaryString() + "'[" + getType().x + ']';
   }
 }
diff --git a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/GramKeyPartitioner.java b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/GramKeyPartitioner.java
index ce71d158..d7e89919 100644
--- a/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/GramKeyPartitioner.java
+++ b/lucene/mahout/trunk/utils/src/main/java/org/apache/mahout/utils/nlp/collocations/llr/GramKeyPartitioner.java
@@ -33,7 +33,7 @@ public static void setOffsets(Configuration conf, int left, int right) {
     conf.setInt(HASH_OFFSET_PROPERTY_NAME, left);
   }
   
-  int offset;
+  private int offset;
 
   @Override
   public int getPartition(GramKey key, Gram value, int numPartitions) {
