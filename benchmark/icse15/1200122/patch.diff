diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
index 7f5234f4..d83284c6 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.WordlistLoader;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 /**
@@ -64,7 +65,7 @@
 
   /**
    * The comment character in the stopwords file.  All lines prefixed with this will be ignored
-   * @deprecated use {@link WordlistLoader#getWordSet(File, String)} directly  
+   * @deprecated use {@link WordlistLoader#getWordSet(Reader, String, Version)} directly  
    */
   // TODO make this private 
   @Deprecated
@@ -159,7 +160,8 @@ public ArabicAnalyzer( Version matchVersion, Hashtable<?,?> stopwords ) {
    */
   @Deprecated
   public ArabicAnalyzer( Version matchVersion, File stopwords ) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet( stopwords, STOPWORDS_COMMENT));
+    this(matchVersion, WordlistLoader.getWordSet(IOUtils.getDecodingReader(stopwords,
+        IOUtils.CHARSET_UTF_8), STOPWORDS_COMMENT, matchVersion));
   }
 
   /**
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
index ac417df6..7c43a231 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
@@ -57,7 +57,7 @@
   /**
    * The comment character in the stopwords file. All lines prefixed with this
    * will be ignored
-   * @deprecated use {@link WordlistLoader#getWordSet(File, String)} directly
+   * @deprecated use {@link WordlistLoader#getWordSet(Reader, String, Version)} directly
    */
   //TODO make this private
   @Deprecated
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
index 3c5a76b1..0481e52d 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
@@ -37,6 +37,7 @@
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 /**
@@ -94,9 +95,8 @@
     
     static {
       try {
-        DEFAULT_STOP_SET = CharArraySet.unmodifiableSet(new CharArraySet(
-            Version.LUCENE_CURRENT, WordlistLoader.getWordSet(BrazilianAnalyzer.class, 
-                DEFAULT_STOPWORD_FILE, "#"), false));
+        DEFAULT_STOP_SET = WordlistLoader.getWordSet(IOUtils.getDecodingReader(BrazilianAnalyzer.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), "#", Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
@@ -171,7 +171,8 @@ public BrazilianAnalyzer(Version matchVersion, Map<?,?> stopwords) {
   @Deprecated
   public BrazilianAnalyzer(Version matchVersion, File stopwords)
       throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
+    this(matchVersion, WordlistLoader.getWordSet(
+        IOUtils.getDecodingReader(stopwords, IOUtils.CHARSET_UTF_8), matchVersion));
   }
 
 	/**
@@ -198,7 +199,8 @@ public void setStemExclusionTable( Map<?,?> exclusionlist ) {
 	 */
 	@Deprecated
 	public void setStemExclusionTable( File exclusionlist ) throws IOException {
-		excltable = WordlistLoader.getWordSet( exclusionlist );
+		excltable = WordlistLoader.getWordSet(
+		    IOUtils.getDecodingReader(exclusionlist, IOUtils.CHARSET_UTF_8), matchVersion);
 		setPreviousTokenStream(null); // force a new stemmer to be created
 	}
 
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
index c5dd3fc8..1de85af5 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
@@ -28,9 +28,11 @@
 import org.apache.lucene.analysis.WordlistLoader;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 import java.io.*;
+import java.nio.charset.Charset;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Set;
@@ -99,9 +101,8 @@
 	  
 	  static {
 	    try {
-	      DEFAULT_SET = CharArraySet.unmodifiableSet(new CharArraySet(
-	          Version.LUCENE_CURRENT, WordlistLoader.getWordSet(CzechAnalyzer.class, 
-	              DEFAULT_STOPWORD_FILE, "#"), false));
+	      DEFAULT_SET = WordlistLoader.getWordSet(IOUtils.getDecodingReader(CzechAnalyzer.class, 
+	          DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), "#", Version.LUCENE_CURRENT);
 	    } catch (IOException ex) {
 	      // default set should always be present as it is part of the
 	      // distribution (JAR)
@@ -192,14 +193,15 @@ public CzechAnalyzer(Version matchVersion, HashSet<?> stopwords) {
    */
   @Deprecated
   public CzechAnalyzer(Version matchVersion, File stopwords ) throws IOException {
-    this(matchVersion, (Set<?>)WordlistLoader.getWordSet( stopwords ));
+    this(matchVersion, (Set<?>)WordlistLoader.getWordSet(
+        IOUtils.getDecodingReader(stopwords, IOUtils.CHARSET_UTF_8), matchVersion));
 	}
 
     /**
      * Loads stopwords hash from resource stream (file, database...).
      * @param   wordfile    File containing the wordlist
      * @param   encoding    Encoding used (win-1250, iso-8859-2, ...), null for default system encoding
-     * @deprecated use {@link WordlistLoader#getWordSet(Reader, String) }
+     * @deprecated use {@link WordlistLoader#getWordSet(Reader, String, Version) }
      *             and {@link #CzechAnalyzer(Version, Set)} instead
      */
     // TODO extend StopwordAnalyzerBase once this method is gone!
@@ -207,20 +209,14 @@ public CzechAnalyzer(Version matchVersion, File stopwords ) throws IOException {
     public void loadStopWords( InputStream wordfile, String encoding ) {
         setPreviousTokenStream(null); // force a new stopfilter to be created
         if ( wordfile == null ) {
-            stoptable = Collections.emptySet();
+            stoptable = CharArraySet.EMPTY_SET;
             return;
         }
         try {
             // clear any previous table (if present)
-            stoptable = Collections.emptySet();
-
-            InputStreamReader isr;
-            if (encoding == null)
-                isr = new InputStreamReader(wordfile);
-            else
-                isr = new InputStreamReader(wordfile, encoding);
-
-            stoptable = WordlistLoader.getWordSet(isr);
+            stoptable = CharArraySet.EMPTY_SET;
+            stoptable = WordlistLoader.getWordSet(IOUtils.getDecodingReader(wordfile, 
+                encoding == null ? IOUtils.CHARSET_UTF_8 : Charset.forName(encoding)), matchVersion);
         } catch ( IOException e ) {
           // clear any previous table (if present)
           // TODO: throw IOException
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java
index 6c5ae269..1ad9f63d 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/da/DanishAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.DanishStemmer;
 
@@ -62,8 +63,8 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(SnowballFilter.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
index ac8f6e6c..c57876cf 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
@@ -39,6 +39,7 @@
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.German2Stemmer;
 
@@ -106,8 +107,8 @@
     private static final Set<?> DEFAULT_SET;
     static {
       try {
-        DEFAULT_SET = 
-          WordlistLoader.getSnowballWordSet(SnowballFilter.class, DEFAULT_STOPWORD_FILE);
+        DEFAULT_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
@@ -188,7 +189,8 @@ public GermanAnalyzer(Version matchVersion, Map<?,?> stopwords) {
    */
   @Deprecated
   public GermanAnalyzer(Version matchVersion, File stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
+    this(matchVersion, WordlistLoader.getWordSet(
+        IOUtils.getDecodingReader(stopwords, IOUtils.CHARSET_UTF_8), matchVersion));
   }
 
   /**
@@ -217,7 +219,8 @@ public void setStemExclusionTable(Map<?,?> exclusionlist) {
    */
   @Deprecated
   public void setStemExclusionTable(File exclusionlist) throws IOException {
-    exclusionSet = WordlistLoader.getWordSet(exclusionlist);
+    exclusionSet = WordlistLoader.getWordSet(IOUtils.getDecodingReader(exclusionlist,
+        IOUtils.CHARSET_UTF_8), matchVersion);
     setPreviousTokenStream(null); // force a new stemmer to be created
   }
 
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
index 149f3eb2..b338c944 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.SpanishStemmer;
 
@@ -62,8 +63,8 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(SnowballFilter.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
index 48cd6aaa..da69f69d 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
@@ -35,6 +35,7 @@
 import org.apache.lucene.analysis.ar.ArabicNormalizationFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 /**
@@ -134,7 +135,9 @@ public PersianAnalyzer(Version matchVersion, Hashtable<?, ?> stopwords) {
    */
   @Deprecated
   public PersianAnalyzer(Version matchVersion, File stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords, STOPWORDS_COMMENT));
+    this(matchVersion, WordlistLoader.getWordSet(
+        IOUtils.getDecodingReader(stopwords, IOUtils.CHARSET_UTF_8),
+        STOPWORDS_COMMENT, matchVersion));
   }
 
   /**
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java
index 94b545e3..8906cdb0 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fi/FinnishAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.FinnishStemmer;
 
@@ -62,8 +63,8 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(SnowballFilter.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
index 2177a402..ebd88e00 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
@@ -30,6 +30,7 @@
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;  // for javadoc
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 import java.io.File;
@@ -103,7 +104,7 @@
   /**
    * Contains words that should be indexed but not stemmed.
    */
-  private Set<?> excltable = Collections.<Object>emptySet();
+  private Set<?> excltable = CharArraySet.EMPTY_SET;
 
   /**
    * Returns an unmodifiable instance of the default stop-words set.
@@ -122,8 +123,8 @@
     static final Set<?> DEFAULT_STOP_SET;
     static {
       try {
-        DEFAULT_STOP_SET = 
-          WordlistLoader.getSnowballWordSet(SnowballFilter.class, DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+                DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
@@ -187,7 +188,8 @@ public FrenchAnalyzer(Version matchVersion, String... stopwords) {
    */
   @Deprecated
   public FrenchAnalyzer(Version matchVersion, File stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
+    this(matchVersion, WordlistLoader.getWordSet(IOUtils.getDecodingReader(stopwords,
+        IOUtils.CHARSET_UTF_8), matchVersion));
   }
 
   /**
@@ -217,7 +219,8 @@ public void setStemExclusionTable(Map<?,?> exclusionlist) {
    */
   @Deprecated
   public void setStemExclusionTable(File exclusionlist) throws IOException {
-    excltable = new HashSet<Object>(WordlistLoader.getWordSet(exclusionlist));
+    excltable = WordlistLoader.getWordSet(IOUtils.getDecodingReader(exclusionlist,
+        IOUtils.CHARSET_UTF_8), matchVersion);
     setPreviousTokenStream(null); // force a new stemmer to be created
   }
 
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java
index 0609cdd6..986ba54c 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/gl/GalicianAnalyzer.java
@@ -32,6 +32,7 @@
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.WordlistLoader;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 /**
@@ -60,12 +61,12 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getWordSet(GalicianAnalyzer.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getWordSet(IOUtils.getDecodingReader(GalicianAnalyzer.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
-        throw new RuntimeException("Unable to load default stopword set");
+        throw new RuntimeException("Unable to load default stopword set", ex);
       }
     }
   }
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java
index b8c827c7..aa4c4c88 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/hu/HungarianAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.HungarianStemmer;
 
@@ -62,8 +63,8 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(SnowballFilter.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
index 5f9acb5b..7eb32031 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
@@ -35,6 +35,7 @@
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.ItalianStemmer;
 
@@ -79,8 +80,8 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(SnowballFilter.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java
index 7578d3b4..da32926b 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/lv/LatvianAnalyzer.java
@@ -27,11 +27,13 @@
 import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.WordlistLoader;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 /**
@@ -60,8 +62,8 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getWordSet(LatvianAnalyzer.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getWordSet(IOUtils.getDecodingReader(LatvianAnalyzer.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
index 854dd038..58ef0a7b 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
@@ -18,6 +18,7 @@
  */
 
 import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.CharArrayMap;
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.KeywordMarkerFilter;
 import org.apache.lucene.analysis.LowerCaseFilter;
@@ -31,6 +32,7 @@
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;  // for javadoc
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 import java.io.File;
@@ -73,11 +75,20 @@
    * @deprecated use {@link #getDefaultStopSet()} instead
    */
   @Deprecated
-  public final static String[] DUTCH_STOP_WORDS = getDefaultStopSet().toArray(new String[0]);
+  public final static String[] DUTCH_STOP_WORDS;
   
   /** File containing default Dutch stopwords. */
   public final static String DEFAULT_STOPWORD_FILE = "dutch_stop.txt";
 
+  static {
+    Set<?> defaultStopSet =  getDefaultStopSet();
+    DUTCH_STOP_WORDS = new String[defaultStopSet.size()];
+    int i = 0;
+    for (Object object: defaultStopSet) {
+      DUTCH_STOP_WORDS[i++] = new String((char[])object);
+    } // what a hack!
+  }
+
   /**
    * Returns an unmodifiable instance of the default stop-words set.
    * @return an unmodifiable instance of the default stop-words set.
@@ -91,14 +102,15 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(SnowballFilter.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
         throw new RuntimeException("Unable to load default stopword set");
       }
     }
+    
   }
 
 
@@ -112,7 +124,7 @@
    */
   private Set<?> excltable = Collections.emptySet();
 
-  private Map<String, String> stemdict = new HashMap<String, String>();
+  private Map<Object,String>  stemdict = CharArrayMap.emptyMap();
   private final Version matchVersion;
 
   /**
@@ -122,6 +134,7 @@
    */
   public DutchAnalyzer(Version matchVersion) {
     this(matchVersion, DefaultSetHolder.DEFAULT_STOP_SET);
+    stemdict = new CharArrayMap<String>(matchVersion, 16, false);
     stemdict.put("fiets", "fiets"); //otherwise fiet
     stemdict.put("bromfiets", "bromfiets"); //otherwise bromfiet
     stemdict.put("ei", "eier");
@@ -171,7 +184,8 @@ public DutchAnalyzer(Version matchVersion, HashSet<?> stopwords) {
   public DutchAnalyzer(Version matchVersion, File stopwords) {
     // this is completely broken!
     try {
-      stoptable = org.apache.lucene.analysis.WordlistLoader.getWordSet(stopwords);
+      stoptable = WordlistLoader.getWordSet(IOUtils.getDecodingReader(stopwords,
+          IOUtils.CHARSET_UTF_8), matchVersion);
     } catch (IOException e) {
       // TODO: throw IOException
       throw new RuntimeException(e);
@@ -208,7 +222,9 @@ public void setStemExclusionTable(HashSet<?> exclusionlist) {
   @Deprecated
   public void setStemExclusionTable(File exclusionlist) {
     try {
-      excltable = org.apache.lucene.analysis.WordlistLoader.getWordSet(exclusionlist);
+      
+      excltable = WordlistLoader.getWordSet(IOUtils.getDecodingReader(exclusionlist,
+          IOUtils.CHARSET_UTF_8), matchVersion);
       setPreviousTokenStream(null); // force a new stemmer to be created
     } catch (IOException e) {
       // TODO: throw IOException
@@ -226,7 +242,8 @@ public void setStemExclusionTable(File exclusionlist) {
   @Deprecated
   public void setStemDictionary(File stemdictFile) {
     try {
-      stemdict = WordlistLoader.getStemDict(stemdictFile);
+      stemdict = WordlistLoader.getStemDict(IOUtils.getDecodingReader(stemdictFile,
+          IOUtils.CHARSET_UTF_8), new CharArrayMap<String>(matchVersion, 16, false));
       setPreviousTokenStream(null); // force a new stemmer to be created
     } catch (IOException e) {
       // TODO: throw IOException
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java
index fe6cd2bb..5b5eb85c 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/no/NorwegianAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.NorwegianStemmer;
 
@@ -62,8 +63,8 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(SnowballFilter.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
index 47ce134d..781abf3d 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.PortugueseStemmer;
 
@@ -62,8 +63,8 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(SnowballFilter.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
index b28e61ca..ecce2221 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
@@ -35,6 +35,7 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.WordlistLoader;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 /**
@@ -85,12 +86,12 @@
       
       static {
         try {
-          DEFAULT_STOP_SET = 
-            WordlistLoader.getSnowballWordSet(SnowballFilter.class, DEFAULT_STOPWORD_FILE);
+          DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+              DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
         } catch (IOException ex) {
           // default set should always be present as it is part of the
           // distribution (JAR)
-          throw new RuntimeException("Unable to load default stopword set");
+          throw new RuntimeException("Unable to load default stopword set", ex);
         }
       }
     }
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java
index 44fc031c..118d6f62 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sv/SwedishAnalyzer.java
@@ -33,6 +33,7 @@
 import org.apache.lucene.analysis.snowball.SnowballFilter;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.tartarus.snowball.ext.SwedishStemmer;
 
@@ -62,8 +63,8 @@
 
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(SnowballFilter.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getSnowballWordSet(IOUtils.getDecodingReader(SnowballFilter.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java
index bd8e00e4..7d178187 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SmartChineseAnalyzer.java
@@ -18,8 +18,6 @@
 package org.apache.lucene.analysis.cn.smart;
 
 import java.io.IOException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
 import java.io.Reader;
 import java.util.Collections;
 import java.util.Set;
@@ -32,6 +30,8 @@
 import org.apache.lucene.analysis.WordlistLoader;
 import org.apache.lucene.analysis.cn.smart.SentenceTokenizer;
 import org.apache.lucene.analysis.cn.smart.WordTokenFilter;
+import org.apache.lucene.analysis.CharArraySet;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 /**
@@ -66,7 +66,7 @@
    * Returns an unmodifiable instance of the default stop-words set.
    * @return an unmodifiable instance of the default stop-words set.
    */
-  public static Set<String> getDefaultStopSet(){
+  public static CharArraySet getDefaultStopSet(){
     return DefaultSetHolder.DEFAULT_STOP_SET;
   }
   
@@ -75,7 +75,7 @@
    * accesses the static final set the first time.;
    */
   private static class DefaultSetHolder {
-    static final Set<String> DEFAULT_STOP_SET;
+    static final CharArraySet DEFAULT_STOP_SET;
 
     static {
       try {
@@ -87,16 +87,12 @@
       }
     }
 
-    static Set<String> loadDefaultStopWordSet() throws IOException {
-      InputStream stream = SmartChineseAnalyzer.class
-          .getResourceAsStream(DEFAULT_STOPWORD_FILE);
-      try {
-        InputStreamReader reader = new InputStreamReader(stream, "UTF-8");
+    static CharArraySet loadDefaultStopWordSet() throws IOException {
         // make sure it is unmodifiable as we expose it in the outer class
-        return Collections.unmodifiableSet(WordlistLoader.getWordSet(reader, STOPWORD_FILE_COMMENT));
-      } finally {
-        stream.close();
-      }
+      return org.apache.lucene.analysis.CharArraySet.unmodifiableSet(WordlistLoader.getWordSet(IOUtils
+          .getDecodingReader(SmartChineseAnalyzer.class, DEFAULT_STOPWORD_FILE,
+              IOUtils.CHARSET_UTF_8), STOPWORD_FILE_COMMENT,
+          Version.LUCENE_CURRENT));
     }
   }
 
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/stempel/src/java/org/apache/lucene/analysis/pl/PolishAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/stempel/src/java/org/apache/lucene/analysis/pl/PolishAnalyzer.java
index c4553a54..281529ad 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/stempel/src/java/org/apache/lucene/analysis/pl/PolishAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/analyzers/stempel/src/java/org/apache/lucene/analysis/pl/PolishAnalyzer.java
@@ -34,6 +34,7 @@
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.stempel.StempelStemmer;
 import org.apache.lucene.analysis.stempel.StempelFilter;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 import org.egothor.stemmer.Trie;
 
@@ -68,8 +69,8 @@
     
     static {
       try {
-        DEFAULT_STOP_SET = WordlistLoader.getWordSet(PolishAnalyzer.class, 
-            DEFAULT_STOPWORD_FILE);
+        DEFAULT_STOP_SET = WordlistLoader.getWordSet(IOUtils.getDecodingReader(PolishAnalyzer.class, 
+            DEFAULT_STOPWORD_FILE, IOUtils.CHARSET_UTF_8), "#", Version.LUCENE_CURRENT);
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/StopAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/StopAnalyzer.java
index 387281a9..9bd6e756 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/StopAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/StopAnalyzer.java
@@ -24,6 +24,7 @@
 import java.util.Set;
 import java.util.List;
 
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 /** Filters {@link LetterTokenizer} with {@link LowerCaseFilter} and {@link StopFilter}.
@@ -74,19 +75,20 @@ public StopAnalyzer(Version matchVersion, Set<?> stopWords) {
   }
 
   /** Builds an analyzer with the stop words from the given file.
-   * @see WordlistLoader#getWordSet(File)
+   * @see WordlistLoader#getWordSet(Reader, Version)
    * @param matchVersion See <a href="#version">above</a>
    * @param stopwordsFile File to load stop words from */
   public StopAnalyzer(Version matchVersion, File stopwordsFile) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwordsFile));
+    this(matchVersion, WordlistLoader.getWordSet(IOUtils.getDecodingReader(stopwordsFile,
+        IOUtils.CHARSET_UTF_8), matchVersion));
   }
 
   /** Builds an analyzer with the stop words from the given reader.
-   * @see WordlistLoader#getWordSet(Reader)
+   * @see WordlistLoader#getWordSet(Reader, Version)
    * @param matchVersion See <a href="#version">above</a>
    * @param stopwords Reader to load stop words from */
   public StopAnalyzer(Version matchVersion, Reader stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
+    this(matchVersion, WordlistLoader.getWordSet(stopwords, matchVersion));
   }
 
   /**
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/StopwordAnalyzerBase.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/StopwordAnalyzerBase.java
index 4e682120..48dae7da 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/StopwordAnalyzerBase.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/StopwordAnalyzerBase.java
@@ -17,12 +17,15 @@
 
 package org.apache.lucene.analysis;
 
+import java.io.File;
 import java.io.IOException;
+import java.io.Reader;
 import java.util.Set;
 
 import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.ReusableAnalyzerBase;
 import org.apache.lucene.analysis.WordlistLoader;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 /**
@@ -95,11 +98,59 @@ protected StopwordAnalyzerBase(final Version version) {
   protected static CharArraySet loadStopwordSet(final boolean ignoreCase,
       final Class<? extends ReusableAnalyzerBase> aClass, final String resource,
       final String comment) throws IOException {
-    final Set<String> wordSet = WordlistLoader.getWordSet(aClass, resource,
-        comment);
-    final CharArraySet set = new CharArraySet(Version.LUCENE_31, wordSet.size(), ignoreCase);
-    set.addAll(wordSet);
-    return set;
+    Reader reader = null;
+    try {
+      reader = IOUtils.getDecodingReader(aClass.getResourceAsStream(resource), IOUtils.CHARSET_UTF_8);
+      return WordlistLoader.getWordSet(reader, comment, new CharArraySet(Version.LUCENE_31, 16, ignoreCase));
+    } finally {
+      IOUtils.close(reader);
   }
 
+  }
+  
+  /**
+   * Creates a CharArraySet from a file.
+   * 
+   * @param stopwords
+   *          the stopwords file to load
+   * 
+   * @param matchVersion
+   *          the Lucene version for cross version compatibility
+   * @return a CharArraySet containing the distinct stopwords from the given
+   *         file
+   * @throws IOException
+   *           if loading the stopwords throws an {@link IOException}
+   */
+  protected static CharArraySet loadStopwordSet(File stopwords,
+      Version matchVersion) throws IOException {
+    Reader reader = null;
+    try {
+      reader = IOUtils.getDecodingReader(stopwords, IOUtils.CHARSET_UTF_8);
+      return WordlistLoader.getWordSet(reader, matchVersion);
+    } finally {
+      IOUtils.close(reader);
+    }
+  }
+  
+  /**
+   * Creates a CharArraySet from a file.
+   * 
+   * @param stopwords
+   *          the stopwords reader to load
+   * 
+   * @param matchVersion
+   *          the Lucene version for cross version compatibility
+   * @return a CharArraySet containing the distinct stopwords from the given
+   *         reader
+   * @throws IOException
+   *           if loading the stopwords throws an {@link IOException}
+   */
+  protected static CharArraySet loadStopwordSet(Reader stopwords,
+      Version matchVersion) throws IOException {
+    try {
+      return WordlistLoader.getWordSet(stopwords, matchVersion);
+    } finally {
+      IOUtils.close(stopwords);
+    }
+  }
 }
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/WordlistLoader.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/WordlistLoader.java
index ac8a2248..42289090 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/WordlistLoader.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/WordlistLoader.java
@@ -18,165 +18,91 @@
  */
 
 import java.io.BufferedReader;
-import java.io.File;
-import java.io.FileReader;
 import java.io.IOException;
-import java.io.InputStreamReader;
 import java.io.Reader;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Set;
+
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.Version;
 
 /**
  * Loader for text files that represent a list of stopwords.
- */
-public class WordlistLoader {
- 
-  /**
-   * Loads a text file associated with a given class (See
-   * {@link Class#getResourceAsStream(String)}) and adds every line as an entry
-   * to a {@link Set} (omitting leading and trailing whitespace). Every line of
-   * the file should contain only one word. The words need to be in lower-case if
-   * you make use of an Analyzer which uses LowerCaseFilter (like
-   * StandardAnalyzer).
    * 
-   * @param aClass
-   *          a class that is associated with the given stopwordResource
-   * @param stopwordResource
-   *          name of the resource file associated with the given class
-   * @return a {@link Set} with the file's words
+ * @see IOUtils to obtain {@link Reader} instances
+ * @lucene.internal
    */
-  public static Set<String> getWordSet(Class<?> aClass, String stopwordResource)
-      throws IOException {
-    final Reader reader = new BufferedReader(new InputStreamReader(aClass
-        .getResourceAsStream(stopwordResource), "UTF-8"));
-    try {
-      return getWordSet(reader);
-    } finally {
-      reader.close();
-    }
-  }
+public class WordlistLoader {
   
-  /**
-   * Loads a text file associated with a given class (See
-   * {@link Class#getResourceAsStream(String)}) and adds every line as an entry
-   * to a {@link Set} (omitting leading and trailing whitespace). Every line of
-   * the file should contain only one word. The words need to be in lower-case if
-   * you make use of an Analyzer which uses LowerCaseFilter (like
-   * StandardAnalyzer).
-   * 
-   * @param aClass
-   *          a class that is associated with the given stopwordResource
-   * @param stopwordResource
-   *          name of the resource file associated with the given class
-   * @param comment
-   *          the comment string to ignore
-   * @return a {@link Set} with the file's words
-   */
-  public static Set<String> getWordSet(Class<?> aClass,
-      String stopwordResource, String comment) throws IOException {
-    final Reader reader = new BufferedReader(new InputStreamReader(aClass
-        .getResourceAsStream(stopwordResource), "UTF-8"));
-    try {
-      return getWordSet(reader, comment);
-    } finally {
-      reader.close();
-    }
-  }
+  private static final int INITITAL_CAPACITY = 16;
   
   /**
-   * Loads a text file and adds every line as an entry to a HashSet (omitting
-   * leading and trailing whitespace). Every line of the file should contain only
+   * Reads lines from a Reader and adds every line as an entry to a CharArraySet (omitting
+   * leading and trailing whitespace). Every line of the Reader should contain only
    * one word. The words need to be in lowercase if you make use of an
    * Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
    *
-   * @param wordfile File containing the wordlist
-   * @return A HashSet with the file's words
+   * @param reader Reader containing the wordlist
+   * @param result the {@link CharArraySet} to fill with the readers words
+   * @return the given {@link CharArraySet} with the reader's words
    */
-  public static HashSet<String> getWordSet(File wordfile) throws IOException {
-    FileReader reader = null;
+  public static CharArraySet getWordSet(Reader reader, CharArraySet result) throws IOException {
+    BufferedReader br = null;
     try {
-      reader = new FileReader(wordfile);
-      return getWordSet(reader);
+      br = getBufferedReader(reader);
+      String word = null;
+      while ((word = br.readLine()) != null) {
+        result.add(word.trim());
+      }
     }
     finally {
-      if (reader != null)
-        reader.close();
+      IOUtils.close(br);
     }
+    return result;
   }
 
   /**
-   * Loads a text file and adds every non-comment line as an entry to a HashSet (omitting
-   * leading and trailing whitespace). Every line of the file should contain only
+   * Reads lines from a Reader and adds every line as an entry to a CharArraySet (omitting
+   * leading and trailing whitespace). Every line of the Reader should contain only
    * one word. The words need to be in lowercase if you make use of an
    * Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
    *
-   * @param wordfile File containing the wordlist
-   * @param comment The comment string to ignore
-   * @return A HashSet with the file's words
+   * @param reader Reader containing the wordlist
+   * @param matchVersion the Lucene {@link Version}
+   * @return A {@link CharArraySet} with the reader's words
    */
-  public static HashSet<String> getWordSet(File wordfile, String comment) throws IOException {
-    FileReader reader = null;
-    try {
-      reader = new FileReader(wordfile);
-      return getWordSet(reader, comment);
-    }
-    finally {
-      if (reader != null)
-        reader.close();
+  public static CharArraySet getWordSet(Reader reader, Version matchVersion) throws IOException {
+    return getWordSet(reader, new CharArraySet(matchVersion, INITITAL_CAPACITY, false));
     }
-  }
-
 
   /**
-   * Reads lines from a Reader and adds every line as an entry to a HashSet (omitting
+   * Reads lines from a Reader and adds every non-comment line as an entry to a CharArraySet (omitting
    * leading and trailing whitespace). Every line of the Reader should contain only
    * one word. The words need to be in lowercase if you make use of an
    * Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
    *
    * @param reader Reader containing the wordlist
-   * @return A HashSet with the reader's words
+   * @param comment The string representing a comment.
+   * @param matchVersion the Lucene {@link Version}
+   * @return A CharArraySet with the reader's words
    */
-  public static HashSet<String> getWordSet(Reader reader) throws IOException {
-    final HashSet<String> result = new HashSet<String>();
-    BufferedReader br = null;
-    try {
-      if (reader instanceof BufferedReader) {
-        br = (BufferedReader) reader;
-      } else {
-        br = new BufferedReader(reader);
-      }
-      String word = null;
-      while ((word = br.readLine()) != null) {
-        result.add(word.trim());
-      }
-    }
-    finally {
-      if (br != null)
-        br.close();
-    }
-    return result;
+  public static CharArraySet getWordSet(Reader reader, String comment, Version matchVersion) throws IOException {
+    return getWordSet(reader, comment, new CharArraySet(matchVersion, INITITAL_CAPACITY, false));
   }
 
   /**
-   * Reads lines from a Reader and adds every non-comment line as an entry to a HashSet (omitting
+   * Reads lines from a Reader and adds every non-comment line as an entry to a CharArraySet (omitting
    * leading and trailing whitespace). Every line of the Reader should contain only
    * one word. The words need to be in lowercase if you make use of an
    * Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
    *
    * @param reader Reader containing the wordlist
    * @param comment The string representing a comment.
-   * @return A HashSet with the reader's words
+   * @param result the {@link CharArraySet} to fill with the readers words
+   * @return the given {@link CharArraySet} with the reader's words
    */
-  public static HashSet<String> getWordSet(Reader reader, String comment) throws IOException {
-    final HashSet<String> result = new HashSet<String>();
+  public static CharArraySet getWordSet(Reader reader, String comment, CharArraySet result) throws IOException {
     BufferedReader br = null;
     try {
-      if (reader instanceof BufferedReader) {
-        br = (BufferedReader) reader;
-      } else {
-        br = new BufferedReader(reader);
-      }
+      br = getBufferedReader(reader);
       String word = null;
       while ((word = br.readLine()) != null) {
         if (word.startsWith(comment) == false){
@@ -185,34 +111,11 @@
       }
     }
     finally {
-      if (br != null)
-        br.close();
+      IOUtils.close(br);
     }
     return result;
   }
 
-  /**
-   * Loads a text file in Snowball format associated with a given class (See
-   * {@link Class#getResourceAsStream(String)}) and adds all words as entries to
-   * a {@link Set}. The words need to be in lower-case if you make use of an
-   * Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
-   * 
-   * @param aClass a class that is associated with the given stopwordResource
-   * @param stopwordResource name of the resource file associated with the given
-   *          class
-   * @return a {@link Set} with the file's words
-   * @see #getSnowballWordSet(Reader)
-   */
-  public static Set<String> getSnowballWordSet(Class<?> aClass,
-      String stopwordResource) throws IOException {
-    final Reader reader = new BufferedReader(new InputStreamReader(aClass
-        .getResourceAsStream(stopwordResource), "UTF-8"));
-    try {
-      return getSnowballWordSet(reader);
-    } finally {
-      reader.close();
-    }
-  }
   
   /**
    * Reads stopwords from a stopword list in Snowball format.
@@ -226,18 +129,14 @@
    * </p>
    * 
    * @param reader Reader containing a Snowball stopword list
-   * @return A Set with the reader's words
+   * @param result the {@link CharArraySet} to fill with the readers words
+   * @return the given {@link CharArraySet} with the reader's words
    */
-  public static Set<String> getSnowballWordSet(Reader reader)
+  public static CharArraySet getSnowballWordSet(Reader reader, CharArraySet result)
       throws IOException {
-    final Set<String> result = new HashSet<String>();
     BufferedReader br = null;
     try {
-      if (reader instanceof BufferedReader) {
-        br = (BufferedReader) reader;
-      } else {
-        br = new BufferedReader(reader);
-      }
+      br = getBufferedReader(reader);
       String line = null;
       while ((line = br.readLine()) != null) {
         int comment = line.indexOf('|');
@@ -247,11 +146,30 @@
           if (words[i].length() > 0) result.add(words[i]);
       }
     } finally {
-      if (br != null) br.close();
+      IOUtils.close(br);
     }
     return result;
   }
 
+  /**
+   * Reads stopwords from a stopword list in Snowball format.
+   * <p>
+   * The snowball format is the following:
+   * <ul>
+   * <li>Lines may contain multiple words separated by whitespace.
+   * <li>The comment character is the vertical line (&#124;).
+   * <li>Lines may contain trailing comments.
+   * </ul>
+   * </p>
+   * 
+   * @param reader Reader containing a Snowball stopword list
+   * @param matchVersion the Lucene {@link Version}
+   * @return A {@link CharArraySet} with the reader's words
+   */
+  public static CharArraySet getSnowballWordSet(Reader reader, Version matchVersion) throws IOException {
+    return getSnowballWordSet(reader, new CharArraySet(matchVersion, INITITAL_CAPACITY, false));
+  }
+
 
   /**
    * Reads a stem dictionary. Each line contains:
@@ -261,24 +179,24 @@
    * @return stem dictionary that overrules the stemming algorithm
    * @throws IOException 
    */
-  public static HashMap<String, String> getStemDict(File wordstemfile) throws IOException {
-    if (wordstemfile == null)
-      throw new NullPointerException("wordstemfile may not be null");
-    final HashMap<String, String> result = new HashMap<String,String>();
+  public static CharArrayMap<String> getStemDict(Reader reader, CharArrayMap<String> result) throws IOException {
     BufferedReader br = null;
-    
     try {
-      br = new BufferedReader(new FileReader(wordstemfile));
+      br = getBufferedReader(reader);
       String line;
       while ((line = br.readLine()) != null) {
         String[] wordstem = line.split("\t", 2);
         result.put(wordstem[0], wordstem[1]);
       }
     } finally {
-      if(br != null)
-        br.close();
+      IOUtils.close(br);
     }
     return result;
   }
 
+  private static BufferedReader getBufferedReader(Reader reader) {
+    return (reader instanceof BufferedReader) ? (BufferedReader) reader
+        : new BufferedReader(reader);
+  }
+  
 }
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
index bd3d796f..c5560169 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
@@ -23,6 +23,7 @@
 import org.apache.lucene.analysis.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.WordlistLoader;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 import java.io.File;
@@ -87,21 +88,22 @@ public ClassicAnalyzer(Version matchVersion) {
   }
 
   /** Builds an analyzer with the stop words from the given file.
-   * @see WordlistLoader#getWordSet(File)
+   * @see WordlistLoader#getWordSet(Reader, Version)
    * @param matchVersion Lucene version to match See {@link
    * <a href="#version">above</a>}
    * @param stopwords File to read stop words from */
   public ClassicAnalyzer(Version matchVersion, File stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
+    this(matchVersion, WordlistLoader.getWordSet(IOUtils.getDecodingReader(stopwords,
+        IOUtils.CHARSET_UTF_8), matchVersion));
   }
 
   /** Builds an analyzer with the stop words from the given reader.
-   * @see WordlistLoader#getWordSet(Reader)
+   * @see WordlistLoader#getWordSet(Reader, Version)
    * @param matchVersion Lucene version to match See {@link
    * <a href="#version">above</a>}
    * @param stopwords Reader to read stop words from */
   public ClassicAnalyzer(Version matchVersion, Reader stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
+    this(matchVersion, WordlistLoader.getWordSet(stopwords, matchVersion));
   }
 
   /**
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
index eaec2d45..3d6d1b8b 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
@@ -18,6 +18,7 @@
  */
 
 import org.apache.lucene.analysis.*;
+import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.Version;
 
 import java.io.File;
@@ -83,21 +84,22 @@ public StandardAnalyzer(Version matchVersion) {
   }
 
   /** Builds an analyzer with the stop words from the given file.
-   * @see WordlistLoader#getWordSet(File)
+   * @see WordlistLoader#getWordSet(Reader, Version)
    * @param matchVersion Lucene version to match See {@link
    * <a href="#version">above</a>}
    * @param stopwords File to read stop words from */
   public StandardAnalyzer(Version matchVersion, File stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
+    this(matchVersion, WordlistLoader.getWordSet(IOUtils.getDecodingReader(stopwords,
+        IOUtils.CHARSET_UTF_8), matchVersion));
   }
 
   /** Builds an analyzer with the stop words from the given reader.
-   * @see WordlistLoader#getWordSet(Reader)
+   * @see WordlistLoader#getWordSet(Reader, Version)
    * @param matchVersion Lucene version to match See {@link
    * <a href="#version">above</a>}
    * @param stopwords Reader to read stop words from */
   public StandardAnalyzer(Version matchVersion, Reader stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
+    this(matchVersion, WordlistLoader.getWordSet(stopwords, matchVersion));
   }
 
   /**
diff --git a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/IOUtils.java b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/IOUtils.java
index 87f6c3e3..8206e1fa 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/IOUtils.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/java/org/apache/lucene/util/IOUtils.java
@@ -30,15 +30,35 @@
  * limitations under the License.
  */
 
+import java.io.BufferedReader;
 import java.io.Closeable;
+import java.io.File;
+import java.io.FileInputStream;
 import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.Reader;
 import java.lang.reflect.Method;
+import java.nio.charset.Charset;
+import java.nio.charset.CharsetDecoder;
+import java.nio.charset.CodingErrorAction;
 
 /** This class emulates the new Java 7 "Try-With-Resources" statement.
  * Remove once Lucene is on Java 7.
  * @lucene.internal */
 public final class IOUtils {
 
+  /**
+   * UTF-8 charset string
+   * @see Charset#forName(String)
+   */
+  public static final String UTF_8 = "UTF-8";
+  
+  /**
+   * UTF-8 {@link Charset} instance to prevent repeated
+   * {@link Charset#forName(String)} lookups
+   */
+  public static final Charset CHARSET_UTF_8 = Charset.forName("UTF-8");
   private IOUtils() {} // no instance
 
   /**
@@ -234,4 +254,83 @@ private static final void addSuppressed(Throwable exception, Throwable suppresse
     }
   }
 
+  /**
+   * Wrapping the given {@link InputStream} in a reader using a {@link CharsetDecoder}.
+   * Unlike Java's defaults this reader will throw an exception if your it detects 
+   * the read charset doesn't match the expected {@link Charset}. 
+   * <p>
+   * Decoding readers are useful to load configuration files, stopword lists or synonym files
+   * to detect character set problems. However, its not recommended to use as a common purpose 
+   * reader.
+   * 
+   * @param stream the stream to wrap in a reader
+   * @param charSet the expected charset
+   * @return a wrapping reader
+   */
+  public static Reader getDecodingReader(InputStream stream, Charset charSet) {
+    final CharsetDecoder charSetDecoder = charSet.newDecoder()
+        .onMalformedInput(CodingErrorAction.REPORT)
+        .onUnmappableCharacter(CodingErrorAction.REPORT);
+    return new BufferedReader(new InputStreamReader(stream, charSetDecoder));
+  }
+  
+  /**
+   * Opens a Reader for the given {@link File} using a {@link CharsetDecoder}.
+   * Unlike Java's defaults this reader will throw an exception if your it detects 
+   * the read charset doesn't match the expected {@link Charset}. 
+   * <p>
+   * Decoding readers are useful to load configuration files, stopword lists or synonym files
+   * to detect character set problems. However, its not recommended to use as a common purpose 
+   * reader.
+   * @param file the file to open a reader on
+   * @param charSet the expected charset
+   * @return a reader to read the given file
+   */
+  public static Reader getDecodingReader(File file, Charset charSet) throws IOException {
+    FileInputStream stream = null;
+    boolean success = false;
+    try {
+      stream = new FileInputStream(file);
+      final Reader reader = getDecodingReader(stream, charSet);
+      success = true;
+      return reader;
+
+    } finally {
+      if (!success) {
+        IOUtils.close(stream);
+      }
+    }
+  }
+
+  /**
+   * Opens a Reader for the given resource using a {@link CharsetDecoder}.
+   * Unlike Java's defaults this reader will throw an exception if your it detects 
+   * the read charset doesn't match the expected {@link Charset}. 
+   * <p>
+   * Decoding readers are useful to load configuration files, stopword lists or synonym files
+   * to detect character set problems. However, its not recommended to use as a common purpose 
+   * reader.
+   * @param clazz the class used to locate the resource
+   * @param resource the resource name to load
+   * @param charSet the expected charset
+   * @return a reader to read the given file
+   * 
+   */
+  public static Reader getDecodingReader(Class<?> clazz, String resource, Charset charSet) throws IOException {
+    InputStream stream = null;
+    boolean success = false;
+    try {
+      stream = clazz
+      .getResourceAsStream(resource);
+      final Reader reader = getDecodingReader(stream, charSet);
+      success = true;
+      return reader;
+    } finally {
+      if (!success) {
+        IOUtils.close(stream);
+      }
+    }
+  }
+
+
 }
diff --git a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/analysis/TestCharArraySet.java b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/analysis/TestCharArraySet.java
index e363f345..b1825cc6 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/analysis/TestCharArraySet.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/analysis/TestCharArraySet.java
@@ -66,7 +66,7 @@ public void testRehash() throws Exception {
   public void testNonZeroOffset() {
     String[] words={"Hello","World","this","is","a","test"};
     char[] findme="xthisy".toCharArray();   
-    CharArraySet set=new CharArraySet(TEST_VERSION_CURRENT, 10,true);
+    CharArraySet set= new CharArraySet(TEST_VERSION_CURRENT, 10, true);
     set.addAll(Arrays.asList(words));
     assertTrue(set.contains(findme, 1, 4));
     assertTrue(set.contains(new String(findme,1,4)));
diff --git a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/TestWordlistLoader.java b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/TestWordlistLoader.java
index 5a8a89ce..7ea4ab87 100644
--- a/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/TestWordlistLoader.java
+++ b/lucene/dev/branches/branch_3x/lucene/src/test/org/apache/lucene/index/TestWordlistLoader.java
@@ -33,33 +33,32 @@
 import java.io.BufferedReader;
 import java.io.IOException;
 import java.io.StringReader;
-import java.util.HashSet;
-import java.util.Set;
 
 import org.apache.lucene.util.LuceneTestCase;
 
+import org.apache.lucene.analysis.CharArraySet;
 import org.apache.lucene.analysis.WordlistLoader;
 
 public class TestWordlistLoader extends LuceneTestCase {
 
   public void testWordlistLoading() throws IOException {
     String s = "ONE\n  two \nthree";
-    HashSet<String> wordSet1 = WordlistLoader.getWordSet(new StringReader(s));
+    CharArraySet wordSet1 = WordlistLoader.getWordSet(new StringReader(s), TEST_VERSION_CURRENT);
     checkSet(wordSet1);
-    HashSet<String> wordSet2 = WordlistLoader.getWordSet(new BufferedReader(new StringReader(s)));
+    CharArraySet wordSet2 = WordlistLoader.getWordSet(new BufferedReader(new StringReader(s)), TEST_VERSION_CURRENT);
     checkSet(wordSet2);
   }
 
   public void testComments() throws Exception {
     String s = "ONE\n  two \nthree\n#comment";
-    HashSet<String> wordSet1 = WordlistLoader.getWordSet(new StringReader(s), "#");
+    CharArraySet wordSet1 = WordlistLoader.getWordSet(new StringReader(s), "#", TEST_VERSION_CURRENT);
     checkSet(wordSet1);
     assertFalse(wordSet1.contains("#comment"));
     assertFalse(wordSet1.contains("comment"));
   }
 
 
-  private void checkSet(HashSet<String> wordset) {
+  private void checkSet(CharArraySet wordset) {
     assertEquals(3, wordset.size());
     assertTrue(wordset.contains("ONE"));		// case is not modified
     assertTrue(wordset.contains("two"));		// surrounding whitespace is removed
@@ -81,7 +80,7 @@ public void testSnowballListLoading() throws IOException {
       "   two   \n" + // stopword with leading/trailing space
       " three   four five \n" + // multiple stopwords
       "six seven | comment\n"; //multiple stopwords + comment
-    Set<String> wordset = WordlistLoader.getSnowballWordSet(new StringReader(s));
+    CharArraySet wordset = WordlistLoader.getSnowballWordSet(new StringReader(s), TEST_VERSION_CURRENT);
     assertEquals(7, wordset.size());
     assertTrue(wordset.contains("ONE"));
     assertTrue(wordset.contains("two"));
