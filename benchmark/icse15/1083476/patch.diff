diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/AbstractCluster.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/AbstractCluster.java
index afa6456e..f6669863 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/AbstractCluster.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/AbstractCluster.java
@@ -21,9 +21,13 @@
 import java.io.DataOutput;
 import java.io.IOException;
 import java.lang.reflect.Type;
+import java.util.Collection;
+import java.util.Collections;
 import java.util.Iterator;
 import java.util.Locale;
 
+import org.apache.hadoop.conf.Configuration;
+import org.apache.mahout.common.parameters.Parameter;
 import org.apache.mahout.math.JsonVectorAdapter;
 import org.apache.mahout.math.NamedVector;
 import org.apache.mahout.math.RandomAccessSparseVector;
@@ -66,6 +70,21 @@ protected AbstractCluster(Vector center2, Vector radius2, int id2) {
     this.id = id2;
   }
 
+  @Override
+  public void configure(Configuration job) {
+    // nothing to do
+  }
+  
+  @Override
+  public Collection<Parameter<?>> getParameters() {
+    return Collections.emptyList();
+  }
+  
+  @Override
+  public void createParameters(String prefix, Configuration jobConf) {
+    // nothing to do
+  }
+
   /**
    * @param id the id to set
    */
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/Cluster.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/Cluster.java
index da784b92..27a5dc6d 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/Cluster.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/Cluster.java
@@ -15,6 +15,7 @@
  */
 package org.apache.mahout.clustering;
 
+import org.apache.mahout.common.parameters.Parametered;
 import org.apache.mahout.math.Vector;
 import org.apache.mahout.math.VectorWritable;
 
@@ -23,7 +24,7 @@
  * attributes that are common across all clustering implementations
  * 
  */
-public interface Cluster extends Model<VectorWritable> {
+public interface Cluster extends Model<VectorWritable>, Parametered {
   
   // default directory for all clustered points
   String CLUSTERED_POINTS_DIR = "clusteredPoints";
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/DistanceMeasureCluster.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/DistanceMeasureCluster.java
index a35edcd9..a8d9d5d9 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/DistanceMeasureCluster.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/DistanceMeasureCluster.java
@@ -20,8 +20,12 @@
 import java.io.DataInput;
 import java.io.DataOutput;
 import java.io.IOException;
+import java.util.Collection;
+import java.util.Collections;
 
+import org.apache.hadoop.conf.Configuration;
 import org.apache.mahout.common.distance.DistanceMeasure;
+import org.apache.mahout.common.parameters.Parameter;
 import org.apache.mahout.math.Vector;
 import org.apache.mahout.math.VectorWritable;
 
@@ -37,6 +41,23 @@ public DistanceMeasureCluster(Vector point, int id, DistanceMeasure measure) {
   public DistanceMeasureCluster() {
   }
 
+  @Override
+  public void configure(Configuration job) {
+    if (getMeasure() != null) {
+      getMeasure().configure(job);
+    }
+  }
+  
+  @Override
+  public Collection<Parameter<?>> getParameters() {
+    return Collections.emptyList();
+  }
+  
+  @Override
+  public void createParameters(String prefix, Configuration jobConf) {
+    // nothing to do
+  }
+
   @Override
   public void readFields(DataInput in) throws IOException {
     String dm = in.readUTF();
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/JsonDistanceMeasureAdapter.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/JsonDistanceMeasureAdapter.java
index 7712b9ad..c2df6371 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/JsonDistanceMeasureAdapter.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/JsonDistanceMeasureAdapter.java
@@ -19,7 +19,9 @@
 import java.lang.reflect.Type;
 
 import org.apache.mahout.common.distance.DistanceMeasure;
+import org.apache.mahout.math.JsonMatrixAdapter;
 import org.apache.mahout.math.JsonVectorAdapter;
+import org.apache.mahout.math.Matrix;
 import org.apache.mahout.math.Vector;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -42,6 +44,7 @@
   public JsonElement serialize(DistanceMeasure src, Type typeOfSrc, JsonSerializationContext context) {
     GsonBuilder builder = new GsonBuilder();
     builder.registerTypeAdapter(Vector.class, new JsonVectorAdapter());
+    builder.registerTypeAdapter(Matrix.class, new JsonMatrixAdapter());
     Gson gson = builder.create();
     JsonObject obj = new JsonObject();
     obj.add("class", new JsonPrimitive(src.getClass().getName()));
@@ -53,6 +56,7 @@ public JsonElement serialize(DistanceMeasure src, Type typeOfSrc, JsonSerializat
   public DistanceMeasure deserialize(JsonElement json, Type typeOfT, JsonDeserializationContext context) {
     GsonBuilder builder = new GsonBuilder();
     builder.registerTypeAdapter(Vector.class, new JsonVectorAdapter());
+    builder.registerTypeAdapter(Matrix.class, new JsonMatrixAdapter());
     Gson gson = builder.create();
     JsonObject obj = json.getAsJsonObject();
     String klass = obj.get("class").getAsString();
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletCluster.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletCluster.java
index 68878e00..ad54a584 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletCluster.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletCluster.java
@@ -20,9 +20,13 @@
 import java.io.DataOutput;
 import java.io.IOException;
 import java.lang.reflect.Type;
+import java.util.Collection;
+import java.util.Collections;
 
+import org.apache.hadoop.conf.Configuration;
 import org.apache.mahout.clustering.Cluster;
 import org.apache.mahout.clustering.Model;
+import org.apache.mahout.common.parameters.Parameter;
 import org.apache.mahout.math.Vector;
 import org.apache.mahout.math.VectorWritable;
 
@@ -51,6 +55,21 @@ public DirichletCluster(Cluster model) {
   public DirichletCluster() {
   }
 
+  @Override
+  public void configure(Configuration job) {
+    // nothing to do
+  }
+  
+  @Override
+  public Collection<Parameter<?>> getParameters() {
+    return Collections.emptyList();
+  }
+  
+  @Override
+  public void createParameters(String prefix, Configuration jobConf) {
+    // nothing to do
+  }
+
   public Cluster getModel() {
     return model;
   }
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletClusterMapper.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletClusterMapper.java
index 103dae25..87fc15c7 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletClusterMapper.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletClusterMapper.java
@@ -52,6 +52,9 @@ protected void setup(Context context) throws IOException, InterruptedException {
     Configuration conf = context.getConfiguration();
     try {
       clusters = getClusters(conf);
+      for (DirichletCluster cluster : clusters) {
+        cluster.getModel().configure(conf);
+      }
       String emitMostLikely = conf.get(DirichletDriver.EMIT_MOST_LIKELY_KEY);
       String threshold = conf.get(DirichletDriver.THRESHOLD_KEY);
       clusterer = new DirichletClusterer(Boolean.parseBoolean(emitMostLikely), Double.parseDouble(threshold));
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletDriver.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletDriver.java
index 0a3ce461..e0362724 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletDriver.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletDriver.java
@@ -396,14 +396,15 @@ public static Path buildClusters(Configuration conf,
     writeInitialState(output, clustersIn, modelDistribution, numClusters, alpha0);
 
     if (runSequential) {
-      clustersIn = buildClustersSeq(input, output, modelDistribution, numClusters, maxIterations, alpha0, clustersIn);
+      clustersIn = buildClustersSeq(conf, input, output, modelDistribution, numClusters, maxIterations, alpha0, clustersIn);
     } else {
       clustersIn = buildClustersMR(conf, input, output, modelDistribution, numClusters, maxIterations, alpha0, clustersIn);
     }
     return clustersIn;
   }
 
-  private static Path buildClustersSeq(Path input,
+  private static Path buildClustersSeq(Configuration conf,
+                                       Path input,
                                        Path output,
                                        ModelDistribution<VectorWritable> modelDistribution,
                                        int numClusters,
@@ -415,14 +416,21 @@ private static Path buildClustersSeq(Path input,
       log.info("Iteration {}", iteration);
       // point the output to a new directory per iteration
       Path clustersOut = new Path(output, Cluster.CLUSTERS_DIR + iteration);
-      DirichletState state = DirichletMapper.loadState(new Configuration(),
+      DirichletState state = DirichletMapper.loadState(conf,
                                                        clustersIn.toString(),
                                                        modelDistribution,
                                                        alpha0,
                                                        numClusters);
+      
+      List<DirichletCluster> oldModels = state.getClusters();
+      for (DirichletCluster oldModel : oldModels) {
+        oldModel.getModel().configure(conf);
+      }
       Cluster[] newModels = (Cluster[]) state.getModelFactory().sampleFromPosterior(state.getModels());
+      for (Cluster newModel : newModels) {
+        newModel.configure(conf);
+      }
       DirichletClusterer clusterer = new DirichletClusterer(state);
-      Configuration conf = new Configuration();
       FileSystem fs = FileSystem.get(input.toUri(), conf);
       FileStatus[] status = fs.listStatus(input, new OutputLogFilter());
       for (FileStatus s : status) {
@@ -492,16 +500,22 @@ public static void clusterData(Configuration conf,
                                  boolean runSequential)
     throws IOException, InterruptedException, ClassNotFoundException, InstantiationException, IllegalAccessException {
     if (runSequential) {
-      clusterDataSeq(input, stateIn, output, emitMostLikely, threshold);
+      clusterDataSeq(conf, input, stateIn, output, emitMostLikely, threshold);
     } else {
       clusterDataMR(conf, input, stateIn, output, emitMostLikely, threshold);
     }
   }
 
-  private static void clusterDataSeq(Path input, Path stateIn, Path output, boolean emitMostLikely, double threshold)
+  private static void clusterDataSeq(Configuration conf, Path input, Path stateIn, Path output, boolean emitMostLikely, double threshold)
     throws IOException, InstantiationException, IllegalAccessException {
-    Configuration conf = new Configuration();
     List<DirichletCluster> clusters = DirichletClusterMapper.loadClusters(conf, stateIn);
+    
+    for(int i=0; i<clusters.size(); i++)
+    {
+  	  Cluster cluster = clusters.get(i).getModel();
+  	  cluster.configure(conf);
+    }
+    
     DirichletClusterer clusterer = new DirichletClusterer(emitMostLikely, threshold);
     // iterate over all points, assigning each to the closest canopy and outputing that clustering
     FileSystem fs = FileSystem.get(input.toUri(), conf);
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletMapper.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletMapper.java
index 7f19bcab..dbc9e719 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletMapper.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletMapper.java
@@ -53,6 +53,9 @@ protected void setup(Context context) throws IOException, InterruptedException {
     super.setup(context);
     try {
       DirichletState dirichletState = getDirichletState(context.getConfiguration());
+      for (DirichletCluster cluster : dirichletState.getClusters()) {
+        cluster.getModel().configure(context.getConfiguration());
+      }
       clusterer = new DirichletClusterer(dirichletState);
       for (int i = 0; i < dirichletState.getNumClusters(); i++) {
         // write an empty vector to each clusterId so that all will be seen by a reducer
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletReducer.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletReducer.java
index e3aae737..5b1769ac 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletReducer.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/DirichletReducer.java
@@ -18,16 +18,17 @@
 package org.apache.mahout.clustering.dirichlet;
 
 import java.io.IOException;
+import java.util.List;
 
+import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.io.Text;
 import org.apache.hadoop.mapreduce.Reducer;
 import org.apache.mahout.clustering.Cluster;
 import org.apache.mahout.math.VectorWritable;
 
-public class DirichletReducer extends Reducer<Text, VectorWritable, Text, DirichletCluster> {
+public class DirichletReducer extends Reducer<Text,VectorWritable,Text,DirichletCluster> {
 
   private DirichletClusterer clusterer;
-
   private Cluster[] newModels;
 
   public Cluster[] getNewModels() {
@@ -38,8 +39,16 @@
   protected void setup(Context context) throws IOException, InterruptedException {
     super.setup(context);
     try {
-      clusterer = new DirichletClusterer(DirichletMapper.getDirichletState(context.getConfiguration()));
-      this.newModels = (Cluster[]) clusterer.samplePosteriorModels();
+      DirichletState state = DirichletMapper.getDirichletState(context.getConfiguration());
+      clusterer = new DirichletClusterer(state);
+      List<DirichletCluster> oldModels = state.getClusters();
+      for (DirichletCluster cluster : oldModels) {
+        cluster.getModel().configure(context.getConfiguration());
+      }
+      this.newModels = (Cluster[]) state.getModelFactory().sampleFromPosterior(state.getModels());
+      for (Cluster cluster : newModels) {
+        cluster.configure(context.getConfiguration());
+      }
     } catch (NumberFormatException e) {
       throw new IllegalStateException(e);
     } catch (SecurityException e) {
@@ -50,7 +59,8 @@ protected void setup(Context context) throws IOException, InterruptedException {
   }
 
   @Override
-  protected void reduce(Text key, Iterable<VectorWritable> values, Context context) throws IOException, InterruptedException {
+  protected void reduce(Text key, Iterable<VectorWritable> values, Context context)
+    throws IOException, InterruptedException {
     int k = Integer.parseInt(key.toString());
     Cluster model = newModels[k];
     for (VectorWritable value : values) {
@@ -65,7 +75,14 @@ protected void reduce(Text key, Iterable<VectorWritable> values, Context context
 
   public void setup(DirichletState state) {
     clusterer = new DirichletClusterer(state);
-    this.newModels = (Cluster[]) clusterer.samplePosteriorModels();
+    List<DirichletCluster> oldModels = state.getClusters();
+    for (DirichletCluster cluster : oldModels) {
+      cluster.getModel().configure(new Configuration());
+    }
+    this.newModels = (Cluster[]) state.getModelFactory().sampleFromPosterior(state.getModels());
+    for (Cluster cluster : newModels) {
+      cluster.configure(new Configuration());
+    }
   }
 
 }
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/AsymmetricSampledNormalModel.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/AsymmetricSampledNormalModel.java
index 4b48c544..ec861105 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/AsymmetricSampledNormalModel.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/AsymmetricSampledNormalModel.java
@@ -21,12 +21,16 @@
 import java.io.DataOutput;
 import java.io.IOException;
 import java.lang.reflect.Type;
+import java.util.Collection;
+import java.util.Collections;
 
+import org.apache.hadoop.conf.Configuration;
 import org.apache.mahout.clustering.AbstractCluster;
 import org.apache.mahout.clustering.Cluster;
 import org.apache.mahout.clustering.JsonModelAdapter;
 import org.apache.mahout.clustering.Model;
 import org.apache.mahout.clustering.dirichlet.UncommonDistributions;
+import org.apache.mahout.common.parameters.Parameter;
 import org.apache.mahout.math.Vector;
 import org.apache.mahout.math.VectorWritable;
 import org.apache.mahout.math.function.SquareRootFunction;
@@ -66,6 +70,21 @@ public AsymmetricSampledNormalModel(int id, Vector mean, Vector stdDev) {
     this.s2 = mean.like();
   }
 
+  @Override
+  public void configure(Configuration job) {
+    // nothing to do
+  }
+  
+  @Override
+  public Collection<Parameter<?>> getParameters() {
+    return Collections.emptyList();
+  }
+  
+  @Override
+  public void createParameters(String prefix, Configuration jobConf) {
+    // nothing to do
+  }
+
   public Vector getMean() {
     return mean;
   }
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/L1Model.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/L1Model.java
index 6ffa6815..2b8da5f6 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/L1Model.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/L1Model.java
@@ -20,13 +20,17 @@
 import java.io.DataOutput;
 import java.io.IOException;
 import java.lang.reflect.Type;
+import java.util.Collection;
+import java.util.Collections;
 
+import org.apache.hadoop.conf.Configuration;
 import org.apache.mahout.clustering.AbstractCluster;
 import org.apache.mahout.clustering.Cluster;
 import org.apache.mahout.clustering.JsonModelAdapter;
 import org.apache.mahout.clustering.Model;
 import org.apache.mahout.common.distance.DistanceMeasure;
 import org.apache.mahout.common.distance.ManhattanDistanceMeasure;
+import org.apache.mahout.common.parameters.Parameter;
 import org.apache.mahout.math.Vector;
 import org.apache.mahout.math.VectorWritable;
 
@@ -56,6 +60,21 @@ public L1Model(int id, Vector v) {
     coefficients = v;
   }
 
+  @Override
+  public void configure(Configuration job) {
+    // nothing to do
+  }
+  
+  @Override
+  public Collection<Parameter<?>> getParameters() {
+    return Collections.emptyList();
+  }
+  
+  @Override
+  public void createParameters(String prefix, Configuration jobConf) {
+    // nothing to do
+  }
+
   @Override
   public void computeParameters() {
     coefficients = observed.divide(counter);
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/NormalModel.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/NormalModel.java
index 47d6e892..ef177efd 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/NormalModel.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/dirichlet/models/NormalModel.java
@@ -21,12 +21,16 @@
 import java.io.DataOutput;
 import java.io.IOException;
 import java.lang.reflect.Type;
+import java.util.Collection;
+import java.util.Collections;
 import java.util.Locale;
 
+import org.apache.hadoop.conf.Configuration;
 import org.apache.mahout.clustering.AbstractCluster;
 import org.apache.mahout.clustering.Cluster;
 import org.apache.mahout.clustering.JsonModelAdapter;
 import org.apache.mahout.clustering.Model;
+import org.apache.mahout.common.parameters.Parameter;
 import org.apache.mahout.math.Vector;
 import org.apache.mahout.math.VectorWritable;
 import org.apache.mahout.math.function.SquareRootFunction;
@@ -68,6 +72,21 @@ public NormalModel(int id, Vector mean, double stdDev) {
     this.s2 = mean.like();
   }
 
+  @Override
+  public void configure(Configuration job) {
+    // nothing to do
+  }
+  
+  @Override
+  public Collection<Parameter<?>> getParameters() {
+    return Collections.emptyList();
+  }
+  
+  @Override
+  public void createParameters(String prefix, Configuration jobConf) {
+    // nothing to do
+  }
+
   int getS0() {
     return s0;
   }
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/common/distance/MahalanobisDistanceMeasure.java b/mahout/trunk/core/src/main/java/org/apache/mahout/common/distance/MahalanobisDistanceMeasure.java
index 794ce471..5f9365d4 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/common/distance/MahalanobisDistanceMeasure.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/common/distance/MahalanobisDistanceMeasure.java
@@ -49,6 +49,7 @@
   private Vector meanVector;
   
   private ClassParameter vectorClass;
+  private ClassParameter matrixClass;
   private List<Parameter<?>> parameters;
   private Parameter<Path> inverseCovarianceFile;
   private Parameter<Path> meanVectorFile;
@@ -70,7 +71,7 @@ public void configure(Configuration jobConf) {
     try {
       if (inverseCovarianceFile.get() != null) {
         FileSystem fs = FileSystem.get(inverseCovarianceFile.get().toUri(), jobConf);
-        MatrixWritable inverseCovarianceMatrix = (MatrixWritable) vectorClass.get().newInstance();
+        MatrixWritable inverseCovarianceMatrix = (MatrixWritable) matrixClass.get().newInstance();
         if (!fs.exists(inverseCovarianceFile.get())) {
           throw new FileNotFoundException(inverseCovarianceFile.get().toString());
         }
@@ -119,7 +120,7 @@ public void createParameters(String prefix, Configuration jobConf) {
                                               "Path on DFS to a file containing the inverse covariance matrix.");
     parameters.add(inverseCovarianceFile);
 
-    Parameter matrixClass =
+    matrixClass =
         new ClassParameter(prefix, "maxtrixClass", jobConf, DenseMatrix.class,
                            "Class<Matix> file specified in parameter inverseCovarianceFile has been serialized with.");
     parameters.add(matrixClass);      
diff --git a/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/dirichlet/TestMapReduce.java b/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/dirichlet/TestMapReduce.java
index 248d53ca..a291e6f4 100644
--- a/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/dirichlet/TestMapReduce.java
+++ b/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/dirichlet/TestMapReduce.java
@@ -16,6 +16,7 @@
  */
 package org.apache.mahout.clustering.dirichlet;
 
+import java.io.DataOutputStream;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collection;
@@ -37,6 +38,7 @@
 import org.apache.mahout.clustering.Model;
 import org.apache.mahout.clustering.dirichlet.models.AbstractVectorModelDistribution;
 import org.apache.mahout.clustering.dirichlet.models.AsymmetricSampledNormalModel;
+import org.apache.mahout.clustering.dirichlet.models.DistanceMeasureClusterDistribution;
 import org.apache.mahout.clustering.dirichlet.models.NormalModel;
 import org.apache.mahout.clustering.dirichlet.models.NormalModelDistribution;
 import org.apache.mahout.clustering.dirichlet.models.SampledNormalDistribution;
@@ -44,7 +46,11 @@
 import org.apache.mahout.common.DummyRecordWriter;
 import org.apache.mahout.common.MahoutTestCase;
 import org.apache.mahout.common.commandline.DefaultOptionCreator;
+import org.apache.mahout.common.distance.MahalanobisDistanceMeasure;
+import org.apache.mahout.math.DenseMatrix;
 import org.apache.mahout.math.DenseVector;
+import org.apache.mahout.math.Matrix;
+import org.apache.mahout.math.MatrixWritable;
 import org.apache.mahout.math.Vector;
 import org.apache.mahout.math.VectorWritable;
 import org.junit.Before;
@@ -85,6 +91,27 @@ private void generateSamples(int num, double mx, double my, double sd) {
     }
   }
 
+  /**
+   * Generate random samples with asymmetric standard deviations and add them to the sampleData
+   * 
+   * @param num
+   *          int number of samples to generate
+   * @param mx
+   *          double x-value of the sample mean
+   * @param my
+   *          double y-value of the sample mean
+   * @param sdx
+   *          double standard deviation in x of the samples
+   * @param sdy
+   *          double standard deviation in y of the samples
+   */
+  private void generateAsymmetricSamples(int num, double mx, double my, double sdx, double sdy) {
+    System.out.println("Generating " + num + " samples m=[" + mx + ", " + my + "] sd=[" + sdx + ", " + sdy + "]");
+    for (int i = 0; i < num; i++) {
+      addSample(new double[] { UncommonDistributions.rNorm(mx, sdx), UncommonDistributions.rNorm(my, sdy) });
+    }
+  }
+
   @Override
   @Before
   public void setUp() throws Exception {
@@ -239,7 +266,9 @@ public void testDriverIterationsSeq() throws Exception {
         maxIterations.toString(), optKey(DirichletDriver.ALPHA_OPTION), "1.0", optKey(DefaultOptionCreator.OVERWRITE_OPTION),
         optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.METHOD_OPTION),
         DefaultOptionCreator.SEQUENTIAL_METHOD };
-    new DirichletDriver().run(args);
+    DirichletDriver dirichletDriver = new DirichletDriver();
+    dirichletDriver.setConf(conf);
+    dirichletDriver.run(args);
     // and inspect results
     Collection<List<DirichletCluster>> clusters = new ArrayList<List<DirichletCluster>>();
     Configuration conf = new Configuration();
@@ -316,6 +345,138 @@ public void testDriverMnRIterations() throws Exception {
     printResults(clusters, 0);
   }
 
+  /** Test the Driver in sequential execution mode using MahalanobisDistanceMeasure */
+  @Test
+  public void testDriverIterationsMahalanobisSeq() throws Exception {
+    generateAsymmetricSamples(100, 0, 0, 0.5, 3.0);
+    generateAsymmetricSamples(100, 0, 3, 0.3, 4.0);
+    ClusteringTestUtils.writePointsToFile(sampleData, getTestTempFilePath("input/data.txt"), fs, conf);
+    // Now run the driver using the run() method. Others can use runJob() as before
+    Integer maxIterations = 5;
+    MahalanobisDistanceMeasure measure = new MahalanobisDistanceMeasure();
+    AbstractVectorModelDistribution modelDistribution = new DistanceMeasureClusterDistribution(new VectorWritable(new DenseVector(2)), measure);
+    
+    Vector meanVector = new DenseVector(new double [] {0.0, 0.0});
+    ((MahalanobisDistanceMeasure)measure).setMeanVector(meanVector);
+    Matrix m= new DenseMatrix(new double [][] {{0.5, 0.0}, {0.0, 4.0}});
+    ((MahalanobisDistanceMeasure)measure).setCovarianceMatrix(m);
+    
+    Path inverseCovarianceFile = new Path(getTestTempDirPath("mahalanobis"), "MahalanobisDistanceMeasureInverseCovarianceFile");
+    conf.set("MahalanobisDistanceMeasure.inverseCovarianceFile", inverseCovarianceFile.toString());
+    FileSystem fs = FileSystem.get(inverseCovarianceFile.toUri(), conf);
+    MatrixWritable inverseCovarianceMatrix = new MatrixWritable(((MahalanobisDistanceMeasure)measure).getInverseCovarianceMatrix());
+    DataOutputStream out = fs.create(inverseCovarianceFile);
+    try {
+      inverseCovarianceMatrix.write(out);
+    } finally {
+      out.close();
+    }
+    
+    Path meanVectorFile = new Path(getTestTempDirPath("mahalanobis"), "MahalanobisDistanceMeasureMeanVectorFile");
+    conf.set("MahalanobisDistanceMeasure.meanVectorFile", meanVectorFile.toString());
+    fs = FileSystem.get(meanVectorFile.toUri(), conf);
+    VectorWritable meanVectorWritable = new VectorWritable(meanVector);
+    out = fs.create(meanVectorFile);
+    try {
+      meanVectorWritable.write(out);
+    } finally {
+      out.close();
+    }
+    
+    conf.set("MahalanobisDistanceMeasure.maxtrixClass", MatrixWritable.class.getName());
+    conf.set("MahalanobisDistanceMeasure.vectorClass", VectorWritable.class.getName());
+    
+    String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), getTestTempDirPath("input").toString(),
+        optKey(DefaultOptionCreator.OUTPUT_OPTION), getTestTempDirPath("output").toString(),
+        optKey(DirichletDriver.MODEL_DISTRIBUTION_CLASS_OPTION), modelDistribution.getClass().getName(),
+        optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), measure.getClass().getName(),
+        optKey(DirichletDriver.MODEL_PROTOTYPE_CLASS_OPTION), modelDistribution.getModelPrototype().get().getClass().getName(),
+        optKey(DefaultOptionCreator.NUM_CLUSTERS_OPTION), "20", optKey(DefaultOptionCreator.MAX_ITERATIONS_OPTION),
+        maxIterations.toString(), optKey(DirichletDriver.ALPHA_OPTION), "1.0", optKey(DefaultOptionCreator.OVERWRITE_OPTION),
+        optKey(DefaultOptionCreator.CLUSTERING_OPTION), optKey(DefaultOptionCreator.METHOD_OPTION),
+        DefaultOptionCreator.SEQUENTIAL_METHOD };
+    DirichletDriver dirichletDriver = new DirichletDriver();
+    dirichletDriver.setConf(conf);
+    dirichletDriver.run(args);
+    // and inspect results
+    Collection<List<DirichletCluster>> clusters = new ArrayList<List<DirichletCluster>>();
+    Configuration conf = new Configuration();
+    conf.set(DirichletDriver.MODEL_DISTRIBUTION_KEY, modelDistribution.asJsonString());
+    conf.set(DirichletDriver.NUM_CLUSTERS_KEY, "20");
+    conf.set(DirichletDriver.ALPHA_0_KEY, "1.0");
+    for (int i = 0; i <= maxIterations; i++) {
+      conf.set(DirichletDriver.STATE_IN_KEY, new Path(getTestTempDirPath("output"), "clusters-" + i).toString());
+      clusters.add(DirichletMapper.getDirichletState(conf).getClusters());
+    }
+    printResults(clusters, 0);
+  }
+  
+  /** Test the Mapper and Reducer using the Driver in mapreduce mode */
+  @Test
+  public void testDriverIterationsMahalanobisMR() throws Exception {
+    generateAsymmetricSamples(100, 0, 0, 0.5, 3.0);
+    generateAsymmetricSamples(100, 0, 3, 0.3, 4.0);
+    ClusteringTestUtils.writePointsToFile(sampleData, getTestTempFilePath("input/data.txt"), fs, conf);
+    // Now run the driver using the run() method. Others can use runJob() as before
+    Integer maxIterations = 5;
+    
+    MahalanobisDistanceMeasure measure = new MahalanobisDistanceMeasure();
+    AbstractVectorModelDistribution modelDistribution = new DistanceMeasureClusterDistribution(new VectorWritable(new DenseVector(2)), measure);
+    
+    Vector meanVector = new DenseVector(new double [] {0.0, 0.0});
+    ((MahalanobisDistanceMeasure)measure).setMeanVector(meanVector);
+    Matrix m= new DenseMatrix(new double [][] {{0.5, 0.0}, {0.0, 4.0}});
+    ((MahalanobisDistanceMeasure)measure).setCovarianceMatrix(m);
+    
+    Path inverseCovarianceFile = new Path(getTestTempDirPath("mahalanobis"), "MahalanobisDistanceMeasureInverseCovarianceFile");
+    conf.set("MahalanobisDistanceMeasure.inverseCovarianceFile", inverseCovarianceFile.toString());
+    FileSystem fs = FileSystem.get(inverseCovarianceFile.toUri(), conf);
+    MatrixWritable inverseCovarianceMatrix = new MatrixWritable(((MahalanobisDistanceMeasure)measure).getInverseCovarianceMatrix());
+    DataOutputStream out = fs.create(inverseCovarianceFile);
+    try {
+      inverseCovarianceMatrix.write(out);
+    } finally {
+      out.close();
+    }
+    
+    Path meanVectorFile = new Path(getTestTempDirPath("mahalanobis"), "MahalanobisDistanceMeasureMeanVectorFile");
+    conf.set("MahalanobisDistanceMeasure.meanVectorFile", meanVectorFile.toString());
+    fs = FileSystem.get(meanVectorFile.toUri(), conf);
+    VectorWritable meanVectorWritable = new VectorWritable(meanVector);
+    out = fs.create(meanVectorFile);
+    try {
+      meanVectorWritable.write(out);
+    } finally {
+      out.close();
+    }
+    
+    conf.set("MahalanobisDistanceMeasure.maxtrixClass", MatrixWritable.class.getName());
+    conf.set("MahalanobisDistanceMeasure.vectorClass", VectorWritable.class.getName());
+    
+    String[] args = { optKey(DefaultOptionCreator.INPUT_OPTION), getTestTempDirPath("input").toString(),
+        optKey(DefaultOptionCreator.OUTPUT_OPTION), getTestTempDirPath("output").toString(),
+        optKey(DirichletDriver.MODEL_DISTRIBUTION_CLASS_OPTION), modelDistribution.getClass().getName(),
+        optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION), measure.getClass().getName(),
+        optKey(DirichletDriver.MODEL_PROTOTYPE_CLASS_OPTION), modelDistribution.getModelPrototype().get().getClass().getName(),
+        optKey(DefaultOptionCreator.NUM_CLUSTERS_OPTION), "20", optKey(DefaultOptionCreator.MAX_ITERATIONS_OPTION),
+        maxIterations.toString(), optKey(DirichletDriver.ALPHA_OPTION), "1.0", optKey(DefaultOptionCreator.OVERWRITE_OPTION),
+        optKey(DefaultOptionCreator.CLUSTERING_OPTION) };
+    DirichletDriver dirichletDriver = new DirichletDriver();
+    dirichletDriver.setConf(conf);
+    ToolRunner.run(conf, dirichletDriver, args);
+    // and inspect results
+    Collection<List<DirichletCluster>> clusters = new ArrayList<List<DirichletCluster>>();
+    Configuration conf = new Configuration();
+    conf.set(DirichletDriver.MODEL_DISTRIBUTION_KEY, modelDistribution.asJsonString());
+    conf.set(DirichletDriver.NUM_CLUSTERS_KEY, "20");
+    conf.set(DirichletDriver.ALPHA_0_KEY, "1.0");
+    for (int i = 0; i <= maxIterations; i++) {
+      conf.set(DirichletDriver.STATE_IN_KEY, new Path(getTestTempDirPath("output"), "clusters-" + i).toString());
+      clusters.add(DirichletMapper.getDirichletState(conf).getClusters());
+    }
+    printResults(clusters, 0);
+  }
+
   private void generate4Datasets() throws IOException {
     generateSamples(500, 0, 0, 0.5);
     ClusteringTestUtils.writePointsToFile(sampleData, getTestTempFilePath("input/data1.txt"), fs, conf);
