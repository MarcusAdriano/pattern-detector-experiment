diff --git a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationTree.java b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationTree.java
index 810e8085..1e2baa82 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationTree.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationTree.java
@@ -191,7 +191,7 @@ protected int hstrcmp(char[] s, int si, char[] t, int ti) {
    * interletter values. In other words, it does something like:
    * </p>
    * <code>
-   * for(i=0; i<patterns.length; i++) {
+   * for(i=0; i&lt;patterns.length; i++) {
    * if ( word.substring(index).startsWidth(patterns[i]) )
    * update_interletter_values(patterns[i]);
    * }
diff --git a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java
index e022f0eb..870bd726 100644
--- a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java
+++ b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java
@@ -54,7 +54,7 @@
  *  merge fewer segments (down to 1 at once, if that one has
  *  deletions) to keep the segment size under budget.
  *      
- *  <p<b>NOTE</b>: this policy freely merges non-adjacent
+ *  <p><b>NOTE</b>: this policy freely merges non-adjacent
  *  segments; if this is a problem, use {@link
  *  LogMergePolicy}.
  *
diff --git a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java
index 68d8019a..ae46ba3f 100644
--- a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java
+++ b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java
@@ -103,7 +103,7 @@
  *    </table>
  *    </td></tr>
  *    <tr><td>
- *    <center><font=-1><u>VSM Score</u></font></center>
+ *    <center><font size=-1><u>VSM Score</u></font></center>
  *    </td></tr>
  *  </table>
  *  <br>&nbsp;<br>
@@ -194,7 +194,7 @@
  *    </table>
  *    </td></tr>
  *    <tr><td>
- *    <center><font=-1><u>Lucene Conceptual Scoring Formula</u></font></center>
+ *    <center><font size=-1><u>Lucene Conceptual Scoring Formula</u></font></center>
  *    </td></tr>
  *  </table>
  *  <br>&nbsp;<br>
@@ -291,7 +291,7 @@
  *  </table>
  * </td></tr>
  * <tr><td>
- *  <center><font=-1><u>Lucene Practical Scoring Function</u></font></center>
+ *  <center><font size=-1><u>Lucene Practical Scoring Function</u></font></center>
  * </td></tr>
  * </table>
  *
@@ -410,7 +410,7 @@
  *      computes this value as:
  *
  *      <br>&nbsp;<br>
- *      <table cellpadding="1" cellspacing="0" border="0"n align="center" style="width:auto">
+ *      <table cellpadding="1" cellspacing="0" border="0" align="center" style="width:auto">
  *        <tr>
  *          <td valign="middle" align="right" rowspan="1">
  *            {@link org.apache.lucene.search.Weight#getValueForNormalization() sumOfSquaredWeights} &nbsp; = &nbsp;
@@ -476,7 +476,7 @@
  *      If the document has multiple fields with the same name, all their boosts are multiplied together:
  *
  *      <br>&nbsp;<br>
- *      <table cellpadding="1" cellspacing="0" border="0"n align="center" style="width:auto">
+ *      <table cellpadding="1" cellspacing="0" border="0" align="center" style="width:auto">
  *        <tr>
  *          <td valign="middle" align="right" rowspan="1">
  *            norm(t,d) &nbsp; = &nbsp;
diff --git a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/BytesRefHash.java b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/BytesRefHash.java
index e1c01ee0..8fad50d7 100644
--- a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/BytesRefHash.java
+++ b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/BytesRefHash.java
@@ -30,7 +30,7 @@
 /**
  * {@link BytesRefHash} is a special purpose hash-map like data-structure
  * optimized for {@link BytesRef} instances. BytesRefHash maintains mappings of
- * byte arrays to ordinal (Map<BytesRef,int>) storing the hashed bytes
+ * byte arrays to ordinal (Map&lt;BytesRef,int&gt;) storing the hashed bytes
  * efficiently in continuous storage. The mapping to the ordinal is
  * encapsulated inside {@link BytesRefHash} and is guaranteed to be increased
  * for each added {@link BytesRef}.
diff --git a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/FieldCacheSanityChecker.java b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/FieldCacheSanityChecker.java
index 86e9c891..32e8f2aa 100644
--- a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/FieldCacheSanityChecker.java
+++ b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/FieldCacheSanityChecker.java
@@ -409,7 +409,7 @@ private InsanityType(final String label) {
      * it's typically an indication of a possible problem.
      * </p>
      * <p>
-     * <bPNOTE:</b> Only the reader, fieldname, and cached value are actually 
+     * <b>NOTE:</b> Only the reader, fieldname, and cached value are actually 
      * tested -- if two cache entries have different parsers or datatypes but 
      * the cached values are the same Object (== not just equal()) this method 
      * does not consider that a red flag.  This allows for subtle variations 
diff --git a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/PagedBytes.java b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/PagedBytes.java
index 0cd08fef..fb32f16f 100644
--- a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/PagedBytes.java
+++ b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/util/PagedBytes.java
@@ -253,7 +253,7 @@ public BytesRef fillSliceWithPrefix(BytesRef b, long start) {
     }
   }
 
-  /** 1<<blockBits must be bigger than biggest single
+  /** 1&lt;&lt;blockBits must be bigger than biggest single
    *  BytesRef slice that will be pulled */
   public PagedBytes(int blockBits) {
     this.blockSize = 1 << blockBits;
diff --git a/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetRequest.java b/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetRequest.java
index a64cc8c3..6ef723a9 100644
--- a/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetRequest.java
+++ b/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/search/params/FacetRequest.java
@@ -158,7 +158,7 @@ public final int getDepth() {
   }
 
   /**
-   * If getNumLabel()<getNumResults(), only the first getNumLabel() results
+   * If getNumLabel() &lt; getNumResults(), only the first getNumLabel() results
    * will have their category paths calculated, and the rest will only be
    * available as ordinals (category numbers) and will have null paths.
    * <P>
diff --git a/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal.java b/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal.java
index a3300211..bdb87c7b 100644
--- a/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal.java
+++ b/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/cl2o/CompactLabelToOrdinal.java
@@ -1,17 +1,5 @@
 package org.apache.lucene.facet.taxonomy.writercache.cl2o;
 
-import java.io.BufferedInputStream;
-import java.io.BufferedOutputStream;
-import java.io.DataInputStream;
-import java.io.DataOutputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.util.Iterator;
-
-import org.apache.lucene.facet.taxonomy.CategoryPath;
-
 /**
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -29,6 +17,20 @@
  * limitations under the License.
  */
 
+import java.io.BufferedInputStream;
+import java.io.BufferedOutputStream;
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.util.Iterator;
+
+import org.apache.lucene.facet.taxonomy.CategoryPath;
+
+// TODO: maybe this could use an FST instead...
+
 /**
  * This is a very efficient LabelToOrdinal implementation that uses a
  * CharBlockArray to store all labels and a configurable number of HashArrays to
@@ -47,7 +49,7 @@
  * 
  * <p>
  * This data structure has a much lower memory footprint (~30%) compared to a
- * Java HashMap<String, Integer>. It also only uses a small fraction of objects
+ * Java HashMap&lt;String, Integer&gt;. It also only uses a small fraction of objects
  * a HashMap would use, thus limiting the GC overhead. Ingestion speed was also
  * ~50% faster compared to a HashMap for 3M unique labels.
  * 
