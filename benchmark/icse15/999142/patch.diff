diff --git a/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java b/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
index 2cabcd60..fcd4bb37 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
@@ -450,7 +450,6 @@ public void runMayThrow() throws InterruptedException, IOException
                     {
                         // if we're not writing to the commit log, we are replaying the log, so marking
                         // the log header with "you can discard anything written before the context" is not valid
-                        logger.debug("Discarding {}", metadata.cfId);
                         CommitLog.instance().discardCompletedSegments(metadata.cfId, ctx);
                     }
                 }
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLog.java b/cassandra/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLog.java
index 8760d1a0..1f21f76e 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLog.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLog.java
@@ -302,7 +302,7 @@ public void runMayThrow() throws IOException
                                     // null means the cf has been dropped
                                     continue;
 
-                                if (finalHeader == null || (finalHeader.isDirty(columnFamily.id()) && entryLocation >= finalHeader.getPosition(columnFamily.id())))
+                                if (finalHeader == null || (finalHeader.isDirty(columnFamily.id()) && entryLocation > finalHeader.getPosition(columnFamily.id())))
                                     newRm.add(columnFamily);
                             }
                             if (!newRm.isEmpty())
@@ -338,7 +338,6 @@ public void runMayThrow() throws IOException
         for (Table table : tablesRecovered)
             futures.addAll(table.flush());
         FBUtilities.waitOnFutures(futures);
-        logger.info("Recovery complete");
     }
 
     private CommitLogSegment currentSegment()
diff --git a/cassandra/trunk/test/unit/org/apache/cassandra/db/CommitLogTest.java b/cassandra/trunk/test/unit/org/apache/cassandra/db/CommitLogTest.java
index 042a7d40..dc9a2b2f 100644
--- a/cassandra/trunk/test/unit/org/apache/cassandra/db/CommitLogTest.java
+++ b/cassandra/trunk/test/unit/org/apache/cassandra/db/CommitLogTest.java
@@ -33,42 +33,6 @@
 
 public class CommitLogTest extends CleanupHelper
 {
-    @Test
-    public void testCleanup() throws Exception
-    {
-        int segmentCount = CommitLog.instance().getSegmentCount();
-        assert segmentCount == 1 : segmentCount + " != 1";
-
-        //must me large enough to hold persistent_stats
-        CommitLog.setSegmentSize(10000);
-
-        Table table = Table.open("Keyspace1");
-        ColumnFamilyStore store1 = table.getColumnFamilyStore("Standard1");
-        ColumnFamilyStore store2 = table.getColumnFamilyStore("Standard2");
-        RowMutation rm;
-        byte[] value = new byte[5001];
-
-        // add data, one each of Standard1/Standard2 per segment
-        for (int i = 0; i < 10; i++)
-        {
-            rm = new RowMutation("Keyspace1", "key1".getBytes());
-            rm.add(new QueryPath("Standard1", null, "Column1".getBytes()), value, new TimestampClock(0));
-            rm.add(new QueryPath("Standard2", null, "Column1".getBytes()), value, new TimestampClock(0));
-            rm.apply();
-        }
-        assert CommitLog.instance().getSegmentCount() > 1;
-
-        // nothing should get removed after flushing just Standard1
-        store1.forceBlockingFlush();
-        segmentCount = CommitLog.instance().getSegmentCount();
-        assert segmentCount > 1 : segmentCount + " !> 1";
-
-        // after flushing Standard2 we should be able to clean out all segments
-        store2.forceBlockingFlush();
-        segmentCount = CommitLog.instance().getSegmentCount();
-        assert segmentCount == 1 : segmentCount + " != 1";
-    }
-
     @Test
     public void testRecoveryWithEmptyHeader() throws Exception
     {
diff --git a/cassandra/trunk/test/unit/org/apache/cassandra/db/RecoveryManager2Test.java b/cassandra/trunk/test/unit/org/apache/cassandra/db/RecoveryManager2Test.java
index 2b0ef1f4..7c071a38 100644
--- a/cassandra/trunk/test/unit/org/apache/cassandra/db/RecoveryManager2Test.java
+++ b/cassandra/trunk/test/unit/org/apache/cassandra/db/RecoveryManager2Test.java
@@ -25,6 +25,9 @@
 
 import org.junit.Test;
 
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import static org.apache.cassandra.Util.column;
 import org.apache.cassandra.CleanupHelper;
 import org.apache.cassandra.Util;
@@ -32,25 +35,32 @@
 
 public class RecoveryManager2Test extends CleanupHelper
 {
+    private static Logger logger = LoggerFactory.getLogger(RecoveryManager2Test.class);
+
     @Test
     /* test that commit logs do not replay flushed data */
     public void testWithFlush() throws Exception
     {
         CompactionManager.instance.disableAutoCompaction();
 
+        // add a row to another CF so we test skipping mutations within a not-entirely-flushed CF
+        insertRow("Standard2", "key");
+
         for (int i = 0; i < 100; i++)
         {
             String key = "key" + i;
-            insertRow(key);
+            insertRow("Standard1", key);
         }
 
         Table table1 = Table.open("Keyspace1");
         ColumnFamilyStore cfs = table1.getColumnFamilyStore("Standard1");
+        logger.debug("forcing flush");
         cfs.forceBlockingFlush();
 
-        // remove all SSTable/MemTables
+        // remove Standard1 SSTable/MemTables
         cfs.clearUnsafe();
 
+        logger.debug("begin manual replay");
         // replay the commit log (nothing should be replayed since everything was flushed)
         CommitLog.recover();
 
@@ -59,10 +69,10 @@ public void testWithFlush() throws Exception
         assert Util.getRangeSlice(cfs).isEmpty();
     }
 
-    private void insertRow(String key) throws IOException
+    private void insertRow(String cfname, String key) throws IOException
     {
         RowMutation rm = new RowMutation("Keyspace1", key.getBytes());
-        ColumnFamily cf = ColumnFamily.create("Keyspace1", "Standard1");
+        ColumnFamily cf = ColumnFamily.create("Keyspace1", cfname);
         cf.addColumn(column("col1", "val1", new TimestampClock(1L)));
         rm.add(cf);
         rm.apply();
