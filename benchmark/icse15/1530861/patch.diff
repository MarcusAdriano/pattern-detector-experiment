diff --git a/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/cloud/Overseer.java b/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/cloud/Overseer.java
index 1ec7fc48..2172da19 100644
--- a/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/cloud/Overseer.java
+++ b/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/cloud/Overseer.java
@@ -413,10 +413,11 @@ private ClusterState updateState(ClusterState state, final ZkNodeProps message)
       }
 
       private ClusterState createCollection(ClusterState state, String collectionName, List<String> shards , ZkNodeProps message) {
-        log.info("Create collection {} with shards {}", collectionName, shards);;
+        log.info("Create collection {} with shards {}", collectionName, shards);
 
-//        String routerName = message.getStr(OverseerCollectionProcessor.ROUTER,DocRouter.DEFAULT_NAME);
-        DocRouter router = DocRouter.getDocRouter(message.getStr(OverseerCollectionProcessor.ROUTER,DocRouter.DEFAULT_NAME));
+        Map<String, Object> routerSpec = DocRouter.getRouterSpec(message);
+        String routerName = routerSpec.get("name") == null ? DocRouter.DEFAULT_NAME : (String) routerSpec.get("name");
+        DocRouter router = DocRouter.getDocRouter(routerName);
 
         List<DocRouter.Range> ranges = router.partitionRange(shards.size(), router.fullRange());
 
@@ -447,7 +448,7 @@ private ClusterState createCollection(ClusterState state, String collectionName,
           }
           if(val != null) collectionProps.put(e.getKey(),val);
         }
-        collectionProps.put(DocCollection.DOC_ROUTER, DocRouter.getRouterSpec(message));
+        collectionProps.put(DocCollection.DOC_ROUTER, routerSpec);
 
         DocCollection newCollection = new DocCollection(collectionName, newSlices, collectionProps, router);
 
diff --git a/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java b/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java
index 0926154a..658cef7e 100644
--- a/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java
+++ b/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java
@@ -386,7 +386,7 @@ private void deleteAlias(Aliases aliases, ZkNodeProps message) {
   }
 
   private boolean createShard(ClusterState clusterState, ZkNodeProps message, NamedList results) throws KeeperException, InterruptedException {
-    log.info("create shard invoked");
+    log.info("Create shard invoked: {}", message);
     String collectionName = message.getStr(COLLECTION_PROP);
     String shard = message.getStr(SHARD_ID_PROP);
     if(collectionName == null || shard ==null)
@@ -395,19 +395,18 @@ private boolean createShard(ClusterState clusterState, ZkNodeProps message, Name
 
     DocCollection collection = clusterState.getCollection(collectionName);
     int maxShardsPerNode = collection.getInt(MAX_SHARDS_PER_NODE, 1);
-    int repFactor = message.getInt(REPLICATION_FACTOR, collection.getInt(MAX_SHARDS_PER_NODE, 1));
-//    int minReplicas = message.getInt("minReplicas",repFactor);
-    String createNodeSetStr =message.getStr(CREATE_NODE_SET);
+    int repFactor = message.getInt(REPLICATION_FACTOR, collection.getInt(REPLICATION_FACTOR, 1));
+    String createNodeSetStr = message.getStr(CREATE_NODE_SET);
 
     ArrayList<Node> sortedNodeList = getNodesForNewShard(clusterState, collectionName, numSlices, maxShardsPerNode, repFactor, createNodeSetStr);
 
     Overseer.getInQueue(zkStateReader.getZkClient()).offer(ZkStateReader.toJSON(message));
-    // wait for a while until we don't see the collection
+    // wait for a while until we see the shard
     long waitUntil = System.currentTimeMillis() + 30000;
     boolean created = false;
     while (System.currentTimeMillis() < waitUntil) {
       Thread.sleep(100);
-      created = zkStateReader.getClusterState().getCollection(collectionName).getSlice(shard) !=null;
+      created = zkStateReader.getClusterState().getCollection(collectionName).getSlice(shard) != null;
       if (created) break;
     }
     if (!created)
@@ -677,16 +676,17 @@ private boolean splitShard(ClusterState clusterState, ZkNodeProps message, Named
       collectShardResponses(results, true,
           "SPLTSHARD failed to create subshard replicas or timed out waiting for them to come up");
 
+      log.info("Calling soft commit to make sub shard updates visible");
       String coreUrl = new ZkCoreNodeProps(parentShardLeader).getCoreUrl();
       // HttpShardHandler is hard coded to send a QueryRequest hence we go direct
       // and we force open a searcher so that we have documents to show upon switching states
       UpdateResponse updateResponse = null;
       try {
-        updateResponse = commit(coreUrl, true);
+        updateResponse = softCommit(coreUrl);
         processResponse(results, null, coreUrl, updateResponse, slice);
       } catch (Exception e) {
         processResponse(results, e, coreUrl, updateResponse, slice);
-        throw new SolrException(ErrorCode.SERVER_ERROR, "Unable to call distrib commit on: " + coreUrl, e);
+        throw new SolrException(ErrorCode.SERVER_ERROR, "Unable to call distrib softCommit on: " + coreUrl, e);
       }
 
       log.info("Successfully created all replica shards for all sub-slices "
@@ -713,16 +713,15 @@ private boolean splitShard(ClusterState clusterState, ZkNodeProps message, Named
     }
   }
 
-  static UpdateResponse commit(String url, boolean openSearcher) throws SolrServerException, IOException {
+  static UpdateResponse softCommit(String url) throws SolrServerException, IOException {
     HttpSolrServer server = null;
     try {
       server = new HttpSolrServer(url);
       server.setConnectionTimeout(30000);
-      server.setSoTimeout(60000);
+      server.setSoTimeout(120000);
       UpdateRequest ureq = new UpdateRequest();
       ureq.setParams(new ModifiableSolrParams());
-      ureq.getParams().set(UpdateParams.OPEN_SEARCHER, openSearcher);
-      ureq.setAction(AbstractUpdateRequest.ACTION.COMMIT, false, true);
+      ureq.setAction(AbstractUpdateRequest.ACTION.COMMIT, false, true, true);
       return ureq.process(server);
     } finally {
       if (server != null) {
diff --git a/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java b/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
index 962ee77a..5e51ae6c 100644
--- a/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
+++ b/lucene/dev/branches/lucene_solr_4_5/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
@@ -111,6 +111,12 @@ public void handleRequestBody(SolrQueryRequest req, SolrQueryResponse rsp) throw
               "Core container instance missing");
     }
 
+    // Make sure that the core is ZKAware
+    if(!cores.isZooKeeperAware()) {
+      throw new SolrException(ErrorCode.BAD_REQUEST,
+          "Solr instance is not running in SolrCloud mode.");
+    }
+
     // Pick the action
     SolrParams params = req.getParams();
     CollectionAction action = null;
@@ -256,7 +262,7 @@ private void handleDeleteAliasAction(SolrQueryRequest req,
     ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION,
         OverseerCollectionProcessor.DELETEALIAS, "name", name);
     
-    handleResponse(OverseerCollectionProcessor.CREATEALIAS, m, rsp);
+    handleResponse(OverseerCollectionProcessor.DELETEALIAS, m, rsp);
   }
 
   private void handleDeleteAction(SolrQueryRequest req, SolrQueryResponse rsp) throws KeeperException, InterruptedException {
diff --git a/lucene/dev/branches/lucene_solr_4_5/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java b/lucene/dev/branches/lucene_solr_4_5/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java
index 0b6f8f2c..b31d0d5b 100644
--- a/lucene/dev/branches/lucene_solr_4_5/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java
+++ b/lucene/dev/branches/lucene_solr_4_5/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java
@@ -135,6 +135,7 @@ protected void setDistributedParams(ModifiableSolrParams params) {
   public void doTest() throws Exception {
     testCustomCollectionsAPI();
     testRouteFieldForHashRouter();
+    testCreateShardRepFactor();
     if (DEBUG) {
       super.printLayout();
     }
@@ -201,7 +202,7 @@ private void testCustomCollectionsAPI() throws Exception {
       List<Integer> list = entry.getValue();
       checkForCollection(collection, list, null);
 
-      String url = getUrlFromZk(collection);
+      String url = getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collection);
 
       HttpSolrServer collectionClient = new HttpSolrServer(url);
 
@@ -219,6 +220,8 @@ private void testCustomCollectionsAPI() throws Exception {
     assertEquals("implicit", ((Map)coll.get(ROUTER)).get("name") );
     assertNotNull(coll.getStr(REPLICATION_FACTOR));
     assertNotNull(coll.getStr(MAX_SHARDS_PER_NODE));
+    assertNull("A shard of a Collection configured with implicit router must have null range",
+        coll.getSlice("a").getRange());
 
     List<String> collectionNameList = new ArrayList<String>();
     collectionNameList.addAll(collectionInfos.keySet());
@@ -226,7 +229,7 @@ private void testCustomCollectionsAPI() throws Exception {
 
     String collectionName = collectionNameList.get(random().nextInt(collectionNameList.size()));
 
-    String url = getUrlFromZk(collectionName);
+    String url = getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);
 
     HttpSolrServer collectionClient = new HttpSolrServer(url);
 
@@ -325,7 +328,7 @@ private void testCustomCollectionsAPI() throws Exception {
     checkForCollection(collectionName, list, null);
 
 
-    url = getUrlFromZk(collectionName);
+    url = getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);
 
     collectionClient = new HttpSolrServer(url);
 
@@ -386,7 +389,7 @@ private void testRouteFieldForHashRouter()throws Exception{
     checkForCollection(collectionName, list, null);
 
 
-    String url = getUrlFromZk(collectionName);
+    String url = getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);
 
     HttpSolrServer collectionClient = new HttpSolrServer(url);
 
@@ -417,11 +420,52 @@ private void testRouteFieldForHashRouter()throws Exception{
 
   }
 
+  private void testCreateShardRepFactor() throws Exception  {
+    String collectionName = "testCreateShardRepFactor";
+    HashMap<String, List<Integer>> collectionInfos = new HashMap<String, List<Integer>>();
+    CloudSolrServer client = null;
+    try {
+      client = createCloudClient(null);
+      Map<String, Object> props = ZkNodeProps.makeMap(
+          REPLICATION_FACTOR, 1,
+          MAX_SHARDS_PER_NODE, 5,
+          NUM_SLICES, 2,
+          "shards", "a,b",
+          "router.name", "implicit");
 
+      createCollection(collectionInfos, collectionName, props, client);
+    } finally {
+      if (client != null) client.shutdown();
+    }
+    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();
+    waitForRecoveriesToFinish(collectionName, zkStateReader, false);
+
+    ModifiableSolrParams params = new ModifiableSolrParams();
+    params.set("action", CollectionAction.CREATESHARD.toString());
+    params.set("collection", collectionName);
+    params.set("shard", "x");
+    SolrRequest request = new QueryRequest(params);
+    request.setPath("/admin/collections");
+    createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(0))).request(request);
+
+    waitForRecoveriesToFinish(collectionName, zkStateReader, false);
+
+    int replicaCount = 0;
+    int attempts = 0;
+    while (true) {
+      if (attempts > 30) fail("Not enough active replicas in the shard 'x'");
+      zkStateReader.updateClusterState(true);
+      attempts++;
+      replicaCount = zkStateReader.getClusterState().getSlice(collectionName, "x").getReplicas().size();
+      if (replicaCount >= 1) break;
+      Thread.sleep(500);
+    }
+
+    assertEquals("CREATESHARD API created more than replicationFactor number of replicas", 1, replicaCount);
+  }
 
 
-  private String getUrlFromZk(String collection) {
-    ClusterState clusterState = getCommonCloudSolrServer().getZkStateReader().getClusterState();
+  public static String getUrlFromZk(ClusterState clusterState, String collection) {
     Map<String,Slice> slices = clusterState.getCollectionStates().get(collection).getSlicesMap();
 
     if (slices == null) {
diff --git a/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrServer.java b/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrServer.java
index 8053db03..33fc9aec 100644
--- a/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrServer.java
+++ b/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrServer.java
@@ -88,15 +88,6 @@
   private HttpClient myClient;
   Random rand = new Random();
   
-  private Object cachLock = new Object();
-  // since the state shouldn't change often, should be very cheap reads
-  private Map<String,List<String>> urlLists = new HashMap<String,List<String>>();
-  private Map<String,List<String>> leaderUrlLists = new HashMap<String,List<String>>();
-
-  private Map<String,List<String>> replicasLists = new HashMap<String,List<String>>();
-  
-  private volatile int lastClusterStateHashCode;
-  
   private final boolean updatesToLeaders;
   private boolean parallelUpdates = true;
   private ExecutorService threadPool = Executors
@@ -502,9 +493,10 @@ public NamedList getExceptions() {
     List<String> replicas = null;
     
     if (request instanceof IsUpdateRequest) {
-      if(request instanceof UpdateRequest) {
-        NamedList response = directUpdate((AbstractUpdateRequest)request,clusterState);
-        if(response != null) {
+      if (request instanceof UpdateRequest) {
+        NamedList response = directUpdate((AbstractUpdateRequest) request,
+            clusterState);
+        if (response != null) {
           return response;
         }
       }
@@ -517,13 +509,16 @@ public NamedList getExceptions() {
       reqParams = new ModifiableSolrParams();
     }
     List<String> theUrlList = new ArrayList<String>();
-    if (request.getPath().equals("/admin/collections") || request.getPath().equals("/admin/cores")) {
+    if (request.getPath().equals("/admin/collections")
+        || request.getPath().equals("/admin/cores")) {
       Set<String> liveNodes = clusterState.getLiveNodes();
       for (String liveNode : liveNodes) {
         int splitPointBetweenHostPortAndContext = liveNode.indexOf("_");
         theUrlList.add("http://"
-            + liveNode.substring(0, splitPointBetweenHostPortAndContext) + "/"
-            + URLDecoder.decode(liveNode, "UTF-8").substring(splitPointBetweenHostPortAndContext + 1));
+            + liveNode.substring(0, splitPointBetweenHostPortAndContext)
+            + "/"
+            + URLDecoder.decode(liveNode, "UTF-8").substring(
+                splitPointBetweenHostPortAndContext + 1));
       }
     } else {
       String collection = reqParams.get("collection", defaultCollection);
@@ -535,7 +530,8 @@ public NamedList getExceptions() {
       
       Set<String> collectionsList = getCollectionList(clusterState, collection);
       if (collectionsList.size() == 0) {
-        throw new SolrException(ErrorCode.BAD_REQUEST, "Could not find collection: " + collection);
+        throw new SolrException(ErrorCode.BAD_REQUEST,
+            "Could not find collection: " + collection);
       }
       collection = collectionsList.iterator().next();
       
@@ -557,22 +553,20 @@ public NamedList getExceptions() {
       // add it to the Map of slices.
       Map<String,Slice> slices = new HashMap<String,Slice>();
       for (String collectionName : collectionsList) {
-        Collection<Slice> colSlices = clusterState.getActiveSlices(collectionName);
+        Collection<Slice> colSlices = clusterState
+            .getActiveSlices(collectionName);
         if (colSlices == null) {
-          throw new SolrServerException("Could not find collection:" + collectionName);
+          throw new SolrServerException("Could not find collection:"
+              + collectionName);
         }
         ClientUtils.addSlices(slices, collectionName, colSlices, true);
       }
       Set<String> liveNodes = clusterState.getLiveNodes();
       
-      synchronized (cachLock) {
-        List<String> leaderUrlList = leaderUrlLists.get(collection);
-        List<String> urlList = urlLists.get(collection);
-        List<String> replicasList = replicasLists.get(collection);
-        
-        if ((sendToLeaders && leaderUrlList == null)
-            || (!sendToLeaders && urlList == null)
-            || clusterState.hashCode() != this.lastClusterStateHashCode) {
+      List<String> leaderUrlList = null;
+      List<String> urlList = null;
+      List<String> replicasList = null;
+      
           // build a map of unique nodes
           // TODO: allow filtering by group, role, etc
           Map<String,ZkNodeProps> nodes = new HashMap<String,ZkNodeProps>();
@@ -584,8 +578,7 @@ public NamedList getExceptions() {
               if (!liveNodes.contains(coreNodeProps.getNodeName())
                   || !coreNodeProps.getState().equals(ZkStateReader.ACTIVE)) continue;
               if (nodes.put(node, nodeProps) == null) {
-                if (!sendToLeaders
-                    || (sendToLeaders && coreNodeProps.isLeader())) {
+            if (!sendToLeaders || (sendToLeaders && coreNodeProps.isLeader())) {
                   String url = coreNodeProps.getCoreUrl();
                   urlList2.add(url);
                 } else if (sendToLeaders) {
@@ -597,16 +590,11 @@ public NamedList getExceptions() {
           }
           
           if (sendToLeaders) {
-            this.leaderUrlLists.put(collection, urlList2);
             leaderUrlList = urlList2;
-            this.replicasLists.put(collection, replicas);
             replicasList = replicas;
           } else {
-            this.urlLists.put(collection, urlList2);
             urlList = urlList2;
           }
-          this.lastClusterStateHashCode = clusterState.hashCode();
-        }
         
         if (sendToLeaders) {
           theUrlList = new ArrayList<String>(leaderUrlList.size());
@@ -625,7 +613,7 @@ public NamedList getExceptions() {
           // System.out.println("replicas:" + theReplicas);
           theUrlList.addAll(theReplicas);
         }
-      }
+      
     }
     
     // System.out.println("########################## MAKING REQUEST TO " +
@@ -691,19 +679,4 @@ public boolean isUpdatesToLeaders() {
     return updatesToLeaders;
   }
 
-  // for tests
-  Map<String,List<String>> getUrlLists() {
-    return urlLists;
-  }
-
-  //for tests
-  Map<String,List<String>> getLeaderUrlLists() {
-    return leaderUrlLists;
-  }
-
-  //for tests
-  Map<String,List<String>> getReplicasLists() {
-    return replicasLists;
-  }
-
 }
diff --git a/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java b/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java
index 356f14b9..f606599c 100644
--- a/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java
+++ b/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java
@@ -218,11 +218,6 @@ public void process(WatchedEvent event) {
               Stat stat = new Stat();
               byte[] data = zkClient.getData(CLUSTER_STATE, thisWatch, stat ,
                   true);
-              List<String> liveNodes = zkClient.getChildren(
-                  LIVE_NODES_ZKNODE, this, true);
-     
-              Set<String> liveNodesSet = new HashSet<String>();
-              liveNodesSet.addAll(liveNodes);
               Set<String> ln = ZkStateReader.this.clusterState.getLiveNodes();
               ClusterState clusterState = ClusterState.load(stat.getVersion(), data, ln);
               // update volatile
diff --git a/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerTest.java b/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerTest.java
index e474e8a6..f05ba8b8 100644
--- a/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerTest.java
+++ b/lucene/dev/branches/lucene_solr_4_5/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerTest.java
@@ -196,53 +196,7 @@ public void doTest() throws Exception {
     
     del("*:*");
     commit();
-    
-    indexr(id, 0, "a_t", "to come to the aid of their country.");
-    
-    CloudJettyRunner shard1Leader = shardToLeaderJetty.get("shard1");
-    CloudJettyRunner shard2Leader = shardToLeaderJetty.get("shard2");
-    
-    if (cloudClient.isUpdatesToLeaders()) {
-      // compare leaders list
-      assertEquals(2, cloudClient.getLeaderUrlLists().get("collection1").size());
-      HashSet<String> leaderUrlSet = new HashSet<String>();
-      leaderUrlSet.addAll(cloudClient.getLeaderUrlLists().get("collection1"));
-      assertTrue("fail check for leader:" + shard1Leader.url + " in "
-          + leaderUrlSet, leaderUrlSet.contains(shard1Leader.url + "/"));
-      assertTrue("fail check for leader:" + shard2Leader.url + " in "
-          + leaderUrlSet, leaderUrlSet.contains(shard2Leader.url + "/"));
-      
-      // compare replicas list
-      Set<String> replicas = new HashSet<String>();
-      List<CloudJettyRunner> jetties = shardToJetty.get("shard1");
-      for (CloudJettyRunner cjetty : jetties) {
-        replicas.add(cjetty.url);
       }
-      jetties = shardToJetty.get("shard2");
-      for (CloudJettyRunner cjetty : jetties) {
-        replicas.add(cjetty.url);
-      }
-      replicas.remove(shard1Leader.url);
-      replicas.remove(shard2Leader.url);
-      
-      assertEquals(replicas.size(),
-          cloudClient.getReplicasLists().get("collection1").size());
-      
-      for (String url : cloudClient.getReplicasLists().get("collection1")) {
-        assertTrue("fail check for replica:" + url + " in " + replicas,
-            replicas.contains(stripTrailingSlash(url)));
-      }
-    }
-    
-  }
-
-  private String stripTrailingSlash(String url) {
-    if (url.endsWith("/")) {
-      return url.substring(0, url.length() - 1);
-    }
-    return url;
-  }
-  
   
   @Override
   protected void indexr(Object... fields) throws Exception {
