diff --git a/lucene/java/trunk/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java b/lucene/java/trunk/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
index c0260fa7..c447ef83 100644
--- a/lucene/java/trunk/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
+++ b/lucene/java/trunk/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
@@ -51,12 +51,22 @@ public SnowballAnalyzer(Version matchVersion, String name) {
     this.matchVersion = matchVersion;
   }
 
-  /** Builds the named analyzer with the given stop words. */
+  /** 
+   * Builds the named analyzer with the given stop words.
+   * @deprecated Use {@link #SnowballAnalyzer(Version, String, Set)} instead.  
+   */
   public SnowballAnalyzer(Version matchVersion, String name, String[] stopWords) {
     this(matchVersion, name);
     stopSet = StopFilter.makeStopSet(matchVersion, stopWords);
   }
 
+  /** Builds the named analyzer with the given stop words. */
+  public SnowballAnalyzer(Version matchVersion, String name, Set<?> stopWords) {
+    this(matchVersion, name);
+    stopSet = CharArraySet.unmodifiableSet(CharArraySet.copy(matchVersion,
+        stopWords));
+  }
+
   /** Constructs a {@link StandardTokenizer} filtered by a {@link
       StandardFilter}, a {@link LowerCaseFilter}, a {@link StopFilter},
       and a {@link SnowballFilter} */
diff --git a/lucene/java/trunk/contrib/snowball/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java b/lucene/java/trunk/contrib/snowball/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java
index 2f3b2a5b..aa361064 100644
--- a/lucene/java/trunk/contrib/snowball/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java
+++ b/lucene/java/trunk/contrib/snowball/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java
@@ -21,6 +21,7 @@
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.index.Payload;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
@@ -37,6 +38,13 @@ public void testEnglish() throws Exception {
         new String[]{"he", "abhor", "accent"});
   }
 
+  public void testStopwords() throws Exception {
+    Analyzer a = new SnowballAnalyzer(Version.LUCENE_CURRENT, "English",
+        StandardAnalyzer.STOP_WORDS_SET);
+    assertAnalyzesTo(a, "the quick brown fox jumped",
+        new String[]{"quick", "brown", "fox", "jump"});
+  }
+
   /**
    * Test english lowercasing. Test both cases (pre-3.1 and post-3.1) to ensure
    * we lowercase I correct for non-Turkish languages in either case.
