diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/filter/SSTableSliceIterator.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/filter/SSTableSliceIterator.java
index 28ab5c5f..814bdf2a 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/filter/SSTableSliceIterator.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/filter/SSTableSliceIterator.java
@@ -36,8 +36,9 @@ public SSTableSliceIterator(String filename, String key, String cfName, Abstract
 
         /* Morph key into actual key based on the partition type. */
         String decoratedKey = ssTable.getPartitioner().decorateKey(key);
-        long position = ssTable.getPosition(decoratedKey);
         AbstractType comparator1 = DatabaseDescriptor.getComparator(ssTable.getTableName(), cfName);
+        long position = ssTable.getPosition(decoratedKey);
+        if (position >= 0)
         reader = new SequenceFile.ColumnGroupReader(ssTable.getFilename(), decoratedKey, cfName, comparator1, startColumn, isAscending, position);
         this.comparator = comparator;
         this.startColumn = startColumn;
@@ -89,6 +90,9 @@ public ColumnFamily getColumnFamily()
 
     protected IColumn computeNext()
     {
+        if (reader == null)
+            return endOfData();
+
         while (true)
         {
             if (isAscending)
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/IndexHelper.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/IndexHelper.java
index 4c82fdf8..308b4909 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/IndexHelper.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/IndexHelper.java
@@ -18,15 +18,13 @@
 
 package org.apache.cassandra.io;
 
-import java.io.DataInput;
-import java.io.DataInputStream;
-import java.io.DataOutputStream;
-import java.io.IOException;
+import java.io.*;
 import java.util.*;
 
 import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.db.ColumnSerializer;
 import org.apache.cassandra.db.marshal.AbstractType;
+import org.apache.cassandra.utils.BloomFilter;
 
 
 /**
@@ -246,6 +244,40 @@ static ColumnRange getColumnRangeFromNameIndex(IndexHelper.ColumnIndexInfo cInde
         return columnRanges;
 	}
 
+    /**
+         * Reads the column name indexes if present. If the
+     * indexes are based on time then skip over them.
+     */
+    static int readColumnIndexes(RandomAccessFile file, String tableName, String cfName, List<ColumnIndexInfo> columnIndexList) throws IOException
+    {
+        /* check if we have an index */
+        boolean hasColumnIndexes = file.readBoolean();
+        int totalBytesRead = 1;
+        /* if we do then deserialize the index */
+        if (hasColumnIndexes)
+        {
+            /* read the index */
+            totalBytesRead += deserializeIndex(tableName, cfName, file, columnIndexList);
+        }
+        return totalBytesRead;
+    }
+
+    /**
+         * Defreeze the bloom filter.
+     *
+     * @return bloom filter summarizing the column information
+     * @throws java.io.IOException
+     */
+    static BloomFilter defreezeBloomFilter(RandomAccessFile file) throws IOException
+    {
+        int size = file.readInt();
+        byte[] bytes = new byte[size];
+        file.readFully(bytes);
+        DataInputBuffer bufIn = new DataInputBuffer();
+        bufIn.reset(bytes, bytes.length);
+        return BloomFilter.serializer().deserialize(bufIn);
+    }
+
 
     /**
      * A column range containing the start and end
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SequenceFile.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SequenceFile.java
index 1a18fb6b..c03020de 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SequenceFile.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SequenceFile.java
@@ -22,7 +22,6 @@
 import java.util.*;
 
 import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.utils.BloomFilter;
 import org.apache.cassandra.db.marshal.AbstractType;
 
 import org.apache.log4j.Logger;
@@ -106,12 +105,10 @@ public ColumnGroupReader(String filename, String key, String cfName, AbstractTyp
 
         private void init(byte[] startColumn, long position) throws IOException
         {
-            String keyInDisk = null;
-            if (seekTo(position) >= 0)
-                keyInDisk = file_.readUTF();
+            seek(position);
+            String keyInDisk = file_.readUTF();
+            assert keyInDisk.equals(key_);
 
-            if ( keyInDisk != null && keyInDisk.equals(key_))
-            {
                 /* read off the size of this row */
                 int dataSize = file_.readInt();
                 /* skip the bloomfilter */
@@ -152,13 +149,6 @@ private void init(byte[] startColumn, long position) throws IOException
                     curRangeIndex_ = index < 0 ? (++index) * (-1) - 1 : index;
                 }
             }
-            else
-            {
-                /* no keys found in this file because of a false positive in BF */
-                curRangeIndex_ = -1;
-                columnIndexList_ = new ArrayList<IndexHelper.ColumnIndexInfo>();
-            }
-        }
 
         private boolean getBlockFromCurIndex(DataOutputBuffer bufOut) throws IOException
         {
@@ -220,52 +210,6 @@ public String getFileName()
             return filename_;
         }
 
-        long seekTo(long position) throws IOException
-        {
-            if (position >= 0)
-                seek(position);
-            return position;
-        }
-
-        /**
-         * Defreeze the bloom filter.
-         *
-         * @return bloom filter summarizing the column information
-         * @throws IOException
-         */
-        private BloomFilter defreezeBloomFilter() throws IOException
-        {
-            int size = file_.readInt();
-            byte[] bytes = new byte[size];
-            file_.readFully(bytes);
-            DataInputBuffer bufIn = new DataInputBuffer();
-            bufIn.reset(bytes, bytes.length);
-            BloomFilter bf = BloomFilter.serializer().deserialize(bufIn);
-            return bf;
-        }
-
-        /**
-         * Reads the column name indexes if present. If the
-         * indexes are based on time then skip over them.
-         *
-         * @param cfName
-         * @return
-         */
-        private int handleColumnNameIndexes(String cfName, List<IndexHelper.ColumnIndexInfo> columnIndexList) throws IOException
-        {
-            /* check if we have an index */
-            boolean hasColumnIndexes = file_.readBoolean();
-            int totalBytesRead = 1;
-            /* if we do then deserialize the index */
-            if (hasColumnIndexes)
-            {
-                String tableName = getTableName();
-                /* read the index */
-                totalBytesRead += IndexHelper.deserializeIndex(tableName, cfName, file_, columnIndexList);
-            }
-            return totalBytesRead;
-        }
-
         /**
          * This method dumps the next key/value into the DataOuputStream
          * passed in. Always use this method to query for application
@@ -279,26 +223,12 @@ private int handleColumnNameIndexes(String cfName, List<IndexHelper.ColumnIndexI
         public long next(String key, DataOutputBuffer bufOut, String columnFamilyName, SortedSet<byte[]> columnNames, long position) throws IOException
         {
             assert columnNames != null;
-
-            long bytesRead = -1L;
-            if (isEOF() || seekTo(position) < 0)
-                return bytesRead;
+            seek(position);
 
             /* note the position where the key starts */
             long startPosition = file_.getFilePointer();
             String keyInDisk = file_.readUTF();
             assert keyInDisk.equals(key);
-            readColumns(key, bufOut, columnFamilyName, columnNames);
-
-            long endPosition = file_.getFilePointer();
-            bytesRead = endPosition - startPosition;
-
-            return bytesRead;
-        }
-
-        private void readColumns(String key, DataOutputBuffer bufOut, String columnFamilyName, SortedSet<byte[]> cNames)
-        throws IOException
-        {
             int dataSize = file_.readInt();
 
             /* write the key into buffer */
@@ -306,42 +236,25 @@ private void readColumns(String key, DataOutputBuffer bufOut, String columnFamil
 
             /* Read the bloom filter summarizing the columns */
             long preBfPos = file_.getFilePointer();
-            BloomFilter bf = defreezeBloomFilter();
+            IndexHelper.defreezeBloomFilter(file_);
             long postBfPos = file_.getFilePointer();
             dataSize -= (postBfPos - preBfPos);
 
             List<IndexHelper.ColumnIndexInfo> columnIndexList = new ArrayList<IndexHelper.ColumnIndexInfo>();
-            /* read the column name indexes if present */
-            int totalBytesRead = handleColumnNameIndexes(columnFamilyName, columnIndexList);
-            dataSize -= totalBytesRead;
+            dataSize -= IndexHelper.readColumnIndexes(file_, getTableName(), columnFamilyName, columnIndexList);
 
-            /* read the column family name */
+            // read CF data so we can echo it back to the outstream
             String cfName = file_.readUTF();
-            dataSize -= (utfPrefix_ + cfName.length());
-
             String cfType = file_.readUTF();
-            dataSize -= (utfPrefix_ + cfType.length());
-
             String comparatorName = file_.readUTF();
-            dataSize -= (utfPrefix_ + comparatorName.length());
-
             String subComparatorName = file_.readUTF();
-            dataSize -= (utfPrefix_ + subComparatorName.length());
-
-            /* read local deletion time */
             int localDeletionTime = file_.readInt();
-            dataSize -=4;
-
-            /* read if this cf is marked for delete */
             long markedForDeleteAt = file_.readLong();
-            dataSize -= 8;
-
-            /* read the total number of columns */
-            int totalNumCols = file_.readInt();
-            dataSize -= 4;
+            int totalColumns = file_.readInt();
+            dataSize -= (4 * utfPrefix_ + cfName.length() + cfType.length() + comparatorName.length() + subComparatorName.length() + 4 + 8 + 4);
 
             /* get the various column ranges we have to read */
-            List<IndexHelper.ColumnRange> columnRanges = IndexHelper.getMultiColumnRangesFromNameIndex(cNames, columnIndexList, dataSize, totalNumCols);
+            List<IndexHelper.ColumnRange> columnRanges = IndexHelper.getMultiColumnRangesFromNameIndex(columnNames, columnIndexList, dataSize, totalColumns);
 
             /* calculate the data size */
             int numColsReturned = 0;
@@ -354,7 +267,7 @@ private void readColumns(String key, DataOutputBuffer bufOut, String columnFamil
             }
 
             // returned data size
-            bufOut.writeInt(dataSizeReturned + utfPrefix_ * 4 + cfName.length() + cfType.length() + comparatorName.length() + subComparatorName.length() + 4 + 4 + 8 + 4);
+            bufOut.writeInt(dataSizeReturned + utfPrefix_ * 4 + cfName.length() + cfType.length() + comparatorName.length() + subComparatorName.length() + 4 + 8 + 4);
             // echo back the CF data we read
             bufOut.writeUTF(cfName);
             bufOut.writeUTF(cfType);
@@ -374,7 +287,11 @@ private void readColumns(String key, DataOutputBuffer bufOut, String columnFamil
                 bufOut.write(file_, (int) (coordinate.end_ - coordinate.start_));
                 prevPosition = (int) coordinate.end_;
             }
+
+            long endPosition = file_.getFilePointer();
+            return endPosition - startPosition;
         }
+
     }
 
     public static class Reader extends AbstractReader
