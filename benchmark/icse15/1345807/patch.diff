diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/AbstractNaiveBayesClassifier.java b/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/AbstractNaiveBayesClassifier.java
index 0da2917c..5a3de9c0 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/AbstractNaiveBayesClassifier.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/AbstractNaiveBayesClassifier.java
@@ -45,7 +45,7 @@ protected double getScoreForLabelInstance(int label, Vector instance) {
       Element e = elements.next();
       result += e.get() * getScoreForLabelFeature(label, e.index());
     }
-    return result / model.thetaNormalizer(label);
+    return -result;
   }
   
   @Override
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/ComplementaryNaiveBayesClassifier.java b/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/ComplementaryNaiveBayesClassifier.java
index f02a8c90..45fbc8b8 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/ComplementaryNaiveBayesClassifier.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/ComplementaryNaiveBayesClassifier.java
@@ -1,3 +1,6 @@
+prepare20newsgroups = deprecated : Use new naivebayes classifier see examples/bin/classify-20newsgroups.sh 
+trainclassifier = deprecated : Use new naivebayes classifier see examples/bin/classify-20newsgroups.sh 
+testclassifier = deprecated : Use new naivebayes classifier see examples/bin/classify-20newsgroups.sh 
 /**
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -33,7 +36,6 @@ public double getScoreForLabelFeature(int label, int feature) {
     NaiveBayesModel model = getModel();
     double numerator = model.featureWeight(feature) - model.weight(label, feature) + model.alphaI();
     double denominator =  model.totalWeightSum() - model.labelWeight(label) + model.alphaI() * model.numFeatures();
-
     return Math.log(numerator / denominator);
   }
 }
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/training/ComplementaryThetaTrainer.java b/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/training/ComplementaryThetaTrainer.java
index 790854b9..61a575c1 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/training/ComplementaryThetaTrainer.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/training/ComplementaryThetaTrainer.java
@@ -28,13 +28,13 @@ public ComplementaryThetaTrainer(Vector weightsPerFeature, Vector weightsPerLabe
   }
 
   @Override
-  public void train(int label, Vector instance) {
+  public void train(int label, Vector perLabelWeight) {
     double sigmaK = labelWeight(label);
-    Iterator<Vector.Element> it = instance.iterateNonZero();
+    Iterator<Vector.Element> it = perLabelWeight.iterateNonZero();
     while (it.hasNext()) {
       Vector.Element e = it.next();
       double numerator = featureWeight(e.index()) - e.get() + alphaI();
-      double denominator = totalWeightSum() - sigmaK + alphaI() * numFeatures();
+      double denominator = totalWeightSum() - sigmaK + numFeatures() ;
       double weight = Math.log(numerator / denominator);
       updatePerLabelThetaNormalizer(label, weight);
     }
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/training/StandardThetaTrainer.java b/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/training/StandardThetaTrainer.java
index 707adc3d..5397c863 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/training/StandardThetaTrainer.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/classifier/naivebayes/training/StandardThetaTrainer.java
@@ -28,13 +28,13 @@ public StandardThetaTrainer(Vector weightsPerFeature, Vector weightsPerLabel, do
   }
 
   @Override
-  public void train(int label, Vector instance) {
+  public void train(int label, Vector perLabelWeight) {
     double sigmaK = labelWeight(label);
-    Iterator<Vector.Element> it = instance.iterateNonZero();
+    Iterator<Vector.Element> it = perLabelWeight.iterateNonZero();
     while (it.hasNext()) {
       Vector.Element e = it.next();
       double numerator = e.get() + alphaI();
-      double denominator = sigmaK + alphaI() * numFeatures();
+      double denominator = sigmaK + numFeatures();
       double weight = Math.log(numerator / denominator);
       updatePerLabelThetaNormalizer(label, weight);
     }
