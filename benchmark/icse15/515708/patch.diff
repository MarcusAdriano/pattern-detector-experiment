diff --git a/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ColumnInfo.java b/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ColumnInfo.java
index 7397ddd9..d33948b8 100644
--- a/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ColumnInfo.java
+++ b/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ColumnInfo.java
@@ -208,8 +208,7 @@ private boolean initializeColumnInfo(String columnPattern)
 	//return true if the given type is supported by import/export
 	public  static final boolean importExportSupportedType(int type){
 
-		return !(type == java.sql.Types.BINARY ||
-				 type == java.sql.Types.BIT ||
+		return !(type == java.sql.Types.BIT ||
 				 type == java.sql.Types.JAVA_OBJECT ||
 				 type == java.sql.Types.OTHER ||
 				 type == StoredFormatIds.XML_TYPE_ID); 
diff --git a/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ControlInfo.java b/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ControlInfo.java
index 401dcb0e..3f82e68b 100644
--- a/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ControlInfo.java
+++ b/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ControlInfo.java
@@ -363,12 +363,19 @@ private void validateDelimiters() throws Exception
 		}
 		
 		
-		//A delimiter is not valid or is used more than once.
+        // check for the invalid delimiters. A delimiter is not valid it 
+        // is used more than once, i.e same character is used 
+        // character data delimiter and also as a column delimiter. 
+        // An hex decimal character (0-9, a-f ,A-F ) is not a 
+        // valid delimiter, because binary data can be imported/exported 
+        // as hex string.
+
 		if(colDel == charDel || 
 		   colDel == '.' ||
 		   Character.isSpaceChar(colDel) ||  
-		   Character.isSpaceChar(charDel)
-		   )
+		   Character.isSpaceChar(charDel) ||
+           Character.digit(colDel, 16) != -1 ||
+           Character.digit(charDel, 16) != -1 )
 		{
 			throw LoadError.delimitersAreNotMutuallyExclusive();
 		}
diff --git a/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ImportAbstract.java b/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ImportAbstract.java
index 9b95d285..4bdc8bf6 100644
--- a/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ImportAbstract.java
+++ b/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ImportAbstract.java
@@ -26,6 +26,7 @@ Licensed to the Apache Software Foundation (ASF) under one or more
 import java.sql.ResultSetMetaData;
 import org.apache.derby.vti.VTITemplate;
 import java.util.ArrayList;
+import org.apache.derby.iapi.util.StringUtil;
 
 /**
  * 
@@ -176,6 +177,32 @@ public String getString(int columnIndex) throws SQLException {
 	}
 
 
+    /**
+     * Returns byte array that contains the columnn data 
+     * from the import file. 
+     * @param columnIndex number of the column. starts at 1.
+     * @exception SQLException if any error occurs.
+     */
+	public byte[] getBytes(int columnIndex) throws SQLException {
+        
+        // This method is called to import data into 
+        // LONG VARCHAR FOR BIT DATA VARCHAR FOR BIT DATA,  
+        // and CHAR FOR BIT DATA  type columns. Data for 
+        // these type of columns expected to be in the  
+        // main import file in hex format.  
+
+        // convert the binary data in the hex format to a byte array.
+        String hexData = nextRow[columnIndex-1];
+        // if hex data is null, then column value is SQL NULL
+        wasNull = (hexData == null);
+        byte[] data = null;
+        if (hexData != null) 
+            data = StringUtil.fromHexString(hexData, 0, hexData.length());
+        return data;
+	}
+
+
+
     /**
      * Check if for this column type, real data is stored in an 
      * external file and only the reference is in the main import 
diff --git a/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ImportResultSetMetaData.java b/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ImportResultSetMetaData.java
index 5608bc02..3ab82f59 100644
--- a/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ImportResultSetMetaData.java
+++ b/db/derby/code/trunk/java/engine/org/apache/derby/impl/load/ImportResultSetMetaData.java
@@ -54,21 +54,58 @@ public String getColumnName(int column) {
 
 	public int getColumnType(int column) {
 
-        // if the table column type is BLOB/CLOB , then the 
-        // data in the import files will converted to 
-        // BLOB/CLOB type objects. So the vti result column 
-        // type for blob/clob is same as  table column type. 
-        // Data for Other types is considered is of VARCHAR type, 
-        // and they are casted to table column type, if needed 
-        // while doing the select from the VTI. 
-
-		if (tableColumnTypes[column -1] ==  java.sql.Types.BLOB)
-			return java.sql.Types.BLOB;
-		else
-            if (tableColumnTypes[column -1] ==  java.sql.Types.CLOB)
-                return java.sql.Types.CLOB;
-            else
-                return java.sql.Types.VARCHAR;
+        /* By default all the data in the import file is assumed
+         * to be in varchar format. Appropriate casting is applied 
+         * while executing the select on the import VTI. Using this 
+         * approach import vti does not have to do the data conversion, 
+         * casting will do that. 
+         *
+         * But for some types like binary types there is no casting 
+         * support from varchar or the data in the file is hex format, 
+         * so data  needs to be converted to binary format first. And 
+         * incase of blobs/clobs stored in an exteranl file memory usage 
+         * will  be less if data is supplied as stream, instead of 
+         * materializing the column data as one string. For these
+         * types import vti result set will return resultset column
+         * type is same as the column type of the import table. Data 
+         * for the blob, clob or binary type columns is returned by 
+         * the getXXX() calls used by the VTI Resultset to read the 
+         * data for that particular type. For example, Blob data 
+         * is read using getBlob() method, which will return a 
+         * Blob object that contains the data in the import file 
+         * for a column. 
+         */
+
+        int colType;
+        switch (tableColumnTypes[column -1])
+        {
+        case java.sql.Types.BLOB: 
+            // blob 
+            colType = java.sql.Types.BLOB;
+            break;
+        case java.sql.Types.CLOB: 
+            // clob 
+            colType = java.sql.Types.CLOB;
+            break;
+        case java.sql.Types.LONGVARBINARY: 
+            // LONG VARCHAR FOR BIT DATA
+            colType = java.sql.Types.LONGVARBINARY; 
+            break;
+        case java.sql.Types.VARBINARY: 
+            // VARCHAR FOR BIT DATA
+            colType = java.sql.Types.VARBINARY;
+            break;
+        case java.sql.Types.BINARY: 
+            // CHAR FOR BIT DATA 
+            colType = java.sql.Types.BINARY;
+            break;
+        default: 
+            // all other data in the import file is 
+            // assumed to be in varchar format.
+            colType = java.sql.Types.VARCHAR;
+        }
+
+        return colType;
     }
 
 	public int isNullable(int column) {
diff --git a/db/derby/code/trunk/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java b/db/derby/code/trunk/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java
index e69de29b..bbbbe370 100644
--- a/db/derby/code/trunk/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java
+++ b/db/derby/code/trunk/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java
@@ -0,0 +1,382 @@
+/*
+
+   Derby - Class org.apache.derbyTesting.functionTests.tests.
+                                         tools.ImportExportBinaryDataTest
+
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+
+ */
+package org.apache.derbyTesting.functionTests.tests.tools;
+
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.Statement;
+import java.io.IOException;
+
+import junit.framework.Test;
+import junit.framework.TestSuite;
+
+import org.apache.derbyTesting.junit.BaseJDBCTestCase;
+import org.apache.derbyTesting.junit.CleanDatabaseTestSetup;
+import org.apache.derbyTesting.junit.TestConfiguration;
+import org.apache.derbyTesting.junit.SupportFilesSetup;
+import org.apache.derbyTesting.junit.JDBC;
+
+/**
+ * This class tests import/export of  a table with simple binary data types 
+ * CHAR FOR BIT DATA, VARCHAR FOR BIT DATA,  LONG VARCHAR FOR BIT DATA.
+ */
+
+public class ImportExportBinaryDataTest extends BaseJDBCTestCase {
+
+    String fileName; // file used to perform import/export.
+
+    public ImportExportBinaryDataTest(String name) {
+        super(name);
+        // set the file that is used by the import/export. 
+        fileName = 
+            (SupportFilesSetup.getReadWrite("bin_tab.del")).getPath();
+    }
+
+    /**
+     * Runs the tests in the default embedded configuration and then
+     * the client server configuration.
+     */
+    public static Test suite()
+    {
+        TestSuite suite = new TestSuite(ImportExportBinaryDataTest.class);
+        suite.addTest(TestConfiguration.clientServerSuite(
+                      ImportExportBinaryDataTest.class));
+        Test test = suite;
+        test = new SupportFilesSetup(test);
+        return new CleanDatabaseTestSetup(test) {
+                protected void decorateSQL(Statement s) throws SQLException {
+                    // table used to test  export.
+                    s.execute("CREATE TABLE BIN_TAB (id int," +
+                              "C_BD CHAR(4) FOR BIT DATA," + 
+                              "C_VBD VARCHAR(10) FOR BIT DATA, " +
+                              "C_LVBD LONG VARCHAR FOR BIT DATA)");
+                    // load some data into the above table. 
+                    loadData(s);
+                    // table used to test import. 
+                    s.execute("CREATE TABLE BIN_TAB_IMP(id int," +
+                              "C_BD CHAR(4) FOR BIT DATA," + 
+                              "C_VBD VARCHAR(10) FOR BIT DATA, " +
+                              "C_LVBD LONG VARCHAR FOR BIT DATA)");
+                }
+            };
+    }
+
+    
+    /**
+     * Simple set up, just empty the import table.
+     * @throws SQLException 
+     */
+    protected void setUp() throws SQLException
+    {
+        Statement s  = createStatement();
+        // delete the rows from the import table.
+        s.executeUpdate("DELETE FROM BIN_TAB_IMP");
+        s.close();
+    }
+    
+
+    /**
+     * Test import/export of a table, using 
+     * SYSCS_EXPORT_TABLE and SYSCS_IMPORT_TABLE procedures.
+     */
+    public void testImportTableExportTable()  
+        throws SQLException, IOException
+    {
+        doExportTable("APP", "BIN_TAB", fileName, null, null , null);
+	    doImportTable("APP", "BIN_TAB_IMP", fileName, null, null, null, 0);
+        verifyData(" * ");
+    }
+
+    
+    /*
+     * Test import/export of all the columns using 
+     * SYSCS_EXPORT_QUERY and SYSCS_IMPORT_DATA procedures.  
+     */
+    public void testImportDataExportQuery() 
+        throws SQLException, IOException
+    {
+        doExportQuery("select * from BIN_TAB", fileName,
+                      null, null , null);
+	    doImportData(null, "BIN_TAB_IMP", null, null, fileName, 
+                     null, null, null, 0);
+        verifyData(" * ");
+
+        // perform import with column names specified in random order.
+        doImportData(null, "BIN_TAB_IMP", "C_LVBD, C_VBD, C_BD, ID", 
+                     "4, 3, 2, 1",  fileName, null, null, null, 1);
+        verifyData("C_LVBD, C_VBD, C_BD, ID");
+
+        // test with  non-default delimiters. 
+        doExportQuery("select * from BIN_TAB", fileName,
+                      ";", "%" , null);
+	    doImportData(null, "BIN_TAB_IMP", null, null, fileName, 
+                     ";", "%", null, 1);
+
+    }
+
+
+    /*
+     * Test import of only some columns of the table 
+     * using  SYSCS_EXPOR_QUERY and IMPORT_DATA procedures.  
+     */
+    public void testImportDataExportQueryWithFewColumns() 
+        throws SQLException, IOException
+    {
+        doExportQuery("select id, c_bd, c_vbd, c_lvbd from BIN_TAB",  
+                      fileName,  null, null, null);
+        doImportData(null, "BIN_TAB_IMP", "ID,C_LVBD", "1 , 4",
+                     fileName, null, null, null, 0);
+        verifyData("ID,C_LVBD");
+        doImportData(null, "BIN_TAB_IMP", "ID, C_LVBD, C_BD", "1, 4, 2",
+                     fileName, null, null, null, 1);
+        verifyData("ID, C_LVBD, C_BD");
+        doImportData(null, "BIN_TAB_IMP", "ID, C_VBD, C_BD", "1, 3, 2",
+                     fileName, null, null, null, 1);
+        verifyData("ID, C_VBD, C_BD");
+
+        // test with  non-default delimiters. 
+        doExportQuery("select id, c_bd, c_vbd, c_lvbd from BIN_TAB",  
+                      fileName,  "$", "!" , null);
+        doImportData(null, "BIN_TAB_IMP", "ID,C_LVBD", "1 , 4",
+                     fileName, "$", "!", null, 0);
+    }
+
+
+    /* 
+     *  Tests import/export procedures with invalid
+     *  hex decimal characters (0-9, a-f, A-F)  as delimiters. 
+     */
+    public void testImportExportInvalideDelimiters() 
+         throws SQLException, IOException   
+    {
+        try {
+            doExportTable("APP", "BIN_TAB", fileName, null, "9" , null);
+        } catch (SQLException e) {
+            assertSQLState("XIE0J", e);
+        }
+
+        try {
+            doExportQuery("select * from BIN_TAB", fileName,
+                          "|", "f", null);
+        } catch (SQLException e) {
+            assertSQLState("XIE0J", e);
+        }
+
+        try {
+            doExportTable("APP", "BIN_TAB", fileName, "B", null , null);
+        } catch (SQLException e) {
+            assertSQLState("XIE0J", e);
+        }
+
+        doExportTable("APP", "BIN_TAB", fileName, null, null , null);
+
+        /* Currently BaseJDBCTestCase.assertSQLState() is unable
+         * to find nested SQLSTATEs with 1.6 JVMs, so we have to
+         * check for the top-level SQLSTATE in that case.  When
+         * that changes the "JDBC.vmSupportsJDBC4()" call can be
+         * removed from the following assertSQLState() calls.
+         * (DERBY-1440)
+         */
+
+        try {
+            doImportTable("APP", "BIN_TAB_IMP", fileName, "2", null, null, 0);
+        } catch (SQLException e) {
+             assertSQLState(JDBC.vmSupportsJDBC4() ? "38000": "XIE0J", e);
+        }
+
+        try {
+            doImportData(null, "BIN_TAB_IMP", null, 
+                         null,  fileName, null, "c", null, 1);
+        } catch (SQLException e) {
+            assertSQLState(JDBC.vmSupportsJDBC4() ? "38000": "XIE0J", e);
+        }
+    }
+
+
+
+    /* 
+     * Verifies data in the import test table (BIN_TAB_IMP) is same 
+     * as the test table from which the data was exported earlier(BIN_TAB). 
+     * @param cols  imported columns , if all then " * ", otherwise 
+     *              comma separated column list. 
+     * @exception SQLException  if the data does match or if 
+     *                          any other error during comparision.  
+     */
+    private void verifyData(String cols)  
+        throws SQLException, IOException
+    {
+        Statement s1 = createStatement();
+        ResultSet rsExport = s1.executeQuery("SELECT " + cols  +  
+                                             " FROM BIN_TAB order by id");
+        Statement s2 = createStatement();
+        ResultSet rsImport = s2.executeQuery("SELECT " + cols  +  
+                                             " FROM BIN_TAB_IMP order by id");
+        JDBC.assertSameContents(rsExport, rsImport);
+        
+        s1.close();
+        s2.close();
+    }
+    
+
+    /**
+     * Perform export using SYSCS_UTIL.SYSCS_EXPORT_TABLE procedure.
+     */
+    private void doExportTable(String schemaName, 
+                               String tableName, 
+                               String fileName, 
+                               String colDel , 
+                               String charDel, 
+                               String codeset) throws SQLException 
+    {
+        String expsql = 
+            "call SYSCS_UTIL.SYSCS_EXPORT_TABLE (? , ? , ? , ?, ? , ?)";
+        PreparedStatement ps = prepareStatement(expsql);
+        ps.setString(1, schemaName);
+        ps.setString(2, tableName);
+        ps.setString(3, fileName);
+        ps.setString(4, colDel);
+        ps.setString(5, charDel);
+        ps.setString(6, codeset);
+        ps.execute();
+        ps.close();
+    }
+
+    
+
+    /**
+     * Perform export using SYSCS_UTIL.SYSCS_EXPORT_QUERY procedure.
+     */
+    private void doExportQuery(String query,
+                               String fileName,
+                               String colDel , 
+                               String charDel, 
+                               String codeset) 
+        throws SQLException 
+    {
+        String expsql = 
+            "call SYSCS_UTIL.SYSCS_EXPORT_QUERY(? , ? , ? , ?, ?)";
+        PreparedStatement ps = prepareStatement(expsql);
+        ps.setString(1, query);
+        ps.setString(2, fileName);
+        ps.setString(3, colDel);
+        ps.setString(4, charDel);
+        ps.setString(5, codeset);
+        ps.execute();
+        ps.close();
+    }
+
+    /**
+     * Perform import using SYSCS_UTIL.SYSCS_IMPORT_TABLE procedure.
+     */
+    private void doImportTable(String schemaName,
+                               String tableName, 
+                               String fileName, 
+                               String colDel, 
+                               String charDel , 
+                               String codeset, 
+                               int replace) throws SQLException 
+    {
+        String impsql = 
+            "call SYSCS_UTIL.SYSCS_IMPORT_TABLE (?, ?, ?, ?, ?, ?, ?)";
+        PreparedStatement ps = prepareStatement(impsql);
+        ps.setString(1 , schemaName);
+        ps.setString(2, tableName);
+        ps.setString(3, fileName);
+        ps.setString(4 , colDel);
+        ps.setString(5 , charDel);
+        ps.setString(6 , codeset);
+        ps.setInt(7, replace);
+        ps.execute();
+        ps.close();
+    }
+
+
+    /**
+     *  Perform import using SYSCS_UTIL.SYSCS_IMPORT_DATA procedure.
+     */
+    private void doImportData(String schemaName,
+                              String tableName, 
+                              String insertCols,
+                              String colIndexes, 
+                              String fileName,
+                              String colDel, 
+                              String charDel , 
+                              String codeset, 
+                              int replace) throws SQLException 
+    {
+        String impsql = 
+            "call SYSCS_UTIL.SYSCS_IMPORT_DATA(?, ?, ?, ?, ?, ?, ?, ?, ?)";
+        PreparedStatement ps = prepareStatement(impsql);
+        ps.setString(1, schemaName);
+        ps.setString(2, tableName);
+        ps.setString(3, insertCols);
+        ps.setString(4, colIndexes);
+        ps.setString(5, fileName);
+        ps.setString(6 , colDel);
+        ps.setString(7 , charDel);
+        ps.setString(8 , codeset);
+        ps.setInt(9, replace);
+        ps.execute();
+        ps.close();
+    }
+
+    
+    /*
+     * Insert data to the into the table, whose data will be exported.
+     */
+    private static void loadData(Statement s) throws SQLException {
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(1, X'31', X'3241510B',  X'3743640ADE12337610')");
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(2, X'33', X'3341610B',  X'3843640ADE12337610')");
+        // rows with empty strings. 
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(4, X'41', X'42',  X'')");
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(5, X'41', X'', X'42')");
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(6, X'', X'42',  X'3233445578990122558820')");
+        
+        // rows with a null
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(7, null, X'3341610B',  X'3843640ADE12337610')");
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(8,  X'3341610B', null,  X'3843640ADE12337610')");
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(9,  X'3341610B',  X'3843640ADE' , null)");
+
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(10, X'', null,  X'3843640ADE12')");
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(11, X'66', null,  X'')");
+        
+        // insert data that contains some delimiter characters 
+        // ( "(x22) ,(x2C) %(x25) ;(x3B) , tab(9) LF(A) )
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(12, X'2C313B09', X'224122',  X'222C23B90A')");
+        // !(x21) $(24)
+        s.executeUpdate("insert into bin_tab values " + 
+                        "(13, X'212C3B24', X'2422412221', " + 
+                        "  X'212421222C23B90A2124')");
+    }
+}
diff --git a/db/derby/code/trunk/java/testing/org/apache/derbyTesting/functionTests/tests/tools/_Suite.java b/db/derby/code/trunk/java/testing/org/apache/derbyTesting/functionTests/tests/tools/_Suite.java
index de0bcbd5..6a1dc11b 100644
--- a/db/derby/code/trunk/java/testing/org/apache/derbyTesting/functionTests/tests/tools/_Suite.java
+++ b/db/derby/code/trunk/java/testing/org/apache/derbyTesting/functionTests/tests/tools/_Suite.java
@@ -47,6 +47,7 @@ public static Test suite() {
 
         suite.addTest(IJRunScriptTest.suite());
         suite.addTest(ImportExportTest.suite());
+        suite.addTest(ImportExportBinaryDataTest.suite());
 
         // SysinfoAPITest currently fails when run against jars, so is
         // disabled. Only the first jar file on the classpath properly
