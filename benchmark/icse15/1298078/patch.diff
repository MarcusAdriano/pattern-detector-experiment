diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java b/lucene/dev/branches/solr_3159_jetty8/lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java
index da45f552..c70fe7a1 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest.java
@@ -22,6 +22,7 @@
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
+import java.io.StringReader;
 import java.util.HashSet;
 import java.util.Set;
 
@@ -41,11 +42,16 @@
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.queryparser.classic.QueryParser;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.RegexpQuery;
 import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util._TestUtil;
@@ -226,4 +232,28 @@ public void testDocsAndPositionsEnumStart() throws Exception {
     assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
     reader.close();
   }
+
+  // LUCENE-3831
+  public void testNullPointerException() throws IOException {
+    RegexpQuery regex = new RegexpQuery(new Term("field", "worl."));
+    SpanQuery wrappedquery = new SpanMultiTermQueryWrapper<RegexpQuery>(regex);
+        
+    MemoryIndex mindex = new MemoryIndex();
+    mindex.addField("field", new MockAnalyzer(random).tokenStream("field", new StringReader("hello there")));
+
+    // This throws an NPE
+    assertEquals(0, mindex.search(wrappedquery), 0.00001f);
+  }
+    
+  // LUCENE-3831
+  public void testPassesIfWrapped() throws IOException {
+    RegexpQuery regex = new RegexpQuery(new Term("field", "worl."));
+    SpanQuery wrappedquery = new SpanOrQuery(new SpanMultiTermQueryWrapper<RegexpQuery>(regex));
+
+    MemoryIndex mindex = new MemoryIndex();
+    mindex.addField("field", new MockAnalyzer(random).tokenStream("field", new StringReader("hello there")));
+
+    // This passes though
+    assertEquals(0, mindex.search(wrappedquery), 0.00001f);
+  }
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/BlockTermsReader.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/BlockTermsReader.java
index d2e42c63..72be59cc 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/BlockTermsReader.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/BlockTermsReader.java
@@ -197,6 +197,7 @@ public FieldsEnum iterator() {
 
   @Override
   public Terms terms(String field) throws IOException {
+    assert field != null;
     return fields.get(field);
   }
 
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java
index f773e1e7..00a0c2a6 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/BlockTreeTermsReader.java
@@ -211,6 +211,7 @@ public FieldsEnum iterator() {
 
   @Override
   public Terms terms(String field) throws IOException {
+    assert field != null;
     return fields.get(field);
   }
 
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/DocValuesArraySource.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/DocValuesArraySource.java
index e69de29b..0081e88d 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/DocValuesArraySource.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/DocValuesArraySource.java
@@ -0,0 +1,513 @@
+package org.apache.lucene.codecs;
+
+import java.io.IOException;
+import java.util.Collections;
+import java.util.EnumMap;
+import java.util.Map;
+
+import org.apache.lucene.index.DocValues.Source;
+import org.apache.lucene.index.DocValues.Type;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.RamUsageEstimator;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with this
+ * work for additional information regarding copyright ownership. The ASF
+ * licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ * 
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+/**
+ * @lucene.experimental
+ * @lucene.internal
+ */
+public abstract class DocValuesArraySource extends Source {
+
+  private static final Map<Type, DocValuesArraySource> TEMPLATES;
+
+  static {
+    EnumMap<Type, DocValuesArraySource> templates = new EnumMap<Type, DocValuesArraySource>(
+        Type.class);
+    templates.put(Type.FIXED_INTS_16, new ShortValues());
+    templates.put(Type.FIXED_INTS_32, new IntValues());
+    templates.put(Type.FIXED_INTS_64, new LongValues());
+    templates.put(Type.FIXED_INTS_8, new ByteValues());
+    templates.put(Type.FLOAT_32, new FloatValues());
+    templates.put(Type.FLOAT_64, new DoubleValues());
+    TEMPLATES = Collections.unmodifiableMap(templates);
+  }
+  
+  public static DocValuesArraySource forType(Type type) {
+    return TEMPLATES.get(type);
+  }
+
+  protected final int bytesPerValue;
+
+  DocValuesArraySource(int bytesPerValue, Type type) {
+    super(type);
+    this.bytesPerValue = bytesPerValue;
+  }
+
+  @Override
+  public abstract BytesRef getBytes(int docID, BytesRef ref);
+
+  
+  public abstract DocValuesArraySource newFromInput(IndexInput input, int numDocs)
+      throws IOException;
+  
+  public abstract DocValuesArraySource newFromArray(Object array);
+
+  @Override
+  public final boolean hasArray() {
+    return true;
+  }
+
+  public void toBytes(long value, BytesRef bytesRef) {
+    copyLong(bytesRef, value);
+  }
+
+  public void toBytes(double value, BytesRef bytesRef) {
+    copyLong(bytesRef, Double.doubleToRawLongBits(value));
+  }
+
+  final static class ByteValues extends DocValuesArraySource {
+    private final byte[] values;
+    
+    ByteValues() {
+      super(1, Type.FIXED_INTS_8);
+      values = new byte[0];
+    }
+    private ByteValues(byte[] array) {
+      super(1, Type.FIXED_INTS_8);
+      values = array;
+    }
+
+    private ByteValues(IndexInput input, int numDocs) throws IOException {
+      super(1, Type.FIXED_INTS_8);
+      values = new byte[numDocs];
+      input.readBytes(values, 0, values.length, false);
+    }
+
+    @Override
+    public byte[] getArray() {
+      return values;
+    }
+
+    @Override
+    public long getInt(int docID) {
+      assert docID >= 0 && docID < values.length;
+      return values[docID];
+    }
+
+    @Override
+    public DocValuesArraySource newFromInput(IndexInput input, int numDocs)
+        throws IOException {
+      return new ByteValues(input, numDocs);
+    }
+    
+    @Override
+    public DocValuesArraySource newFromArray(Object array) {
+      assert array instanceof byte[];
+      return new ByteValues((byte[]) array);
+    }
+
+    public void toBytes(long value, BytesRef bytesRef) {
+      if (bytesRef.bytes.length == 0) {
+        bytesRef.bytes = new byte[1];
+      }
+      bytesRef.bytes[0] = (byte) (0xFFL & value);
+      bytesRef.offset = 0;
+      bytesRef.length = 1;
+    }
+    
+    @Override
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      toBytes(getInt(docID), ref);
+      return ref;
+    }
+
+  };
+
+  final static class ShortValues extends DocValuesArraySource {
+    private final short[] values;
+
+    ShortValues() {
+      super(RamUsageEstimator.NUM_BYTES_SHORT, Type.FIXED_INTS_16);
+      values = new short[0];
+    }
+    
+    private ShortValues(short[] array) {
+      super(RamUsageEstimator.NUM_BYTES_SHORT, Type.FIXED_INTS_16);
+      values = array;
+    }
+
+    private ShortValues(IndexInput input, int numDocs) throws IOException {
+      super(RamUsageEstimator.NUM_BYTES_SHORT, Type.FIXED_INTS_16);
+      values = new short[numDocs];
+      for (int i = 0; i < values.length; i++) {
+        values[i] = input.readShort();
+      }
+    }
+
+    @Override
+    public short[] getArray() {
+      return values;
+    }
+
+    @Override
+    public long getInt(int docID) {
+      assert docID >= 0 && docID < values.length;
+      return values[docID];
+    }
+
+    @Override
+    public DocValuesArraySource newFromInput(IndexInput input, int numDocs)
+        throws IOException {
+      return new ShortValues(input, numDocs);
+    }
+
+    public void toBytes(long value, BytesRef bytesRef) {
+      copyShort(bytesRef, (short) (0xFFFFL & value));
+    }
+
+    @Override
+    public DocValuesArraySource newFromArray(Object array) {
+      assert array instanceof short[];
+      return new ShortValues((short[]) array);
+    }
+    
+    @Override
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      toBytes(getInt(docID), ref);
+      return ref;
+    }
+
+  };
+
+  final static class IntValues extends DocValuesArraySource {
+    private final int[] values;
+
+    IntValues() {
+      super(RamUsageEstimator.NUM_BYTES_INT, Type.FIXED_INTS_32);
+      values = new int[0];
+    }
+
+    private IntValues(IndexInput input, int numDocs) throws IOException {
+      super(RamUsageEstimator.NUM_BYTES_INT, Type.FIXED_INTS_32);
+      values = new int[numDocs];
+      for (int i = 0; i < values.length; i++) {
+        values[i] = input.readInt();
+      }
+    }
+
+    private IntValues(int[] array) {
+      super(RamUsageEstimator.NUM_BYTES_INT, Type.FIXED_INTS_32);
+      values = array;
+    }
+
+    @Override
+    public int[] getArray() {
+      return values;
+    }
+
+    @Override
+    public long getInt(int docID) {
+      assert docID >= 0 && docID < values.length;
+      return 0xFFFFFFFF & values[docID];
+    }
+
+    @Override
+    public DocValuesArraySource newFromInput(IndexInput input, int numDocs)
+        throws IOException {
+      return new IntValues(input, numDocs);
+    }
+
+    public void toBytes(long value, BytesRef bytesRef) {
+      copyInt(bytesRef, (int) (0xFFFFFFFF & value));
+    }
+
+    @Override
+    public DocValuesArraySource newFromArray(Object array) {
+      assert array instanceof int[];
+      return new IntValues((int[]) array);
+    }
+    
+    @Override
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      toBytes(getInt(docID), ref);
+      return ref;
+    }
+
+  };
+
+  final static class LongValues extends DocValuesArraySource {
+    private final long[] values;
+
+    LongValues() {
+      super(RamUsageEstimator.NUM_BYTES_LONG, Type.FIXED_INTS_64);
+      values = new long[0];
+    }
+
+    private LongValues(IndexInput input, int numDocs) throws IOException {
+      super(RamUsageEstimator.NUM_BYTES_LONG, Type.FIXED_INTS_64);
+      values = new long[numDocs];
+      for (int i = 0; i < values.length; i++) {
+        values[i] = input.readLong();
+      }
+    }
+
+    private LongValues(long[] array) {
+      super(RamUsageEstimator.NUM_BYTES_LONG, Type.FIXED_INTS_64);
+      values = array;
+    }
+
+    @Override
+    public long[] getArray() {
+      return values;
+    }
+
+    @Override
+    public long getInt(int docID) {
+      assert docID >= 0 && docID < values.length;
+      return values[docID];
+    }
+
+    @Override
+    public DocValuesArraySource newFromInput(IndexInput input, int numDocs)
+        throws IOException {
+      return new LongValues(input, numDocs);
+    }
+
+    @Override
+    public DocValuesArraySource newFromArray(Object array) {
+      assert array instanceof long[];
+      return new LongValues((long[])array);
+    }
+    
+    @Override
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      toBytes(getInt(docID), ref);
+      return ref;
+    }
+
+  };
+
+  final static class FloatValues extends DocValuesArraySource {
+    private final float[] values;
+
+    FloatValues() {
+      super(RamUsageEstimator.NUM_BYTES_FLOAT, Type.FLOAT_32);
+      values = new float[0];
+    }
+
+    private FloatValues(IndexInput input, int numDocs) throws IOException {
+      super(RamUsageEstimator.NUM_BYTES_FLOAT, Type.FLOAT_32);
+      values = new float[numDocs];
+      /*
+       * we always read BIG_ENDIAN here since the writer serialized plain bytes
+       * we can simply read the ints / longs back in using readInt / readLong
+       */
+      for (int i = 0; i < values.length; i++) {
+        values[i] = Float.intBitsToFloat(input.readInt());
+      }
+    }
+
+    private FloatValues(float[] array) {
+      super(RamUsageEstimator.NUM_BYTES_FLOAT, Type.FLOAT_32);
+      values = array;
+    }
+
+    @Override
+    public float[] getArray() {
+      return values;
+    }
+
+    @Override
+    public double getFloat(int docID) {
+      assert docID >= 0 && docID < values.length;
+      return values[docID];
+    }
+    
+    @Override
+    public void toBytes(double value, BytesRef bytesRef) {
+      copyInt(bytesRef, Float.floatToRawIntBits((float)value));
+
+    }
+
+    @Override
+    public DocValuesArraySource newFromInput(IndexInput input, int numDocs)
+        throws IOException {
+      return new FloatValues(input, numDocs);
+    }
+
+    @Override
+    public DocValuesArraySource newFromArray(Object array) {
+      assert array instanceof float[];
+      return new FloatValues((float[]) array);
+    }
+    
+    @Override
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      toBytes(getFloat(docID), ref);
+      return ref;
+    }
+  };
+
+  final static class DoubleValues extends DocValuesArraySource {
+    private final double[] values;
+
+    DoubleValues() {
+      super(RamUsageEstimator.NUM_BYTES_DOUBLE, Type.FLOAT_64);
+      values = new double[0];
+    }
+
+    private DoubleValues(IndexInput input, int numDocs) throws IOException {
+      super(RamUsageEstimator.NUM_BYTES_DOUBLE, Type.FLOAT_64);
+      values = new double[numDocs];
+      /*
+       * we always read BIG_ENDIAN here since the writer serialized plain bytes
+       * we can simply read the ints / longs back in using readInt / readLong
+       */
+      for (int i = 0; i < values.length; i++) {
+        values[i] = Double.longBitsToDouble(input.readLong());
+      }
+    }
+
+    private DoubleValues(double[] array) {
+      super(RamUsageEstimator.NUM_BYTES_DOUBLE, Type.FLOAT_64);
+      values = array;
+    }
+
+    @Override
+    public double[] getArray() {
+      return values;
+    }
+
+    @Override
+    public double getFloat(int docID) {
+      assert docID >= 0 && docID < values.length;
+      return values[docID];
+    }
+
+    @Override
+    public DocValuesArraySource newFromInput(IndexInput input, int numDocs)
+        throws IOException {
+      return new DoubleValues(input, numDocs);
+    }
+
+    @Override
+    public DocValuesArraySource newFromArray(Object array) {
+      assert array instanceof double[];
+      return new DoubleValues((double[]) array);
+    }
+    
+    @Override
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      toBytes(getFloat(docID), ref);
+      return ref;
+    }
+
+  };
+  
+  /**
+   * Copies the given long value and encodes it as 8 byte Big-Endian.
+   * <p>
+   * NOTE: this method resets the offset to 0, length to 8 and resizes the
+   * reference array if needed.
+   */
+  public static void copyLong(BytesRef ref, long value) {
+    if (ref.bytes.length < 8) {
+      ref.bytes = new byte[8];
+    }
+    copyInternal(ref, (int) (value >> 32), ref.offset = 0);
+    copyInternal(ref, (int) value, 4);
+    ref.length = 8;
+  }
+
+  /**
+   * Copies the given int value and encodes it as 4 byte Big-Endian.
+   * <p>
+   * NOTE: this method resets the offset to 0, length to 4 and resizes the
+   * reference array if needed.
+   */
+  public static void copyInt(BytesRef ref, int value) {
+    if (ref.bytes.length < 4) {
+      ref.bytes = new byte[4];
+    }
+    copyInternal(ref, value, ref.offset = 0);
+    ref.length = 4;
+    
+  }
+
+  /**
+   * Copies the given short value and encodes it as a 2 byte Big-Endian.
+   * <p>
+   * NOTE: this method resets the offset to 0, length to 2 and resizes the
+   * reference array if needed.
+   */
+  public static void copyShort(BytesRef ref, short value) {
+    if (ref.bytes.length < 2) {
+      ref.bytes = new byte[2];
+    }
+    ref.offset = 0;
+    ref.bytes[ref.offset] = (byte) (value >> 8);
+    ref.bytes[ref.offset + 1] = (byte) (value);
+    ref.length = 2;
+  }
+
+  private static void copyInternal(BytesRef ref, int value, int startOffset) {
+    ref.bytes[startOffset] = (byte) (value >> 24);
+    ref.bytes[startOffset + 1] = (byte) (value >> 16);
+    ref.bytes[startOffset + 2] = (byte) (value >> 8);
+    ref.bytes[startOffset + 3] = (byte) (value);
+  }
+
+  /**
+   * Converts 2 consecutive bytes from the current offset to a short. Bytes are
+   * interpreted as Big-Endian (most significant bit first)
+   * <p>
+   * NOTE: this method does <b>NOT</b> check the bounds of the referenced array.
+   */
+  public static short asShort(BytesRef b) {
+    return (short) (0xFFFF & ((b.bytes[b.offset] & 0xFF) << 8) | (b.bytes[b.offset + 1] & 0xFF));
+  }
+
+  /**
+   * Converts 4 consecutive bytes from the current offset to an int. Bytes are
+   * interpreted as Big-Endian (most significant bit first)
+   * <p>
+   * NOTE: this method does <b>NOT</b> check the bounds of the referenced array.
+   */
+  public static int asInt(BytesRef b) {
+    return asIntInternal(b, b.offset);
+  }
+
+  /**
+   * Converts 8 consecutive bytes from the current offset to a long. Bytes are
+   * interpreted as Big-Endian (most significant bit first)
+   * <p>
+   * NOTE: this method does <b>NOT</b> check the bounds of the referenced array.
+   */
+  public static long asLong(BytesRef b) {
+    return (((long) asIntInternal(b, b.offset) << 32) | asIntInternal(b,
+        b.offset + 4) & 0xFFFFFFFFL);
+  }
+
+  private static int asIntInternal(BytesRef b, int pos) {
+    return ((b.bytes[pos++] & 0xFF) << 24) | ((b.bytes[pos++] & 0xFF) << 16)
+        | ((b.bytes[pos++] & 0xFF) << 8) | (b.bytes[pos] & 0xFF);
+  }
+
+
+}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/DocValuesConsumer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/DocValuesConsumer.java
index e59ffbb4..5b621395 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/DocValuesConsumer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/DocValuesConsumer.java
@@ -22,6 +22,7 @@
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.DocValues.Source;
 import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Type;
 import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.MergeState;
 import org.apache.lucene.util.Bits;
@@ -40,6 +41,7 @@
 
   protected final BytesRef spare = new BytesRef();
 
+  protected abstract Type getType();
   /**
    * Adds the given {@link IndexableField} instance to this
    * {@link DocValuesConsumer}
@@ -110,7 +112,7 @@ protected void merge(DocValues reader, int docBase, int docCount, Bits liveDocs)
     final Source source = reader.getDirectSource();
     assert source != null;
     int docID = docBase;
-    final DocValues.Type type = reader.type();
+    final Type type = getType();
     final Field scratchField;
     switch(type) {
     case VAR_INTS:
@@ -160,7 +162,7 @@ protected void merge(DocValues reader, int docBase, int docCount, Bits liveDocs)
    */
   protected void mergeDoc(Field scratchField, Source source, int docID, int sourceDoc)
       throws IOException {
-    switch(source.type()) {
+    switch(getType()) {
     case BYTES_FIXED_DEREF:
     case BYTES_FIXED_SORTED:
     case BYTES_FIXED_STRAIGHT:
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/PerDocProducerBase.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/PerDocProducerBase.java
index e69de29b..d9da76ea 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/PerDocProducerBase.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/PerDocProducerBase.java
@@ -0,0 +1,122 @@
+package org.apache.lucene.codecs;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Closeable;
+import java.io.IOException;
+import java.util.Collection;
+import java.util.Comparator;
+import java.util.Map;
+import java.util.TreeMap;
+
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Type; // javadocs
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IOContext;
+import org.apache.lucene.util.BytesRef;
+
+/**
+ * Abstract base class for PerDocProducer implementations
+ * @lucene.experimental
+ */
+public abstract class PerDocProducerBase extends PerDocProducer {
+
+  protected abstract void closeInternal(Collection<? extends Closeable> closeables) throws IOException;
+  protected abstract Map<String, DocValues> docValues();
+  
+  @Override
+  public void close() throws IOException {
+    closeInternal(docValues().values());
+  }
+  
+  @Override
+  public DocValues docValues(String field) throws IOException {
+    return docValues().get(field);
+  }
+  
+  public Comparator<BytesRef> getComparator() throws IOException {
+    return BytesRef.getUTF8SortedAsUnicodeComparator();
+  }
+
+  // Only opens files... doesn't actually load any values
+  protected TreeMap<String, DocValues> load(FieldInfos fieldInfos,
+      String segment, int docCount, Directory dir, IOContext context)
+      throws IOException {
+    TreeMap<String, DocValues> values = new TreeMap<String, DocValues>();
+    boolean success = false;
+    try {
+
+      for (FieldInfo fieldInfo : fieldInfos) {
+        if (canLoad(fieldInfo)) {
+          final String field = fieldInfo.name;
+          final String id = docValuesId(segment,
+              fieldInfo.number);
+          values.put(field,
+              loadDocValues(docCount, dir, id, getDocValuesType(fieldInfo), context));
+        }
+      }
+      success = true;
+    } finally {
+      if (!success) {
+        // if we fail we must close all opened resources if there are any
+        closeInternal(values.values());
+      }
+    }
+    return values;
+  }
+  
+  protected boolean canLoad(FieldInfo info) {
+    return info.hasDocValues();
+  }
+  
+  protected Type getDocValuesType(FieldInfo info) {
+    return info.getDocValuesType();
+  }
+  
+  protected boolean anyDocValuesFields(FieldInfos infos) {
+    return infos.anyDocValuesFields();
+  }
+  
+  public static String docValuesId(String segmentsName, int fieldId) {
+    return segmentsName + "_" + fieldId;
+  }
+  
+  /**
+   * Loads a {@link DocValues} instance depending on the given {@link Type}.
+   * Codecs that use different implementations for a certain {@link Type} can
+   * simply override this method and return their custom implementations.
+   * 
+   * @param docCount
+   *          number of documents in the segment
+   * @param dir
+   *          the {@link Directory} to load the {@link DocValues} from
+   * @param id
+   *          the unique file ID within the segment
+   * @param type
+   *          the type to load
+   * @return a {@link DocValues} instance for the given type
+   * @throws IOException
+   *           if an {@link IOException} occurs
+   * @throws IllegalArgumentException
+   *           if the given {@link Type} is not supported
+   */
+  protected abstract DocValues loadDocValues(int docCount, Directory dir, String id,
+      DocValues.Type type, IOContext context) throws IOException;
+}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40DocValuesProducer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40DocValuesProducer.java
index 67521f64..aea22072 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40DocValuesProducer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40DocValuesProducer.java
@@ -24,19 +24,24 @@
 import java.util.Map;
 import java.util.TreeMap;
 
-import org.apache.lucene.codecs.lucene40.values.DocValuesReaderBase;
+import org.apache.lucene.codecs.PerDocProducerBase;
+import org.apache.lucene.codecs.lucene40.values.Bytes;
+import org.apache.lucene.codecs.lucene40.values.Floats;
+import org.apache.lucene.codecs.lucene40.values.Ints;
 import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Type;
 import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.SegmentReadState;
 import org.apache.lucene.store.CompoundFileDirectory;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IOContext;
 import org.apache.lucene.util.IOUtils;
 
 /**
  * Default PerDocProducer implementation that uses compound file.
  * @lucene.experimental
  */
-public class Lucene40DocValuesProducer extends DocValuesReaderBase {
+public class Lucene40DocValuesProducer extends PerDocProducerBase {
   protected final TreeMap<String,DocValues> docValues;
   private final Directory cfs;
   /**
@@ -71,4 +76,35 @@ protected void closeInternal(Collection<? extends Closeable> closeables) throws
       IOUtils.close(closeables);
     }
   }
+
+  @Override
+  protected DocValues loadDocValues(int docCount, Directory dir, String id,
+      Type type, IOContext context) throws IOException {
+      switch (type) {
+      case FIXED_INTS_16:
+      case FIXED_INTS_32:
+      case FIXED_INTS_64:
+      case FIXED_INTS_8:
+      case VAR_INTS:
+        return Ints.getValues(dir, id, docCount, type, context);
+      case FLOAT_32:
+        return Floats.getValues(dir, id, docCount, context, type);
+      case FLOAT_64:
+        return Floats.getValues(dir, id, docCount, context, type);
+      case BYTES_FIXED_STRAIGHT:
+        return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, true, docCount, getComparator(), context);
+      case BYTES_FIXED_DEREF:
+        return Bytes.getValues(dir, id, Bytes.Mode.DEREF, true, docCount, getComparator(), context);
+      case BYTES_FIXED_SORTED:
+        return Bytes.getValues(dir, id, Bytes.Mode.SORTED, true, docCount, getComparator(), context);
+      case BYTES_VAR_STRAIGHT:
+        return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, false, docCount, getComparator(), context);
+      case BYTES_VAR_DEREF:
+        return Bytes.getValues(dir, id, Bytes.Mode.DEREF, false, docCount, getComparator(), context);
+      case BYTES_VAR_SORTED:
+        return Bytes.getValues(dir, id, Bytes.Mode.SORTED, false, docCount, getComparator(), context);
+      default:
+        throw new IllegalStateException("unrecognized index values mode " + type);
+      }
+    }
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Bytes.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Bytes.java
index 06bf58e5..d73bd46c 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Bytes.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Bytes.java
@@ -23,7 +23,6 @@
 import java.util.concurrent.atomic.AtomicLong;
 
 import org.apache.lucene.codecs.DocValuesConsumer;
-import org.apache.lucene.document.Field;
 import org.apache.lucene.index.DocValues.SortedSource;
 import org.apache.lucene.index.DocValues.Source;
 import org.apache.lucene.index.DocValues.Type;
@@ -64,7 +63,7 @@
  * 
  * @lucene.experimental
  */
-final class Bytes {
+public final class Bytes {
 
   static final String DV_SEGMENT_SUFFIX = "dv";
 
@@ -242,8 +241,8 @@ protected BytesSourceBase(IndexInput datIn, IndexInput idxIn,
     private final IOContext context;
 
     protected BytesWriterBase(Directory dir, String id, String codecName,
-        int version, Counter bytesUsed, IOContext context) throws IOException {
-      super(bytesUsed);
+        int version, Counter bytesUsed, IOContext context, Type type) throws IOException {
+      super(bytesUsed, type);
       this.id = id;
       this.dir = dir;
       this.codecName = codecName;
@@ -292,25 +291,11 @@ protected IndexOutput getOrCreateIndexOut() throws IOException {
       }
       return idxOut;
     }
-    /**
-     * Must be called only with increasing docIDs. It's OK for some docIDs to be
-     * skipped; they will be filled with 0 bytes.
-     */
-    protected
-    abstract void add(int docID, BytesRef bytes) throws IOException;
 
-    @Override
-    public abstract void finish(int docCount) throws IOException;
 
     @Override
-    protected void mergeDoc(Field scratchField, Source source, int docID, int sourceDoc) throws IOException {
-      add(docID, source.getBytes(sourceDoc, bytesRef));
-    }
+    public abstract void finish(int docCount) throws IOException;
 
-    @Override
-    public void add(int docID, IndexableField docValue) throws IOException {
-      add(docID, docValue.binaryValue());
-    }
   }
 
   /**
@@ -393,22 +378,22 @@ public Type type() {
     protected long maxBytes = 0;
     
     protected DerefBytesWriterBase(Directory dir, String id, String codecName,
-        int codecVersion, Counter bytesUsed, IOContext context)
+        int codecVersion, Counter bytesUsed, IOContext context, Type type)
         throws IOException {
       this(dir, id, codecName, codecVersion, new DirectTrackingAllocator(
-          ByteBlockPool.BYTE_BLOCK_SIZE, bytesUsed), bytesUsed, context, false);
+          ByteBlockPool.BYTE_BLOCK_SIZE, bytesUsed), bytesUsed, context, false, type);
     }
 
     protected DerefBytesWriterBase(Directory dir, String id, String codecName,
-                                   int codecVersion, Counter bytesUsed, IOContext context, boolean fasterButMoreRam)
+                                   int codecVersion, Counter bytesUsed, IOContext context, boolean fasterButMoreRam, Type type)
         throws IOException {
       this(dir, id, codecName, codecVersion, new DirectTrackingAllocator(
-          ByteBlockPool.BYTE_BLOCK_SIZE, bytesUsed), bytesUsed, context, fasterButMoreRam);
+          ByteBlockPool.BYTE_BLOCK_SIZE, bytesUsed), bytesUsed, context, fasterButMoreRam,type);
     }
 
     protected DerefBytesWriterBase(Directory dir, String id, String codecName, int codecVersion, Allocator allocator,
-        Counter bytesUsed, IOContext context, boolean fasterButMoreRam) throws IOException {
-      super(dir, id, codecName, codecVersion, bytesUsed, context);
+        Counter bytesUsed, IOContext context, boolean fasterButMoreRam, Type type) throws IOException {
+      super(dir, id, codecName, codecVersion, bytesUsed, context, type);
       hash = new BytesRefHash(new ByteBlockPool(allocator),
           BytesRefHash.DEFAULT_CAPACITY, new TrackingDirectBytesStartArray(
               BytesRefHash.DEFAULT_CAPACITY, bytesUsed));
@@ -430,7 +415,9 @@ protected static int writePrefixLength(DataOutput datOut, BytesRef bytes)
     }
 
     @Override
-    protected void add(int docID, BytesRef bytes) throws IOException {
+    public void add(int docID, IndexableField value) throws IOException {
+      BytesRef bytes = value.binaryValue();
+      assert bytes != null;
       if (bytes.length == 0) { // default value - skip it
         return;
       }
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/BytesRefUtils.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/BytesRefUtils.java
index 4d4e7eae..e69de29b 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/BytesRefUtils.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/BytesRefUtils.java
@@ -1,120 +0,0 @@
-package org.apache.lucene.codecs.lucene40.values;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements. See the NOTICE file distributed with this
- * work for additional information regarding copyright ownership. The ASF
- * licenses this file to You under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- * 
- * http://www.apache.org/licenses/LICENSE-2.0
- * 
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
- * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
- * License for the specific language governing permissions and limitations under
- * the License.
- */
-
-import org.apache.lucene.util.BytesRef;
-
-/**
- * Package private BytesRefUtils - can move this into the o.a.l.utils package if
- * needed.
- * 
- * @lucene.internal
- */
-final class BytesRefUtils {
-
-  private BytesRefUtils() {
-  }
-
-  /**
-   * Copies the given long value and encodes it as 8 byte Big-Endian.
-   * <p>
-   * NOTE: this method resets the offset to 0, length to 8 and resizes the
-   * reference array if needed.
-   */
-  public static void copyLong(BytesRef ref, long value) {
-    if (ref.bytes.length < 8) {
-      ref.bytes = new byte[8];
-    }
-    copyInternal(ref, (int) (value >> 32), ref.offset = 0);
-    copyInternal(ref, (int) value, 4);
-    ref.length = 8;
-  }
-
-  /**
-   * Copies the given int value and encodes it as 4 byte Big-Endian.
-   * <p>
-   * NOTE: this method resets the offset to 0, length to 4 and resizes the
-   * reference array if needed.
-   */
-  public static void copyInt(BytesRef ref, int value) {
-    if (ref.bytes.length < 4) {
-      ref.bytes = new byte[4];
-    }
-    copyInternal(ref, value, ref.offset = 0);
-    ref.length = 4;
-  }
-
-  /**
-   * Copies the given short value and encodes it as a 2 byte Big-Endian.
-   * <p>
-   * NOTE: this method resets the offset to 0, length to 2 and resizes the
-   * reference array if needed.
-   */
-  public static void copyShort(BytesRef ref, short value) {
-    if (ref.bytes.length < 2) {
-      ref.bytes = new byte[2];
-    }
-    ref.bytes[ref.offset] = (byte) (value >> 8);
-    ref.bytes[ref.offset + 1] = (byte) (value);
-    ref.length = 2;
-  }
-
-  private static void copyInternal(BytesRef ref, int value, int startOffset) {
-    ref.bytes[startOffset] = (byte) (value >> 24);
-    ref.bytes[startOffset + 1] = (byte) (value >> 16);
-    ref.bytes[startOffset + 2] = (byte) (value >> 8);
-    ref.bytes[startOffset + 3] = (byte) (value);
-  }
-
-  /**
-   * Converts 2 consecutive bytes from the current offset to a short. Bytes are
-   * interpreted as Big-Endian (most significant bit first)
-   * <p>
-   * NOTE: this method does <b>NOT</b> check the bounds of the referenced array.
-   */
-  public static short asShort(BytesRef b) {
-    return (short) (0xFFFF & ((b.bytes[b.offset] & 0xFF) << 8) | (b.bytes[b.offset + 1] & 0xFF));
-  }
-
-  /**
-   * Converts 4 consecutive bytes from the current offset to an int. Bytes are
-   * interpreted as Big-Endian (most significant bit first)
-   * <p>
-   * NOTE: this method does <b>NOT</b> check the bounds of the referenced array.
-   */
-  public static int asInt(BytesRef b) {
-    return asIntInternal(b, b.offset);
-  }
-
-  /**
-   * Converts 8 consecutive bytes from the current offset to a long. Bytes are
-   * interpreted as Big-Endian (most significant bit first)
-   * <p>
-   * NOTE: this method does <b>NOT</b> check the bounds of the referenced array.
-   */
-  public static long asLong(BytesRef b) {
-    return (((long) asIntInternal(b, b.offset) << 32) | asIntInternal(b,
-        b.offset + 4) & 0xFFFFFFFFL);
-  }
-
-  private static int asIntInternal(BytesRef b, int pos) {
-    return ((b.bytes[pos++] & 0xFF) << 24) | ((b.bytes[pos++] & 0xFF) << 16)
-        | ((b.bytes[pos++] & 0xFF) << 8) | (b.bytes[pos] & 0xFF);
-  }
-
-}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesArray.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesArray.java
index 668f094f..e69de29b 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesArray.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesArray.java
@@ -1,306 +0,0 @@
-package org.apache.lucene.codecs.lucene40.values;
-
-import java.io.IOException;
-import java.util.Collections;
-import java.util.EnumMap;
-import java.util.Map;
-
-import org.apache.lucene.index.DocValues.Source;
-import org.apache.lucene.index.DocValues.Type;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.RamUsageEstimator;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements. See the NOTICE file distributed with this
- * work for additional information regarding copyright ownership. The ASF
- * licenses this file to You under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- * 
- * http://www.apache.org/licenses/LICENSE-2.0
- * 
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
- * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
- * License for the specific language governing permissions and limitations under
- * the License.
- */
-
-/**
- * @lucene.experimental
- */
-abstract class DocValuesArray extends Source {
-
-  static final Map<Type, DocValuesArray> TEMPLATES;
-
-  static {
-    EnumMap<Type, DocValuesArray> templates = new EnumMap<Type, DocValuesArray>(
-        Type.class);
-    templates.put(Type.FIXED_INTS_16, new ShortValues());
-    templates.put(Type.FIXED_INTS_32, new IntValues());
-    templates.put(Type.FIXED_INTS_64, new LongValues());
-    templates.put(Type.FIXED_INTS_8, new ByteValues());
-    templates.put(Type.FLOAT_32, new FloatValues());
-    templates.put(Type.FLOAT_64, new DoubleValues());
-    TEMPLATES = Collections.unmodifiableMap(templates);
-  }
-
-  protected final int bytesPerValue;
-
-  DocValuesArray(int bytesPerValue, Type type) {
-    super(type);
-    this.bytesPerValue = bytesPerValue;
-  }
-
-  public abstract DocValuesArray newFromInput(IndexInput input, int numDocs)
-      throws IOException;
-
-  @Override
-  public final boolean hasArray() {
-    return true;
-  }
-
-  void toBytes(long value, BytesRef bytesRef) {
-    BytesRefUtils.copyLong(bytesRef, value);
-  }
-
-  void toBytes(double value, BytesRef bytesRef) {
-    BytesRefUtils.copyLong(bytesRef, Double.doubleToRawLongBits(value));
-  }
-
-  final static class ByteValues extends DocValuesArray {
-    private final byte[] values;
-
-    ByteValues() {
-      super(1, Type.FIXED_INTS_8);
-      values = new byte[0];
-    }
-
-    private ByteValues(IndexInput input, int numDocs) throws IOException {
-      super(1, Type.FIXED_INTS_8);
-      values = new byte[numDocs];
-      input.readBytes(values, 0, values.length, false);
-    }
-
-    @Override
-    public byte[] getArray() {
-      return values;
-    }
-
-    @Override
-    public long getInt(int docID) {
-      assert docID >= 0 && docID < values.length;
-      return values[docID];
-    }
-
-    @Override
-    public DocValuesArray newFromInput(IndexInput input, int numDocs)
-        throws IOException {
-      return new ByteValues(input, numDocs);
-    }
-
-    void toBytes(long value, BytesRef bytesRef) {
-      bytesRef.bytes[0] = (byte) (0xFFL & value);
-    }
-
-  };
-
-  final static class ShortValues extends DocValuesArray {
-    private final short[] values;
-
-    ShortValues() {
-      super(RamUsageEstimator.NUM_BYTES_SHORT, Type.FIXED_INTS_16);
-      values = new short[0];
-    }
-
-    private ShortValues(IndexInput input, int numDocs) throws IOException {
-      super(RamUsageEstimator.NUM_BYTES_SHORT, Type.FIXED_INTS_16);
-      values = new short[numDocs];
-      for (int i = 0; i < values.length; i++) {
-        values[i] = input.readShort();
-      }
-    }
-
-    @Override
-    public short[] getArray() {
-      return values;
-    }
-
-    @Override
-    public long getInt(int docID) {
-      assert docID >= 0 && docID < values.length;
-      return values[docID];
-    }
-
-    @Override
-    public DocValuesArray newFromInput(IndexInput input, int numDocs)
-        throws IOException {
-      return new ShortValues(input, numDocs);
-    }
-
-    void toBytes(long value, BytesRef bytesRef) {
-      BytesRefUtils.copyShort(bytesRef, (short) (0xFFFFL & value));
-    }
-
-  };
-
-  final static class IntValues extends DocValuesArray {
-    private final int[] values;
-
-    IntValues() {
-      super(RamUsageEstimator.NUM_BYTES_INT, Type.FIXED_INTS_32);
-      values = new int[0];
-    }
-
-    private IntValues(IndexInput input, int numDocs) throws IOException {
-      super(RamUsageEstimator.NUM_BYTES_INT, Type.FIXED_INTS_32);
-      values = new int[numDocs];
-      for (int i = 0; i < values.length; i++) {
-        values[i] = input.readInt();
-      }
-    }
-
-    @Override
-    public int[] getArray() {
-      return values;
-    }
-
-    @Override
-    public long getInt(int docID) {
-      assert docID >= 0 && docID < values.length;
-      return 0xFFFFFFFF & values[docID];
-    }
-
-    @Override
-    public DocValuesArray newFromInput(IndexInput input, int numDocs)
-        throws IOException {
-      return new IntValues(input, numDocs);
-    }
-
-    void toBytes(long value, BytesRef bytesRef) {
-      BytesRefUtils.copyInt(bytesRef, (int) (0xFFFFFFFF & value));
-    }
-
-  };
-
-  final static class LongValues extends DocValuesArray {
-    private final long[] values;
-
-    LongValues() {
-      super(RamUsageEstimator.NUM_BYTES_LONG, Type.FIXED_INTS_64);
-      values = new long[0];
-    }
-
-    private LongValues(IndexInput input, int numDocs) throws IOException {
-      super(RamUsageEstimator.NUM_BYTES_LONG, Type.FIXED_INTS_64);
-      values = new long[numDocs];
-      for (int i = 0; i < values.length; i++) {
-        values[i] = input.readLong();
-      }
-    }
-
-    @Override
-    public long[] getArray() {
-      return values;
-    }
-
-    @Override
-    public long getInt(int docID) {
-      assert docID >= 0 && docID < values.length;
-      return values[docID];
-    }
-
-    @Override
-    public DocValuesArray newFromInput(IndexInput input, int numDocs)
-        throws IOException {
-      return new LongValues(input, numDocs);
-    }
-
-  };
-
-  final static class FloatValues extends DocValuesArray {
-    private final float[] values;
-
-    FloatValues() {
-      super(RamUsageEstimator.NUM_BYTES_FLOAT, Type.FLOAT_32);
-      values = new float[0];
-    }
-
-    private FloatValues(IndexInput input, int numDocs) throws IOException {
-      super(RamUsageEstimator.NUM_BYTES_FLOAT, Type.FLOAT_32);
-      values = new float[numDocs];
-      /*
-       * we always read BIG_ENDIAN here since the writer serialized plain bytes
-       * we can simply read the ints / longs back in using readInt / readLong
-       */
-      for (int i = 0; i < values.length; i++) {
-        values[i] = Float.intBitsToFloat(input.readInt());
-      }
-    }
-
-    @Override
-    public float[] getArray() {
-      return values;
-    }
-
-    @Override
-    public double getFloat(int docID) {
-      assert docID >= 0 && docID < values.length;
-      return values[docID];
-    }
-    
-    @Override
-    void toBytes(double value, BytesRef bytesRef) {
-      BytesRefUtils.copyInt(bytesRef, Float.floatToRawIntBits((float)value));
-
-    }
-
-    @Override
-    public DocValuesArray newFromInput(IndexInput input, int numDocs)
-        throws IOException {
-      return new FloatValues(input, numDocs);
-    }
-  };
-
-  final static class DoubleValues extends DocValuesArray {
-    private final double[] values;
-
-    DoubleValues() {
-      super(RamUsageEstimator.NUM_BYTES_DOUBLE, Type.FLOAT_64);
-      values = new double[0];
-    }
-
-    private DoubleValues(IndexInput input, int numDocs) throws IOException {
-      super(RamUsageEstimator.NUM_BYTES_DOUBLE, Type.FLOAT_64);
-      values = new double[numDocs];
-      /*
-       * we always read BIG_ENDIAN here since the writer serialized plain bytes
-       * we can simply read the ints / longs back in using readInt / readLong
-       */
-      for (int i = 0; i < values.length; i++) {
-        values[i] = Double.longBitsToDouble(input.readLong());
-      }
-    }
-
-    @Override
-    public double[] getArray() {
-      return values;
-    }
-
-    @Override
-    public double getFloat(int docID) {
-      assert docID >= 0 && docID < values.length;
-      return values[docID];
-    }
-
-    @Override
-    public DocValuesArray newFromInput(IndexInput input, int numDocs)
-        throws IOException {
-      return new DoubleValues(input, numDocs);
-    }
-
-  };
-
-}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesReaderBase.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesReaderBase.java
index 71fb02f0..e69de29b 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesReaderBase.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesReaderBase.java
@@ -1,151 +0,0 @@
-package org.apache.lucene.codecs.lucene40.values;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Closeable;
-import java.io.IOException;
-import java.util.Collection;
-import java.util.Comparator;
-import java.util.Map;
-import java.util.TreeMap;
-
-import org.apache.lucene.codecs.PerDocProducer;
-import org.apache.lucene.codecs.lucene40.values.Bytes;
-import org.apache.lucene.codecs.lucene40.values.Floats;
-import org.apache.lucene.codecs.lucene40.values.Ints;
-import org.apache.lucene.index.FieldInfo;
-import org.apache.lucene.index.FieldInfos;
-import org.apache.lucene.index.DocValues;
-import org.apache.lucene.index.DocValues.Type; // javadocs
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.IOContext;
-import org.apache.lucene.util.BytesRef;
-
-/**
- * Abstract base class for PerDocProducer implementations
- * @lucene.experimental
- */
-public abstract class DocValuesReaderBase extends PerDocProducer {
-
-  protected abstract void closeInternal(Collection<? extends Closeable> closeables) throws IOException;
-  protected abstract Map<String, DocValues> docValues();
-  
-  @Override
-  public void close() throws IOException {
-    closeInternal(docValues().values());
-  }
-  
-  @Override
-  public DocValues docValues(String field) throws IOException {
-    return docValues().get(field);
-  }
-  
-  public Comparator<BytesRef> getComparator() throws IOException {
-    return BytesRef.getUTF8SortedAsUnicodeComparator();
-  }
-
-  // Only opens files... doesn't actually load any values
-  protected TreeMap<String, DocValues> load(FieldInfos fieldInfos,
-      String segment, int docCount, Directory dir, IOContext context)
-      throws IOException {
-    TreeMap<String, DocValues> values = new TreeMap<String, DocValues>();
-    boolean success = false;
-    try {
-
-      for (FieldInfo fieldInfo : fieldInfos) {
-        if (canLoad(fieldInfo)) {
-          final String field = fieldInfo.name;
-          // TODO can we have a compound file per segment and codec for
-          // docvalues?
-          final String id = DocValuesWriterBase.docValuesId(segment,
-              fieldInfo.number);
-          values.put(field,
-              loadDocValues(docCount, dir, id, getDocValuesType(fieldInfo), context));
-        }
-      }
-      success = true;
-    } finally {
-      if (!success) {
-        // if we fail we must close all opened resources if there are any
-        closeInternal(values.values());
-      }
-    }
-    return values;
-  }
-  
-  protected boolean canLoad(FieldInfo info) {
-    return info.hasDocValues();
-  }
-  
-  protected Type getDocValuesType(FieldInfo info) {
-    return info.getDocValuesType();
-  }
-  
-  protected boolean anyDocValuesFields(FieldInfos infos) {
-    return infos.anyDocValuesFields();
-  }
-  
-  /**
-   * Loads a {@link DocValues} instance depending on the given {@link Type}.
-   * Codecs that use different implementations for a certain {@link Type} can
-   * simply override this method and return their custom implementations.
-   * 
-   * @param docCount
-   *          number of documents in the segment
-   * @param dir
-   *          the {@link Directory} to load the {@link DocValues} from
-   * @param id
-   *          the unique file ID within the segment
-   * @param type
-   *          the type to load
-   * @return a {@link DocValues} instance for the given type
-   * @throws IOException
-   *           if an {@link IOException} occurs
-   * @throws IllegalArgumentException
-   *           if the given {@link Type} is not supported
-   */
-  protected DocValues loadDocValues(int docCount, Directory dir, String id,
-      DocValues.Type type, IOContext context) throws IOException {
-    switch (type) {
-    case FIXED_INTS_16:
-    case FIXED_INTS_32:
-    case FIXED_INTS_64:
-    case FIXED_INTS_8:
-    case VAR_INTS:
-      return Ints.getValues(dir, id, docCount, type, context);
-    case FLOAT_32:
-      return Floats.getValues(dir, id, docCount, context, type);
-    case FLOAT_64:
-      return Floats.getValues(dir, id, docCount, context, type);
-    case BYTES_FIXED_STRAIGHT:
-      return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, true, docCount, getComparator(), context);
-    case BYTES_FIXED_DEREF:
-      return Bytes.getValues(dir, id, Bytes.Mode.DEREF, true, docCount, getComparator(), context);
-    case BYTES_FIXED_SORTED:
-      return Bytes.getValues(dir, id, Bytes.Mode.SORTED, true, docCount, getComparator(), context);
-    case BYTES_VAR_STRAIGHT:
-      return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, false, docCount, getComparator(), context);
-    case BYTES_VAR_DEREF:
-      return Bytes.getValues(dir, id, Bytes.Mode.DEREF, false, docCount, getComparator(), context);
-    case BYTES_VAR_SORTED:
-      return Bytes.getValues(dir, id, Bytes.Mode.SORTED, false, docCount, getComparator(), context);
-    default:
-      throw new IllegalStateException("unrecognized index values mode " + type);
-    }
-  }
-}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesWriterBase.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesWriterBase.java
index 7b8483f2..aeeb2308 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesWriterBase.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/DocValuesWriterBase.java
@@ -21,6 +21,7 @@
 import java.util.Comparator;
 
 import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.codecs.PerDocProducerBase;
 import org.apache.lucene.codecs.PerDocConsumer;
 import org.apache.lucene.codecs.lucene40.values.Writer;
 import org.apache.lucene.index.FieldInfo;
@@ -81,14 +82,10 @@ public void close() throws IOException {
   @Override
   public DocValuesConsumer addValuesField(Type valueType, FieldInfo field) throws IOException {
     return Writer.create(valueType,
-        docValuesId(segmentName, field.number), 
+        PerDocProducerBase.docValuesId(segmentName, field.number), 
         getDirectory(), getComparator(), bytesUsed, context, fasterButMoreRam);
   }
 
-  public static String docValuesId(String segmentsName, int fieldId) {
-    return segmentsName + "_" + fieldId;
-  }
-  
   
   public Comparator<BytesRef> getComparator() throws IOException {
     return BytesRef.getUTF8SortedAsUnicodeComparator();
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedDerefBytesImpl.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedDerefBytesImpl.java
index 72efc15a..0d5d549e 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedDerefBytesImpl.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedDerefBytesImpl.java
@@ -46,7 +46,7 @@
   public static class Writer extends DerefBytesWriterBase {
     public Writer(Directory dir, String id, Counter bytesUsed, IOContext context)
         throws IOException {
-      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context);
+      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context, Type.BYTES_FIXED_DEREF);
     }
 
     @Override
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedSortedBytesImpl.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedSortedBytesImpl.java
index 7e12c9c9..2ab17004 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedSortedBytesImpl.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedSortedBytesImpl.java
@@ -58,7 +58,7 @@
 
     public Writer(Directory dir, String id, Comparator<BytesRef> comp,
         Counter bytesUsed, IOContext context, boolean fasterButMoreRam) throws IOException {
-      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context, fasterButMoreRam);
+      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context, fasterButMoreRam, Type.BYTES_FIXED_SORTED);
       this.comp = comp;
     }
 
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedStraightBytesImpl.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedStraightBytesImpl.java
index 1b0c2e7a..8d2bb7e1 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedStraightBytesImpl.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/FixedStraightBytesImpl.java
@@ -22,10 +22,12 @@
 import org.apache.lucene.codecs.lucene40.values.Bytes.BytesReaderBase;
 import org.apache.lucene.codecs.lucene40.values.Bytes.BytesSourceBase;
 import org.apache.lucene.codecs.lucene40.values.Bytes.BytesWriterBase;
+import org.apache.lucene.document.DocValuesField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.DocValues.Source;
 import org.apache.lucene.index.DocValues.Type;
 import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
@@ -52,6 +54,7 @@
   static final int VERSION_CURRENT = VERSION_START;
   
   static abstract class FixedBytesWriterBase extends BytesWriterBase {
+    protected final DocValuesField bytesSpareField = new DocValuesField("", new BytesRef(), Type.BYTES_FIXED_STRAIGHT);
     protected int lastDocID = -1;
     // start at -1 if the first added value is > 0
     protected int size = -1;
@@ -60,13 +63,20 @@
 
     protected FixedBytesWriterBase(Directory dir, String id, String codecName,
         int version, Counter bytesUsed, IOContext context) throws IOException {
-      super(dir, id, codecName, version, bytesUsed, context);
+     this(dir, id, codecName, version, bytesUsed, context, Type.BYTES_FIXED_STRAIGHT);
+    }
+    
+    protected FixedBytesWriterBase(Directory dir, String id, String codecName,
+        int version, Counter bytesUsed, IOContext context, Type type) throws IOException {
+      super(dir, id, codecName, version, bytesUsed, context, type);
       pool = new ByteBlockPool(new DirectTrackingAllocator(bytesUsed));
       pool.nextBuffer();
     }
     
     @Override
-    protected void add(int docID, BytesRef bytes) throws IOException {
+    public void add(int docID, IndexableField value) throws IOException {
+      final BytesRef bytes = value.binaryValue();
+      assert bytes != null;
       assert lastDocID < docID;
 
       if (size == -1) {
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Floats.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Floats.java
index 3f306ec2..e50a2f2f 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Floats.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Floats.java
@@ -18,6 +18,7 @@
  */
 import java.io.IOException;
 
+import org.apache.lucene.codecs.DocValuesArraySource;
 import org.apache.lucene.codecs.DocValuesConsumer;
 import org.apache.lucene.index.DocValues.Source;
 import org.apache.lucene.index.DocValues.Type;
@@ -39,7 +40,7 @@
  * 
  * @lucene.experimental
  */
-class Floats {
+public class Floats {
   
   protected static final String CODEC_NAME = "Floats";
   protected static final int VERSION_START = 0;
@@ -69,33 +70,30 @@ private static int typeToSize(Type type) {
   final static class FloatsWriter extends FixedStraightBytesImpl.Writer {
    
     private final int size; 
-    private final DocValuesArray template;
+    private final DocValuesArraySource template;
     public FloatsWriter(Directory dir, String id, Counter bytesUsed,
         IOContext context, Type type) throws IOException {
       super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context);
       size = typeToSize(type);
       this.bytesRef = new BytesRef(size);
       bytesRef.length = size;
-      template = DocValuesArray.TEMPLATES.get(type);
+      template = DocValuesArraySource.forType(type);
       assert template != null;
     }
     
-    protected void add(int docID, double v) throws IOException {
-      template.toBytes(v, bytesRef);
-      add(docID, bytesRef);
-    }
-    
-    @Override
-    public void add(int docID, IndexableField docValue) throws IOException {
-      add(docID, docValue.numericValue().doubleValue());
-    }
-    
     @Override
     protected boolean tryBulkMerge(DocValues docValues) {
       // only bulk merge if value type is the same otherwise size differs
       return super.tryBulkMerge(docValues) && docValues.type() == template.type();
     }
     
+    @Override
+    public void add(int docID, IndexableField value) throws IOException {
+      template.toBytes(value.numericValue().doubleValue(), bytesRef);
+      bytesSpareField.setBytesValue(bytesRef);
+      super.add(docID, bytesSpareField);
+    }
+    
     @Override
     protected void setMergeBytes(Source source, int sourceDoc) {
       final double value = source.getFloat(sourceDoc);
@@ -104,11 +102,11 @@ protected void setMergeBytes(Source source, int sourceDoc) {
   }
   
   final static class FloatsReader extends FixedStraightBytesImpl.FixedStraightReader {
-    final DocValuesArray arrayTemplate;
+    final DocValuesArraySource arrayTemplate;
     FloatsReader(Directory dir, String id, int maxDoc, IOContext context, Type type)
         throws IOException {
       super(dir, id, CODEC_NAME, VERSION_CURRENT, maxDoc, context, type);
-      arrayTemplate = DocValuesArray.TEMPLATES.get(type);
+      arrayTemplate = DocValuesArraySource.forType(type);
       assert size == 4 || size == 8: "wrong size=" + size + " type=" + type + " id=" + id;
     }
     
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Ints.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Ints.java
index a9ba6c3e..4b5c2260 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Ints.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Ints.java
@@ -19,6 +19,7 @@
 
 import java.io.IOException;
 
+import org.apache.lucene.codecs.DocValuesArraySource;
 import org.apache.lucene.codecs.DocValuesConsumer;
 import org.apache.lucene.index.DocValues.Source;
 import org.apache.lucene.index.DocValues.Type;
@@ -36,7 +37,7 @@
  * 
  * @lucene.experimental
  */
-final class Ints {
+public final class Ints {
   protected static final String CODEC_NAME = "Ints";
   protected static final int VERSION_START = 0;
   protected static final int VERSION_CURRENT = VERSION_START;
@@ -88,7 +89,7 @@ private static int typeToSize(Type type) {
 
 
   static class IntsWriter extends FixedStraightBytesImpl.Writer {
-    private final DocValuesArray template;
+    private final DocValuesArraySource template;
 
     public IntsWriter(Directory dir, String id, Counter bytesUsed,
         IOContext context, Type valueType) throws IOException {
@@ -101,17 +102,7 @@ protected IntsWriter(Directory dir, String id, String codecName,
       size = typeToSize(valueType);
       this.bytesRef = new BytesRef(size);
       bytesRef.length = size;
-      template = DocValuesArray.TEMPLATES.get(valueType);
-    }
-    
-    protected void add(int docID, long v) throws IOException {
-      template.toBytes(v, bytesRef);
-      add(docID, bytesRef);
-    }
-
-    @Override
-    public void add(int docID, IndexableField docValue) throws IOException {
-      add(docID, docValue.numericValue().longValue());
+      template = DocValuesArraySource.forType(valueType);
     }
     
     @Override
@@ -120,6 +111,13 @@ protected void setMergeBytes(Source source, int sourceDoc) {
       template.toBytes(value, bytesRef);
     }
     
+    @Override
+    public void add(int docID, IndexableField value) throws IOException {
+      template.toBytes(value.numericValue().longValue(), bytesRef);
+      bytesSpareField.setBytesValue(bytesRef);
+      super.add(docID, bytesSpareField);
+    }
+
     @Override
     protected boolean tryBulkMerge(DocValues docValues) {
       // only bulk merge if value type is the same otherwise size differs
@@ -128,13 +126,13 @@ protected boolean tryBulkMerge(DocValues docValues) {
   }
   
   final static class IntsReader extends FixedStraightBytesImpl.FixedStraightReader {
-    private final DocValuesArray arrayTemplate;
+    private final DocValuesArraySource arrayTemplate;
 
     IntsReader(Directory dir, String id, int maxDoc, IOContext context, Type type)
         throws IOException {
       super(dir, id, CODEC_NAME, VERSION_CURRENT, maxDoc,
           context, type);
-      arrayTemplate = DocValuesArray.TEMPLATES.get(type);
+      arrayTemplate = DocValuesArraySource.forType(type);
       assert arrayTemplate != null;
       assert type == sizeToType(size);
     }
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/PackedIntValues.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/PackedIntValues.java
index 2705ec77..f11a2568 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/PackedIntValues.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/PackedIntValues.java
@@ -18,9 +18,8 @@
  */
 import java.io.IOException;
 
-import org.apache.lucene.codecs.lucene40.values.DocValuesArray.LongValues;
+import org.apache.lucene.codecs.DocValuesArraySource;
 import org.apache.lucene.codecs.lucene40.values.FixedStraightBytesImpl.FixedBytesWriterBase;
-import org.apache.lucene.document.Field;
 import org.apache.lucene.index.DocValues.Source;
 import org.apache.lucene.index.DocValues.Type;
 import org.apache.lucene.index.DocValues;
@@ -59,27 +58,10 @@
 
     protected PackedIntsWriter(Directory dir, String id, Counter bytesUsed,
         IOContext context) throws IOException {
-      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context);
+      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context, Type.VAR_INTS);
       bytesRef = new BytesRef(8);
     }
 
-    protected void add(int docID, long v) throws IOException {
-      assert lastDocId < docID;
-      if (!started) {
-        started = true;
-        minValue = maxValue = v;
-      } else {
-        if (v < minValue) {
-          minValue = v;
-        } else if (v > maxValue) {
-          maxValue = v;
-        }
-      }
-      lastDocId = docID;
-      BytesRefUtils.copyLong(bytesRef, v);
-      add(docID, bytesRef);
-    }
-
     @Override
     public void finish(int docCount) throws IOException {
       boolean success = false;
@@ -112,13 +94,6 @@ public void finish(int docCount) throws IOException {
       }
     }
 
-    @Override
-    protected void mergeDoc(Field scratchField, Source source, int docID, int sourceDoc) throws IOException {
-      assert docID > lastDocId : "docID: " + docID
-          + " must be greater than the last added doc id: " + lastDocId;
-        add(docID, source.getInt(sourceDoc));
-    }
-
     private void writePackedInts(IndexOutput datOut, int docCount) throws IOException {
       datOut.writeLong(minValue);
       
@@ -152,7 +127,22 @@ private void writePackedInts(IndexOutput datOut, int docCount) throws IOExceptio
 
     @Override
     public void add(int docID, IndexableField docValue) throws IOException {
-      add(docID, docValue.numericValue().longValue());
+      final long v = docValue.numericValue().longValue();
+      assert lastDocId < docID;
+      if (!started) {
+        started = true;
+        minValue = maxValue = v;
+      } else {
+        if (v < minValue) {
+          minValue = v;
+        } else if (v > maxValue) {
+          maxValue = v;
+        }
+      }
+      lastDocId = docID;
+      DocValuesArraySource.copyLong(bytesRef, v);
+      bytesSpareField.setBytesValue(bytesRef);
+      super.add(docID, bytesSpareField);
     }
   }
 
@@ -164,7 +154,7 @@ public void add(int docID, IndexableField docValue) throws IOException {
     private final IndexInput datIn;
     private final byte type;
     private final int numDocs;
-    private final LongValues values;
+    private final DocValuesArraySource values;
 
     protected PackedIntsReader(Directory dir, String id, int numDocs,
         IOContext context) throws IOException {
@@ -176,7 +166,7 @@ protected PackedIntsReader(Directory dir, String id, int numDocs,
       try {
         CodecUtil.checkHeader(datIn, CODEC_NAME, VERSION_START, VERSION_START);
         type = datIn.readByte();
-        values = type == FIXED_64 ? new LongValues() : null;
+        values = type == FIXED_64 ?  DocValuesArraySource.forType(Type.FIXED_INTS_64) : null;
         success = true;
       } finally {
         if (!success) {
@@ -247,7 +237,7 @@ public PackedIntsSource(IndexInput dataIn, boolean direct) throws IOException {
     @Override
     public BytesRef getBytes(int docID, BytesRef ref) {
       ref.grow(8);
-      BytesRefUtils.copyLong(ref, getInt(docID));
+      DocValuesArraySource.copyLong(ref, getInt(docID));
       return ref;
     }
 
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarDerefBytesImpl.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarDerefBytesImpl.java
index 19a7bd71..4fb8deda 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarDerefBytesImpl.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarDerefBytesImpl.java
@@ -57,7 +57,7 @@
   static class Writer extends DerefBytesWriterBase {
     public Writer(Directory dir, String id, Counter bytesUsed, IOContext context)
         throws IOException {
-      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context);
+      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context, Type.BYTES_VAR_DEREF);
       size = 0;
     }
     
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.java
index 0229199f..cff1f461 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.java
@@ -59,7 +59,7 @@
 
     public Writer(Directory dir, String id, Comparator<BytesRef> comp,
         Counter bytesUsed, IOContext context, boolean fasterButMoreRam) throws IOException {
-      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context, fasterButMoreRam);
+      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context, fasterButMoreRam, Type.BYTES_VAR_SORTED);
       this.comp = comp;
       size = 0;
     }
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.java
index 2902801c..5b5a43e7 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarStraightBytesImpl.java
@@ -26,6 +26,7 @@
 import org.apache.lucene.index.DocValues.Source;
 import org.apache.lucene.index.DocValues.Type;
 import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
@@ -63,7 +64,7 @@
     private boolean merge = false;
     public Writer(Directory dir, String id, Counter bytesUsed, IOContext context)
         throws IOException {
-      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context);
+      super(dir, id, CODEC_NAME, VERSION_CURRENT, bytesUsed, context, Type.BYTES_VAR_STRAIGHT);
       pool = new ByteBlockPool(new DirectTrackingAllocator(bytesUsed));
       docToAddress = new long[1];
       pool.nextBuffer(); // init
@@ -84,7 +85,9 @@ private void fill(final int docID, final long nextAddress) {
     }
 
     @Override
-    protected void add(int docID, BytesRef bytes) throws IOException {
+    public void add(int docID, IndexableField value) throws IOException {
+      final BytesRef bytes = value.binaryValue();
+      assert bytes != null;
       assert !merge;
       if (bytes.length == 0) {
         return; // default
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Writer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Writer.java
index 13529d3d..f6aced77 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Writer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/Writer.java
@@ -40,6 +40,7 @@
  */
 abstract class Writer extends DocValuesConsumer {
   protected final Counter bytesUsed;
+  protected Type type;
 
   /**
    * Creates a new {@link Writer}.
@@ -49,10 +50,20 @@
    *          internally allocated memory. All tracked bytes must be released
    *          once {@link #finish(int)} has been called.
    */
-  protected Writer(Counter bytesUsed) {
+  protected Writer(Counter bytesUsed, Type type) {
     this.bytesUsed = bytesUsed;
+    this.type = type;
   }
 
+  
+
+  @Override
+  protected Type getType() {
+    return type;
+  }
+
+
+
   /**
    * Factory method to create a {@link Writer} instance for a given type. This
    * method returns default implementations for each of the different types
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/sep/SepDocValuesConsumer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/sep/SepDocValuesConsumer.java
index 5a8472b9..b28b40e4 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/sep/SepDocValuesConsumer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/sep/SepDocValuesConsumer.java
@@ -21,6 +21,7 @@
 import java.util.HashSet;
 import java.util.Set;
 
+import org.apache.lucene.codecs.PerDocProducerBase;
 import org.apache.lucene.codecs.lucene40.values.DocValuesWriterBase;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.FieldInfos;
@@ -58,7 +59,7 @@ public static void files(SegmentInfo segmentInfo,
   private static void files(Directory dir,FieldInfos fieldInfos, String segmentName, Set<String> files)  {
     for (FieldInfo fieldInfo : fieldInfos) {
       if (fieldInfo.hasDocValues()) {
-        String filename = docValuesId(segmentName, fieldInfo.number);
+        String filename = PerDocProducerBase.docValuesId(segmentName, fieldInfo.number);
         switch (fieldInfo.getDocValuesType()) {
           case BYTES_FIXED_DEREF:
           case BYTES_VAR_DEREF:
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/sep/SepDocValuesProducer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/sep/SepDocValuesProducer.java
index 6cfb2f6b..0406c26a 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/sep/SepDocValuesProducer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/sep/SepDocValuesProducer.java
@@ -22,16 +22,22 @@
 import java.util.Map;
 import java.util.TreeMap;
 
-import org.apache.lucene.codecs.lucene40.values.DocValuesReaderBase;
+import org.apache.lucene.codecs.PerDocProducerBase;
+import org.apache.lucene.codecs.lucene40.values.Bytes;
+import org.apache.lucene.codecs.lucene40.values.Floats;
+import org.apache.lucene.codecs.lucene40.values.Ints;
 import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Type;
 import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IOContext;
 import org.apache.lucene.util.IOUtils;
 
 /**
  * Implementation of PerDocProducer that uses separate files.
  * @lucene.experimental
  */
-public class SepDocValuesProducer extends DocValuesReaderBase {
+public class SepDocValuesProducer extends PerDocProducerBase {
   private final TreeMap<String, DocValues> docValues;
 
   /**
@@ -51,4 +57,35 @@ public SepDocValuesProducer(SegmentReadState state) throws IOException {
   protected void closeInternal(Collection<? extends Closeable> closeables) throws IOException {
     IOUtils.close(closeables);
   }
+
+  @Override
+  protected DocValues loadDocValues(int docCount, Directory dir, String id,
+      Type type, IOContext context) throws IOException {
+      switch (type) {
+      case FIXED_INTS_16:
+      case FIXED_INTS_32:
+      case FIXED_INTS_64:
+      case FIXED_INTS_8:
+      case VAR_INTS:
+        return Ints.getValues(dir, id, docCount, type, context);
+      case FLOAT_32:
+        return Floats.getValues(dir, id, docCount, context, type);
+      case FLOAT_64:
+        return Floats.getValues(dir, id, docCount, context, type);
+      case BYTES_FIXED_STRAIGHT:
+        return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, true, docCount, getComparator(), context);
+      case BYTES_FIXED_DEREF:
+        return Bytes.getValues(dir, id, Bytes.Mode.DEREF, true, docCount, getComparator(), context);
+      case BYTES_FIXED_SORTED:
+        return Bytes.getValues(dir, id, Bytes.Mode.SORTED, true, docCount, getComparator(), context);
+      case BYTES_VAR_STRAIGHT:
+        return Bytes.getValues(dir, id, Bytes.Mode.STRAIGHT, false, docCount, getComparator(), context);
+      case BYTES_VAR_DEREF:
+        return Bytes.getValues(dir, id, Bytes.Mode.DEREF, false, docCount, getComparator(), context);
+      case BYTES_VAR_SORTED:
+        return Bytes.getValues(dir, id, Bytes.Mode.SORTED, false, docCount, getComparator(), context);
+      default:
+        throw new IllegalStateException("unrecognized index values mode " + type);
+      }
+    }
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextCodec.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextCodec.java
index 39b53e4f..23defd7b 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextCodec.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextCodec.java
@@ -26,7 +26,6 @@
 import org.apache.lucene.codecs.SegmentInfosFormat;
 import org.apache.lucene.codecs.StoredFieldsFormat;
 import org.apache.lucene.codecs.TermVectorsFormat;
-import org.apache.lucene.codecs.lucene40.Lucene40DocValuesFormat;
 
 /**
  * plain text index format.
@@ -41,7 +40,7 @@
   private final FieldInfosFormat fieldInfosFormat = new SimpleTextFieldInfosFormat();
   private final TermVectorsFormat vectorsFormat = new SimpleTextTermVectorsFormat();
   // TODO: need a plain-text impl
-  private final DocValuesFormat docValues = new Lucene40DocValuesFormat();
+  private final DocValuesFormat docValues = new SimpleTextDocValuesFormat();
   // TODO: need a plain-text impl (using the above)
   private final NormsFormat normsFormat = new SimpleTextNormsFormat();
   private final LiveDocsFormat liveDocs = new SimpleTextLiveDocsFormat();
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesConsumer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesConsumer.java
index e69de29b..168dbc3d 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesConsumer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesConsumer.java
@@ -0,0 +1,288 @@
+package org.apache.lucene.codecs.simpletext;
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with this
+ * work for additional information regarding copyright ownership. The ASF
+ * licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ * 
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+import java.io.IOException;
+
+import org.apache.lucene.codecs.DocValuesArraySource;
+import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.index.DocValues.Type;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.IndexableField;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.BytesRefHash;
+import org.apache.lucene.util.IOUtils;
+
+/**
+ * @lucene.experimental
+ */
+public class SimpleTextDocValuesConsumer extends DocValuesConsumer {
+
+  static final BytesRef ZERO_DOUBLE = new BytesRef(Double.toString(0d));
+  static final BytesRef ZERO_INT = new BytesRef(Integer.toString(0));
+  static final BytesRef HEADER = new BytesRef("SimpleTextDocValues"); 
+
+  static final BytesRef END = new BytesRef("END");
+  static final BytesRef VALUE_SIZE = new BytesRef("valuesize ");
+  static final BytesRef DOC = new BytesRef("  doc ");
+  static final BytesRef VALUE = new BytesRef("    value ");
+  protected BytesRef scratch = new BytesRef();
+  protected int maxDocId = -1;
+  protected final String segment;
+  protected final Directory dir;
+  protected final IOContext ctx;
+  protected final Type type;
+  protected final BytesRefHash hash;
+  private int[] ords;
+  private int fixedSize = Integer.MIN_VALUE;
+  private BytesRef zeroBytes;
+  private final String segmentSuffix;
+  
+
+  public SimpleTextDocValuesConsumer(String segment, Directory dir,
+      IOContext ctx, Type type, String segmentSuffix) {
+    this.ctx = ctx;
+    this.dir = dir;
+    this.segment = segment;
+    this.type = type;
+    hash = new BytesRefHash();
+    ords = new int[0];
+    this.segmentSuffix = segmentSuffix;
+
+  }
+
+  @Override
+  public void add(int docID, IndexableField value) throws IOException {
+    assert docID >= 0;
+    int ord = -1;
+    int vSize = -1;
+    switch (type) {
+    case BYTES_FIXED_DEREF:
+    case BYTES_FIXED_SORTED:
+    case BYTES_FIXED_STRAIGHT:
+      vSize = value.binaryValue().length;
+      ord = hash.add(value.binaryValue());
+      break;
+    case BYTES_VAR_DEREF:
+    case BYTES_VAR_SORTED:
+    case BYTES_VAR_STRAIGHT:
+      vSize = -1;
+      try {
+      ord = hash.add(value.binaryValue());
+      } catch (NullPointerException e) {
+        System.err.println();
+      }
+      break;
+    case FIXED_INTS_16:
+      vSize = 2;
+      scratch.grow(2);
+      DocValuesArraySource.copyShort(scratch, value.numericValue().shortValue());
+      ord = hash.add(scratch);
+      break;
+    case FIXED_INTS_32:
+      vSize = 4;
+      scratch.grow(4);
+      DocValuesArraySource.copyInt(scratch, value.numericValue().intValue());
+      ord = hash.add(scratch);
+      break;
+    case FIXED_INTS_8:
+      vSize = 1;
+      scratch.grow(1); 
+      scratch.bytes[scratch.offset] = value.numericValue().byteValue();
+      scratch.length = 1;
+      ord = hash.add(scratch);
+      break;
+    case FIXED_INTS_64:
+      vSize = 8;
+    case VAR_INTS:
+      scratch.grow(8);
+      DocValuesArraySource.copyLong(scratch, value.numericValue().longValue());
+      ord = hash.add(scratch);
+      break;
+    case FLOAT_32:
+      vSize = 4;
+      scratch.grow(4);
+      DocValuesArraySource.copyInt(scratch,
+          Float.floatToRawIntBits(value.numericValue().floatValue()));
+      ord = hash.add(scratch);
+      break;
+    case FLOAT_64:
+      vSize = 8;
+      scratch.grow(8);
+      DocValuesArraySource.copyLong(scratch,
+          Double.doubleToRawLongBits(value.numericValue().doubleValue()));
+      ord = hash.add(scratch);
+      break;
+
+    }
+    
+    if (fixedSize == Integer.MIN_VALUE) {
+      assert maxDocId == -1;
+      fixedSize = vSize;
+    } else {
+      if (fixedSize != vSize) {
+        throw new IllegalArgumentException("value size must be " + fixedSize + " but was: " + vSize);
+      }
+    }
+    maxDocId = Math.max(docID, maxDocId);
+    ords = grow(ords, docID);
+    
+    ords[docID] = (ord < 0 ? (-ord)-1 : ord) + 1;
+  }
+  
+  protected BytesRef getHeader() {
+    return HEADER;
+  }
+
+  private int[] grow(int[] array, int upto) {
+    if (array.length <= upto) {
+      return ArrayUtil.grow(array, 1 + upto);
+    }
+    return array;
+  }
+
+  private void prepareFlush(int docCount) {
+    assert ords != null;
+    ords = grow(ords, docCount);
+  }
+
+  @Override
+  public void finish(int docCount) throws IOException {
+    final String fileName = IndexFileNames.segmentFileName(segment, "",
+        segmentSuffix);
+    IndexOutput output = dir.createOutput(fileName, ctx);
+    boolean success = false;
+    BytesRef spare = new BytesRef();
+    try {
+      SimpleTextUtil.write(output, getHeader());
+      SimpleTextUtil.writeNewline(output);
+      SimpleTextUtil.write(output, VALUE_SIZE);
+      SimpleTextUtil.write(output, Integer.toString(this.fixedSize), scratch);
+      SimpleTextUtil.writeNewline(output);
+      prepareFlush(docCount);
+      for (int i = 0; i < docCount; i++) {
+        SimpleTextUtil.write(output, DOC);
+        SimpleTextUtil.write(output, Integer.toString(i), scratch);
+        SimpleTextUtil.writeNewline(output);
+        SimpleTextUtil.write(output, VALUE);
+        writeDoc(output, i, spare);
+        SimpleTextUtil.writeNewline(output);
+      }
+      SimpleTextUtil.write(output, END);
+      SimpleTextUtil.writeNewline(output);
+      success = true;
+    } finally {
+      hash.close();
+      if (success) {
+        IOUtils.close(output);
+      } else {
+        IOUtils.closeWhileHandlingException(output);
+      }
+    }
+  }
+
+  protected void writeDoc(IndexOutput output, int docId, BytesRef spare) throws IOException {
+    int ord = ords[docId] - 1;
+    if (ord != -1) {
+      assert ord >= 0;
+      hash.get(ord, spare);
+
+      switch (type) {
+      case BYTES_FIXED_DEREF:
+      case BYTES_FIXED_SORTED:
+      case BYTES_FIXED_STRAIGHT:
+      case BYTES_VAR_DEREF:
+      case BYTES_VAR_SORTED:
+      case BYTES_VAR_STRAIGHT:
+        SimpleTextUtil.write(output, spare);
+        break;
+      case FIXED_INTS_16:
+        SimpleTextUtil.write(output,
+            Short.toString(DocValuesArraySource.asShort(spare)), scratch);
+        break;
+      case FIXED_INTS_32:
+        SimpleTextUtil.write(output,
+            Integer.toString(DocValuesArraySource.asInt(spare)), scratch);
+        break;
+      case VAR_INTS:
+      case FIXED_INTS_64:
+        SimpleTextUtil.write(output,
+            Long.toString(DocValuesArraySource.asLong(spare)), scratch);
+        break;
+      case FIXED_INTS_8:
+        assert spare.length == 1 : spare.length;
+        SimpleTextUtil.write(output,
+            Integer.toString(spare.bytes[spare.offset]), scratch);
+        break;
+      case FLOAT_32:
+        float valueFloat = Float.intBitsToFloat(DocValuesArraySource.asInt(spare));
+        SimpleTextUtil.write(output, Float.toString(valueFloat), scratch);
+        break;
+      case FLOAT_64:
+        double valueDouble = Double.longBitsToDouble(DocValuesArraySource
+            .asLong(spare));
+        SimpleTextUtil.write(output, Double.toString(valueDouble), scratch);
+        break;
+      default:
+        throw new IllegalArgumentException("unsupported type: " + type);
+      }
+    } else {
+      switch (type) {
+      case BYTES_FIXED_DEREF:
+      case BYTES_FIXED_SORTED:
+      case BYTES_FIXED_STRAIGHT:
+        if(zeroBytes == null) {
+          assert fixedSize > 0;
+          zeroBytes = new BytesRef(new byte[fixedSize]);
+        }
+        SimpleTextUtil.write(output, zeroBytes);
+        break;
+      case BYTES_VAR_DEREF:
+      case BYTES_VAR_SORTED:
+      case BYTES_VAR_STRAIGHT:
+        scratch.length = 0;
+        SimpleTextUtil.write(output, scratch);
+        break;
+      case FIXED_INTS_16:
+      case FIXED_INTS_32:
+      case FIXED_INTS_64:
+      case FIXED_INTS_8:
+      case VAR_INTS:
+        SimpleTextUtil.write(output, ZERO_INT);
+        break;
+      case FLOAT_32:
+      case FLOAT_64:
+        SimpleTextUtil.write(output, ZERO_DOUBLE);
+        break;
+      default:
+        throw new IllegalArgumentException("unsupported type: " + type);
+      }
+    }
+
+  }
+
+  @Override
+  protected Type getType() {
+    return type;
+  }
+  
+  
+
+}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesFormat.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesFormat.java
index e69de29b..b3318678 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesFormat.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDocValuesFormat.java
@@ -0,0 +1,53 @@
+package org.apache.lucene.codecs.simpletext;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with this
+ * work for additional information regarding copyright ownership. The ASF
+ * licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ * 
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+import java.io.IOException;
+import java.util.Set;
+
+import org.apache.lucene.codecs.DocValuesFormat;
+import org.apache.lucene.codecs.PerDocConsumer;
+import org.apache.lucene.codecs.PerDocProducer;
+import org.apache.lucene.index.PerDocWriteState;
+import org.apache.lucene.index.SegmentInfo;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.util.BytesRef;
+/**
+ * @lucene.experimental
+ */
+public class SimpleTextDocValuesFormat extends DocValuesFormat {
+  private static final String DOC_VALUES_SEG_SUFFIX = "dv";
+  @Override
+  public PerDocConsumer docsConsumer(PerDocWriteState state) throws IOException {
+    return new SimpleTextPerDocConsumer(state, DOC_VALUES_SEG_SUFFIX);
+  }
+
+  @Override
+  public PerDocProducer docsProducer(SegmentReadState state) throws IOException {
+    return new SimpleTextPerDocProducer(state, BytesRef.getUTF8SortedAsUnicodeComparator(), DOC_VALUES_SEG_SUFFIX);
+  }
+
+  static String docValuesId(String segmentsName, int fieldId) {
+    return segmentsName + "_" + fieldId;
+  }
+
+  @Override
+  public void files(SegmentInfo info, Set<String> files)
+      throws IOException {
+    SimpleTextPerDocConsumer.files(info, files, DOC_VALUES_SEG_SUFFIX);
+  }
+}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsConsumer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsConsumer.java
index 086e770f..e69de29b 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsConsumer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsConsumer.java
@@ -1,294 +0,0 @@
-package org.apache.lucene.codecs.simpletext;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Closeable;
-import java.io.IOException;
-import java.util.Set;
-
-import org.apache.lucene.codecs.DocValuesConsumer;
-import org.apache.lucene.codecs.PerDocConsumer;
-import org.apache.lucene.index.DocValues.Type;
-import org.apache.lucene.index.DocValues;
-import org.apache.lucene.index.FieldInfo;
-import org.apache.lucene.index.FieldInfos;
-import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.AtomicReader;
-import org.apache.lucene.index.IndexableField;
-import org.apache.lucene.index.SegmentInfo;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.IOContext;
-import org.apache.lucene.store.IndexOutput;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IOUtils;
-
-/**
- * Writes plain-text norms
- * <p>
- * <b><font color="red">FOR RECREATIONAL USE ONLY</font></B>
- * 
- * @lucene.experimental
- */
-public class SimpleTextNormsConsumer extends PerDocConsumer {
-  
-  /** Extension of norms file */
-  static final String NORMS_EXTENSION = "len";
-  final static BytesRef END = new BytesRef("END");
-  final static BytesRef FIELD = new BytesRef("field ");
-  final static BytesRef DOC = new BytesRef("  doc ");
-  final static BytesRef NORM = new BytesRef("    norm ");
-  
-  private NormsWriter writer;
-
-  private final Directory directory;
-
-  private final String segment;
-
-  private final IOContext context;
-
-  public SimpleTextNormsConsumer(Directory directory, String segment,
-      IOContext context) throws IOException {
-    this.directory = directory;
-    this.segment = segment;
-    this.context = context;
-  }
-
-  @Override
-  public void close() throws IOException {
-    if (writer != null) {
-      boolean success = false;
-      try {
-        writer.finish();
-        success = true;
-      } finally {
-        if (success) {
-          IOUtils.close(writer);
-        } else {
-          IOUtils.closeWhileHandlingException(writer);
-        }
-      }
-    }
-  }
-  
-  @Override
-  protected DocValues getDocValuesForMerge(AtomicReader reader, FieldInfo info)
-      throws IOException {
-    return reader.normValues(info.name);
-  }
-
-  @Override
-  protected boolean canMerge(FieldInfo info) {
-    return info.normsPresent();
-  }
-
-  @Override
-  protected Type getDocValuesType(FieldInfo info) {
-    return info.getNormType();
-  }
-
-  @Override
-  public DocValuesConsumer addValuesField(Type type, FieldInfo fieldInfo)
-      throws IOException {
-    if (type != Type.FIXED_INTS_8) {
-      throw new UnsupportedOperationException("Codec only supports single byte norm values. Type give: " + type);
-    }
-    return new SimpleTextNormsDocValuesConsumer(fieldInfo);
-  }
-
-  @Override
-  public void abort() {
-    if (writer != null) {
-      try {
-        writer.abort();
-      } catch (IOException e) {
-      }
-    }
-  }
-
-  private class SimpleTextNormsDocValuesConsumer extends DocValuesConsumer {
-    // Holds all docID/norm pairs we've seen
-    int[] docIDs = new int[1];
-    byte[] norms = new byte[1];
-    int upto;
-    private final FieldInfo fi;
-
-    public SimpleTextNormsDocValuesConsumer(FieldInfo fieldInfo) {
-      fi = fieldInfo;
-    }
-
-    @Override
-    public void add(int docID, IndexableField docValue) throws IOException {
-      add(docID, docValue.numericValue().longValue());
-    }
-    
-    public void add(int docID, long value) {
-      if (docIDs.length <= upto) {
-        assert docIDs.length == upto;
-        docIDs = ArrayUtil.grow(docIDs, 1 + upto);
-      }
-      if (norms.length <= upto) {
-        assert norms.length == upto;
-        norms = ArrayUtil.grow(norms, 1 + upto);
-      }
-      norms[upto] = (byte) value;
-      
-      docIDs[upto] = docID;
-      upto++;
-    }
-
-    @Override
-    public void finish(int docCount) throws IOException {
-      final NormsWriter normsWriter = getNormsWriter();
-      boolean success = false;
-      try {
-        int uptoDoc = 0;
-        normsWriter.setNumTotalDocs(docCount);
-        if (upto > 0) {
-          normsWriter.startField(fi);
-          int docID = 0;
-          for (; docID < docCount; docID++) {
-            if (uptoDoc < upto && docIDs[uptoDoc] == docID) {
-              normsWriter.writeNorm(norms[uptoDoc]);
-              uptoDoc++;
-            } else {
-              normsWriter.writeNorm((byte) 0);
-            }
-          }
-          // we should have consumed every norm
-          assert uptoDoc == upto;
-
-        } else {
-          // Fill entire field with default norm:
-          normsWriter.startField(fi);
-          for (; upto < docCount; upto++)
-            normsWriter.writeNorm((byte) 0);
-        }
-        success = true;
-      } finally {
-        if (!success) {
-          normsWriter.abort();
-        }
-      }
-    }
-  }
-
-  public NormsWriter getNormsWriter() throws IOException {
-    if (writer == null) {
-      writer = new NormsWriter(directory, segment, context);
-    }
-    return writer;
-  }
-
-  private static class NormsWriter implements Closeable{
-
-    private final IndexOutput output;
-    private int numTotalDocs = 0;
-    private int docid = 0;
-
-    private final BytesRef scratch = new BytesRef();
-
-
-    public NormsWriter(Directory directory, String segment, IOContext context)
-        throws IOException {
-      final String normsFileName = IndexFileNames.segmentFileName(segment, "",
-          NORMS_EXTENSION);
-      output = directory.createOutput(normsFileName, context);
-
-    }
-
-    public void startField(FieldInfo info) throws IOException {
-      assert info.omitNorms == false;
-      docid = 0;
-      write(FIELD);
-      write(info.name);
-      newLine();
-    }
-
-    public void writeNorm(byte norm) throws IOException {
-      write(DOC);
-      write(Integer.toString(docid));
-      newLine();
-
-      write(NORM);
-      write(norm);
-      newLine();
-      docid++;
-    }
-
-    public void finish(int numDocs) throws IOException {
-      if (docid != numDocs) {
-        throw new RuntimeException(
-            "mergeNorms produced an invalid result: docCount is " + numDocs
-                + " but only saw " + docid + " file=" + output.toString()
-                + "; now aborting this merge to prevent index corruption");
-      }
-      write(END);
-      newLine();
-    }
-
-    private void write(String s) throws IOException {
-      SimpleTextUtil.write(output, s, scratch);
-    }
-
-    private void write(BytesRef bytes) throws IOException {
-      SimpleTextUtil.write(output, bytes);
-    }
-
-    private void write(byte b) throws IOException {
-      scratch.grow(1);
-      scratch.bytes[scratch.offset] = b;
-      scratch.length = 1;
-      SimpleTextUtil.write(output, scratch);
-    }
-
-    private void newLine() throws IOException {
-      SimpleTextUtil.writeNewline(output);
-    }
-
-    public void setNumTotalDocs(int numTotalDocs) {
-      assert this.numTotalDocs == 0 || numTotalDocs == this.numTotalDocs;
-      this.numTotalDocs = numTotalDocs;
-    }
-
-    public void abort() throws IOException {
-      close();
-    }
-
-    public void finish() throws IOException {
-        finish(numTotalDocs);
-    }
-
-    @Override
-    public void close() throws IOException {
-      output.close();
-    }
-  }
-
-  public static void files(SegmentInfo info, Set<String> files) throws IOException {
-    FieldInfos fieldInfos = info.getFieldInfos();
-    
-    for (FieldInfo fieldInfo : fieldInfos) {
-      if (fieldInfo.normsPresent()) {
-        files.add(IndexFileNames.segmentFileName(info.name, "",
-            NORMS_EXTENSION));  
-        break;
-      }
-    }
-  }
-}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsFormat.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsFormat.java
index 596dd715..cc60f883 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsFormat.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsFormat.java
@@ -18,35 +18,123 @@
  */
 
 import java.io.IOException;
+import java.util.Comparator;
+import java.util.HashSet;
 import java.util.Set;
 
 import org.apache.lucene.codecs.NormsFormat;
 import org.apache.lucene.codecs.PerDocConsumer;
 import org.apache.lucene.codecs.PerDocProducer;
+import org.apache.lucene.index.AtomicReader;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.Type;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.PerDocWriteState;
 import org.apache.lucene.index.SegmentInfo;
 import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IOUtils;
 
 /**
  * plain-text norms format
  * <p>
  * <b><font color="red">FOR RECREATIONAL USE ONLY</font></B>
+ * 
  * @lucene.experimental
  */
 public class SimpleTextNormsFormat extends NormsFormat {
+  private static final String NORMS_SEG_SUFFIX = "len";
   
   @Override
   public PerDocConsumer docsConsumer(PerDocWriteState state) throws IOException {
-    return new SimpleTextNormsConsumer(state.directory, state.segmentName, state.context);
+    return new SimpleTextNormsPerDocConsumer(state, NORMS_SEG_SUFFIX);
   }
 
   @Override
   public PerDocProducer docsProducer(SegmentReadState state) throws IOException {
-    return new SimpleTextNormsProducer(state.dir, state.segmentInfo, state.fieldInfos, state.context);
+    return new SimpleTextNormsPerDocProducer(state,
+        BytesRef.getUTF8SortedAsUnicodeComparator(), NORMS_SEG_SUFFIX);
   }
 
   @Override
   public void files(SegmentInfo info, Set<String> files) throws IOException {
-    SimpleTextNormsConsumer.files(info, files);
+    SimpleTextNormsPerDocConsumer.files(info, files);
+  }
+  
+  public static class SimpleTextNormsPerDocProducer extends
+      SimpleTextPerDocProducer {
+    
+    public SimpleTextNormsPerDocProducer(SegmentReadState state,
+        Comparator<BytesRef> comp, String segmentSuffix) throws IOException {
+      super(state, comp, segmentSuffix);
+    }
+    
+    @Override
+    protected boolean canLoad(FieldInfo info) {
+      return info.normsPresent();
+    }
+    
+    @Override
+    protected Type getDocValuesType(FieldInfo info) {
+      return info.getNormType();
+    }
+    
+    @Override
+    protected boolean anyDocValuesFields(FieldInfos infos) {
+      return infos.hasNorms();
+    }
+    
+  }
+  
+  public static class SimpleTextNormsPerDocConsumer extends
+      SimpleTextPerDocConsumer {
+    
+    public SimpleTextNormsPerDocConsumer(PerDocWriteState state,
+        String segmentSuffix) throws IOException {
+      super(state, segmentSuffix);
+    }
+    
+    @Override
+    protected DocValues getDocValuesForMerge(AtomicReader reader, FieldInfo info)
+        throws IOException {
+      return reader.normValues(info.name);
+    }
+    
+    @Override
+    protected boolean canMerge(FieldInfo info) {
+      return info.normsPresent();
+    }
+    
+    @Override
+    protected Type getDocValuesType(FieldInfo info) {
+      return info.getNormType();
+    }
+    
+    @Override
+    public void abort() {
+      Set<String> files = new HashSet<String>();
+      filesInternal(state.fieldInfos, state.segmentName, files, segmentSuffix);
+      IOUtils.deleteFilesIgnoringExceptions(state.directory,
+          files.toArray(new String[0]));
+    }
+    
+    public static void files(SegmentInfo segmentInfo, Set<String> files)
+        throws IOException {
+      filesInternal(segmentInfo.getFieldInfos(), segmentInfo.name, files,
+          NORMS_SEG_SUFFIX);
+    }
+    
+    public static void filesInternal(FieldInfos fieldInfos, String segmentName,
+        Set<String> files, String segmentSuffix) {
+      for (FieldInfo fieldInfo : fieldInfos) {
+        if (fieldInfo.normsPresent()) {
+          String id = docValuesId(segmentName, fieldInfo.number);
+          files.add(IndexFileNames.segmentFileName(id, "",
+              segmentSuffix));
+        }
+      }
+    }
   }   
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsProducer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsProducer.java
index 126770b1..e69de29b 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsProducer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextNormsProducer.java
@@ -1,175 +0,0 @@
-package org.apache.lucene.codecs.simpletext;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import static org.apache.lucene.codecs.simpletext.SimpleTextNormsConsumer.DOC;
-import static org.apache.lucene.codecs.simpletext.SimpleTextNormsConsumer.END;
-import static org.apache.lucene.codecs.simpletext.SimpleTextNormsConsumer.FIELD;
-import static org.apache.lucene.codecs.simpletext.SimpleTextNormsConsumer.NORM;
-import static org.apache.lucene.codecs.simpletext.SimpleTextNormsConsumer.NORMS_EXTENSION;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
-
-import org.apache.lucene.codecs.PerDocProducer;
-import org.apache.lucene.index.DocValues;
-import org.apache.lucene.index.DocValues.Source;
-import org.apache.lucene.index.DocValues.Type;
-import org.apache.lucene.index.FieldInfo;
-import org.apache.lucene.index.FieldInfos;
-import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.SegmentInfo;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.IOContext;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.StringHelper;
-
-/**
- * Reads plain-text norms
- * <p>
- * <b><font color="red">FOR RECREATIONAL USE ONLY</font></B>
- * @lucene.experimental
- */
-public class SimpleTextNormsProducer extends PerDocProducer {
-  
-  Map<String,NormsDocValues> norms = new HashMap<String,NormsDocValues>();
-  
-  public SimpleTextNormsProducer(Directory directory, SegmentInfo si, FieldInfos fields, IOContext context) throws IOException {
-    if (fields.hasNorms()) {
-      readNorms(directory.openInput(IndexFileNames.segmentFileName(si.name, "", NORMS_EXTENSION), context), si.docCount);
-    }
-  }
-  
-  // we read in all the norms up front into a hashmap
-  private void readNorms(IndexInput in, int maxDoc) throws IOException {
-    BytesRef scratch = new BytesRef();
-    boolean success = false;
-    try {
-      SimpleTextUtil.readLine(in, scratch);
-      while (!scratch.equals(END)) {
-        assert StringHelper.startsWith(scratch, FIELD);
-        final String fieldName = readString(FIELD.length, scratch);
-        byte bytes[] = new byte[maxDoc];
-        for (int i = 0; i < bytes.length; i++) {
-          SimpleTextUtil.readLine(in, scratch);
-          assert StringHelper.startsWith(scratch, DOC);
-          SimpleTextUtil.readLine(in, scratch);
-          assert StringHelper.startsWith(scratch, NORM);
-          bytes[i] = scratch.bytes[scratch.offset + NORM.length];
-        }
-        norms.put(fieldName, new NormsDocValues(new Norm(bytes)));
-        SimpleTextUtil.readLine(in, scratch);
-        assert StringHelper.startsWith(scratch, FIELD) || scratch.equals(END);
-      }
-      success = true;
-    } finally {
-      if (success) {
-        IOUtils.close(in);
-      } else {
-        IOUtils.closeWhileHandlingException(in);
-      }
-    }
-  }
-  
-  @Override
-  public void close() throws IOException {
-    norms = null;
-  }
-  
-  static void files(Directory dir, SegmentInfo info, Set<String> files) throws IOException {
-    FieldInfos fieldInfos = info.getFieldInfos();
-    for (FieldInfo fieldInfo : fieldInfos) {
-      if (fieldInfo.normsPresent()) {
-        files.add(IndexFileNames.segmentFileName(info.name, "", SimpleTextNormsConsumer.NORMS_EXTENSION));
-        break;
-      }
-    }
-  }
-  
-  private String readString(int offset, BytesRef scratch) {
-    return new String(scratch.bytes, scratch.offset+offset, scratch.length-offset, IOUtils.CHARSET_UTF_8);
-  }
-
-  @Override
-  public DocValues docValues(String field) throws IOException {
-    return norms.get(field);
-  }
-  
-  private class NormsDocValues extends DocValues {
-    private final Source source;
-    public NormsDocValues(Source source) {
-      this.source = source;
-    }
-
-    @Override
-    public Source load() throws IOException {
-      return source;
-    }
-
-    @Override
-    public Source getDirectSource() throws IOException {
-      return getSource();
-    }
-
-    @Override
-    public Type type() {
-      return Type.FIXED_INTS_8;
-    }
-
-    @Override
-    public int getValueSize() {
-      return 1;
-    }
-  }
-  
-  static final class Norm extends Source {
-    protected Norm(byte[] bytes) {
-      super(Type.FIXED_INTS_8);
-      this.bytes = bytes;
-    }
-    final byte bytes[];
-    
-    @Override
-    public BytesRef getBytes(int docID, BytesRef ref) {
-      ref.bytes = bytes;
-      ref.offset = docID;
-      ref.length = 1;
-      return ref;
-    }
-    
-    @Override
-    public long getInt(int docID) {
-      return bytes[docID];
-    }
-
-    @Override
-    public boolean hasArray() {
-      return true;
-    }
-
-    @Override
-    public Object getArray() {
-      return bytes;
-    }
-    
-  }
-}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPerDocConsumer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPerDocConsumer.java
index e69de29b..3af2c4cd 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPerDocConsumer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPerDocConsumer.java
@@ -0,0 +1,94 @@
+package org.apache.lucene.codecs.simpletext;
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with this
+ * work for additional information regarding copyright ownership. The ASF
+ * licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ * 
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.lucene.codecs.DocValuesConsumer;
+import org.apache.lucene.codecs.PerDocConsumer;
+import org.apache.lucene.index.FieldInfo;
+import org.apache.lucene.index.FieldInfos;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.PerDocWriteState;
+import org.apache.lucene.index.SegmentInfo;
+import org.apache.lucene.index.DocValues.Type;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.IOUtils;
+
+/**
+ * @lucene.experimental
+ */
+class SimpleTextPerDocConsumer extends PerDocConsumer {
+
+  protected final PerDocWriteState state;
+  protected final String segmentSuffix;
+  public SimpleTextPerDocConsumer(PerDocWriteState state, String segmentSuffix)
+      throws IOException {
+    this.state = state;
+    this.segmentSuffix = segmentSuffix;
+  }
+
+  @Override
+  public void close() throws IOException {
+
+  }
+
+  @Override
+  public DocValuesConsumer addValuesField(Type type, FieldInfo field)
+      throws IOException {
+    return new SimpleTextDocValuesConsumer(SimpleTextDocValuesFormat.docValuesId(state.segmentName,
+        field.number), state.directory, state.context, type, segmentSuffix);
+  }
+
+  @Override
+  public void abort() {
+    Set<String> files = new HashSet<String>();
+    files(state.directory, state.fieldInfos, state.segmentName, files, segmentSuffix);
+    IOUtils.deleteFilesIgnoringExceptions(state.directory,
+        files.toArray(new String[0]));
+  }
+  
+  
+  static void files(SegmentInfo info, Set<String> files, String segmentSuffix) throws IOException {
+    files(info.dir, info.getFieldInfos(), info.name, files, segmentSuffix);
+  }
+  
+  static String docValuesId(String segmentsName, int fieldId) {
+    return segmentsName + "_" + fieldId;
+  }
+
+  @SuppressWarnings("fallthrough")
+  private static void files(Directory dir, FieldInfos fieldInfos,
+      String segmentName, Set<String> files, String segmentSuffix) {
+    for (FieldInfo fieldInfo : fieldInfos) {
+      if (fieldInfo.hasDocValues()) {
+        String filename = docValuesId(segmentName, fieldInfo.number);
+        files.add(IndexFileNames.segmentFileName(filename, "",
+            segmentSuffix));
+        try {
+          assert dir.fileExists(IndexFileNames.segmentFileName(filename, "",
+              segmentSuffix));
+        } catch (IOException e) {
+          // don't throw checked exception - dir is only used in assert
+          throw new RuntimeException(e);
+        }
+      }
+    }
+  }
+
+}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPerDocProducer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPerDocProducer.java
index e69de29b..88f91c3b 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPerDocProducer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPerDocProducer.java
@@ -0,0 +1,431 @@
+package org.apache.lucene.codecs.simpletext;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with this
+ * work for additional information regarding copyright ownership. The ASF
+ * licenses this file to You under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ * 
+ * http://www.apache.org/licenses/LICENSE-2.0
+ * 
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+import static org.apache.lucene.codecs.simpletext.SimpleTextDocValuesConsumer.DOC;
+import static org.apache.lucene.codecs.simpletext.SimpleTextDocValuesConsumer.END;
+import static org.apache.lucene.codecs.simpletext.SimpleTextDocValuesConsumer.HEADER;
+import static org.apache.lucene.codecs.simpletext.SimpleTextDocValuesConsumer.VALUE;
+import static org.apache.lucene.codecs.simpletext.SimpleTextDocValuesConsumer.VALUE_SIZE;
+
+import java.io.Closeable;
+import java.io.IOException;
+import java.util.Collection;
+import java.util.Comparator;
+import java.util.Map;
+import java.util.TreeMap;
+
+import org.apache.lucene.codecs.DocValuesArraySource;
+import org.apache.lucene.codecs.PerDocProducerBase;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValues.SortedSource;
+import org.apache.lucene.index.DocValues.Source;
+import org.apache.lucene.index.DocValues.Type;
+import org.apache.lucene.index.IndexFileNames;
+import org.apache.lucene.index.SegmentReadState;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.BytesRefHash;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.StringHelper;
+import org.apache.lucene.util.packed.PackedInts.Reader;
+
+/**
+ * @lucene.experimental
+ */
+public class SimpleTextPerDocProducer extends PerDocProducerBase {
+  protected final TreeMap<String, DocValues> docValues;
+  private Comparator<BytesRef> comp;
+  private final String segmentSuffix;
+
+  /**
+   * Creates a new {@link SimpleTextPerDocProducer} instance and loads all
+   * {@link DocValues} instances for this segment and codec.
+   */
+  public SimpleTextPerDocProducer(SegmentReadState state,
+      Comparator<BytesRef> comp, String segmentSuffix) throws IOException {
+    this.comp = comp;
+    this.segmentSuffix = segmentSuffix;
+    if (anyDocValuesFields(state.fieldInfos)) {
+      docValues = load(state.fieldInfos, state.segmentInfo.name,
+          state.segmentInfo.docCount, state.dir, state.context);
+    } else {
+      docValues = new TreeMap<String, DocValues>();
+    }
+  }
+
+  @Override
+  protected Map<String, DocValues> docValues() {
+    return docValues;
+  }
+
+  protected DocValues loadDocValues(int docCount, Directory dir, String id,
+      DocValues.Type type, IOContext context) throws IOException {
+    return new SimpleTextDocValues(dir, context, type, id, docCount, comp, segmentSuffix);
+  }
+
+  @Override
+  protected void closeInternal(Collection<? extends Closeable> closeables)
+      throws IOException {
+    IOUtils.close(closeables);
+  }
+
+  private static class SimpleTextDocValues extends DocValues {
+
+    private int docCount;
+
+    @Override
+    public void close() throws IOException {
+      try {
+        super.close();
+      } finally {
+        IOUtils.close(input);
+      }
+    }
+
+    private Type type;
+    private Comparator<BytesRef> comp;
+    private int valueSize;
+    private final IndexInput input;
+
+    public SimpleTextDocValues(Directory dir, IOContext ctx, Type type,
+        String id, int docCount, Comparator<BytesRef> comp, String segmentSuffix) throws IOException {
+      this.type = type;
+      this.docCount = docCount;
+      this.comp = comp;
+      final String fileName = IndexFileNames.segmentFileName(id, "", segmentSuffix);
+      boolean success = false;
+      IndexInput in = null;
+      try {
+        in = dir.openInput(fileName, ctx);
+        valueSize = readHeader(in);
+        success = true;
+      } finally {
+        if (!success) {
+          IOUtils.closeWhileHandlingException(in);
+        }
+      }
+      input = in;
+
+    }
+
+    @Override
+    public Source load() throws IOException {
+      boolean success = false;
+      IndexInput in = (IndexInput) input.clone();
+      try {
+        Source source = null;
+        switch (type) {
+        case BYTES_FIXED_DEREF:
+        case BYTES_FIXED_SORTED:
+        case BYTES_FIXED_STRAIGHT:
+        case BYTES_VAR_DEREF:
+        case BYTES_VAR_SORTED:
+        case BYTES_VAR_STRAIGHT:
+          source = read(in, new ValueReader(type, docCount, comp));
+          break;
+        case FIXED_INTS_16:
+        case FIXED_INTS_32:
+        case VAR_INTS:
+        case FIXED_INTS_64:
+        case FIXED_INTS_8:
+        case FLOAT_32:
+        case FLOAT_64:
+          source = read(in, new ValueReader(type, docCount, null));
+          break;
+        default:
+          throw new IllegalArgumentException("unknown type: " + type);
+        }
+        assert source != null;
+        success = true;
+        return source;
+      } finally {
+        if (!success) {
+          IOUtils.closeWhileHandlingException(in);
+        } else {
+          IOUtils.close(in);
+        }
+      }
+    }
+
+    private int readHeader(IndexInput in) throws IOException {
+      BytesRef scratch = new BytesRef();
+      SimpleTextUtil.readLine(in, scratch);
+      assert StringHelper.startsWith(scratch, HEADER);
+      SimpleTextUtil.readLine(in, scratch);
+      assert StringHelper.startsWith(scratch, VALUE_SIZE);
+      return Integer.parseInt(readString(scratch.offset + VALUE_SIZE.length,
+          scratch));
+    }
+
+    private Source read(IndexInput in, ValueReader reader) throws IOException {
+      BytesRef scratch = new BytesRef();
+      for (int i = 0; i < docCount; i++) {
+        SimpleTextUtil.readLine(in, scratch);
+
+        assert StringHelper.startsWith(scratch, DOC) : scratch.utf8ToString();
+        SimpleTextUtil.readLine(in, scratch);
+        assert StringHelper.startsWith(scratch, VALUE);
+        reader.fromString(i, scratch, scratch.offset + VALUE.length);
+      }
+      SimpleTextUtil.readLine(in, scratch);
+      assert scratch.equals(END);
+      return reader.getSource();
+    }
+
+    @Override
+    public Source getDirectSource() throws IOException {
+      return this.getSource();
+    }
+
+    @Override
+    public int getValueSize() {
+      return valueSize;
+    }
+
+    @Override
+    public Type type() {
+      return type;
+    }
+
+  }
+
+  public static String readString(int offset, BytesRef scratch) {
+    return new String(scratch.bytes, scratch.offset + offset, scratch.length
+        - offset, IOUtils.CHARSET_UTF_8);
+  }
+
+  private static final class ValueReader {
+    private final Type type;
+    private byte[] bytes;
+    private short[] shorts;
+    private int[] ints;
+    private long[] longs;
+    private float[] floats;
+    private double[] doubles;
+    private Source source;
+    private BytesRefHash hash;
+    private BytesRef scratch;
+
+    public ValueReader(Type type, int maxDocs, Comparator<BytesRef> comp) {
+      super();
+      this.type = type;
+      Source docValuesArray = null;
+      switch (type) {
+      case FIXED_INTS_16:
+        shorts = new short[maxDocs];
+        docValuesArray = DocValuesArraySource.forType(type)
+            .newFromArray(shorts);
+        break;
+      case FIXED_INTS_32:
+        ints = new int[maxDocs];
+        docValuesArray = DocValuesArraySource.forType(type).newFromArray(ints);
+        break;
+      case FIXED_INTS_64:
+        longs = new long[maxDocs];
+        docValuesArray = DocValuesArraySource.forType(type)
+            .newFromArray(longs);
+        break;
+      case VAR_INTS:
+        longs = new long[maxDocs];
+        docValuesArray = new VarIntsArraySource(type, longs);
+        break;
+      case FIXED_INTS_8:
+        bytes = new byte[maxDocs];
+        docValuesArray = DocValuesArraySource.forType(type).newFromArray(bytes);
+        break;
+      case FLOAT_32:
+        floats = new float[maxDocs];
+        docValuesArray = DocValuesArraySource.forType(type)
+            .newFromArray(floats);
+        break;
+      case FLOAT_64:
+        doubles = new double[maxDocs];
+        docValuesArray = DocValuesArraySource.forType(type).newFromArray(
+            doubles);
+        break;
+      case BYTES_FIXED_DEREF:
+      case BYTES_FIXED_SORTED:
+      case BYTES_FIXED_STRAIGHT:
+      case BYTES_VAR_DEREF:
+      case BYTES_VAR_SORTED:
+      case BYTES_VAR_STRAIGHT:
+        assert comp != null;
+        hash = new BytesRefHash();
+        BytesSource bytesSource = new BytesSource(type, comp, maxDocs, hash);
+        ints = bytesSource.docIdToEntry;
+        source = bytesSource;
+        scratch = new BytesRef();
+        break;
+
+      }
+      if (docValuesArray != null) {
+        assert source == null;
+        this.source = docValuesArray;
+      }
+    }
+
+    public void fromString(int ord, BytesRef ref, int offset) {
+      switch (type) {
+      case FIXED_INTS_16:
+        assert shorts != null;
+        shorts[ord] = Short.parseShort(readString(offset, ref));
+        break;
+      case FIXED_INTS_32:
+        assert ints != null;
+        ints[ord] = Integer.parseInt(readString(offset, ref));
+        break;
+      case FIXED_INTS_64:
+      case VAR_INTS:
+        assert longs != null;
+        longs[ord] = Long.parseLong(readString(offset, ref));
+        break;
+      case FIXED_INTS_8:
+        assert bytes != null;
+        bytes[ord] = (byte) Integer.parseInt(readString(offset, ref));
+        break;
+      case FLOAT_32:
+        assert floats != null;
+        floats[ord] = Float.parseFloat(readString(offset, ref));
+        break;
+      case FLOAT_64:
+        assert doubles != null;
+        doubles[ord] = Double.parseDouble(readString(offset, ref));
+        break;
+      case BYTES_FIXED_DEREF:
+      case BYTES_FIXED_SORTED:
+      case BYTES_FIXED_STRAIGHT:
+      case BYTES_VAR_DEREF:
+      case BYTES_VAR_SORTED:
+      case BYTES_VAR_STRAIGHT:
+        scratch.bytes = ref.bytes;
+        scratch.length = ref.length - offset;
+        scratch.offset = ref.offset + offset;
+        int key = hash.add(scratch);
+        ints[ord] = key < 0 ? (-key) - 1 : key;
+        break;
+      }
+    }
+
+    public Source getSource() {
+      if (source instanceof BytesSource) {
+        ((BytesSource) source).maybeSort();
+      }
+      return source;
+    }
+  }
+
+  private static final class BytesSource extends SortedSource {
+
+    private final BytesRefHash hash;
+    int[] docIdToEntry;
+    int[] sortedEntries;
+    int[] adresses;
+    private final boolean isSorted;
+
+    protected BytesSource(Type type, Comparator<BytesRef> comp, int maxDoc,
+        BytesRefHash hash) {
+      super(type, comp);
+      docIdToEntry = new int[maxDoc];
+      this.hash = hash;
+      isSorted = type == Type.BYTES_FIXED_SORTED
+          || type == Type.BYTES_VAR_SORTED;
+    }
+
+    void maybeSort() {
+      if (isSorted) {
+        adresses = new int[hash.size()];
+        sortedEntries = hash.sort(getComparator());
+        for (int i = 0; i < adresses.length; i++) {
+          int entry = sortedEntries[i];
+          adresses[entry] = i;
+        }
+      }
+
+    }
+
+    @Override
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      if (isSorted) {
+        return hash.get(sortedEntries[ord(docID)], ref);
+      } else {
+        return hash.get(docIdToEntry[docID], ref);
+      }
+    }
+
+    @Override
+    public SortedSource asSortedSource() {
+      if (isSorted) {
+        return this;
+      }
+      return null;
+    }
+
+    @Override
+    public int ord(int docID) {
+      assert isSorted;
+      try {
+        return adresses[docIdToEntry[docID]];
+      } catch (Exception e) {
+
+        return 0;
+      }
+    }
+
+    @Override
+    public BytesRef getByOrd(int ord, BytesRef bytesRef) {
+      assert isSorted;
+      return hash.get(sortedEntries[ord], bytesRef);
+    }
+
+    @Override
+    public Reader getDocToOrd() {
+      return null;
+    }
+
+    @Override
+    public int getValueCount() {
+      return hash.size();
+    }
+
+  }
+  
+  private static class VarIntsArraySource extends Source {
+
+    private final long[] array;
+
+    protected VarIntsArraySource(Type type, long[] array) {
+      super(type);
+      this.array = array;
+    }
+
+    @Override
+    public long getInt(int docID) {
+      return array[docID];
+    }
+
+    @Override
+    public BytesRef getBytes(int docID, BytesRef ref) {
+      DocValuesArraySource.copyLong(ref, getInt(docID));
+      return ref;
+    }
+    
+  }
+
+}
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/index/IndexableField.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/index/IndexableField.java
index 267de2e1..fac46e01 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/index/IndexableField.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/index/IndexableField.java
@@ -54,7 +54,7 @@
   /** Non-null if this field has a Reader value */
   public Reader readerValue();
 
-  /** Non-null if this field hasa numeric value */
+  /** Non-null if this field has a numeric value */
   public Number numericValue();
 
   /**
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
index fa19fad4..ebc8640f 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/search/IndexSearcher.java
@@ -584,8 +584,9 @@ public Weight createNormalizedWeight(Query query) throws IOException {
     Weight weight = query.createWeight(this);
     float v = weight.getValueForNormalization();
     float norm = getSimilarity().queryNorm(v);
-    if (Float.isInfinite(norm) || Float.isNaN(norm))
+    if (Float.isInfinite(norm) || Float.isNaN(norm)) {
       norm = 1.0f;
+    }
     weight.normalize(norm, 1.0f);
     return weight;
   }
@@ -813,6 +814,8 @@ public CollectionStatistics collectionStatistics(String field) throws IOExceptio
     final long sumTotalTermFreq;
     final long sumDocFreq;
     
+    assert field != null;
+    
     Terms terms = MultiFields.getTerms(reader, field);
     if (terms == null) {
       docCount = 0;
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java
index 8c6f3d33..aa5ab171 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/java/org/apache/lucene/search/spans/SpanWeight.java
@@ -57,29 +57,38 @@ public SpanWeight(SpanQuery query, IndexSearcher searcher)
       termContexts.put(term, state);
       i++;
     }
+    final String field = query.getField();
+    if (field != null) {
     stats = similarity.computeWeight(query.getBoost(), 
         searcher.collectionStatistics(query.getField()), 
         termStats);
   }
+  }
 
   @Override
   public Query getQuery() { return query; }
 
   @Override
   public float getValueForNormalization() throws IOException {
-    return stats.getValueForNormalization();
+    return stats == null ? 1.0f : stats.getValueForNormalization();
   }
 
   @Override
   public void normalize(float queryNorm, float topLevelBoost) {
+    if (stats != null) {
     stats.normalize(queryNorm, topLevelBoost);
   }
+  }
 
   @Override
   public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder,
       boolean topScorer, Bits acceptDocs) throws IOException {
+    if (stats == null) {
+      return null;
+    } else {
     return new SpanScorer(query.getSpans(context, acceptDocs, termContexts), this, similarity.sloppySimScorer(stats, context));
   }
+  }
 
   @Override
   public Explanation explain(AtomicReaderContext context, int doc) throws IOException {
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java
index a7d85449..e7e90711 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing.java
@@ -148,8 +148,8 @@ public void testAddIndexes() throws IOException {
 
     Directory target = newDirectory();
     IndexWriter w = new IndexWriter(target, writerConfig(random.nextBoolean()));
-    IndexReader r_1 = IndexReader.open(w_1, true);
-    IndexReader r_2 = IndexReader.open(w_2, true);
+    DirectoryReader r_1 = DirectoryReader.open(w_1, true);
+    DirectoryReader r_2 = DirectoryReader.open(w_2, true);
     if (random.nextBoolean()) {
       w.addIndexes(d_1, d_2);
     } else {
@@ -163,7 +163,7 @@ public void testAddIndexes() throws IOException {
 
     // check values
     
-    IndexReader merged = IndexReader.open(w, true);
+    DirectoryReader merged = DirectoryReader.open(w, true);
     Source source_1 = getSource(getDocValues(r_1, first.name()));
     Source source_2 = getSource(getDocValues(r_2, second.name()));
     Source source_1_merged = getSource(getDocValues(merged, first.name()));
@@ -260,7 +260,7 @@ public void runTestNumerics(IndexWriterConfig cfg, boolean withDeletions)
       FixedBitSet deleted = indexValues(w, numValues, val, numVariantList,
           withDeletions, 7);
       List<Closeable> closeables = new ArrayList<Closeable>();
-      IndexReader r = IndexReader.open(w, true);
+      DirectoryReader r = DirectoryReader.open(w, true);
       final int numRemainingValues = numValues - deleted.cardinality();
       final int base = r.numDocs() - numRemainingValues;
       // for FIXED_INTS_8 we use value mod 128 - to enable testing in 
@@ -338,7 +338,7 @@ public void runTestIndexBytes(IndexWriterConfig cfg, boolean withDeletions)
       final int bytesSize = 1 + atLeast(50);
       FixedBitSet deleted = indexValues(w, numValues, byteIndexValue,
           byteVariantList, withDeletions, bytesSize);
-      final IndexReader r = IndexReader.open(w, withDeletions);
+      final DirectoryReader r = DirectoryReader.open(w, withDeletions);
       assertEquals(0, r.numDeletedDocs());
       final int numRemainingValues = numValues - deleted.cardinality();
       final int base = r.numDocs() - numRemainingValues;
@@ -422,12 +422,16 @@ public void testGetArrayNumerics() throws CorruptIndexException, IOException {
     for (Type val : numVariantList) {
       indexValues(w, numValues, val, numVariantList,
           false, 7);
-      IndexReader r = IndexReader.open(w, true);
+      DirectoryReader r = DirectoryReader.open(w, true);
+      if (val == Type.VAR_INTS) {
+      DocValues docValues = getDocValues(r, val.name());
+      }
       DocValues docValues = getDocValues(r, val.name());
       assertNotNull(docValues);
       // make sure we don't get a direct source since they don't support getArray()
+      if (val == Type.VAR_INTS) {
+      }
       Source source = docValues.getSource();
-      
       switch (source.type()) {
       case FIXED_INTS_8:
       {
@@ -466,6 +470,7 @@ public void testGetArrayNumerics() throws CorruptIndexException, IOException {
       }
       break;
       case VAR_INTS: 
+        System.out.println(source.hasArray());
         assertFalse(source.hasArray());
         break;
       case FLOAT_32:
@@ -503,7 +508,7 @@ public void testGetArrayBytes() throws CorruptIndexException, IOException {
     final int numValues = 50 + atLeast(10);
     // only single byte fixed straight supports getArray()
     indexValues(w, numValues, Type.BYTES_FIXED_STRAIGHT, null, false, 1);
-    IndexReader r = IndexReader.open(w, true);
+    DirectoryReader r = DirectoryReader.open(w, true);
     DocValues docValues = getDocValues(r, Type.BYTES_FIXED_STRAIGHT.name());
     assertNotNull(docValues);
     // make sure we don't get a direct source since they don't support
@@ -513,13 +518,14 @@ public void testGetArrayBytes() throws CorruptIndexException, IOException {
     switch (source.type()) {
     case BYTES_FIXED_STRAIGHT: {
       BytesRef ref = new BytesRef();
-      assertTrue(source.hasArray());
+      if (source.hasArray()) {
       byte[] values = (byte[]) source.getArray();
       for (int i = 0; i < numValues; i++) {
         source.getBytes(i, ref);
         assertEquals(1, ref.length);
         assertEquals(values[i], ref.bytes[ref.offset]);
       }
+    }
     }
       break;
     default:
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java
index 92b9caae..768c528f 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/core/src/test/org/apache/lucene/search/spans/TestSpans.java
@@ -17,31 +17,31 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.AtomicReaderContext;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexReaderContext;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.CheckHits;
 import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.CheckHits;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.similarities.DefaultSimilarity;
 import org.apache.lucene.search.similarities.Similarity;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.index.AtomicReaderContext;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.IndexReaderContext;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.document.TextField;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.ReaderUtil;
 
-import java.io.IOException;
-
 public class TestSpans extends LuceneTestCase {
   private IndexSearcher searcher;
   private IndexReader reader;
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWNormsConsumer.java b/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWNormsConsumer.java
index 2bb54828..de2e4145 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWNormsConsumer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/codecs/lucene3x/PreFlexRWNormsConsumer.java
@@ -164,6 +164,11 @@ protected void add(int docID, long value) {
       upto++;
     }
     
+    @Override
+    protected Type getType() {
+      return Type.FIXED_INTS_8;
+    }
+    
     
   }
   
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java b/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
index 7c10d88b..3f2994f8 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
@@ -265,9 +265,7 @@ public UncaughtExceptionEntry(Thread thread, Throwable exception) {
 
   protected static Map<MockDirectoryWrapper,StackTraceElement[]> stores;
 
-  /** @deprecated (4.0) until we fix no-fork problems in solr tests */
-  @Deprecated
-  static List<String> testClassesRun = new ArrayList<String>();
+  private static List<String> testClassesRun = new ArrayList<String>();
 
   private static void initRandom() {
     assert !random.initialized;
@@ -279,11 +277,20 @@ private static void initRandom() {
   @Deprecated
   private static boolean icuTested = false;
 
+  /**
+   * Stores the currently class under test.
+   */
+  private static final StoreClassNameRule classNameRule = new StoreClassNameRule(); 
+  
   @ClassRule
-  public static TestRule classRules = RuleChain.outerRule(new SystemPropertiesInvariantRule());
+  public static TestRule classRules = RuleChain
+    .outerRule(new SystemPropertiesInvariantRule())
+    .around(classNameRule);
 
   @BeforeClass
   public static void beforeClassLuceneTestCaseJ4() {
+    testClassesRun.add(getTestClass().getSimpleName());
+
     initRandom();
     tempDirs.clear();
     stores = Collections.synchronizedMap(new IdentityHashMap<MockDirectoryWrapper,StackTraceElement[]>());
@@ -1565,6 +1572,13 @@ public static IOContext newIOContext(Random random) {
     return context;
   }
   
+  /**
+   * Return the current class being tested.
+   */
+  public static Class<?> getTestClass() {
+    return classNameRule.getTestClass();
+  }
+  
   // initialized by the TestRunner
   static boolean useNoMemoryExpensiveCodec;
   
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCaseRunner.java b/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCaseRunner.java
index 322acd20..a0663b21 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCaseRunner.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCaseRunner.java
@@ -68,7 +68,6 @@
     
     Random r = new Random(runnerSeed);
     
-    LuceneTestCase.testClassesRun.add(getTestClass().getJavaClass().getSimpleName());
     testMethods = new ArrayList<FrameworkMethod>();
     for (Method m : getTestClass().getJavaClass().getMethods()) {
       // check if the current test's class has methods annotated with @Ignore
diff --git a/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/StoreClassNameRule.java b/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/StoreClassNameRule.java
index e69de29b..97544fb1 100644
--- a/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/StoreClassNameRule.java
+++ b/lucene/dev/branches/solr_3159_jetty8/lucene/test-framework/src/java/org/apache/lucene/util/StoreClassNameRule.java
@@ -0,0 +1,39 @@
+package org.apache.lucene.util;
+
+import org.junit.rules.TestRule;
+import org.junit.runner.Description;
+import org.junit.runners.model.Statement;
+
+public class StoreClassNameRule implements TestRule {
+  private volatile Class<?> testClass;
+
+  @Override
+  public Statement apply(final Statement s, final Description d) {
+    if (!d.isSuite()) {
+      throw new IllegalArgumentException("This is a @ClassRule (applies to suites only).");
+    }
+
+    return new Statement() {
+      @Override
+      public void evaluate() throws Throwable {
+        try {
+          testClass = d.getTestClass();
+          s.evaluate();
+        } finally {
+          testClass = null;
+        }
+      }
+    };
+  }
+  
+  /**
+   * Returns the test class currently executing in this rule.
+   */
+  public Class<?> getTestClass() {
+    Class<?> clz = testClass;
+    if (clz == null) {
+      throw new RuntimeException("The rule is not currently executing.");
+    }
+    return clz;
+  }
+}
diff --git a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/Lookup.java b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/Lookup.java
index 667002aa..fd0b5477 100644
--- a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/Lookup.java
+++ b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/Lookup.java
@@ -152,21 +152,4 @@ public void build(Dictionary dict) throws IOException {
    */
   public abstract boolean load(InputStream input) throws IOException;
   
-  /**
-   * Persist the constructed lookup data to a directory. Optional operation.
-   * @param storeDir directory where data can be stored.
-   * @return true if successful, false if unsuccessful or not supported.
-   * @throws IOException when fatal IO error occurs.
-   */
-  public abstract boolean store(File storeDir) throws IOException;
-
-  /**
-   * Discard current lookup data and load it from a previously saved copy.
-   * Optional operation.
-   * @param storeDir directory where lookup data was stored.
-   * @return true if completed successfully, false if unsuccessful or not supported.
-   * @throws IOException when fatal IO error occurs.
-   */
-  public abstract boolean load(File storeDir) throws IOException;
-  
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup.java b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup.java
index 9bd0ce79..dd0b58aa 100644
--- a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup.java
+++ b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTCompletionLookup.java
@@ -79,14 +79,6 @@
    */
   private final static int sharedTailLength = 5;
 
-  /**
-   * File name for the automaton.
-   * 
-   * @see #store(File)
-   * @see #load(File)
-   */
-  private static final String FILENAME = "fst.bin";
-
   private int buckets;
   private boolean exactMatchFirst;
 
@@ -264,46 +256,13 @@ public Object get(CharSequence key) {
     return bucket == -1 ? null : Long.valueOf(bucket);
   }
 
-  /**
-   * Deserialization from disk.
-   */
-  @Override
-  public synchronized boolean load(File storeDir) throws IOException {
-    File data = new File(storeDir, FILENAME);
-    if (!data.exists() || !data.canRead()) {
-      return false;
-    }
-
-    this.higherWeightsCompletion = new FSTCompletion(
-        FST.read(data, NoOutputs.getSingleton()));
-    this.normalCompletion = new FSTCompletion(
-        higherWeightsCompletion.getFST(), false, exactMatchFirst);
-
-    return true;
-  }
-
-  /**
-   * Serialization to disk.
-   */
-  @Override
-  public synchronized boolean store(File storeDir) throws IOException {
-    if (!storeDir.exists() || !storeDir.isDirectory() || !storeDir.canWrite()) {
-      return false;
-    }
-
-    if (this.normalCompletion == null) 
-      return false;
-
-    normalCompletion.getFST().save(new File(storeDir, FILENAME));
-    return true;
-  }
 
   @Override
   public synchronized boolean store(OutputStream output) throws IOException {
 
-    if (this.normalCompletion == null) 
-      return false;
     try {
+      if (this.normalCompletion == null || normalCompletion.getFST() == null) 
+        return false;
       normalCompletion.getFST().save(new OutputStreamDataOutput(output));
     } finally {
       IOUtils.close(output);
diff --git a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java
index 330cf3c8..a373f920 100644
--- a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java
+++ b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/WFSTCompletionLookup.java
@@ -17,7 +17,6 @@
  * limitations under the License.
  */
 
-import java.io.File;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.OutputStream;
@@ -63,14 +62,6 @@
  */
 public class WFSTCompletionLookup extends Lookup {
   
-  /**
-   * File name for the automaton.
-   * 
-   * @see #store(File)
-   * @see #load(File)
-   */
-  private static final String FILENAME = "wfst.bin";
-  
   /**
    * FST<Long>, weights are encoded as costs: (Integer.MAX_VALUE-weight)
    */
@@ -127,21 +118,13 @@ public void build(TermFreqIterator iterator) throws IOException {
     fst = builder.finish();
   }
 
-  @Override
-  public boolean store(File storeDir) throws IOException {
-    fst.save(new File(storeDir, FILENAME));
-    return true;
-  }
-
-  @Override
-  public boolean load(File storeDir) throws IOException {
-    this.fst = FST.read(new File(storeDir, FILENAME), PositiveIntOutputs.getSingleton(true));
-    return true;
-  }
   
   @Override
   public boolean store(OutputStream output) throws IOException {
     try {
+      if (fst == null) {
+        return false;
+      }
       fst.save(new OutputStreamDataOutput(output));
     } finally {
       IOUtils.close(output);
diff --git a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellLookup.java b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellLookup.java
index b7bb15e8..9e570671 100644
--- a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellLookup.java
+++ b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/jaspell/JaspellLookup.java
@@ -19,9 +19,6 @@
 
 import java.io.DataInputStream;
 import java.io.DataOutputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.OutputStream;
@@ -109,22 +106,11 @@ public Object get(CharSequence key) {
     return res;
   }
 
-  public static final String FILENAME = "jaspell.dat";
   private static final byte LO_KID = 0x01;
   private static final byte EQ_KID = 0x02;
   private static final byte HI_KID = 0x04;
   private static final byte HAS_VALUE = 0x08;
  
-  
-  @Override
-  public boolean load(File storeDir) throws IOException {
-    File data = new File(storeDir, FILENAME);
-    if (!data.exists() || !data.canRead()) {
-      return false;
-    }
-    return load(new FileInputStream(data));
-  }
-  
   private void readRecursively(DataInputStream in, TSTNode node) throws IOException {
     node.splitchar = in.readChar();
     byte mask = in.readByte();
@@ -148,15 +134,6 @@ private void readRecursively(DataInputStream in, TSTNode node) throws IOExceptio
     }
   }
 
-  @Override
-  public boolean store(File storeDir) throws IOException {
-    if (!storeDir.exists() || !storeDir.isDirectory() || !storeDir.canWrite()) {
-      return false;
-    }
-    File data = new File(storeDir, FILENAME);
-    return store(new FileOutputStream(data));
-  }
-  
   private void writeRecursively(DataOutputStream out, TSTNode node) throws IOException {
     if (node == null) {
       return;
diff --git a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/tst/TSTLookup.java b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/tst/TSTLookup.java
index 99e4e6a8..86a10cde 100644
--- a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/tst/TSTLookup.java
+++ b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/java/org/apache/lucene/search/suggest/tst/TSTLookup.java
@@ -119,23 +119,12 @@ private static boolean charSeqEquals(CharSequence left, CharSequence right) {
     return res;
   }
   
-  public static final String FILENAME = "tst.dat";
-  
   private static final byte LO_KID = 0x01;
   private static final byte EQ_KID = 0x02;
   private static final byte HI_KID = 0x04;
   private static final byte HAS_TOKEN = 0x08;
   private static final byte HAS_VALUE = 0x10;
 
-  @Override
-  public synchronized boolean load(File storeDir) throws IOException {
-    File data = new File(storeDir, FILENAME);
-    if (!data.exists() || !data.canRead()) {
-      return false;
-    }
-    return load(new FileInputStream(data));
-  }
-  
   // pre-order traversal
   private void readRecursively(DataInputStream in, TernaryTreeNode node) throws IOException {
     node.splitchar = in.readChar();
@@ -160,15 +149,6 @@ private void readRecursively(DataInputStream in, TernaryTreeNode node) throws IO
     }
   }
 
-  @Override
-  public synchronized boolean store(File storeDir) throws IOException {
-    if (!storeDir.exists() || !storeDir.isDirectory() || !storeDir.canWrite()) {
-      return false;
-    }
-    File data = new File(storeDir, FILENAME);
-    return store(new FileOutputStream(data));
-  }
-  
   // pre-order traversal
   private void writeRecursively(DataOutputStream out, TernaryTreeNode node) throws IOException {
     // write out the current node
diff --git a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/test/org/apache/lucene/search/suggest/PersistenceTest.java b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/test/org/apache/lucene/search/suggest/PersistenceTest.java
index 73f5ae82..34bf6b1e 100644
--- a/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/test/org/apache/lucene/search/suggest/PersistenceTest.java
+++ b/lucene/dev/branches/solr_3159_jetty8/modules/suggest/src/test/org/apache/lucene/search/suggest/PersistenceTest.java
@@ -17,6 +17,8 @@
 package org.apache.lucene.search.suggest;
 
 import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
 import java.util.List;
 
 import org.apache.lucene.search.suggest.Lookup;
@@ -69,11 +71,11 @@ private void runTest(Class<? extends Lookup> lookupClass,
 
     // Store the suggester.
     File storeDir = TEMP_DIR;
-    lookup.store(storeDir);
+    lookup.store(new FileOutputStream(new File(storeDir, "lookup.dat")));
 
     // Re-read it from disk.
     lookup = lookupClass.newInstance();
-    lookup.load(storeDir);
+    lookup.load(new FileInputStream(new File(storeDir, "lookup.dat")));
 
     // Assert validity.
     long previous = Long.MIN_VALUE;
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrEntityProcessor.java b/lucene/dev/branches/solr_3159_jetty8/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrEntityProcessor.java
index ed7f978e..a623ad6c 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrEntityProcessor.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrEntityProcessor.java
@@ -18,16 +18,6 @@
  * limitations under the License.
  */
 
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
-import static org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow;
-
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.Map;
-
 import org.apache.commons.httpclient.HttpClient;
 import org.apache.commons.httpclient.MultiThreadedHttpConnectionManager;
 import org.apache.solr.client.solrj.SolrQuery;
@@ -38,9 +28,20 @@
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.params.CommonParams;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.Map;
+
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.SEVERE;
+import static org.apache.solr.handler.dataimport.DataImportHandlerException.wrapAndThrow;
+
 /**
  * <p>
  * An implementation of {@link EntityProcessor} which fetches values from a
@@ -59,13 +60,6 @@
   
   public static final String SOLR_SERVER = "url";
   public static final String QUERY = "query";
-  /**
-   * (format="javabin|xml") default is javabin
-   */
-  public static final String FORMAT = "format";
-  public static final String ROWS = "rows";
-  public static final String FIELDS = "fields";
-  public static final String FQ = "fq";
   public static final String TIMEOUT = "timeout";
   
   public static final int TIMEOUT_SECS = 5 * 60; // 5 minutes
@@ -76,10 +70,22 @@
   private int rows = ROWS_DEFAULT;
   private String[] filterQueries;
   private String[] fields;
+  private String queryType;
   private int timeout = TIMEOUT_SECS;
   
   private boolean initDone = false;
   
+  /**
+   * Factory method that returns a {@link HttpClient} instance used for interfacing with a source Solr service.
+   * One can override this method to return a differently configured {@link HttpClient} instance.
+   * For example configure https and http authentication.
+   *
+   * @return a {@link HttpClient} instance used for interfacing with a source Solr service
+   */
+  protected HttpClient getHttpClient() {
+    return new HttpClient(new MultiThreadedHttpConnectionManager());
+  }
+
   @Override
   protected void firstInit(Context context) {
     super.firstInit(context);
@@ -90,19 +96,17 @@ protected void firstInit(Context context) {
         throw new DataImportHandlerException(DataImportHandlerException.SEVERE,
             "SolrEntityProcessor: parameter 'url' is required");
       }
-      HttpClient client = new HttpClient(
-          new MultiThreadedHttpConnectionManager());
-      URL url = new URL(serverPath);
       
-      if ("xml".equals(context.getResolvedEntityAttribute(FORMAT))) {
-        solrServer = new CommonsHttpSolrServer(url, client,
-            new XMLResponseParser(), false);
+      HttpClient client = getHttpClient();
+      URL url = new URL(serverPath);
+      // (wt="javabin|xml") default is javabin
+      if ("xml".equals(context.getResolvedEntityAttribute(CommonParams.WT))) {
+        solrServer = new CommonsHttpSolrServer(url, client, new XMLResponseParser(), false);
         LOG.info("using XMLResponseParser");
       } else {
         solrServer = new CommonsHttpSolrServer(url, client);
         LOG.info("using BinaryResponseParser");
       }
-      
     } catch (MalformedURLException e) {
       throw new DataImportHandlerException(DataImportHandlerException.SEVERE, e);
     }
@@ -115,21 +119,21 @@ protected void firstInit(Context context) {
       );
     }
     
-    String rowsP = context.getResolvedEntityAttribute(ROWS);
+    String rowsP = context.getResolvedEntityAttribute(CommonParams.ROWS);
     if (rowsP != null) {
       rows = Integer.parseInt(rowsP);
     }
     
-    String fqAsString = context.getResolvedEntityAttribute(FQ);
+    String fqAsString = context.getResolvedEntityAttribute(CommonParams.FQ);
     if (fqAsString != null) {
       this.filterQueries = fqAsString.split(",");
     }
     
-    String fieldsAsString = context.getResolvedEntityAttribute(FIELDS);
+    String fieldsAsString = context.getResolvedEntityAttribute(CommonParams.FL);
     if (fieldsAsString != null) {
       this.fields = fieldsAsString.split(",");
     }
-    
+    this.queryType = context.getResolvedEntityAttribute(CommonParams.QT);
     String timeoutAsString = context.getResolvedEntityAttribute(TIMEOUT);
     if (timeoutAsString != null) {
       this.timeout = Integer.parseInt(timeoutAsString);
@@ -182,6 +186,7 @@ protected SolrDocumentList doQuery(int start) {
         solrQuery.addField(field);
       }
     }
+    solrQuery.setQueryType(queryType);
     solrQuery.setFilterQueries(filterQueries);
     solrQuery.setTimeAllowed(timeout * 1000);
     
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSolrEntityProcessorEndToEnd.java b/lucene/dev/branches/solr_3159_jetty8/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSolrEntityProcessorEndToEnd.java
index dbd7df08..89b95c89 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSolrEntityProcessorEndToEnd.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSolrEntityProcessorEndToEnd.java
@@ -145,7 +145,7 @@ public void testFullImport() {
     
     try {
       addDocumentsToSolr(SOLR_DOCS);
-      runFullImport(generateDIHConfig("query='*:*' rows='2' fields='id,desc' onError='skip'", jetty.getLocalPort()));
+      runFullImport(generateDIHConfig("query='*:*' rows='2' fl='id,desc' onError='skip'", jetty.getLocalPort()));
     } catch (Exception e) {
       LOG.error(e.getMessage(), e);
       fail(e.getMessage());
@@ -178,7 +178,7 @@ public void testFullImportFieldsParam() {
     
     try {
       addDocumentsToSolr(generateSolrDocuments(7));
-      runFullImport(generateDIHConfig("query='*:*' fields='id' rows='2'", jetty.getLocalPort()));
+      runFullImport(generateDIHConfig("query='*:*' fl='id' rows='2'", jetty.getLocalPort()));
     } catch (Exception e) {
       LOG.error(e.getMessage(), e);
       fail(e.getMessage());
@@ -231,7 +231,7 @@ public void testFullImportWrongSolrUrl() {
     assertQ(req("*:*"), "//result[@numFound='0']");
     
     try {
-      runFullImport(generateDIHConfig("query='*:*' rows='2' fields='id,desc' onError='skip'", jetty.getLocalPort()));
+      runFullImport(generateDIHConfig("query='*:*' rows='2' fl='id,desc' onError='skip'", jetty.getLocalPort()));
     } catch (Exception e) {
       LOG.error(e.getMessage(), e);
       fail(e.getMessage());
@@ -244,7 +244,7 @@ public void testFullImportBadConfig() {
     assertQ(req("*:*"), "//result[@numFound='0']");
     
     try {
-      runFullImport(generateDIHConfig("query='bogus:3' rows='2' fields='id,desc' onError='abort'", jetty.getLocalPort()));
+      runFullImport(generateDIHConfig("query='bogus:3' rows='2' fl='id,desc' onError='abort'", jetty.getLocalPort()));
     } catch (Exception e) {
       LOG.error(e.getMessage(), e);
       fail(e.getMessage());
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java
index 1ccf0acc..3c5c9097 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java
@@ -155,6 +155,9 @@ public EmbeddedSolrServer(  CoreContainer coreContainer, String coreName )
       
       core.execute( handler, req, rsp );
       if( rsp.getException() != null ) {
+        if(rsp.getException() instanceof SolrException) {
+          throw rsp.getException();
+        }
         throw new SolrServerException( rsp.getException() );
       }
       
@@ -219,6 +222,9 @@ public void writeSolrDocumentList(SolrDocumentList docs) throws IOException {
     catch( IOException iox ) {
       throw iox;
     }
+    catch( SolrException sx ) {
+      throw sx;
+    }
     catch( Exception ex ) {
       throw new SolrServerException( ex );
     }
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java
index 859a44a3..9c80ea6c 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/handler/ReplicationHandler.java
@@ -642,6 +642,7 @@ public NamedList getStatistics() {
       addVal(slave, SnapPuller.REPLICATION_FAILED_AT, props, Date.class);
       addVal(slave, SnapPuller.PREVIOUS_CYCLE_TIME_TAKEN, props, Long.class);
 
+      slave.add("currentDate", new Date().toString());
       slave.add("isPollingDisabled", String.valueOf(isPollingDisabled()));
       boolean isReplicating = isReplicating();
       slave.add("isReplicating", String.valueOf(isReplicating));
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java
index bf0dabdc..3941f06c 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java
@@ -49,6 +49,7 @@
 import org.apache.solr.common.cloud.ZkNodeProps;
 import org.apache.solr.common.cloud.ZkStateReader;
 import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.util.FastWriter;
 import org.apache.solr.common.util.ContentStreamBase;
 import org.apache.solr.core.*;
@@ -134,13 +135,13 @@ public void doFilter(ServletRequest request, ServletResponse response, FilterCha
       return;
     }
     CoreContainer cores = this.cores;
+    SolrCore core = null;
+    SolrQueryRequest solrReq = null;
     
     if( request instanceof HttpServletRequest) {
       HttpServletRequest req = (HttpServletRequest)request;
       HttpServletResponse resp = (HttpServletResponse)response;
       SolrRequestHandler handler = null;
-      SolrQueryRequest solrReq = null;
-      SolrCore core = null;
       String corename = "";
       try {
         // put the core container in request attribute
@@ -269,21 +270,11 @@ public void doFilter(ServletRequest request, ServletResponse response, FilterCha
             }
             return; // we are done with a valid handler
           }
-          // otherwise (we have a core), let's ensure the core is in the SolrCore request attribute so
-          // a servlet/jsp can retrieve it
-          else {
-            req.setAttribute("org.apache.solr.SolrCore", core);
-            // Modify the request so each core gets its own /admin
-            if( path.startsWith( "/admin" ) ) {
-              req.getRequestDispatcher( pathPrefix == null ? path : pathPrefix + path ).forward( request, response );
-              return;
-            }
-          }
         }
         log.debug("no handler or core retrieved for " + path + ", follow through...");
       } 
       catch (Throwable ex) {
-        sendError( (HttpServletResponse)response, ex );
+        sendError( core, solrReq, request, (HttpServletResponse)response, ex );
         return;
       } 
       finally {
@@ -372,14 +363,19 @@ private void handleAdminRequest(HttpServletRequest req, ServletResponse response
   private void writeResponse(SolrQueryResponse solrRsp, ServletResponse response,
                              QueryResponseWriter responseWriter, SolrQueryRequest solrReq, Method reqMethod)
           throws IOException {
-    if (solrRsp.getException() != null) {
-      sendError((HttpServletResponse) response, solrRsp.getException());
-    } else {
+
       // Now write it out
       final String ct = responseWriter.getContentType(solrReq, solrRsp);
       // don't call setContentType on null
       if (null != ct) response.setContentType(ct); 
 
+    if (solrRsp.getException() != null) {
+      NamedList info = new SimpleOrderedMap();
+      int code = getErrorInfo(solrRsp.getException(),info);
+      solrRsp.add("error", info);
+      ((HttpServletResponse) response).setStatus(code);
+    }
+    
       if (Method.HEAD != reqMethod) {
         if (responseWriter instanceof BinaryQueryResponseWriter) {
           BinaryQueryResponseWriter binWriter = (BinaryQueryResponseWriter) responseWriter;
@@ -396,19 +392,9 @@ private void writeResponse(SolrQueryResponse solrRsp, ServletResponse response,
       }
       //else http HEAD request, nothing to write out, waited this long just to get ContentType
     }
-  }
 
-  protected void execute( HttpServletRequest req, SolrRequestHandler handler, SolrQueryRequest sreq, SolrQueryResponse rsp) {
-    // a custom filter could add more stuff to the request before passing it on.
-    // for example: sreq.getContext().put( "HttpServletRequest", req );
-    // used for logging query stats in SolrCore.execute()
-    sreq.getContext().put( "webapp", req.getContextPath() );
-    sreq.getCore().execute( handler, sreq, rsp );
-  }
-
-  protected void sendError(HttpServletResponse res, Throwable ex) throws IOException {
+  protected int getErrorInfo(Throwable ex, NamedList info) {
     int code=500;
-    String trace = "";
     if( ex instanceof SolrException ) {
       code = ((SolrException)ex).code();
     }
@@ -418,14 +404,16 @@ protected void sendError(HttpServletResponse res, Throwable ex) throws IOExcepti
       msg = th.getMessage();
       if (msg != null) break;
     }
+    if(msg != null) {
+      info.add("msg", msg);
+    }
 
     // For any regular code, don't include the stack trace
     if( code == 500 || code < 100 ) {
       StringWriter sw = new StringWriter();
       ex.printStackTrace(new PrintWriter(sw));
-      trace = "\n\n"+sw.toString();
-
       SolrException.log(log, null, ex);
+      info.add("trace", sw.toString());
 
       // non standard codes have undefined results with various servers
       if( code < 100 ) {
@@ -433,8 +421,45 @@ protected void sendError(HttpServletResponse res, Throwable ex) throws IOExcepti
         code = 500;
       }
     }
+    info.add("code", new Integer(code));
+    return code;
+  }
 
-    res.sendError( code, msg + trace );
+  protected void execute( HttpServletRequest req, SolrRequestHandler handler, SolrQueryRequest sreq, SolrQueryResponse rsp) {
+    // a custom filter could add more stuff to the request before passing it on.
+    // for example: sreq.getContext().put( "HttpServletRequest", req );
+    // used for logging query stats in SolrCore.execute()
+    sreq.getContext().put( "webapp", req.getContextPath() );
+    sreq.getCore().execute( handler, sreq, rsp );
+  }
+
+  protected void sendError(SolrCore core, 
+      SolrQueryRequest req, 
+      ServletRequest request, 
+      HttpServletResponse response, 
+      Throwable ex) throws IOException {
+    try {
+      SolrQueryResponse solrResp = new SolrQueryResponse();
+      if(ex instanceof Exception) {
+        solrResp.setException((Exception)ex);
+      }
+      else {
+        solrResp.setException(new RuntimeException(ex));
+      }
+      if(core==null) {
+        core = cores.getCore(""); // default core
+      }
+      if(req==null) {
+        req = new SolrQueryRequestBase(core,new ServletSolrParams(request)) {};
+      }
+      QueryResponseWriter writer = core.getQueryResponseWriter(req);
+      writeResponse(solrResp, response, writer, req, Method.GET);
+    }
+    catch( Throwable t ) { // This error really does not matter
+      SimpleOrderedMap info = new SimpleOrderedMap();
+      int code=getErrorInfo(ex, info);
+      response.sendError( code, info.toString() );
+    }
   }
 
   //---------------------------------------------------------------------
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/servlet/ZookeeperInfoServlet.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/servlet/ZookeeperInfoServlet.java
index ab29c1f6..66b9ff05 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/servlet/ZookeeperInfoServlet.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/servlet/ZookeeperInfoServlet.java
@@ -17,11 +17,11 @@
 
 package org.apache.solr.servlet;
 
+import org.apache.lucene.util.BytesRef;
 import org.apache.noggit.CharArr;
 import org.apache.noggit.JSONWriter;
 import org.apache.solr.cloud.ZkController;
 import org.apache.solr.common.cloud.SolrZkClient;
-import org.apache.solr.common.util.StrUtils;
 import org.apache.solr.core.CoreContainer;
 import org.apache.zookeeper.KeeperException;
 import org.apache.zookeeper.data.Stat;
@@ -34,7 +34,6 @@
 import javax.servlet.http.HttpServletResponse;
 import java.io.IOException;
 import java.io.PrintWriter;
-import java.io.UnsupportedEncodingException;
 import java.net.URLEncoder;
 import java.util.Date;
 import java.util.List;
@@ -72,11 +71,16 @@ public void doGet(HttpServletRequest request,
 
     String detailS = request.getParameter("detail");
     boolean detail = detailS != null && detailS.equals("true");
+
+    String dumpS = request.getParameter("dump");
+    boolean dump = dumpS != null && dumpS.equals("true");
+
     PrintWriter out = response.getWriter();
 
 
     ZKPrinter printer = new ZKPrinter(response, out, cores.getZkController(), addr);
     printer.detail = detail;
+    printer.dump = dump;
 
     try {
       printer.print(path);
@@ -103,6 +107,7 @@ public void doPost(HttpServletRequest request,
     boolean indent = true;
     boolean fullpath = FULLPATH_DEFAULT;
     boolean detail = false;
+    boolean dump = false;
 
     String addr; // the address passed to us
     String keeperAddr; // the address we're connected to
@@ -260,6 +265,7 @@ boolean printTree(JSONWriter json, String path) throws IOException {
 
       Stat stat = new Stat();
       try {
+        // Trickily, the call to zkClient.getData fills in the stat variable
         byte[] data = zkClient.getData(path, null, stat, true);
 
         if (stat.getEphemeralOwner() != 0) {
@@ -267,6 +273,11 @@ boolean printTree(JSONWriter json, String path) throws IOException {
           writeKeyValue(json, "version", stat.getVersion(), false);
         }
 
+        if (dump) {
+          json.writeValueSeparator();
+          printZnode(json, path);
+        }
+
         /*
         if (stat.getNumChildren() != 0)
         {
@@ -275,32 +286,12 @@ boolean printTree(JSONWriter json, String path) throws IOException {
         }
         */
 
-        //if (data != null)
-        if (stat.getDataLength() != 0) {
-          String str;
-          try {
-            str = new String(data, "UTF-8");
-            str = str.replaceAll("\\\"", "\\\\\"");
-
-            //writeKeyValue(json, "content", str, false );
-          } catch (UnsupportedEncodingException e) {
-            // not UTF8
-            StringBuilder sb = new StringBuilder("BIN(");
-            sb.append("len=" + data.length);
-            sb.append("hex=");
-            int limit = Math.min(data.length, maxData / 2);
-            for (int i = 0; i < limit; i++) {
-              byte b = data[i];
-              sb.append(StrUtils.HEX_DIGITS[(b >> 4) & 0xf]);
-              sb.append(StrUtils.HEX_DIGITS[b & 0xf]);
-            }
-            if (limit != data.length) {
-              sb.append("...");
-            }
-            sb.append(")");
-            str = sb.toString();
+        //if (stat.getDataLength() != 0)
+        if (data != null) {
+          String str = new BytesRef(data).utf8ToString();
             //?? writeKeyValue(json, "content", str, false );
-          }
+          // Does nothing now, but on the assumption this will be used later we'll leave it in. If it comes out
+          // the catches below need to be restructured.
         }
       } catch (IllegalArgumentException e) {
         // path doesn't exist (must have been removed)
@@ -375,6 +366,7 @@ public void writeKeyValue(JSONWriter json, String k, Object v, boolean isFirst)
     boolean printZnode(JSONWriter json, String path) throws IOException {
       try {
         Stat stat = new Stat();
+        // Trickily, the call to zkClient.getData fills in the stat variable
         byte[] data = zkClient.getData(path, null, stat, true);
 
         json.writeString("znode");
@@ -400,28 +392,8 @@ boolean printZnode(JSONWriter json, String path) throws IOException {
         writeKeyValue(json, "pzxid", stat.getPzxid(), false);
         json.endObject();
 
-        if (stat.getDataLength() != 0) {
-          String str;
-          try {
-            str = new String(data, "UTF-8");
-          } catch (UnsupportedEncodingException e) {
-            // The results are unspecified
-            // when the bytes are not properly encoded.
-
-            // not UTF8
-            StringBuilder sb = new StringBuilder(data.length * 2);
-            for (int i = 0; i < data.length; i++) {
-              byte b = data[i];
-              sb.append(StrUtils.HEX_DIGITS[(b >> 4) & 0xf]);
-              sb.append(StrUtils.HEX_DIGITS[b & 0xf]);
-              if ((i & 0x3f) == 0x3f) {
-                sb.append("\n");
-              }
-            }
-            str = sb.toString();
-          }
-          str = str.replaceAll("\\\"", "\\\\\"");
-          writeKeyValue(json, "data", str, false);
+        if (data != null) {
+          writeKeyValue(json, "data", new BytesRef(data).utf8ToString(), false);
         }
         json.endObject();
       } catch (KeeperException e) {
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/LookupFactory.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/LookupFactory.java
index cd24fa7f..d6212959 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/LookupFactory.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/LookupFactory.java
@@ -26,4 +26,5 @@
  */
 public abstract class LookupFactory {
   public abstract Lookup create(NamedList params, SolrCore core);
+  public abstract String storeFileName();
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/Suggester.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/Suggester.java
index 525ce3b9..d5f4775e 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/Suggester.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/Suggester.java
@@ -18,6 +18,8 @@
 package org.apache.solr.spelling.suggest;
 
 import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStreamReader;
 import java.io.UnsupportedEncodingException;
@@ -74,6 +76,8 @@
   protected String lookupImpl;
   protected SolrCore core;
   
+  private LookupFactory factory;
+  
   @Override
   public String init(NamedList config, SolrCore core) {
     LOG.info("init: " + config);
@@ -92,7 +96,8 @@ public String init(NamedList config, SolrCore core) {
       lookupImpl = FSTLookupFactory.class.getName();
     }
 
-    LookupFactory factory = (LookupFactory) core.getResourceLoader().newInstance(lookupImpl);
+    factory = (LookupFactory) core.getResourceLoader().newInstance(lookupImpl);
+    
     lookup = factory.create(config, core);
     String store = (String)config.get(STORE_DIR);
     if (store != null) {
@@ -105,7 +110,7 @@ public String init(NamedList config, SolrCore core) {
       } else {
         // attempt reload of the stored lookup
         try {
-          lookup.load(storeDir);
+          lookup.load(new FileInputStream(new File(storeDir, factory.storeFileName())));
         } catch (IOException e) {
           LOG.warn("Loading stored lookup data failed", e);
         }
@@ -132,8 +137,19 @@ public void build(SolrCore core, SolrIndexSearcher searcher) {
     try {
       lookup.build(dictionary);
       if (storeDir != null) {
-        lookup.store(storeDir);
+        File target = new File(storeDir, factory.storeFileName());
+        if(!lookup.store(new FileOutputStream(target))) {
+          if (sourceLocation == null) {
+            assert reader != null && field != null;
+            LOG.error("Store Lookup build from index on field: " + field + " failed reader has: " + reader.maxDoc() + " docs");
+          } else {
+            LOG.error("Store Lookup build from sourceloaction: " + sourceLocation + " failed");
+      }
+        } else {
+          LOG.info("Stored suggest data to: " + target.getAbsolutePath());
+        }
       }
+
     } catch (Exception e) {
       LOG.error("Error while building or storing Suggester data", e);
     }
@@ -144,7 +160,7 @@ public void reload(SolrCore core, SolrIndexSearcher searcher) throws IOException
     LOG.info("reload()");
     if (dictionary == null && storeDir != null) {
       // this may be a firstSearcher event, try loading it
-      if (lookup.load(storeDir)) {
+      if (lookup.load(new FileInputStream(new File(storeDir, factory.storeFileName())))) {
         return;  // loaded ok
       }
       LOG.debug("load failed, need to build Lookup again");
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/fst/FSTLookupFactory.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/fst/FSTLookupFactory.java
index ed7d86e2..b32af8ee 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/fst/FSTLookupFactory.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/fst/FSTLookupFactory.java
@@ -18,7 +18,7 @@
  */
 
 import org.apache.lucene.search.suggest.Lookup;
-import org.apache.lucene.search.suggest.fst.*;
+import org.apache.lucene.search.suggest.fst.FSTCompletionLookup;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.core.SolrCore;
 import org.apache.solr.spelling.suggest.LookupFactory;
@@ -27,6 +27,12 @@
  * Factory for {@link FSTCompletionLookup}
  */
 public class FSTLookupFactory extends LookupFactory {
+  
+  /**
+   * File name for the automaton.
+   */
+  private static final String FILENAME = "fst.bin";
+  
   /**
    * The number of separate buckets for weights (discretization). The more buckets,
    * the more fine-grained term weights (priorities) can be assigned. The speed of lookup
@@ -56,4 +62,9 @@ public Lookup create(NamedList params, SolrCore core) {
 
     return new FSTCompletionLookup(buckets, exactMatchFirst);
   }
+
+  @Override
+  public String storeFileName() {
+    return FILENAME;
+  }
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/fst/WFSTLookupFactory.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/fst/WFSTLookupFactory.java
index 233fe1e3..9cf54889 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/fst/WFSTLookupFactory.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/fst/WFSTLookupFactory.java
@@ -17,6 +17,8 @@
  * limitations under the License.
  */
 
+import java.io.File;
+
 import org.apache.lucene.search.suggest.Lookup;
 import org.apache.lucene.search.suggest.fst.*;
 import org.apache.solr.common.util.NamedList;
@@ -34,6 +36,12 @@
    */
   public static final String EXACT_MATCH_FIRST = "exactMatchFirst";
 
+  /**
+   * File name for the automaton.
+   * 
+   */
+  private static final String FILENAME = "wfst.bin";
+
   @Override
   public Lookup create(NamedList params, SolrCore core) {
     boolean exactMatchFirst = params.get(EXACT_MATCH_FIRST) != null
@@ -42,4 +50,9 @@ public Lookup create(NamedList params, SolrCore core) {
 
     return new WFSTCompletionLookup(exactMatchFirst);
   }
+
+  @Override
+  public String storeFileName() {
+    return FILENAME;
+  }
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/jaspell/JaspellLookupFactory.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/jaspell/JaspellLookupFactory.java
index 720d9593..94a7f7a6 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/jaspell/JaspellLookupFactory.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/jaspell/JaspellLookupFactory.java
@@ -30,10 +30,16 @@
  */
 public class JaspellLookupFactory extends LookupFactory {
   private static final Logger LOG = LoggerFactory.getLogger(JaspellLookup.class);
+  private static final String FILENAME = "jaspell.dat";
 
   @Override
   public Lookup create(NamedList params, SolrCore core) {
     LOG.info("init: " + params);
     return new JaspellLookup();
   }
+
+  @Override
+  public String storeFileName() {
+    return FILENAME;
+  }
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/tst/TSTLookupFactory.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/tst/TSTLookupFactory.java
index 37e7e4b7..a5aa8ab2 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/tst/TSTLookupFactory.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/spelling/suggest/tst/TSTLookupFactory.java
@@ -27,9 +27,15 @@
  * Factory for {@link TSTLookup}
  */
 public class TSTLookupFactory extends LookupFactory {
+  private static final String FILENAME = "tst.dat";
 
   @Override
   public Lookup create(NamedList params, SolrCore core) {
     return new TSTLookup();
   }
+
+  @Override
+  public String storeFileName() {
+    return FILENAME;
+  }
 }
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/update/UpdateLog.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/update/UpdateLog.java
index d8897ed9..b9c022fb 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/update/UpdateLog.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/java/org/apache/solr/update/UpdateLog.java
@@ -51,6 +51,9 @@
 
 /** @lucene.experimental */
 public class UpdateLog implements PluginInfoInitialized {
+  public static String LOG_FILENAME_PATTERN = "%s.%019d";
+  public static String TLOG_NAME="tlog";
+
   public static Logger log = LoggerFactory.getLogger(UpdateLog.class);
   public boolean debug = log.isDebugEnabled();
   public boolean trace = log.isTraceEnabled();
@@ -78,10 +81,6 @@ public String toString() {
     }
   }
 
-
-
-  public static String TLOG_NAME="tlog";
-
   long id = -1;
   private State state = State.ACTIVE;
 
@@ -617,7 +616,7 @@ public void finish(SyncLevel syncLevel) {
 
   private void ensureLog() {
     if (tlog == null) {
-      String newLogName = String.format(Locale.ENGLISH, "%s.%019d", TLOG_NAME, id);
+      String newLogName = String.format(Locale.ENGLISH, LOG_FILENAME_PATTERN, TLOG_NAME, id);
       try {
         tlog = new TransactionLog(new File(tlogDir, newLogName), globalStrings);
       } catch (IOException e) {
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/test/org/apache/solr/search/TestRecovery.java b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/test/org/apache/solr/search/TestRecovery.java
index c2454914..92d69b46 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/core/src/test/org/apache/solr/search/TestRecovery.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/core/src/test/org/apache/solr/search/TestRecovery.java
@@ -786,7 +786,11 @@ public void run() {
       findReplace("CCCCCC".getBytes("UTF-8"), "cccccc".getBytes("UTF-8"), content);
 
       // WARNING... assumes format of .00000n where n is less than 9
-      String fname2 = fname.substring(0, fname.length()-1) + (char)(fname.charAt(fname.length()-1)+1);
+      long logNumber = Long.parseLong(fname.substring(fname.lastIndexOf(".") + 1));
+      String fname2 = String.format(Locale.ENGLISH, 
+          UpdateLog.LOG_FILENAME_PATTERN,
+          UpdateLog.TLOG_NAME,
+          logNumber + 1);
       raf = new RandomAccessFile(new File(logDir, fname2), "rw");
       raf.write(content);
       raf.close();
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CommonsHttpSolrServer.java b/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CommonsHttpSolrServer.java
index 8bca39e9..a5ea9ad6 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CommonsHttpSolrServer.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CommonsHttpSolrServer.java
@@ -423,17 +423,7 @@ public void writeRequest(OutputStream outputStream) throws IOException {
     try {
       // Execute the method.
       //System.out.println( "EXECUTE:"+method.getURI() );
-
       int statusCode = _httpClient.executeMethod(method);
-      if (statusCode != HttpStatus.SC_OK) {
-        StringBuilder msg = new StringBuilder();
-        msg.append( method.getStatusLine().getReasonPhrase() );
-        msg.append( "\n\n" );
-        msg.append( method.getStatusText() );
-        msg.append( "\n\n" );
-        msg.append( "request: "+method.getURI() );
-        throw new SolrException(SolrException.ErrorCode.getErrorCode(statusCode), java.net.URLDecoder.decode(msg.toString(), "UTF-8") );
-      }
 
       // Read the contents
       String charset = "UTF-8";
@@ -474,7 +464,30 @@ else if ( contentType.startsWith("application/x-deflate") ) {
           }
         }
       }
-      return processor.processResponse(respBody, charset);
+      
+      NamedList<Object> rsp = processor.processResponse(respBody, charset);
+      if (statusCode != HttpStatus.SC_OK) {
+        String reason = null;
+        try {
+          NamedList err = (NamedList)rsp.get("error");
+          if(err!=null) {
+            reason = (String)err.get("msg");
+            // TODO? get the trace?
+    }
+        }
+        catch(Exception ex) {}
+        if(reason == null) {
+          StringBuilder msg = new StringBuilder();
+          msg.append( method.getStatusLine().getReasonPhrase() );
+          msg.append( "\n\n" );
+          msg.append( method.getStatusText() );
+          msg.append( "\n\n" );
+          msg.append( "request: "+method.getURI() );
+          reason = java.net.URLDecoder.decode(msg.toString(), "UTF-8");
+        }
+        throw new SolrException(SolrException.ErrorCode.getErrorCode(statusCode), reason );
+      }
+      return rsp;
     }
     catch (HttpException e) {
       throw new SolrServerException(getBaseURL(), e);
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/client/solrj/request/QueryRequest.java b/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/client/solrj/request/QueryRequest.java
index d75022a6..c788c939 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/client/solrj/request/QueryRequest.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/client/solrj/request/QueryRequest.java
@@ -23,6 +23,7 @@
 import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.QueryResponse;
+import org.apache.solr.common.SolrException;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.util.ContentStream;
@@ -93,6 +94,8 @@ public QueryResponse process( SolrServer server ) throws SolrServerException
       return res;
     } catch (SolrServerException e){
       throw e;
+    } catch (SolrException s){
+      throw s;
     } catch (Exception e) {
       throw new SolrServerException("Error executing query", e);
     }
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/common/SolrException.java b/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/common/SolrException.java
index 533394d5..16a8c9db 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/common/SolrException.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/java/org/apache/solr/common/SolrException.java
@@ -56,7 +56,8 @@ public static ErrorCode getErrorCode(int c){
   };
 
   public SolrException(ErrorCode code, String msg) {
-    this(code, msg, null);
+    super(msg);
+    this.code = code.code;
   }
   public SolrException(ErrorCode code, String msg, Throwable th) {
     super(msg, th);
@@ -64,7 +65,8 @@ public SolrException(ErrorCode code, String msg, Throwable th) {
   }
 
   public SolrException(ErrorCode code, Throwable th) {
-    this(code, null, th);
+    super(th);
+    this.code = code.code;
   }
   
   int code=0;
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java b/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
index efa04659..b3c9515a 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
@@ -49,9 +49,11 @@
 import org.apache.solr.client.solrj.util.ClientUtils;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.util.XML;
 import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.params.AnalysisParams;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.FacetParams;
 import org.junit.Test;
@@ -464,6 +466,42 @@ public void testCommitWithinOnDelete() throws Exception
     Assert.fail("commitWithin failed to commit");
   }
 
+  @Test
+  public void testErrorHandling() throws Exception
+  {    
+    SolrServer server = getSolrServer();
+
+    SolrQuery query = new SolrQuery();
+    query.set(CommonParams.QT, "/analysis/field");
+    query.set(AnalysisParams.FIELD_TYPE, "int");
+    query.set(AnalysisParams.FIELD_VALUE, "hello");
+    try {
+      server.query( query );
+      Assert.fail("should have a number format exception");
+    }
+    catch(SolrException ex) {
+      assertEquals(400, ex.code());
+      assertEquals("Invalid Number: hello", ex.getMessage());  // The reason should get passed through
+    }
+    catch(Throwable t) {
+      t.printStackTrace();
+      Assert.fail("should have thrown a SolrException! not: "+t);
+    }
+    
+    try {
+      server.deleteByQuery( "??::??" ); // query syntax error
+      Assert.fail("should have a number format exception");
+    }
+    catch(SolrException ex) {
+      assertEquals(400, ex.code());
+      assertTrue(ex.getMessage().indexOf("??::??")>0);  // The reason should get passed through
+    }
+    catch(Throwable t) {
+      t.printStackTrace();
+      Assert.fail("should have thrown a SolrException! not: "+t);
+    }
+  }
+
 
   @Test
   public void testAugmentFields() throws Exception
diff --git a/lucene/dev/branches/solr_3159_jetty8/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java b/lucene/dev/branches/solr_3159_jetty8/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
index 6ba879a2..135a424b 100644
--- a/lucene/dev/branches/solr_3159_jetty8/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
+++ b/lucene/dev/branches/solr_3159_jetty8/solr/test-framework/src/java/org/apache/solr/SolrTestCaseJ4.java
@@ -243,20 +243,11 @@ public static void resetExceptionIgnores() {
   }
 
   protected static String getClassName() {
-    StackTraceElement[] stack = new RuntimeException("WhoAmI").fillInStackTrace().getStackTrace();
-    for (int i = stack.length-1; i>=0; i--) {
-      StackTraceElement ste = stack[i];
-      String cname = ste.getClassName();
-      if (cname.indexOf(".lucene.")>=0 || cname.indexOf(".solr.")>=0) {
-        return cname;
-      }
-    }
-    return SolrTestCaseJ4.class.getName();
+    return getTestClass().getName();
   }
 
   protected static String getSimpleClassName() {
-    String cname = getClassName();
-    return cname.substring(cname.lastIndexOf('.')+1);
+    return getTestClass().getSimpleName();
   }
 
   protected static String configString;
