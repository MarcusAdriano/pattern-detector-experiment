diff --git a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java
index d3589cb1..3bed2c30 100644
--- a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java
+++ b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java
@@ -34,11 +34,6 @@
 {
     private static final Logger logger = LoggerFactory.getLogger(CompressedRandomAccessReader.class);
 
-    public static RandomAccessReader open(String dataFilePath, boolean skipIOCache) throws IOException
-    {
-        return open(dataFilePath, CompressionMetadata.get(dataFilePath), skipIOCache);
-    }
-
     public static RandomAccessReader open(String dataFilePath, CompressionMetadata metadata) throws IOException
     {
         return open(dataFilePath, metadata, false);
diff --git a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java
index a96eb765..064d2479 100644
--- a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java
+++ b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/compress/CompressionMetadata.java
@@ -21,7 +21,6 @@
 import java.io.*;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
 
 import org.apache.cassandra.config.ConfigurationException;
 import org.apache.cassandra.io.sstable.Component;
@@ -41,43 +40,23 @@
     public final CompressionParameters parameters;
 
     /**
-     * Caches instances of CompressionMetadata.
-     * Each metada holds the chunk offsets index, which is reasonably big for
-     * enough data, so it's an expensive structure. We thus only want one
-     * CompressionMetadata created for each sstable.
-     * Note that we could have a compressionMetadata field in SSTableReader,
-     * but CompressedSegmentFile.Builder needs it before the reader is
-     * created, so it's easier that way.
-     */
-    private final static Map<String, CompressionMetadata> cache = new ConcurrentHashMap<String, CompressionMetadata>();
-
-    /**
-     * Get metadata about given compressed file including uncompressed data length, chunk size
+     * Create metadata about given compressed file including uncompressed data length, chunk size
      * and list of the chunk offsets of the compressed data.
      *
+     * This is an expensive operation! Don't create more than one for each
+     * sstable.
+     *
      * @param dataFilePath Path to the compressed file
      *
      * @return metadata about given compressed file.
      */
-    public static CompressionMetadata get(String dataFilePath)
+    public static CompressionMetadata create(String dataFilePath)
     {
-        CompressionMetadata metadata = cache.get(dataFilePath);
-        if (metadata != null)
-            return metadata;
-
-        // We want this to be relatively fast, because it's called often (for each
-        // range query). On the side, we don't care too much if the initial
-        // creation is no thread-safe, because we'll call this when the
-        // SSTableReader is loaded/created, so we're pretty sure there won't
-        // be any contention. Besides, if we really do create two
-        // CompressionMetadata, it's not the end of the world, so we don't
-        // bother with synchronization
         Descriptor desc = Descriptor.fromFilename(dataFilePath);
+
         try
         {
-            metadata = new CompressionMetadata(desc.filenameFor(Component.COMPRESSION_INFO), new File(dataFilePath).length());
-            cache.put(dataFilePath, metadata);
-            return metadata;
+            return new CompressionMetadata(desc.filenameFor(Component.COMPRESSION_INFO), new File(dataFilePath).length());
         }
         catch (IOException e)
         {
@@ -85,7 +64,7 @@ public static CompressionMetadata get(String dataFilePath)
         }
     }
 
-    // This is package protected because of the tests. Don't use, use get() instead.
+    // This is package protected because of the tests.
     CompressionMetadata(String indexFilePath, long compressedLength) throws IOException
     {
         this.indexFilePath = indexFilePath;
diff --git a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/sstable/SSTableReader.java b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
index de58f8a2..bc01d784 100644
--- a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
+++ b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/sstable/SSTableReader.java
@@ -44,6 +44,7 @@
 import org.apache.cassandra.dht.AbstractBounds;
 import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.dht.Range;
+import org.apache.cassandra.io.compress.CompressionMetadata;
 import org.apache.cassandra.io.util.*;
 import org.apache.cassandra.service.StorageService;
 import org.apache.cassandra.utils.*;
@@ -312,7 +313,7 @@ private void load(boolean recreatebloom, Set<DecoratedKey> keysToLoadInCache) th
     {
         boolean cacheLoading = keyCache != null && !keysToLoadInCache.isEmpty();
         SegmentedFile.Builder ibuilder = SegmentedFile.getBuilder(DatabaseDescriptor.getIndexAccessMode());
-        SegmentedFile.Builder dbuilder = (components.contains(Component.COMPRESSION_INFO))
+        SegmentedFile.Builder dbuilder = compression
                                           ? SegmentedFile.getCompressedBuilder()
                                           : SegmentedFile.getBuilder(DatabaseDescriptor.getDiskAccessMode());
 
@@ -399,6 +400,18 @@ private void load(boolean recreatebloom, Set<DecoratedKey> keysToLoadInCache) th
         }
     }
 
+    /**
+     * Returns the compression metadata for this sstable.
+     * @throws IllegalStateException if the sstable is not compressed
+     */
+    public CompressionMetadata getCompressionMetadata()
+    {
+        if (!compression)
+            throw new IllegalStateException(this + " is not compressed");
+
+        return ((CompressedSegmentedFile)dfile).metadata;
+    }
+
     /**
      * For testing purposes only.
      */
@@ -894,7 +907,7 @@ public long getMaxTimestamp()
     public RandomAccessReader openDataReader(boolean skipIOCache) throws IOException
     {
         return compression
-               ? CompressedRandomAccessReader.open(getFilename(), skipIOCache)
+               ? CompressedRandomAccessReader.open(getFilename(), getCompressionMetadata(), skipIOCache)
                : RandomAccessReader.open(new File(getFilename()), skipIOCache);
     }
 
diff --git a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/util/CompressedSegmentedFile.java b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/util/CompressedSegmentedFile.java
index eadf7f21..9d1345ac 100644
--- a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/util/CompressedSegmentedFile.java
+++ b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/util/CompressedSegmentedFile.java
@@ -26,7 +26,7 @@
 
 public class CompressedSegmentedFile extends SegmentedFile
 {
-    private final CompressionMetadata metadata;
+    public final CompressionMetadata metadata;
 
     public CompressedSegmentedFile(String path, CompressionMetadata metadata)
     {
@@ -52,7 +52,7 @@ public void addPotentialBoundary(long boundary)
          */
         public SegmentedFile complete(String path)
         {
-            return new CompressedSegmentedFile(path, CompressionMetadata.get(path));
+            return new CompressedSegmentedFile(path, CompressionMetadata.create(path));
         }
     }
 
diff --git a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/util/SegmentedFile.java b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/util/SegmentedFile.java
index 602909fb..8a9682c6 100644
--- a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/util/SegmentedFile.java
+++ b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/io/util/SegmentedFile.java
@@ -26,6 +26,7 @@
 import java.util.NoSuchElementException;
 
 import org.apache.cassandra.config.Config;
+import org.apache.cassandra.io.compress.CompressionMetadata;
 import org.apache.cassandra.utils.Pair;
 
 /**
diff --git a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/streaming/FileStreamTask.java b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/streaming/FileStreamTask.java
index 7c97b29b..9411b164 100644
--- a/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/streaming/FileStreamTask.java
+++ b/cassandra/branches/cassandra-1.0/src/java/org/apache/cassandra/streaming/FileStreamTask.java
@@ -121,7 +121,7 @@ private void stream() throws IOException
 
         // TODO just use a raw RandomAccessFile since we're managing our own buffer here
         RandomAccessReader file = (header.file.sstable.compression) // try to skip kernel page cache if possible
-                                ? CompressedRandomAccessReader.open(header.file.getFilename(), true)
+                                ? CompressedRandomAccessReader.open(header.file.getFilename(), header.file.sstable.getCompressionMetadata(), true)
                                 : RandomAccessReader.open(new File(header.file.getFilename()), true);
 
         // setting up data compression stream
