diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/HashFactory.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/HashFactory.java
index 222335b1..d77c26d0 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/HashFactory.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/HashFactory.java
@@ -32,7 +32,7 @@ private HashFactory() {
 
   public static HashFunction[] createHashFunctions(HashType type, int numFunctions) {
     HashFunction[] hashFunction = new HashFunction[numFunctions];
-    Random seed = new Random(11);
+    Random seed = RandomUtils.getRandom(11);
     switch (type) {
       case LINEAR:
         for (int i = 0; i < numFunctions; i++) {
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/MinHashMapper.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/MinHashMapper.java
index 2a8ac50d..1e73b5dc 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/MinHashMapper.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/MinHashMapper.java
@@ -30,7 +30,7 @@
 
 import java.io.IOException;
 
-public class MinHashMapper extends Mapper<Text, Writable, Text, Writable> {
+public class MinHashMapper extends Mapper<Text,Writable,Text,Writable> {
 
   private static final Logger log = LoggerFactory.getLogger(MinHashMapper.class);
 
@@ -65,11 +65,11 @@ protected void setup(Context context) throws IOException,  InterruptedException
   }
 
   /**
-   * Hash all items with each function and retain min. value for each iteration.
-   * We up with X number of minhash signatures.
+   * Hash all items with each function and retain min. value for each iteration. We up with X number of
+   * minhash signatures.
    * 
-   * Now depending upon the number of key-groups (1 - 4) concatenate that many
-   * minhash values to form cluster-id as 'key' and item-id as 'value'
+   * Now depending upon the number of key-groups (1 - 4) concatenate that many minhash values to form
+   * cluster-id as 'key' and item-id as 'value'
    */
   @Override
   public void map(Text item, Writable features, Context context) throws IOException, InterruptedException {
@@ -81,6 +81,7 @@ public void map(Text item, Writable features, Context context) throws IOExceptio
     for (int i = 0; i < numHashFunctions; i++) {
       minHashValues[i] = Integer.MAX_VALUE;
     }
+    
     for (int i = 0; i < numHashFunctions; i++) {
       for (Vector.Element ele : featureVector) {
         int value = (int) ele.get();
@@ -95,10 +96,10 @@ public void map(Text item, Writable features, Context context) throws IOExceptio
       }
     }
     // output the cluster information
-    for (int i = 0; i < numHashFunctions; i += keyGroups) {
+    for (int i = 0; i < numHashFunctions; i++) {
       StringBuilder clusterIdBuilder = new StringBuilder();
-      for (int j = 0; j < keyGroups && (i + j) < numHashFunctions; j++) {
-        clusterIdBuilder.append(minHashValues[i + j]).append('-');
+      for (int j = 0; j < keyGroups; j++) {
+        clusterIdBuilder.append(minHashValues[(i + j) % numHashFunctions]).append('-');
       }
       String clusterId = clusterIdBuilder.toString();
       clusterId = clusterId.substring(0, clusterId.lastIndexOf('-'));
diff --git a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/MinHashReducer.java b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/MinHashReducer.java
index d010f34c..8e5229bf 100644
--- a/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/MinHashReducer.java
+++ b/mahout/trunk/core/src/main/java/org/apache/mahout/clustering/minhash/MinHashReducer.java
@@ -29,13 +29,14 @@
 import java.util.ArrayList;
 import java.util.Collection;
 
-public class MinHashReducer extends Reducer<Text, Writable, Text, Writable> {
+public class MinHashReducer extends Reducer<Text,Writable,Text,Writable> {
 
   private int minClusterSize;
   private boolean debugOutput;
 
   enum Clusters {
-    Accepted, Discarded
+    Accepted,
+    Discarded
   }
   
   @Override
@@ -50,8 +51,8 @@ protected void setup(Context context) throws IOException, InterruptedException {
    * output the items clustered
    */
   @Override
-  protected void reduce(Text cluster, Iterable<Writable> points, Context context)
-    throws IOException, InterruptedException {
+  protected void reduce(Text cluster, Iterable<Writable> points, Context context) throws IOException,
+                                                                                 InterruptedException {
     Collection<Writable> pointList = new ArrayList<Writable>();
     for (Writable point : points) {
       if (debugOutput) {
diff --git a/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/minhash/TestMinHashClustering.java b/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/minhash/TestMinHashClustering.java
index f1cb24bb..fe76a4cd 100644
--- a/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/minhash/TestMinHashClustering.java
+++ b/mahout/trunk/core/src/test/java/org/apache/mahout/clustering/minhash/TestMinHashClustering.java
@@ -41,10 +41,10 @@
 
 public class TestMinHashClustering extends MahoutTestCase {
 
-  public static final double[][] REFERENCE = { { 1, 2, 3, 4, 5 },
-      { 2, 1, 3, 6, 7 }, { 3, 7, 6, 11, 8, 9 }, { 4, 7, 8, 9, 6, 1 },
-      { 5, 8, 10, 4, 1 }, { 6, 17, 14, 15 }, { 8, 9, 11, 6, 12, 1, 7 },
-      { 10, 13, 9, 7, 4, 6, 3 }, { 3, 5, 7, 9, 2, 11 }, { 13, 7, 6, 8, 5 } };
+  public static final double[][] REFERENCE = { {1, 2, 3, 4, 5}, {2, 1, 3, 6, 7}, {3, 7, 6, 11, 8, 9},
+                                              {4, 7, 8, 9, 6, 1}, {5, 8, 10, 4, 1}, {6, 17, 14, 15},
+                                              {8, 9, 11, 6, 12, 1, 7}, {10, 13, 9, 7, 4, 6, 3},
+                                              {3, 5, 7, 9, 2, 11}, {13, 7, 6, 8, 5}};
 
   private FileSystem fs;
   private Path input;
@@ -69,7 +69,8 @@ public void setUp() throws Exception {
     input = getTestTempDirPath("points");
     output = new Path(getTestTempDirPath(), "output");
     Path pointFile = new Path(input, "file1");
-    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, pointFile, Text.class, VectorWritable.class);
+    SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, pointFile, Text.class,
+        VectorWritable.class);
     int id = 0;
     for (VectorWritable point : points) {
       writer.append(new Text("Id-" + id++), point);
@@ -81,9 +82,8 @@ public void setUp() throws Exception {
                                  int minVectorSize,
                                  int numHashFunctions,
                                  int keyGroups,
-                                 String hashType){
-    return new String[] {
-        optKey(DefaultOptionCreator.INPUT_OPTION), input.toString(),
+                                 String hashType) {
+    return new String[] {optKey(DefaultOptionCreator.INPUT_OPTION), input.toString(),
         optKey(DefaultOptionCreator.OUTPUT_OPTION), output.toString(),
         optKey(MinhashOptionCreator.MIN_CLUSTER_SIZE), String.valueOf(minClusterSize),
         optKey(MinhashOptionCreator.MIN_VECTOR_SIZE), String.valueOf(minVectorSize),
@@ -103,20 +103,8 @@ public void setUp() throws Exception {
     return values;
   }
 
-  private void verify(Path output) throws Exception {
-    Configuration conf = new Configuration();
-    Path outputFile = new Path(output, "part-r-00000");
-    SequenceFile.Reader reader = new SequenceFile.Reader(fs, outputFile, conf);
-    Writable clusterId = new Text();
-    VectorWritable point = new VectorWritable();
-    List<Vector> clusteredItems = new ArrayList<Vector>();
-    String prevClusterId = "";
-    while (reader.next(clusterId, point)) {
-      if (prevClusterId.equals(clusterId.toString())) {
-        clusteredItems.add(point.get().clone());
-      } else {
+  private void runPairwiseSimilarity(List<Vector> clusteredItems, double simThreshold, String msg) {
         if (clusteredItems.size() > 1) {
-          // run pair-wise similarity test on items in a cluster
           for (int i = 0; i < clusteredItems.size(); i++) {
             Set<Integer> itemSet1 = getValues(clusteredItems.get(i));
             for (int j = i + 1; j < clusteredItems.size(); j++) {
@@ -128,33 +116,48 @@ private void verify(Path output) throws Exception {
               intersect.addAll(itemSet1);
               intersect.retainAll(itemSet2);
               double similarity = intersect.size() / (double) union.size();
-              assertTrue("Sets failed min similarity test, Set1: "
-                  + itemSet1 + " Set2: " + itemSet2 + ", similarity:" + similarity, similarity > 0.4);
+          assertTrue(msg + " - Sets failed min similarity test, Set1: " + itemSet1 + " Set2: " + itemSet2
+                     + ", similarity:" + similarity, similarity >= simThreshold);
+        }
             }
           }
         }
+  
+  private void verify(Path output, double simThreshold, String msg) throws Exception {
+    Configuration conf = new Configuration();
+    Path outputFile = new Path(output, "part-r-00000");
+    SequenceFile.Reader reader = new SequenceFile.Reader(fs, outputFile, conf);
+    Writable clusterId = new Text();
+    VectorWritable point = new VectorWritable();
+    List<Vector> clusteredItems = new ArrayList<Vector>();
+    String prevClusterId = "";
+    while (reader.next(clusterId, point)) {
+      if (prevClusterId.equals(clusterId.toString())) {
+        clusteredItems.add(point.get().clone());
+      } else {
+        runPairwiseSimilarity(clusteredItems, simThreshold, msg);
         clusteredItems.clear();
         prevClusterId = clusterId.toString();
+        clusteredItems.add(point.get().clone());
       }
     }
+    runPairwiseSimilarity(clusteredItems, simThreshold, msg);
   }
 
   @Test
   public void testLinearMinHashMRJob() throws Exception {
-    String[] args = makeArguments(2, 3, 20, 4, HashType.LINEAR.toString());
+    String[] args = makeArguments(2, 3, 20, 3, HashType.LINEAR.toString());
     int ret = ToolRunner.run(new Configuration(), new MinHashDriver(), args);
     assertEquals("Minhash MR Job failed for " + HashType.LINEAR.toString(), 0, ret);
-    System.out.println("Verifying linear hash results");
-    verify(output);
+    verify(output, 0.2, "Hash Type: LINEAR");
   }
 
   @Test
   public void testPolynomialMinHashMRJob() throws Exception {
-    String[] args = makeArguments(2, 3, 20, 4, HashType.POLYNOMIAL.toString());
+    String[] args = makeArguments(2, 3, 20, 3, HashType.POLYNOMIAL.toString());
     int ret = ToolRunner.run(new Configuration(), new MinHashDriver(), args);
     assertEquals("Minhash MR Job failed for " + HashType.POLYNOMIAL.toString(), 0, ret);
-    System.out.println("Verifying linear hash results");
-    verify(output);
+    verify(output, 0.3, "Hash Type: POLYNOMIAL");
   }
 
   @Test
@@ -162,8 +165,7 @@ public void testMurmurMinHashMRJob() throws Exception {
     String[] args = makeArguments(2, 3, 20, 4, HashType.MURMUR.toString());
     int ret = ToolRunner.run(new Configuration(), new MinHashDriver(), args);
     assertEquals("Minhash MR Job failed for " + HashType.MURMUR.toString(), 0, ret);
-    System.out.println("verifying murmur hash results");
-    verify(output);
+    verify(output, 0.3, "Hash Type: MURMUR");
   }
 
 }
