diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilterFactory.java
index 27a29de5..914f824a 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilterFactory.java
@@ -49,30 +49,25 @@
   protected NormalizeCharMap normMap;
   private String mapping;
 
-  public void inform(ResourceLoader loader) {
-    mapping = args.get( "mapping" );
+  // TODO: this should use inputstreams from the loader, not File!
+  public void inform(ResourceLoader loader) throws IOException {
+    mapping = args.get("mapping");
 
-    if( mapping != null ){
+    if (mapping != null) {
       List<String> wlist = null;
-      try{
-        File mappingFile = new File( mapping );
-        if( mappingFile.exists() ){
-          wlist = loader.getLines( mapping );
-        }
-        else{
-          List<String> files = splitFileNames( mapping );
+      File mappingFile = new File(mapping);
+      if (mappingFile.exists()) {
+        wlist = loader.getLines(mapping);
+      } else {
+        List<String> files = splitFileNames(mapping);
           wlist = new ArrayList<String>();
-          for( String file : files ){
-            List<String> lines = loader.getLines( file.trim() );
-            wlist.addAll( lines );
-          }
-        }
+        for (String file : files) {
+          List<String> lines = loader.getLines(file.trim());
+          wlist.addAll(lines);
       }
-      catch( IOException e ){
-        throw new InitializationException("IOException thrown while loading mappings", e);
       }
       final NormalizeCharMap.Builder builder = new NormalizeCharMap.Builder();
-      parseRules( wlist, builder );
+      parseRules(wlist, builder);
       normMap = builder.build();
       if (normMap.map == null) {
         // if the inner FST is null, it means it accepts nothing (e.g. the file is empty)
@@ -95,7 +90,7 @@ protected void parseRules( List<String> rules, NormalizeCharMap.Builder builder
     for( String rule : rules ){
       Matcher m = p.matcher( rule );
       if( !m.find() )
-        throw new InitializationException("Invalid Mapping Rule : [" + rule + "], file = " + mapping);
+        throw new IllegalArgumentException("Invalid Mapping Rule : [" + rule + "], file = " + mapping);
       builder.add( parseString( m.group( 1 ) ), parseString( m.group( 2 ) ) );
     }
   }
@@ -110,7 +105,7 @@ protected String parseString( String s ){
       char c = s.charAt( readPos++ );
       if( c == '\\' ){
         if( readPos >= len )
-          throw new InitializationException("Invalid escaped char in [" + s + "]");
+          throw new IllegalArgumentException("Invalid escaped char in [" + s + "]");
         c = s.charAt( readPos++ );
         switch( c ) {
           case '\\' : c = '\\'; break;
@@ -122,7 +117,7 @@ protected String parseString( String s ){
           case 'f' : c = '\f'; break;
           case 'u' :
             if( readPos + 3 >= len )
-              throw new InitializationException("Invalid escaped char in [" + s + "]");
+              throw new IllegalArgumentException("Invalid escaped char in [" + s + "]");
             c = (char)Integer.parseInt( s.substring( readPos, readPos + 4 ), 16 );
             readPos += 4;
             break;
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java
index 1ab62911..a4f8da5e 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java
@@ -42,20 +42,16 @@
 public class CommonGramsFilterFactory extends TokenFilterFactory implements
     ResourceLoaderAware {
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String commonWordFiles = args.get("words");
     ignoreCase = getBoolean("ignoreCase", false);
 
     if (commonWordFiles != null) {
-      try {
         if ("snowball".equalsIgnoreCase(args.get("format"))) {
           commonWords = getSnowballWordSet(loader, commonWordFiles, ignoreCase);
         } else {
           commonWords = getWordSet(loader, commonWordFiles, ignoreCase);
         }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading common word file", e);
-      }
     } else {
       commonWords = StopAnalyzer.ENGLISH_STOP_WORDS_SET;
     }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilterFactory.java
index 23f00cf3..f0828e01 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilterFactory.java
@@ -50,20 +50,16 @@ public void init(Map<String,String> args) {
     assureMatchVersion();
   }
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String commonWordFiles = args.get("words");
     ignoreCase = getBoolean("ignoreCase", false);
 
     if (commonWordFiles != null) {
-      try {
         if ("snowball".equalsIgnoreCase(args.get("format"))) {
           commonWords = getSnowballWordSet(loader, commonWordFiles, ignoreCase);
         } else {
           commonWords = getWordSet(loader, commonWordFiles, ignoreCase);
         }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading common word file", e);
-      }
     } else {
       commonWords = StopAnalyzer.ENGLISH_STOP_WORDS_SET;
     }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java
index 8f69d01a..0ff2f25c 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java
@@ -48,7 +48,7 @@ public void init(Map<String, String> args) {
     assureMatchVersion();
     dictFile = args.get("dictionary");
     if (null == dictFile) {
-      throw new InitializationException("Missing required parameter: dictionary");
+      throw new IllegalArgumentException("Missing required parameter: dictionary");
     }
 
     minWordSize= getInt("minWordSize",CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE);
@@ -56,12 +56,8 @@ public void init(Map<String, String> args) {
     maxSubwordSize= getInt("maxSubwordSize",CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE);
     onlyLongestMatch = getBoolean("onlyLongestMatch",true);
   }
-  public void inform(ResourceLoader loader) {
-    try {
+  public void inform(ResourceLoader loader) throws IOException {
       dictionary = super.getWordSet(loader, dictFile, false);
-    } catch (IOException e) {
-      throw new InitializationException("IOException thrown while loading dictionary", e);
-    }
   }
   public TokenStream create(TokenStream input) {
     // if the dictionary is null, it means it was empty
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
index 518d652c..3716b290 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
@@ -18,6 +18,7 @@
  */
 
 import java.io.File;
+import java.io.IOException;
 
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
@@ -134,7 +135,7 @@ public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream inpu
    * @throws Exception
    */
   public static HyphenationTree getHyphenationTree(String hyphenationFilename)
-      throws Exception {
+      throws IOException {
     return getHyphenationTree(new InputSource(hyphenationFilename));
   }
 
@@ -146,7 +147,7 @@ public static HyphenationTree getHyphenationTree(String hyphenationFilename)
    * @throws Exception
    */
   public static HyphenationTree getHyphenationTree(File hyphenationFile)
-      throws Exception {
+      throws IOException {
     return getHyphenationTree(new InputSource(hyphenationFile.toURL().toExternalForm()));
   }
 
@@ -158,7 +159,7 @@ public static HyphenationTree getHyphenationTree(File hyphenationFile)
    * @throws Exception
    */
   public static HyphenationTree getHyphenationTree(InputSource hyphenationSource)
-      throws Exception {
+      throws IOException {
     HyphenationTree tree = new HyphenationTree();
     tree.loadPatterns(hyphenationSource);
     return tree;
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java
index d05a19ba..9b6585aa 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java
@@ -25,6 +25,7 @@
 import org.apache.lucene.util.IOUtils;
 
 import java.util.Map;
+import java.io.IOException;
 import java.io.InputStream;
 import org.xml.sax.InputSource;
 
@@ -75,7 +76,7 @@ public void init(Map<String, String> args) {
       encoding = args.get("encoding");
     hypFile = args.get("hyphenator");
     if (null == hypFile) {
-      throw new InitializationException("Missing required parameter: hyphenator");
+      throw new IllegalArgumentException("Missing required parameter: hyphenator");
     }
 
     minWordSize = getInt("minWordSize", CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE);
@@ -84,7 +85,7 @@ public void init(Map<String, String> args) {
     onlyLongestMatch = getBoolean("onlyLongestMatch", false);
   }
   
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     InputStream stream = null;
     try {
       if (dictFile != null) // the dictionary can be empty.
@@ -96,8 +97,6 @@ public void inform(ResourceLoader loader) {
       is.setEncoding(encoding); // if it's null let xml parser decide
       is.setSystemId(hypFile);
       hyphenator = HyphenationCompoundWordTokenFilter.getHyphenationTree(is);
-    } catch (Exception e) { // TODO: getHyphenationTree really shouldn't throw "Exception"
-      throw new InitializationException("Exception thrown while loading dictionary and hyphenation file", e);
     } finally {
       IOUtils.closeWhileHandlingException(stream);
     }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationException.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationException.java
index 39652447..e69de29b 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationException.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationException.java
@@ -1,32 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- * 
- *      http://www.apache.org/licenses/LICENSE-2.0
- * 
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.analysis.compound.hyphenation;
-
-/**
- * This class has been taken from the Apache FOP project (http://xmlgraphics.apache.org/fop/). They have been slightly modified. 
- */
-public class HyphenationException extends Exception {
-
-  /**
-   * @see java.lang.Throwable#Throwable(String)
-   */
-  public HyphenationException(String msg) {
-    super(msg);
-  }
-
-}
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationTree.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationTree.java
index 18f2f4dd..502a9b2b 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationTree.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/HyphenationTree.java
@@ -18,8 +18,8 @@
 package org.apache.lucene.analysis.compound.hyphenation;
 
 import java.io.File;
+import java.io.IOException;
 import java.io.PrintStream;
-import java.net.MalformedURLException;
 import java.util.ArrayList;
 import java.util.HashMap;
 
@@ -108,25 +108,20 @@ protected String unpackValues(int k) {
    * Read hyphenation patterns from an XML file.
    * 
    * @param f the filename
-   * @throws HyphenationException In case the parsing fails
+   * @throws IOException In case the parsing fails
    */
-  public void loadPatterns(File f) throws HyphenationException {
-    try {
+  public void loadPatterns(File f) throws IOException {
       InputSource src = new InputSource(f.toURL().toExternalForm());
       loadPatterns(src);
-    } catch (MalformedURLException e) {
-      throw new HyphenationException("Error converting the File '" + f
-          + "' to a URL: " + e.getMessage());
-    }
   }
 
   /**
    * Read hyphenation patterns from an XML file.
    * 
    * @param source the InputSource for the file
-   * @throws HyphenationException In case the parsing fails
+   * @throws IOException In case the parsing fails
    */
-  public void loadPatterns(InputSource source) throws HyphenationException {
+  public void loadPatterns(InputSource source) throws IOException {
     PatternParser pp = new PatternParser(this);
     ivalues = new TernaryTree();
 
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/PatternParser.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/PatternParser.java
index 44cbd7a2..66ad35b6 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/PatternParser.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/hyphenation/PatternParser.java
@@ -27,9 +27,7 @@
 
 // Java
 import java.io.File;
-import java.io.FileNotFoundException;
 import java.io.IOException;
-import java.net.MalformedURLException;
 import java.util.ArrayList;
 
 import javax.xml.parsers.SAXParserFactory;
@@ -87,9 +85,9 @@ public void setConsumer(PatternConsumer consumer) {
    * Parses a hyphenation pattern file.
    * 
    * @param filename the filename
-   * @throws HyphenationException In case of an exception while parsing
+   * @throws IOException In case of an exception while parsing
    */
-  public void parse(String filename) throws HyphenationException {
+  public void parse(String filename) throws IOException {
     parse(new InputSource(filename));
   }
 
@@ -97,33 +95,24 @@ public void parse(String filename) throws HyphenationException {
    * Parses a hyphenation pattern file.
    * 
    * @param file the pattern file
-   * @throws HyphenationException In case of an exception while parsing
+   * @throws IOException In case of an exception while parsing
    */
-  public void parse(File file) throws HyphenationException {
-    try {
+  public void parse(File file) throws IOException {
       InputSource src = new InputSource(file.toURL().toExternalForm());
       parse(src);
-    } catch (MalformedURLException e) {
-      throw new HyphenationException("Error converting the File '" + file
-          + "' to a URL: " + e.getMessage());
-    }
   }
 
   /**
    * Parses a hyphenation pattern file.
    * 
    * @param source the InputSource for the file
-   * @throws HyphenationException In case of an exception while parsing
+   * @throws IOException In case of an exception while parsing
    */
-  public void parse(InputSource source) throws HyphenationException {
+  public void parse(InputSource source) throws IOException {
     try {
       parser.parse(source);
-    } catch (FileNotFoundException fnfe) {
-      throw new HyphenationException("File not found: " + fnfe.getMessage());
-    } catch (IOException ioe) {
-      throw new HyphenationException(ioe.getMessage());
     } catch (SAXException e) {
-      throw new HyphenationException(errMsg);
+      throw new IOException(e);
     }
   }
 
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java
index 8118f7ce..fd5794b1 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java
@@ -46,21 +46,17 @@ public void init(Map<String,String> args) {
   }
 
   @Override
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String stopWordFiles = args.get("words");
     ignoreCase = getBoolean("ignoreCase",false);
     enablePositionIncrements = getBoolean("enablePositionIncrements",false);
 
     if (stopWordFiles != null) {
-      try {
         if ("snowball".equalsIgnoreCase(args.get("format"))) {
           stopWords = getSnowballWordSet(loader, stopWordFiles, ignoreCase);
         } else {
           stopWords = getWordSet(loader, stopWordFiles, ignoreCase);
         }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading stopwords", e);
-      }
     } else {
       stopWords = new CharArraySet(luceneMatchVersion, StopAnalyzer.ENGLISH_STOP_WORDS_SET, ignoreCase);
     }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java
index c5994fe4..7a578d47 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java
@@ -19,7 +19,6 @@
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.TypeTokenFilter;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.ResourceLoader;
 import org.apache.lucene.analysis.util.ResourceLoaderAware;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
@@ -43,12 +42,11 @@
 public class TypeTokenFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
 
   @Override
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String stopTypesFiles = args.get("types");
     enablePositionIncrements = getBoolean("enablePositionIncrements", false);
     useWhitelist = getBoolean("useWhitelist", false);
     if (stopTypesFiles != null) {
-      try {
         List<String> files = splitFileNames(stopTypesFiles);
         if (files.size() > 0) {
           stopTypes = new HashSet<String>();
@@ -57,11 +55,8 @@ public void inform(ResourceLoader loader) {
             stopTypes.addAll(typesLines);
           }
         }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading types", e);
-      }
     } else {
-      throw new InitializationException("Missing required parameter: types.");
+      throw new IllegalArgumentException("Missing required parameter: types.");
     }
   }
 
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilterFactory.java
index 94abb208..4c92d5dd 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilterFactory.java
@@ -22,7 +22,6 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.el.GreekLowerCaseFilter;
 import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.MultiTermAwareComponent;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
@@ -44,7 +43,7 @@ public void init(Map<String, String> args) {
     super.init(args);
     assureMatchVersion();
     if (args.containsKey("charset"))
-      throw new InitializationException(
+      throw new IllegalArgumentException(
           "The charset parameter is no longer supported.  "
           + "Please process your documents as Unicode instead.");
   }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java
index b9baa55f..22da12c6 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java
@@ -39,16 +39,12 @@
 
   private CharArraySet articles;
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String articlesFile = args.get("articles");
     boolean ignoreCase = getBoolean("ignoreCase", false);
 
     if (articlesFile != null) {
-      try {
         articles = getWordSet(loader, articlesFile, ignoreCase);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading articles", e);
-      }
     }
   }
 
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java
index d62caef9..c6026754 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java
@@ -17,14 +17,15 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
 import java.io.InputStream;
+import java.text.ParseException;
 import java.util.ArrayList;
 import java.util.List;
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.hunspell.HunspellDictionary;
 import org.apache.lucene.analysis.hunspell.HunspellStemFilter;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.ResourceLoader;
 import org.apache.lucene.analysis.util.ResourceLoaderAware;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
@@ -66,11 +67,11 @@
    *  
    * @param loader ResourceLoader used to load the files
    */
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     assureMatchVersion();
     String dictionaryArg = args.get(PARAM_DICTIONARY);
     if (dictionaryArg == null) {
-      throw new InitializationException("Parameter " + PARAM_DICTIONARY + " is mandatory.");
+      throw new IllegalArgumentException("Parameter " + PARAM_DICTIONARY + " is mandatory.");
     }
     String dictionaryFiles[] = args.get(PARAM_DICTIONARY).split(",");
     String affixFile = args.get(PARAM_AFFIX);
@@ -78,7 +79,7 @@ public void inform(ResourceLoader loader) {
     if(pic != null) {
       if(pic.equalsIgnoreCase(TRUE)) ignoreCase = true;
       else if(pic.equalsIgnoreCase(FALSE)) ignoreCase = false;
-      else throw new InitializationException("Unknown value for " + PARAM_IGNORE_CASE + ": " + pic + ". Must be true or false");
+      else throw new IllegalArgumentException("Unknown value for " + PARAM_IGNORE_CASE + ": " + pic + ". Must be true or false");
     }
 
     String strictAffixParsingParam = args.get(PARAM_STRICT_AFFIX_PARSING);
@@ -86,7 +87,7 @@ public void inform(ResourceLoader loader) {
     if(strictAffixParsingParam != null) {
       if(strictAffixParsingParam.equalsIgnoreCase(FALSE)) strictAffixParsing = false;
       else if(strictAffixParsingParam.equalsIgnoreCase(TRUE)) strictAffixParsing = true;
-      else throw new InitializationException("Unknown value for " + PARAM_STRICT_AFFIX_PARSING + ": " + strictAffixParsingParam + ". Must be true or false");
+      else throw new IllegalArgumentException("Unknown value for " + PARAM_STRICT_AFFIX_PARSING + ": " + strictAffixParsingParam + ". Must be true or false");
     }
 
     InputStream affix = null;
@@ -100,8 +101,8 @@ public void inform(ResourceLoader loader) {
       affix = loader.openResource(affixFile);
 
       this.dictionary = new HunspellDictionary(affix, dictionaries, luceneMatchVersion, ignoreCase, strictAffixParsing);
-    } catch (Exception e) {
-      throw new InitializationException("Unable to load hunspell data! [dictionary=" + args.get("dictionary") + ",affix=" + affixFile + "]", e);
+    } catch (ParseException e) {
+      throw new IOException("Unable to load hunspell data! [dictionary=" + args.get("dictionary") + ",affix=" + affixFile + "]", e);
     } finally {
       IOUtils.closeWhileHandlingException(affix);
       IOUtils.closeWhileHandlingException(dictionaries);
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java
index d2f94d99..01e7b8b5 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java
@@ -44,17 +44,13 @@ public void init(Map<String,String> args) {
     assureMatchVersion();
   }
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String wordFiles = args.get("words");
     ignoreCase = getBoolean("ignoreCase", false);
     enablePositionIncrements = getBoolean("enablePositionIncrements",false);
 
     if (wordFiles != null) {
-      try {
         words = getWordSet(loader, wordFiles, ignoreCase);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading words", e);
-      }
     }
   }
 
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java
index df98e54b..002350c3 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java
@@ -39,15 +39,11 @@
   private CharArraySet protectedWords;
   private boolean ignoreCase;
   
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String wordFiles = args.get(PROTECTED_TOKENS);
     ignoreCase = getBoolean("ignoreCase", false);
     if (wordFiles != null) {  
-      try {
         protectedWords = getWordSet(loader, wordFiles, ignoreCase);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading protected words", e);
-      }
     }
   }
   
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java
index 38f3e9b7..45f529c5 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java
@@ -19,7 +19,6 @@
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.miscellaneous.LengthFilter;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
 import java.util.Map;
@@ -47,7 +46,7 @@ public void init(Map<String, String> args) {
     String minKey = args.get(MIN_KEY);
     String maxKey = args.get(MAX_KEY);
     if (minKey == null || maxKey == null) {
-      throw new InitializationException("Both " + MIN_KEY + " and " + MAX_KEY + " are mandatory");
+      throw new IllegalArgumentException("Both " + MIN_KEY + " and " + MAX_KEY + " are mandatory");
     }
     min=Integer.parseInt(minKey);
     max=Integer.parseInt(maxKey);
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java
index 8dc85bbc..83d60671 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java
@@ -21,7 +21,6 @@
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.miscellaneous.LimitTokenCountFilter;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
 /**
@@ -44,7 +43,7 @@ public void init(Map<String, String> args) {
     super.init( args );
     String maxTokenCountArg = args.get("maxTokenCount");
     if (maxTokenCountArg == null) {
-      throw new InitializationException("maxTokenCount is mandatory.");
+      throw new IllegalArgumentException("maxTokenCount is mandatory.");
     }
     maxTokenCount = Integer.parseInt(args.get(maxTokenCountArg));
   }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java
index 2baf35fc..340e680c 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java
@@ -39,13 +39,12 @@
   private CharArrayMap<String> dictionary = null;
   private boolean ignoreCase;
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String dictionaryFiles = args.get("dictionary");
     ignoreCase = getBoolean("ignoreCase", false);
     if (dictionaryFiles != null) {
       assureMatchVersion();
       List<String> files = splitFileNames(dictionaryFiles);
-      try {
         if (files.size() > 0) {
           dictionary = new CharArrayMap<String>(luceneMatchVersion, 
               files.size() * 10, ignoreCase);
@@ -57,9 +56,6 @@ public void inform(ResourceLoader loader) {
             }
           }
         }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading dictionary", e);
-      }
     }
   }
 
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilterFactory.java
index 2ec9a02f..7317dc48 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilterFactory.java
@@ -21,7 +21,6 @@
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.miscellaneous.TrimFilter;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
 /**
@@ -45,14 +44,9 @@ public void init(Map<String,String> args) {
     super.init( args );
     
     String v = args.get( "updateOffsets" );
-    if( v != null ) {
-      try {
+    if (v != null) {
         updateOffsets = Boolean.valueOf( v );
       }
-      catch( Exception ex ) {
-        throw new InitializationException("Error reading updateOffsets value.  Must be true or false.", ex);
-      }
-    }
   }
   
   public TrimFilter create(TokenStream input) {
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java
index 40f750b1..eb3460bb 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java
@@ -53,18 +53,13 @@
   public static final String PROTECTED_TOKENS = "protected";
   public static final String TYPES = "types";
   
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String wordFiles = args.get(PROTECTED_TOKENS);
     if (wordFiles != null) {  
-      try {
         protectedWords = getWordSet(loader, wordFiles, false);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading protected words", e);
-      }
     }
     String types = args.get(TYPES);
     if (types != null) {
-      try {
         List<String> files = splitFileNames( types );
         List<String> wlist = new ArrayList<String>();
         for( String file : files ){
@@ -72,9 +67,6 @@ public void inform(ResourceLoader loader) {
           wlist.addAll( lines );
         }
       typeTable = parseTypes(wlist);
-      } catch (IOException e) {
-        throw new InitializationException("IOException while loading types", e);
-      }
     }
   }
 
@@ -128,13 +120,13 @@ public WordDelimiterFilter create(TokenStream input) {
     for( String rule : rules ){
       Matcher m = typePattern.matcher(rule);
       if( !m.find() )
-        throw new InitializationException("Invalid Mapping Rule : [" + rule + "]");
+        throw new IllegalArgumentException("Invalid Mapping Rule : [" + rule + "]");
       String lhs = parseString(m.group(1).trim());
       Byte rhs = parseType(m.group(2).trim());
       if (lhs.length() != 1)
-        throw new InitializationException("Invalid Mapping Rule : [" + rule + "]. Only a single character is allowed.");
+        throw new IllegalArgumentException("Invalid Mapping Rule : [" + rule + "]. Only a single character is allowed.");
       if (rhs == null)
-        throw new InitializationException("Invalid Mapping Rule : [" + rule + "]. Illegal type.");
+        throw new IllegalArgumentException("Invalid Mapping Rule : [" + rule + "]. Illegal type.");
       typeMap.put(lhs.charAt(0), rhs);
     }
     
@@ -174,7 +166,7 @@ private String parseString(String s){
       char c = s.charAt( readPos++ );
       if( c == '\\' ){
         if( readPos >= len )
-          throw new InitializationException("Invalid escaped char in [" + s + "]");
+          throw new IllegalArgumentException("Invalid escaped char in [" + s + "]");
         c = s.charAt( readPos++ );
         switch( c ) {
           case '\\' : c = '\\'; break;
@@ -185,7 +177,7 @@ private String parseString(String s){
           case 'f' : c = '\f'; break;
           case 'u' :
             if( readPos + 3 >= len )
-              throw new InitializationException("Invalid escaped char in [" + s + "]");
+              throw new IllegalArgumentException("Invalid escaped char in [" + s + "]");
             c = (char)Integer.parseInt( s.substring( readPos, readPos + 4 ), 16 );
             readPos += 4;
             break;
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java
index 76e33521..bb9e0423 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java
@@ -23,7 +23,6 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.path.PathHierarchyTokenizer;
 import org.apache.lucene.analysis.path.ReversePathHierarchyTokenizer;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 
 /**
@@ -53,7 +52,7 @@ public void init(Map<String,String> args){
     String v = args.get( "delimiter" );
     if( v != null ){
       if( v.length() != 1 ){
-        throw new InitializationException("delimiter should be a char. \"" + v + "\" is invalid");
+        throw new IllegalArgumentException("delimiter should be a char. \"" + v + "\" is invalid");
       }
       else{
         delimiter = v.charAt(0);
@@ -66,7 +65,7 @@ public void init(Map<String,String> args){
     v = args.get( "replace" );
     if( v != null ){
       if( v.length() != 1 ){
-        throw new InitializationException("replace should be a char. \"" + v + "\" is invalid");
+        throw new IllegalArgumentException("replace should be a char. \"" + v + "\" is invalid");
       }
       else{
         replacement = v.charAt(0);
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java
index 6fc6bc38..d7d7268e 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java
@@ -19,7 +19,6 @@
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.pattern.PatternReplaceFilter;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
 import java.util.Map;
@@ -58,7 +57,7 @@ public void init(Map<String, String> args) {
         if (r.equals("first")) {
           all = false;
         } else {
-          throw new InitializationException
+          throw new IllegalArgumentException
             ("Configuration Error: 'replace' must be 'first' or 'all' in "
              + this.getClass().getName());
         }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
index 6af60d25..e2090958 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
@@ -24,7 +24,6 @@
 
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.pattern.PatternTokenizer;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 
 /**
@@ -84,13 +83,8 @@ public void init(Map<String,String> args)
     group = -1;  // use 'split'
     String g = args.get( GROUP );
     if( g != null ) {
-      try {
         group = Integer.parseInt( g );
       }
-      catch( Exception ex ) {
-        throw new InitializationException("invalid group argument: " + g);
-      }
-    }
   }
   
   /**
@@ -100,7 +94,7 @@ public Tokenizer create(final Reader in) {
     try {
       return new PatternTokenizer(in, pattern, group);
     } catch( IOException ex ) {
-      throw new InitializationException("IOException thrown creating PatternTokenizer instance", ex);
+      throw new RuntimeException("IOException thrown creating PatternTokenizer instance", ex);
     }
   }
 }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java
index d7f67a14..5c938783 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java
@@ -23,7 +23,6 @@
 import org.apache.lucene.analysis.payloads.FloatEncoder;
 import org.apache.lucene.analysis.payloads.IntegerEncoder;
 import org.apache.lucene.analysis.payloads.IdentityEncoder;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.ResourceLoader;
 import org.apache.lucene.analysis.util.ResourceLoaderAware;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
@@ -62,7 +61,7 @@ public void init(Map<String, String> args) {
   public void inform(ResourceLoader loader) {
     String encoderClass = args.get(ENCODER_ATTR);
     if (encoderClass == null) {
-      throw new InitializationException("Parameter " + ENCODER_ATTR + " is mandatory");
+      throw new IllegalArgumentException("Parameter " + ENCODER_ATTR + " is mandatory");
     }
     if (encoderClass.equals("float")){
       encoder = new FloatEncoder();
@@ -79,7 +78,7 @@ public void inform(ResourceLoader loader) {
       if (delim.length() == 1) {
         delimiter = delim.charAt(0);
       } else{
-        throw new InitializationException("Delimiter must be one character only");
+        throw new IllegalArgumentException("Delimiter must be one character only");
       }
     }
   }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterFactory.java
index 0bb92fae..abb115c1 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterFactory.java
@@ -19,7 +19,6 @@
 
 import org.apache.lucene.analysis.payloads.NumericPayloadTokenFilter;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 import java.util.Map;
 
@@ -43,7 +42,7 @@ public void init(Map<String, String> args) {
     String payloadArg = args.get("payload");
     typeMatch = args.get("typeMatch");
     if (payloadArg == null || typeMatch == null) {
-      throw new InitializationException("Both payload and typeMatch are required");
+      throw new IllegalArgumentException("Both payload and typeMatch are required");
     }
     payload = Float.parseFloat(payloadArg);
   }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLetterTokenizerFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLetterTokenizerFactory.java
index 946ecf92..0deb6fa1 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLetterTokenizerFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLetterTokenizerFactory.java
@@ -22,7 +22,6 @@
 
 import org.apache.lucene.analysis.ru.RussianLetterTokenizer;
 import org.apache.lucene.analysis.standard.StandardTokenizerFactory; // javadocs
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 
 /** @deprecated Use {@link StandardTokenizerFactory} instead.
@@ -35,7 +34,7 @@
   public void init(Map<String, String> args) {
     super.init(args);
     if (args.containsKey("charset"))
-      throw new InitializationException(
+      throw new IllegalArgumentException(
           "The charset parameter is no longer supported.  "
           + "Please process your documents as Unicode instead.");
     assureMatchVersion();
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilterFactory.java
index 87405c8d..41fb3f04 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilterFactory.java
@@ -19,7 +19,6 @@
 
 import org.apache.lucene.analysis.shingle.ShingleFilter;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
 import java.util.Map;
@@ -49,17 +48,17 @@ public void init(Map<String, String> args) {
     maxShingleSize = getInt("maxShingleSize", 
                             ShingleFilter.DEFAULT_MAX_SHINGLE_SIZE);
     if (maxShingleSize < 2) {
-      throw new InitializationException("Invalid maxShingleSize (" + maxShingleSize
+      throw new IllegalArgumentException("Invalid maxShingleSize (" + maxShingleSize
                               + ") - must be at least 2");
     }
     minShingleSize = getInt("minShingleSize",
                             ShingleFilter.DEFAULT_MIN_SHINGLE_SIZE);
     if (minShingleSize < 2) {
-      throw new InitializationException("Invalid minShingleSize (" + minShingleSize
+      throw new IllegalArgumentException("Invalid minShingleSize (" + minShingleSize
                               + ") - must be at least 2");
     }
     if (minShingleSize > maxShingleSize) {
-      throw new InitializationException("Invalid minShingleSize (" + minShingleSize
+      throw new IllegalArgumentException("Invalid minShingleSize (" + minShingleSize
                               + ") - must be no greater than maxShingleSize ("
                               + maxShingleSize + ")");
     }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java
index 68115dcf..71b53a7d 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java
@@ -49,14 +49,10 @@
   private Class<?> stemClass;
 
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String wordFiles = args.get(PROTECTED_TOKENS);
     if (wordFiles != null) {
-      try {
         protectedWords = getWordSet(loader, wordFiles, false);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading protected words", e);
-      }
     }
   }
 
@@ -71,7 +67,7 @@ public void init(Map<String, String> args) {
     try {
       stemClass = Class.forName("org.tartarus.snowball.ext." + language + "Stemmer");
     } catch (ClassNotFoundException e) {
-      throw new InitializationException("Can't find class for stemmer language " + language, e);
+      throw new IllegalArgumentException("Can't find class for stemmer language " + language, e);
     }
   }
   
@@ -80,7 +76,7 @@ public TokenFilter create(TokenStream input) {
     try {
       program = (SnowballProgram)stemClass.newInstance();
     } catch (Exception e) {
-      throw new InitializationException("Error instantiating stemmer for language " + language + "from class " + stemClass, e);
+      throw new RuntimeException("Error instantiating stemmer for language " + language + "from class " + stemClass, e);
     }
 
     if (protectedWords != null)
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/FSTSynonymFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/FSTSynonymFilterFactory.java
index 5086c68f..ed58a832 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/FSTSynonymFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/FSTSynonymFilterFactory.java
@@ -58,7 +58,7 @@ public TokenStream create(TokenStream input) {
   }
 
   @Override
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     final boolean ignoreCase = getBoolean("ignoreCase", false); 
     this.ignoreCase = ignoreCase;
 
@@ -84,10 +84,10 @@ protected TokenStreamComponents createComponents(String fieldName, Reader reader
         map = loadWordnetSynonyms(loader, true, analyzer);
       } else {
         // TODO: somehow make this more pluggable
-        throw new InitializationException("Unrecognized synonyms format: " + format);
+        throw new IllegalArgumentException("Unrecognized synonyms format: " + format);
       }
-    } catch (Exception e) {
-      throw new InitializationException("Exception thrown while loading synonyms", e);
+    } catch (ParseException e) {
+      throw new IOException("Exception thrown while loading synonyms", e);
     }
   }
   
@@ -98,7 +98,7 @@ private SynonymMap loadSolrSynonyms(ResourceLoader loader, boolean dedup, Analyz
     final boolean expand = getBoolean("expand", true);
     String synonyms = args.get("synonyms");
     if (synonyms == null)
-      throw new InitializationException("Missing required argument 'synonyms'.");
+      throw new IllegalArgumentException("Missing required argument 'synonyms'.");
     
     CharsetDecoder decoder = Charset.forName("UTF-8").newDecoder()
       .onMalformedInput(CodingErrorAction.REPORT)
@@ -126,7 +126,7 @@ private SynonymMap loadWordnetSynonyms(ResourceLoader loader, boolean dedup, Ana
     final boolean expand = getBoolean("expand", true);
     String synonyms = args.get("synonyms");
     if (synonyms == null)
-      throw new InitializationException("Missing required argument 'synonyms'.");
+      throw new IllegalArgumentException("Missing required argument 'synonyms'.");
     
     CharsetDecoder decoder = Charset.forName("UTF-8").newDecoder()
       .onMalformedInput(CodingErrorAction.REPORT)
@@ -147,7 +147,7 @@ private SynonymMap loadWordnetSynonyms(ResourceLoader loader, boolean dedup, Ana
     return parser.build();
   }
   
-  private TokenizerFactory loadTokenizerFactory(ResourceLoader loader, String cname){
+  private TokenizerFactory loadTokenizerFactory(ResourceLoader loader, String cname) throws IOException {
     TokenizerFactory tokFactory = loader.newInstance(cname, TokenizerFactory.class);
     tokFactory.setLuceneMatchVersion(luceneMatchVersion);
     tokFactory.init(args);
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SlowSynonymFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SlowSynonymFilterFactory.java
index 8201c617..4cf0d89a 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SlowSynonymFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SlowSynonymFilterFactory.java
@@ -43,10 +43,10 @@
 @Deprecated
 final class SlowSynonymFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String synonyms = args.get("synonyms");
     if (synonyms == null)
-      throw new InitializationException("Missing required argument 'synonyms'.");
+      throw new IllegalArgumentException("Missing required argument 'synonyms'.");
     boolean ignoreCase = getBoolean("ignoreCase", false);
     boolean expand = getBoolean("expand", true);
 
@@ -65,9 +65,8 @@ public void inform(ResourceLoader loader) {
   /**
    * @return a list of all rules
    */
-  protected Iterable<String> loadRules( String synonyms, ResourceLoader loader ) {
+  protected Iterable<String> loadRules( String synonyms, ResourceLoader loader ) throws IOException {
     List<String> wlist=null;
-    try {
       File synonymFile = new File(synonyms);
       if (synonymFile.exists()) {
         wlist = loader.getLines(synonyms);
@@ -79,16 +78,13 @@ public void inform(ResourceLoader loader) {
           wlist.addAll(lines);
         }
       }
-    } catch (IOException e) {
-      throw new InitializationException("IOException thrown while loading synonym rules", e);
-    }
     return wlist;
   }
 
   private SlowSynonymMap synMap;
 
   static void parseRules(Iterable<String> rules, SlowSynonymMap map, String mappingSep,
-    String synSep, boolean expansion, TokenizerFactory tokFactory) {
+    String synSep, boolean expansion, TokenizerFactory tokFactory) throws IOException {
     int count=0;
     for (String rule : rules) {
       // To use regexes, we need an expression that specifies an odd number of chars.
@@ -102,7 +98,7 @@ static void parseRules(Iterable<String> rules, SlowSynonymMap map, String mappin
       List<List<String>> target;
 
       if (mapping.size() > 2) {
-        throw new InitializationException("Invalid Synonym Rule:" + rule);
+        throw new IllegalArgumentException("Invalid Synonym Rule:" + rule);
       } else if (mapping.size()==2) {
         source = getSynList(mapping.get(0), synSep, tokFactory);
         target = getSynList(mapping.get(1), synSep, tokFactory);
@@ -133,7 +129,7 @@ static void parseRules(Iterable<String> rules, SlowSynonymMap map, String mappin
   }
 
   // a , b c , d e f => [[a],[b,c],[d,e,f]]
-  private static List<List<String>> getSynList(String str, String separator, TokenizerFactory tokFactory) {
+  private static List<List<String>> getSynList(String str, String separator, TokenizerFactory tokFactory) throws IOException {
     List<String> strList = splitSmart(str, separator, false);
     // now split on whitespace to get a list of token strings
     List<List<String>> synList = new ArrayList<List<String>>();
@@ -145,7 +141,7 @@ static void parseRules(Iterable<String> rules, SlowSynonymMap map, String mappin
     return synList;
   }
 
-  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory){
+  private static List<String> splitByTokenizer(String source, TokenizerFactory tokFactory) throws IOException{
     StringReader reader = new StringReader( source );
     TokenStream ts = loadTokenizer(tokFactory, reader);
     List<String> tokList = new ArrayList<String>();
@@ -155,16 +151,13 @@ static void parseRules(Iterable<String> rules, SlowSynonymMap map, String mappin
         if( termAtt.length() > 0 )
           tokList.add( termAtt.toString() );
       }
-    } catch (IOException e) {
-      throw new InitializationException("IOException thrown while tokenizing source", e);
-    }
-    finally{
+    } finally{
       reader.close();
     }
     return tokList;
   }
 
-  private TokenizerFactory loadTokenizerFactory(ResourceLoader loader, String cname) {
+  private TokenizerFactory loadTokenizerFactory(ResourceLoader loader, String cname) throws IOException {
     TokenizerFactory tokFactory = loader.newInstance(cname, TokenizerFactory.class);
     tokFactory.setLuceneMatchVersion(luceneMatchVersion);
     tokFactory.init( args );
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SlowSynonymMap.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SlowSynonymMap.java
index 8be0d43b..8b2ec5ce 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SlowSynonymMap.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SlowSynonymMap.java
@@ -19,7 +19,6 @@
 
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.util.CharArrayMap;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.util.Version;
 
 import java.util.*;
@@ -72,7 +71,7 @@ public void add(List<String> singleMatch, List<Token> replacement, boolean inclu
     }
 
     if (currMap.synonyms != null && !mergeExisting) {
-      throw new InitializationException("SynonymFilter: there is already a mapping for " + singleMatch);
+      throw new IllegalArgumentException("SynonymFilter: there is already a mapping for " + singleMatch);
     }
     List<Token> superset = currMap.synonyms==null ? replacement :
           mergeTokens(Arrays.asList(currMap.synonyms), replacement);
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
index 43f4f3b4..5dba7705 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
@@ -17,11 +17,11 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
 import java.util.Map;
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.synonym.SynonymFilter;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.util.Version;
 import org.apache.lucene.analysis.util.ResourceLoader;
 import org.apache.lucene.analysis.util.ResourceLoaderAware;
@@ -52,7 +52,7 @@ public void init(Map<String,String> args) {
       // check if you use the new optional arg "format". this makes no sense for the old one, 
       // as its wired to solr's synonyms format only.
       if (args.containsKey("format") && !args.get("format").equals("solr")) {
-        throw new InitializationException("You must specify luceneMatchVersion >= 3.4 to use alternate synonyms formats");
+        throw new IllegalArgumentException("You must specify luceneMatchVersion >= 3.4 to use alternate synonyms formats");
       }
       delegator = new SlowSynonymFilterFactory();
     }
@@ -66,7 +66,7 @@ public TokenStream create(TokenStream input) {
   }
 
   @Override
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     assert delegator != null : "init() was not called!";
     ((ResourceLoaderAware) delegator).inform(loader);
   }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory.java
index 987ce8ef..aa26da9c 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/AbstractAnalysisFactory.java
@@ -59,7 +59,7 @@ public void init(Map<String,String> args) {
    * to inform user, that for this factory a {@link #luceneMatchVersion} is required */
   protected final void assureMatchVersion() {
     if (luceneMatchVersion == null) {
-      throw new InitializationException("Configuration Error: Factory '" + this.getClass().getName() +
+      throw new IllegalArgumentException("Configuration Error: Factory '" + this.getClass().getName() +
         "' needs a 'luceneMatchVersion' parameter");
     }
   }
@@ -86,7 +86,7 @@ protected int getInt(String name, int defaultVal, boolean useDefault) {
       if (useDefault) {
         return defaultVal;
       }
-      throw new InitializationException("Configuration Error: missing parameter '" + name + "'");
+      throw new IllegalArgumentException("Configuration Error: missing parameter '" + name + "'");
     }
     return Integer.parseInt(s);
   }
@@ -99,7 +99,7 @@ protected boolean getBoolean(String name, boolean defaultVal, boolean useDefault
     String s = args.get(name);
     if (s==null) {
       if (useDefault) return defaultVal;
-      throw new InitializationException("Configuration Error: missing parameter '" + name + "'");
+      throw new IllegalArgumentException("Configuration Error: missing parameter '" + name + "'");
     }
     return Boolean.parseBoolean(s);
   }
@@ -108,11 +108,11 @@ protected Pattern getPattern(String name) {
     try {
       String pat = args.get(name);
       if (null == pat) {
-        throw new InitializationException("Configuration Error: missing parameter '" + name + "'");
+        throw new IllegalArgumentException("Configuration Error: missing parameter '" + name + "'");
       }
       return Pattern.compile(args.get(name));
     } catch (PatternSyntaxException e) {
-      throw new InitializationException
+      throw new IllegalArgumentException
         ("Configuration Error: '" + name + "' can not be parsed in " +
          this.getClass().getSimpleName(), e);
     }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/InitializationException.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/InitializationException.java
index c5b46d15..e69de29b 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/InitializationException.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/InitializationException.java
@@ -1,32 +0,0 @@
-package org.apache.lucene.analysis.util;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Exception representing an error occurring during the initialization of a Factory.
- */
-public class InitializationException extends RuntimeException {
-
-  public InitializationException(String message) {
-    super(message);
-  }
-
-  public InitializationException(String message, Throwable cause) {
-    super(message, cause);
-  }
-}
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ResourceLoaderAware.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ResourceLoaderAware.java
index e9949301..cf360241 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ResourceLoaderAware.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/ResourceLoaderAware.java
@@ -17,6 +17,8 @@
 
 package org.apache.lucene.analysis.util;
 
+import java.io.IOException;
+
 /**
  * Interface for a component that needs to be initialized by
  * an implementation of {@link ResourceLoader}.
@@ -25,5 +27,5 @@
  */
 public interface ResourceLoaderAware {
 
-  void inform(ResourceLoader loader);
+  void inform(ResourceLoader loader) throws IOException;
 }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/collation/CollationKeyFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/collation/CollationKeyFilterFactory.java
index c3985fbd..40012f53 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/collation/CollationKeyFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/java/org/apache/lucene/collation/CollationKeyFilterFactory.java
@@ -73,7 +73,7 @@
 public class CollationKeyFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent, ResourceLoaderAware {
   private Collator collator;
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String custom = args.get("custom");
     String language = args.get("language");
     String country = args.get("country");
@@ -82,11 +82,11 @@ public void inform(ResourceLoader loader) {
     String decomposition = args.get("decomposition");
     
     if (custom == null && language == null)
-      throw new InitializationException("Either custom or language is required.");
+      throw new IllegalArgumentException("Either custom or language is required.");
     
     if (custom != null && 
         (language != null || country != null || variant != null))
-      throw new InitializationException("Cannot specify both language and custom. "
+      throw new IllegalArgumentException("Cannot specify both language and custom. "
           + "To tailor rules for a built-in language, see the javadocs for RuleBasedCollator. "
           + "Then save the entire customized ruleset to a file, and use with the custom parameter");
     
@@ -109,7 +109,7 @@ else if (strength.equalsIgnoreCase("tertiary"))
       else if (strength.equalsIgnoreCase("identical"))
         collator.setStrength(Collator.IDENTICAL);
       else
-        throw new InitializationException("Invalid strength: " + strength);
+        throw new IllegalArgumentException("Invalid strength: " + strength);
     }
     
     // set the decomposition flag, otherwise it will be the default.
@@ -121,7 +121,7 @@ else if (decomposition.equalsIgnoreCase("canonical"))
       else if (decomposition.equalsIgnoreCase("full"))
         collator.setDecomposition(Collator.FULL_DECOMPOSITION);
       else
-        throw new InitializationException("Invalid decomposition: " + decomposition);
+        throw new IllegalArgumentException("Invalid decomposition: " + decomposition);
     }
   }
   
@@ -137,7 +137,7 @@ private Collator createFromLocale(String language, String country, String varian
     Locale locale;
     
     if (language != null && country == null && variant != null)
-      throw new InitializationException("To specify variant, country is required");
+      throw new IllegalArgumentException("To specify variant, country is required");
     else if (language != null && country != null && variant != null)
       locale = new Locale(language, country, variant);
     else if (language != null && country != null)
@@ -152,18 +152,15 @@ else if (language != null && country != null)
    * Read custom rules from a file, and create a RuleBasedCollator
    * The file cannot support comments, as # might be in the rules!
    */
-  private Collator createFromRules(String fileName, ResourceLoader loader) {
+  private Collator createFromRules(String fileName, ResourceLoader loader) throws IOException {
     InputStream input = null;
     try {
      input = loader.openResource(fileName);
      String rules = toUTF8String(input);
      return new RuleBasedCollator(rules);
-    } catch (IOException e) {
-      // io error
-      throw new InitializationException("IOException thrown while loading rules", e);
     } catch (ParseException e) {
       // invalid rules
-      throw new InitializationException("ParseException thrown while parsing rules", e);
+      throw new IOException("ParseException thrown while parsing rules", e);
     } finally {
       IOUtils.closeWhileHandlingException(input);
     }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilterFactory.java
index 92963702..97cfbf92 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilterFactory.java
@@ -17,7 +17,6 @@
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.util.LuceneTestCase;
 
 public class TestMappingCharFilterFactory extends LuceneTestCase {
@@ -29,7 +28,7 @@ public void testParseString() throws Exception {
       f.parseString( "\\" );
       fail( "escape character cannot be alone." );
     }
-    catch (InitializationException expected) {}
+    catch (IllegalArgumentException expected) {}
     
     assertEquals( "unexpected escaped characters",
         "\\\"\n\t\r\b\f", f.parseString( "\\\\\\\"\\n\\t\\r\\b\\f" ) );
@@ -42,7 +41,7 @@ public void testParseString() throws Exception {
       f.parseString( "\\u000" );
       fail( "invalid length check." );
     }
-    catch (InitializationException expected) {}
+    catch (IllegalArgumentException expected) {}
 
     try {
       f.parseString( "\\u123x" );
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestAllAnalyzersHaveFactories.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestAllAnalyzersHaveFactories.java
index 11f2435e..d09460df 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestAllAnalyzersHaveFactories.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestAllAnalyzersHaveFactories.java
@@ -53,7 +53,6 @@
 import org.apache.lucene.analysis.util.ResourceLoaderAware;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 import org.apache.lucene.analysis.util.TokenizerFactory;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.util.LuceneTestCase;
 
 /**
@@ -143,7 +142,7 @@ public void test() throws Exception {
           if (!(instance instanceof ResourceLoaderAware)) {
             assertSame(c, instance.create(new StringReader("")).getClass());
           }
-        } catch (InitializationException e) {
+        } catch (IllegalArgumentException e) {
           // TODO: For now pass because some factories have not yet a default config that always works, some require ResourceLoader
         }
       } else if (TokenFilter.class.isAssignableFrom(c)) {
@@ -163,7 +162,7 @@ public void test() throws Exception {
               assertSame(c, createdClazz);
             }
           }
-        } catch (InitializationException e) {
+        } catch (IllegalArgumentException e) {
           // TODO: For now pass because some factories have not yet a default config that always works, some require ResourceLoader
         }
       } else if (CharFilter.class.isAssignableFrom(c)) {
@@ -183,7 +182,7 @@ public void test() throws Exception {
               assertSame(c, createdClazz);
             }
           }
-        } catch (InitializationException e) {
+        } catch (IllegalArgumentException e) {
           // TODO: For now pass because some factories have not yet a default config that always works, some require ResourceLoader
         }
       }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFactories.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFactories.java
index 137eb8eb..f37911cb 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFactories.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestFactories.java
@@ -27,7 +27,6 @@
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
 import org.apache.lucene.analysis.util.CharFilterFactory;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.MultiTermAwareComponent;
 import org.apache.lucene.analysis.util.ResourceLoaderAware;
 import org.apache.lucene.analysis.util.StringMockResourceLoader;
@@ -121,7 +120,7 @@ private boolean initialize(AbstractAnalysisFactory factory) {
       factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
       factory.init(Collections.<String,String>emptyMap());
       success = true;
-    } catch (InitializationException ignored) {
+    } catch (IllegalArgumentException ignored) {
       // its ok if we dont provide the right parameters to throw this
     }
     
@@ -130,8 +129,10 @@ private boolean initialize(AbstractAnalysisFactory factory) {
       try {
         ((ResourceLoaderAware) factory).inform(new StringMockResourceLoader(""));
         success = true;
-      } catch (InitializationException ignored) {
+      } catch (IOException ignored) {
         // its ok if the right files arent available or whatever to throw this
+      } catch (IllegalArgumentException ignored) {
+        // is this ok? I guess so
       }
     }
     return success;
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java
index bf4416ff..a69b24a8 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java
@@ -19,7 +19,6 @@
 
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.NumericTokenStream;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.ResourceAsStreamResourceLoader;
 import org.apache.lucene.analysis.util.ResourceLoader;
 import org.junit.Test;
@@ -96,8 +95,8 @@ public void testMissingTypesParameter() throws Exception {
       typeTokenFilterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
       typeTokenFilterFactory.init(args);
       typeTokenFilterFactory.inform(new ResourceAsStreamResourceLoader(getClass()));
-      fail("not supplying 'types' parameter should cause an InitializationException");
-    } catch (InitializationException e) {
+      fail("not supplying 'types' parameter should cause an IllegalArgumentException");
+    } catch (IllegalArgumentException e) {
       // everything ok
     }
   }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMap.java b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMap.java
index ab2b9b26..6c6d64e5 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMap.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymMap.java
@@ -26,7 +26,6 @@
 
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.ngram.NGramTokenizerFactory;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.analysis.util.ResourceLoader;
@@ -43,9 +42,9 @@ public void testInvalidMappingRules() throws Exception {
     rules.add( "a=>b=>c" );
     try{
         SlowSynonymFilterFactory.parseRules( rules, synMap, "=>", ",", true, null);
-        fail( "InitializationException must be thrown." );
+        fail( "IllegalArgumentException must be thrown." );
     }
-    catch(InitializationException expected) {}
+    catch(IllegalArgumentException expected) {}
   }
   
   public void testReadMappingRules() throws Exception {
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2FilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2FilterFactory.java
index fdb115cc..56186c71 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2FilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUNormalizer2FilterFactory.java
@@ -22,7 +22,6 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.icu.ICUNormalizer2Filter;
 import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.MultiTermAwareComponent;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
@@ -65,7 +64,7 @@ public void init(Map<String,String> args) {
     else if (mode.equals("decompose"))
       normalizer = Normalizer2.getInstance(null, name, Normalizer2.Mode.DECOMPOSE);
     else 
-      throw new InitializationException("Invalid mode: " + mode);
+      throw new IllegalArgumentException("Invalid mode: " + mode);
     
     String filter = args.get("filter");
     if (filter != null) {
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUTransformFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUTransformFilterFactory.java
index 8b0e3c8f..66b3c0ab 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUTransformFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/ICUTransformFilterFactory.java
@@ -22,7 +22,6 @@
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.icu.ICUTransformFilter;
 import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.MultiTermAwareComponent;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
@@ -47,7 +46,7 @@ public void init(Map<String,String> args) {
     super.init(args);
     String id = args.get("id");
     if (id == null) {
-      throw new InitializationException("id is required.");
+      throw new IllegalArgumentException("id is required.");
     }
     
     int dir;
@@ -57,7 +56,7 @@ public void init(Map<String,String> args) {
     else if (direction.equalsIgnoreCase("reverse"))
       dir = Transliterator.REVERSE;
     else
-      throw new InitializationException("invalid direction: " + direction);
+      throw new IllegalArgumentException("invalid direction: " + direction);
     
     transliterator = Transliterator.getInstance(id, dir);
   }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationKeyFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationKeyFilterFactory.java
index 71df66d1..72c1ef5b 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationKeyFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationKeyFilterFactory.java
@@ -72,7 +72,7 @@
 public class ICUCollationKeyFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent, ResourceLoaderAware {
   private Collator collator;
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String custom = args.get("custom");
     String localeID = args.get("locale");
     String strength = args.get("strength");
@@ -85,10 +85,10 @@ public void inform(ResourceLoader loader) {
     String variableTop = args.get("variableTop");
     
     if (custom == null && localeID == null)
-      throw new InitializationException("Either custom or locale is required.");
+      throw new IllegalArgumentException("Either custom or locale is required.");
     
     if (custom != null && localeID != null)
-      throw new InitializationException("Cannot specify both locale and custom. "
+      throw new IllegalArgumentException("Cannot specify both locale and custom. "
           + "To tailor rules for a built-in language, see the javadocs for RuleBasedCollator. "
           + "Then save the entire customized ruleset to a file, and use with the custom parameter");
     
@@ -113,7 +113,7 @@ else if (strength.equalsIgnoreCase("quaternary"))
       else if (strength.equalsIgnoreCase("identical"))
         collator.setStrength(Collator.IDENTICAL);
       else
-        throw new InitializationException("Invalid strength: " + strength);
+        throw new IllegalArgumentException("Invalid strength: " + strength);
     }
     
     // set the decomposition flag, otherwise it will be the default.
@@ -123,7 +123,7 @@ else if (strength.equalsIgnoreCase("identical"))
       else if (decomposition.equalsIgnoreCase("canonical"))
         collator.setDecomposition(Collator.CANONICAL_DECOMPOSITION);
       else
-        throw new InitializationException("Invalid decomposition: " + decomposition);
+        throw new IllegalArgumentException("Invalid decomposition: " + decomposition);
     }
     
     // expert options: concrete subclasses are always a RuleBasedCollator
@@ -134,7 +134,7 @@ else if (decomposition.equalsIgnoreCase("canonical"))
       } else if (alternate.equalsIgnoreCase("non-ignorable")) {
         rbc.setAlternateHandlingShifted(false);
       } else {
-        throw new InitializationException("Invalid alternate: " + alternate);
+        throw new IllegalArgumentException("Invalid alternate: " + alternate);
       }
     }
     if (caseLevel != null) {
@@ -146,7 +146,7 @@ else if (decomposition.equalsIgnoreCase("canonical"))
       } else if (caseFirst.equalsIgnoreCase("upper")) {
         rbc.setUpperCaseFirst(true);
       } else {
-        throw new InitializationException("Invalid caseFirst: " + caseFirst);
+        throw new IllegalArgumentException("Invalid caseFirst: " + caseFirst);
       }
     }
     if (numeric != null) {
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilterFactory.java
index 8904ce88..9f3a1b2e 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilterFactory.java
@@ -19,7 +19,6 @@
 
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.ja.JapaneseKatakanaStemFilter;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
 import java.util.Map;
@@ -45,7 +44,7 @@ public void init(Map<String, String> args) {
     super.init(args);
     minimumLength = getInt(MINIMUM_LENGTH_PARAM, JapaneseKatakanaStemFilter.DEFAULT_MINIMUM_LENGTH);
     if (minimumLength < 2) {
-      throw new InitializationException("Illegal " + MINIMUM_LENGTH_PARAM + " " + minimumLength + " (must be 2 or greater)");
+      throw new IllegalArgumentException("Illegal " + MINIMUM_LENGTH_PARAM + " " + minimumLength + " (must be 2 or greater)");
     }
   }
 
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilterFactory.java
index 2f98bd2c..539bed7f 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilterFactory.java
@@ -44,11 +44,10 @@
   private boolean enablePositionIncrements;
   private Set<String> stopTags;
 
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     String stopTagFiles = args.get("tags");
     enablePositionIncrements = getBoolean("enablePositionIncrements", false);
     stopTags = null;
-    try {
       CharArraySet cas = getWordSet(loader, stopTagFiles, false);
       if (cas != null) {
         stopTags = new HashSet<String>();
@@ -57,9 +56,6 @@ public void inform(ResourceLoader loader) {
           stopTags.add(new String(chars));
         }
       }
-    } catch (IOException e) {
-      throw new InitializationException("IOException thrown while loading tags", e);
-    }
   }
 
   public TokenStream create(TokenStream stream) {
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java
index f5e0c81d..6ccf03b2 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java
@@ -17,6 +17,7 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
@@ -30,7 +31,6 @@
 import org.apache.lucene.analysis.ja.JapaneseTokenizer;
 import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
 import org.apache.lucene.analysis.ja.dict.UserDictionary;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.analysis.util.ResourceLoader;
@@ -68,10 +68,9 @@
   private boolean discardPunctuation;
 
   @Override
-  public void inform(ResourceLoader loader) {
+  public void inform(ResourceLoader loader) throws IOException {
     mode = getMode(args);
     String userDictionaryPath = args.get(USER_DICT_PATH);
-    try {
       if (userDictionaryPath != null) {
         InputStream stream = loader.openResource(userDictionaryPath);
         String encoding = args.get(USER_DICT_ENCODING);
@@ -86,9 +85,6 @@ public void inform(ResourceLoader loader) {
       } else {
         userDictionary = null;
       }
-    } catch (Exception e) {
-      throw new InitializationException("Exception thrown while loading dictionary", e);
-    }
     discardPunctuation = getBoolean(DISCARD_PUNCTUATION, true);
   }
   
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java
index a0a46468..386bf57c 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java
@@ -27,7 +27,6 @@
 import org.apache.commons.codec.language.*;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.phonetic.PhoneticFilter;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 
 /**
@@ -90,7 +89,7 @@ public void init(Map<String,String> args) {
     
     String name = args.get( ENCODER );
     if( name == null ) {
-      throw new InitializationException("Missing required parameter: " + ENCODER
+      throw new IllegalArgumentException("Missing required parameter: " + ENCODER
           + " [" + registry.keySet() + "]");
     }
     clazz = registry.get(name.toUpperCase(Locale.ROOT));
@@ -104,7 +103,7 @@ public void init(Map<String,String> args) {
       try {
         setMaxCodeLenMethod = clazz.getMethod("setMaxCodeLen", int.class);
       } catch (Exception e) {
-        throw new InitializationException("Encoder " + name + " / " + clazz + " does not support " + MAX_CODE_LENGTH, e);
+        throw new IllegalArgumentException("Encoder " + name + " / " + clazz + " does not support " + MAX_CODE_LENGTH, e);
       }
     }
 
@@ -119,9 +118,9 @@ public void init(Map<String,String> args) {
     try {
       return Class.forName(lookupName).asSubclass(Encoder.class);
     } catch (ClassNotFoundException cnfe) {
-      throw new InitializationException("Unknown encoder: " + name + " must be full class name or one of " + registry.keySet(), cnfe);
+      throw new IllegalArgumentException("Unknown encoder: " + name + " must be full class name or one of " + registry.keySet(), cnfe);
     } catch (ClassCastException e) {
-      throw new InitializationException("Not an encoder: " + name + " must be full class name or one of " + registry.keySet(), e);
+      throw new IllegalArgumentException("Not an encoder: " + name + " must be full class name or one of " + registry.keySet(), e);
     }
   }
 
@@ -138,7 +137,7 @@ protected Encoder getEncoder() {
       return encoder;
     } catch (Exception e) {
       final Throwable t = (e instanceof InvocationTargetException) ? e.getCause() : e;
-      throw new InitializationException("Error initializing encoder: " + name + " / " + clazz, t);
+      throw new IllegalArgumentException("Error initializing encoder: " + name + " / " + clazz, t);
     }
   }
 
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/stempel/src/java/org/apache/lucene/analysis/stempel/StempelPolishStemFilterFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/stempel/src/java/org/apache/lucene/analysis/stempel/StempelPolishStemFilterFactory.java
index 8ef04305..2d670616 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/stempel/src/java/org/apache/lucene/analysis/stempel/StempelPolishStemFilterFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/stempel/src/java/org/apache/lucene/analysis/stempel/StempelPolishStemFilterFactory.java
@@ -23,7 +23,6 @@
 import org.apache.lucene.analysis.stempel.StempelFilter;
 import org.apache.lucene.analysis.stempel.StempelStemmer;
 import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.ResourceLoaderAware;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 import org.egothor.stemmer.Trie;
@@ -39,11 +38,7 @@ public TokenStream create(TokenStream input) {
     return new StempelFilter(input, new StempelStemmer(stemmer));
   }
 
-  public void inform(ResourceLoader loader) {
-    try {
+  public void inform(ResourceLoader loader) throws IOException {
       stemmer = StempelStemmer.load(loader.openResource(STEMTABLE));
-    } catch (IOException e) {
-      throw new InitializationException("Could not load stem table: " + STEMTABLE, e);
-    }
   }
 }
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMAAnnotationsTokenizerFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMAAnnotationsTokenizerFactory.java
index 3adb65a4..6c0ea377 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMAAnnotationsTokenizerFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMAAnnotationsTokenizerFactory.java
@@ -18,7 +18,6 @@
  */
 
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 import org.apache.lucene.analysis.uima.UIMAAnnotationsTokenizer;
 
@@ -39,7 +38,7 @@ public void init(Map<String, String> args) {
     descriptorPath = args.get("descriptorPath");
     tokenType = args.get("tokenType");
     if (descriptorPath == null || tokenType == null) {
-      throw new InitializationException("Both descriptorPath and tokenType are mandatory");
+      throw new IllegalArgumentException("Both descriptorPath and tokenType are mandatory");
     }
   }
 
diff --git a/lucene/dev/branches/branch_4x/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMATypeAwareAnnotationsTokenizerFactory.java b/lucene/dev/branches/branch_4x/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMATypeAwareAnnotationsTokenizerFactory.java
index 57b51838..031b0341 100644
--- a/lucene/dev/branches/branch_4x/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMATypeAwareAnnotationsTokenizerFactory.java
+++ b/lucene/dev/branches/branch_4x/lucene/analysis/uima/src/java/org/apache/lucene/analysis/uima/UIMATypeAwareAnnotationsTokenizerFactory.java
@@ -19,7 +19,6 @@
 
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.uima.UIMATypeAwareAnnotationsTokenizer;
-import org.apache.lucene.analysis.util.InitializationException;
 import org.apache.lucene.analysis.util.TokenizerFactory;
 
 import java.io.Reader;
@@ -41,7 +40,7 @@ public void init(Map<String, String> args) {
     tokenType = args.get("tokenType");
     featurePath = args.get("featurePath");
     if (descriptorPath == null || tokenType == null || featurePath == null) {
-      throw new InitializationException("descriptorPath, tokenType, and featurePath are mandatory");
+      throw new IllegalArgumentException("descriptorPath, tokenType, and featurePath are mandatory");
     }
   }
 
diff --git a/lucene/dev/branches/branch_4x/solr/core/src/java/org/apache/solr/core/SolrResourceLoader.java b/lucene/dev/branches/branch_4x/solr/core/src/java/org/apache/solr/core/SolrResourceLoader.java
index 5ef63f3b..ea6a4c89 100644
--- a/lucene/dev/branches/branch_4x/solr/core/src/java/org/apache/solr/core/SolrResourceLoader.java
+++ b/lucene/dev/branches/branch_4x/solr/core/src/java/org/apache/solr/core/SolrResourceLoader.java
@@ -604,7 +604,7 @@ public void inform(SolrCore core)
   /**
    * Tell all {@link ResourceLoaderAware} instances about the loader
    */
-  public void inform( ResourceLoader loader ) 
+  public void inform( ResourceLoader loader ) throws IOException
   {
 
      // make a copy to avoid potential deadlock of a callback adding to the list
diff --git a/lucene/dev/branches/branch_4x/solr/core/src/java/org/apache/solr/schema/IndexSchema.java b/lucene/dev/branches/branch_4x/solr/core/src/java/org/apache/solr/schema/IndexSchema.java
index 75edf3ce..e33e83d3 100644
--- a/lucene/dev/branches/branch_4x/solr/core/src/java/org/apache/solr/schema/IndexSchema.java
+++ b/lucene/dev/branches/branch_4x/solr/core/src/java/org/apache/solr/schema/IndexSchema.java
@@ -40,6 +40,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
@@ -109,7 +110,11 @@ public IndexSchema(SolrConfig solrConfig, String name, InputSource is) {
       is.setSystemId(SystemIdResolver.createSystemIdFromResourceName(name));
     }
     readSchema(is);
+    try {
     loader.inform( loader );
+    } catch (IOException e) {
+      throw new RuntimeException(e);
+    }
   }
   
   /**
