diff --git a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
index 4163a8f8..f39f4ffa 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
@@ -30673,7 +30673,7 @@ the source of the yytext() string */
     upperCaseVariantsAccepted.put("amp", "AMP");
   }
   private static final CharArrayMap<Character> entityValues
-      = new CharArrayMap<Character>(Version.LUCENE_40, 253, false);
+      = new CharArrayMap<Character>(Version.LUCENE_CURRENT, 253, false);
   static {
     String[] entities = {
       "AElig", "\u00C6", "Aacute", "\u00C1", "Acirc", "\u00C2",
@@ -30812,7 +30812,7 @@ public HTMLStripCharFilter(Reader source, Set<String> escapedTags) {
           escapeSTYLE = true;
         } else {
           if (null == this.escapedTags) {
-            this.escapedTags = new CharArraySet(Version.LUCENE_40, 16, true);
+            this.escapedTags = new CharArraySet(Version.LUCENE_CURRENT, 16, true);
           }
           this.escapedTags.add(tag);
         }
diff --git a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java
index 815474f2..3db58dd9 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemmer.java
@@ -196,7 +196,7 @@ private int rule3(char s[], int len) {
     return len;
   }
   
-  private static final CharArraySet exc4 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc4 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("θ", "δ", "ελ", "γαλ", "ν", "π", "ιδ", "παρ"),
       false);
   
@@ -222,7 +222,7 @@ private int rule5(char s[], int len) {
     return len;
   }
 
-  private static final CharArraySet exc6 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc6 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αλ", "αδ", "ενδ", "αμαν", "αμμοχαλ", "ηθ", "ανηθ",
           "αντιδ", "φυσ", "βρωμ", "γερ", "εξωδ", "καλπ", "καλλιν", "καταδ",
           "μουλ", "μπαν", "μπαγιατ", "μπολ", "μποσ", "νιτ", "ξικ", "συνομηλ",
@@ -247,7 +247,7 @@ private int rule6(char s[], int len) {
     return len;
   }
   
-  private static final CharArraySet exc7 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc7 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αναπ", "αποθ", "αποκ", "αποστ", "βουβ", "ξεθ", "ουλ",
           "πεθ", "πικρ", "ποτ", "σιχ", "χ"), 
       false);
@@ -274,11 +274,11 @@ else if (len > 5 && (endsWith(s, len, "αγαμε") ||
     return len;
   }
 
-  private static final CharArraySet exc8a = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc8a = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("τρ", "τσ"),
       false);
 
-  private static final CharArraySet exc8b = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc8b = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("βετερ", "βουλκ", "βραχμ", "γ", "δραδουμ", "θ", "καλπουζ",
           "καστελ", "κορμορ", "λαοπλ", "μωαμεθ", "μ", "μουσουλμ", "ν", "ουλ",
           "π", "πελεκ", "πλ", "πολισ", "πορτολ", "σαρακατσ", "σουλτ",
@@ -337,7 +337,7 @@ private int rule8(char s[], int len) {
     return len;
   }
   
-  private static final CharArraySet exc9 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc9 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αβαρ", "βεν", "εναρ", "αβρ", "αδ", "αθ", "αν", "απλ",
           "βαρον", "ντρ", "σκ", "κοπ", "μπορ", "νιφ", "παγ", "παρακαλ", "σερπ",
           "σκελ", "συρφ", "τοκ", "υ", "δ", "εμ", "θαρρ", "θ"), 
@@ -425,11 +425,11 @@ private int rule11(char s[], int len) {
     return len;
   }
 
-  private static final CharArraySet exc12a = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc12a = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("π", "απ", "συμπ", "ασυμπ", "ακαταπ", "αμεταμφ"),
       false);
 
-  private static final CharArraySet exc12b = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc12b = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αλ", "αρ", "εκτελ", "ζ", "μ", "ξ", "παρακαλ", "αρ", "προ", "νισ"),
       false);
   
@@ -449,7 +449,7 @@ private int rule12(char s[], int len) {
     return len;
   }
   
-  private static final CharArraySet exc13 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc13 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("διαθ", "θ", "παρακαταθ", "προσθ", "συνθ"),
       false);
   
@@ -483,7 +483,7 @@ private int rule13(char s[], int len) {
     return len;
   }
   
-  private static final CharArraySet exc14 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc14 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("φαρμακ", "χαδ", "αγκ", "αναρρ", "βρομ", "εκλιπ", "λαμπιδ",
           "λεχ", "μ", "πατ", "ρ", "λ", "μεδ", "μεσαζ", "υποτειν", "αμ", "αιθ",
           "ανηκ", "δεσποζ", "ενδιαφερ", "δε", "δευτερευ", "καθαρευ", "πλε",
@@ -521,7 +521,7 @@ private int rule14(char s[], int len) {
    return len;
   }
   
-  private static final CharArraySet exc15a = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc15a = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("αβαστ", "πολυφ", "αδηφ", "παμφ", "ρ", "ασπ", "αφ", "αμαλ",
           "αμαλλι", "ανυστ", "απερ", "ασπαρ", "αχαρ", "δερβεν", "δροσοπ",
           "ξεφ", "νεοπ", "νομοτ", "ολοπ", "ομοτ", "προστ", "προσωποπ", "συμπ",
@@ -530,7 +530,7 @@ private int rule14(char s[], int len) {
           "ουλαμ", "ουρ", "π", "τρ", "μ"), 
       false);
   
-  private static final CharArraySet exc15b = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc15b = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ψοφ", "ναυλοχ"),
       false);
   
@@ -567,7 +567,7 @@ private int rule15(char s[], int len) {
     return len;
   }
   
-  private static final CharArraySet exc16 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc16 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ν", "χερσον", "δωδεκαν", "ερημον", "μεγαλον", "επταν"),
       false);
   
@@ -587,7 +587,7 @@ private int rule16(char s[], int len) {
     return len;
   }
   
-  private static final CharArraySet exc17 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc17 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ασβ", "σβ", "αχρ", "χρ", "απλ", "αειμν", "δυσχρ", "ευχρ", "κοινοχρ", "παλιμψ"),
       false);
   
@@ -601,7 +601,7 @@ private int rule17(char s[], int len) {
     return len;
   }
   
-  private static final CharArraySet exc18 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc18 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("ν", "ρ", "σπι", "στραβομουτσ", "κακομουτσ", "εξων"),
       false);
   
@@ -625,7 +625,7 @@ private int rule18(char s[], int len) {
     return len;
   }
   
-  private static final CharArraySet exc19 = new CharArraySet(Version.LUCENE_50,
+  private static final CharArraySet exc19 = new CharArraySet(Version.LUCENE_CURRENT,
       Arrays.asList("παρασουσ", "φ", "χ", "ωριοπλ", "αζ", "αλλοσουσ", "ασουσ"),
       false);
   
diff --git a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
index a0d5bc65..8f87d91d 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
@@ -280,10 +280,7 @@ private boolean isCons(int index) {
     DictEntry defaultEntry;
     DictEntry entry;
 
-    CharArrayMap<DictEntry> d = new CharArrayMap<DictEntry>(
-        Version.LUCENE_50, 1000, false);
-    
-    d = new CharArrayMap<DictEntry>(Version.LUCENE_50, 1000, false);
+    CharArrayMap<DictEntry> d = new CharArrayMap<DictEntry>(Version.LUCENE_CURRENT, 1000, false);
     for (int i = 0; i < exceptionWords.length; i++) {
       if (!d.containsKey(exceptionWords[i])) {
         entry = new DictEntry(exceptionWords[i], true);
diff --git a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java
index b0ded28e..ae294828 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemmer.java
@@ -34,7 +34,7 @@
   private final int recursionCap;
   private final HunspellDictionary dictionary;
   private final StringBuilder segment = new StringBuilder();
-  private CharacterUtils charUtils = CharacterUtils.getInstance(Version.LUCENE_40);
+  private CharacterUtils charUtils = CharacterUtils.getInstance(Version.LUCENE_CURRENT);
 
   /**
    * Constructs a new HunspellStemmer which will use the provided HunspellDictionary to create its stems. Uses the 
@@ -324,7 +324,8 @@ public static void main(String[] args) throws IOException, ParseException {
     InputStream affixInputStream = new FileInputStream(args[offset++]);
     InputStream dicInputStream = new FileInputStream(args[offset++]);
 
-    HunspellDictionary dictionary = new HunspellDictionary(affixInputStream, dicInputStream, Version.LUCENE_40, ignoreCase);
+    // :Post-Release-Update-Version.LUCENE_XY:
+    HunspellDictionary dictionary = new HunspellDictionary(affixInputStream, dicInputStream, Version.LUCENE_50, ignoreCase);
 
     affixInputStream.close();
     dicInputStream.close();
diff --git a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java
index ac779812..e3c7a033 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilter.java
@@ -35,7 +35,7 @@
   private final PositionIncrementAttribute posIncAttribute =  addAttribute(PositionIncrementAttribute.class);
   
   // use a fixed version, as we don't care about case sensitivity.
-  private final CharArraySet previous = new CharArraySet(Version.LUCENE_50, 8, false);
+  private final CharArraySet previous = new CharArraySet(Version.LUCENE_CURRENT, 8, false);
 
   /**
    * Creates a new RemoveDuplicatesTokenFilter
diff --git a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java
index 24cfed79..0915d536 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/RSLPStemmerBase.java
@@ -134,7 +134,7 @@ public RuleWithSetExceptions(String suffix, int min, String replacement,
         if (!exceptions[i].endsWith(suffix))
           throw new RuntimeException("useless exception '" + exceptions[i] + "' does not end with '" + suffix + "'");
       }
-      this.exceptions = new CharArraySet(Version.LUCENE_50,
+      this.exceptions = new CharArraySet(Version.LUCENE_CURRENT,
            Arrays.asList(exceptions), false);
     }
 
diff --git a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
index 6aa504b9..8c1de5ae 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilterFactory.java
@@ -133,8 +133,8 @@ public void inform(ResourceLoader loader) throws IOException {
       analyzer = new Analyzer() {
         @Override
         protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-          Tokenizer tokenizer = factory == null ? new WhitespaceTokenizer(Version.LUCENE_50, reader) : factory.create(reader);
-          TokenStream stream = ignoreCase ? new LowerCaseFilter(Version.LUCENE_50, tokenizer) : tokenizer;
+          Tokenizer tokenizer = factory == null ? new WhitespaceTokenizer(Version.LUCENE_CURRENT, reader) : factory.create(reader);
+          TokenStream stream = ignoreCase ? new LowerCaseFilter(Version.LUCENE_CURRENT, tokenizer) : tokenizer;
           return new TokenStreamComponents(tokenizer, stream);
         }
       };
@@ -201,7 +201,7 @@ private TokenizerFactory loadTokenizerFactory(ResourceLoader loader, String cnam
   private Analyzer loadAnalyzer(ResourceLoader loader, String cname) throws IOException {
     Class<? extends Analyzer> clazz = loader.findClass(cname, Analyzer.class);
     try {
-      Analyzer analyzer = clazz.getConstructor(Version.class).newInstance(Version.LUCENE_50);
+      Analyzer analyzer = clazz.getConstructor(Version.class).newInstance(Version.LUCENE_CURRENT);
       if (analyzer instanceof ResourceLoaderAware) {
         ((ResourceLoaderAware) analyzer).inform(loader);
       }
diff --git a/lucene/dev/trunk/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java b/lucene/dev/trunk/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
index e27adbb5..0656c283 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
@@ -60,7 +60,7 @@ public void testDefaults() throws IOException {
 
   public void testStopList() throws IOException {
     CharArraySet stopWordsSet = new CharArraySet(TEST_VERSION_CURRENT, asSet("good", "test", "analyzer"), false);
-    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);
+    StopAnalyzer newStop = new StopAnalyzer(TEST_VERSION_CURRENT, stopWordsSet);
     try (TokenStream stream = newStop.tokenStream("test", "This is a good test of the english stop analyzer")) {
       assertNotNull(stream);
       CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);
diff --git a/lucene/dev/trunk/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java b/lucene/dev/trunk/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
index 383fd706..b363b009 100644
--- a/lucene/dev/trunk/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
+++ b/lucene/dev/trunk/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
@@ -94,7 +94,7 @@ public void testStopPositons() throws IOException {
   // LUCENE-3849: make sure after .end() we see the "ending" posInc
   public void testEndStopword() throws Exception {
     CharArraySet stopSet = StopFilter.makeStopSet(TEST_VERSION_CURRENT, "of");
-    StopFilter stpf = new StopFilter(Version.LUCENE_40, new MockTokenizer(new StringReader("test of"), MockTokenizer.WHITESPACE, false), stopSet);
+    StopFilter stpf = new StopFilter(TEST_VERSION_CURRENT, new MockTokenizer(new StringReader("test of"), MockTokenizer.WHITESPACE, false), stopSet);
     assertTokenStreamContents(stpf, new String[] { "test" },
                               new int[] {0},
                               new int[] {4},
diff --git a/lucene/dev/trunk/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java b/lucene/dev/trunk/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java
index 24087aad..9d0ee64e 100644
--- a/lucene/dev/trunk/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java
+++ b/lucene/dev/trunk/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTask.java
@@ -97,7 +97,8 @@ public int doLogic() throws IOException {
   }
   
   public static IndexWriterConfig createWriterConfig(Config config, PerfRunData runData, OpenMode mode, IndexCommit commit) {
-    Version version = Version.valueOf(config.get("writer.version", Version.LUCENE_40.toString()));
+    // :Post-Release-Update-Version.LUCENE_XY:
+    Version version = Version.valueOf(config.get("writer.version", Version.LUCENE_50.toString()));
     IndexWriterConfig iwConf = new IndexWriterConfig(version, runData.getAnalyzer());
     iwConf.setOpenMode(mode);
     IndexDeletionPolicy indexDeletionPolicy = getIndexDeletionPolicy(config);
diff --git a/lucene/dev/trunk/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java b/lucene/dev/trunk/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
index 3f1d0ccf..4c1c8fd6 100644
--- a/lucene/dev/trunk/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
+++ b/lucene/dev/trunk/lucene/benchmark/src/test/org/apache/lucene/benchmark/byTask/tasks/CreateIndexTaskTest.java
@@ -37,7 +37,8 @@
 
   private PerfRunData createPerfRunData(String infoStreamValue) throws Exception {
     Properties props = new Properties();
-    props.setProperty("writer.version", Version.LUCENE_40.toString());
+    // :Post-Release-Update-Version.LUCENE_XY:
+    props.setProperty("writer.version", Version.LUCENE_50.toString());
     props.setProperty("print.props", "false"); // don't print anything
     props.setProperty("directory", "RAMDirectory");
     if (infoStreamValue != null) {
diff --git a/lucene/dev/trunk/lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java b/lucene/dev/trunk/lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java
index 401da814..5dbea2ee 100644
--- a/lucene/dev/trunk/lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java
+++ b/lucene/dev/trunk/lucene/classification/src/java/org/apache/lucene/classification/utils/DatasetSplitter.java
@@ -69,6 +69,7 @@ public void split(AtomicReader originalIndex, Directory trainingIndex, Directory
                     Analyzer analyzer, String... fieldNames) throws IOException {
 
     // create IWs for train / test / cv IDXs
+    // :Post-Release-Update-Version.LUCENE_XY:
     IndexWriter testWriter = new IndexWriter(testIndex, new IndexWriterConfig(Version.LUCENE_50, analyzer));
     IndexWriter cvWriter = new IndexWriter(crossValidationIndex, new IndexWriterConfig(Version.LUCENE_50, analyzer));
     IndexWriter trainingWriter = new IndexWriter(trainingIndex, new IndexWriterConfig(Version.LUCENE_50, analyzer));
diff --git a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
index 0d54d57f..c4c09248 100644
--- a/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
+++ b/lucene/dev/trunk/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
@@ -50,7 +50,7 @@
  * <pre class="prettyprint">
  *   Directory fsDir = FSDirectory.open(new File("/path/to/index"));
  *   NRTCachingDirectory cachedFSDir = new NRTCachingDirectory(fsDir, 5.0, 60.0);
- *   IndexWriterConfig conf = new IndexWriterConfig(Version.LUCENE_32, analyzer);
+ *   IndexWriterConfig conf = new IndexWriterConfig(Version.LUCENE_50, analyzer);
  *   IndexWriter writer = new IndexWriter(cachedFSDir, conf);
  * </pre>
  *
diff --git a/lucene/dev/trunk/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java b/lucene/dev/trunk/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
index e78649a7..d43c9b38 100644
--- a/lucene/dev/trunk/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
+++ b/lucene/dev/trunk/lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery.java
@@ -217,7 +217,7 @@ public void testPhraseQueryWithStopAnalyzer() throws Exception {
     Directory directory = newDirectory();
     Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);
     RandomIndexWriter writer = new RandomIndexWriter(random(), directory, 
-        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));
+        newIndexWriterConfig(TEST_VERSION_CURRENT, stopAnalyzer));
     Document doc = new Document();
     doc.add(newTextField("field", "the stop words are here", Field.Store.YES));
     writer.addDocument(doc);
diff --git a/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java b/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
index a4abadc2..5f1e48d6 100644
--- a/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
+++ b/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/IndexFiles.java
@@ -86,8 +86,9 @@ public static void main(String[] args) {
       System.out.println("Indexing to directory '" + indexPath + "'...");
 
       Directory dir = FSDirectory.open(new File(indexPath));
-      Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_40);
-      IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_40, analyzer);
+      // :Post-Release-Update-Version.LUCENE_XY:
+      Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_50);
+      IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_50, analyzer);
 
       if (create) {
         // Create a new index in the directory, removing any
diff --git a/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java b/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java
index 7bb22f6c..621ecf48 100644
--- a/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java
+++ b/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/SearchFiles.java
@@ -90,7 +90,8 @@ public static void main(String[] args) throws Exception {
     
     IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(index)));
     IndexSearcher searcher = new IndexSearcher(reader);
-    Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_40);
+    // :Post-Release-Update-Version.LUCENE_XY:
+    Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_50);
 
     BufferedReader in = null;
     if (queries != null) {
@@ -98,7 +99,8 @@ public static void main(String[] args) throws Exception {
     } else {
       in = new BufferedReader(new InputStreamReader(System.in, "UTF-8"));
     }
-    QueryParser parser = new QueryParser(Version.LUCENE_40, field, analyzer);
+    // :Post-Release-Update-Version.LUCENE_XY:
+    QueryParser parser = new QueryParser(Version.LUCENE_50, field, analyzer);
     while (true) {
       if (queries == null && queryString == null) {                        // prompt the user
         System.out.println("Enter query: ");
diff --git a/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java b/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java
index 23113960..ab489800 100644
--- a/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java
+++ b/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/facet/FacetExamples.java
@@ -26,6 +26,7 @@
  */
 public interface FacetExamples {
   
+  // :Post-Release-Update-Version.LUCENE_XY:
   /** The Lucene {@link Version} used by the example code. */
   public static final Version EXAMPLES_VER = Version.LUCENE_50;
 
diff --git a/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java b/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java
index acef8a55..bda9d3f1 100644
--- a/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java
+++ b/lucene/dev/trunk/lucene/demo/src/java/org/apache/lucene/demo/xmlparser/FormBasedXmlQueryDemo.java
@@ -133,7 +133,7 @@ protected void doPost(HttpServletRequest request, HttpServletResponse response)
   private void openExampleIndex() throws IOException {
     //Create a RAM-based index from our test data file
     RAMDirectory rd = new RAMDirectory();
-    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_40, analyzer);
+    IndexWriterConfig iwConfig = new IndexWriterConfig(Version.LUCENE_CURRENT, analyzer);
     IndexWriter writer = new IndexWriter(rd, iwConfig);
     InputStream dataIn = getServletContext().getResourceAsStream("/WEB-INF/data.tsv");
     BufferedReader br = new BufferedReader(new InputStreamReader(dataIn, IOUtils.CHARSET_UTF_8));
diff --git a/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java b/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
index a269f5cc..083e8011 100644
--- a/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
+++ b/lucene/dev/trunk/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyWriter.java
@@ -300,6 +300,7 @@ protected IndexWriterConfig createIndexWriterConfig(OpenMode openMode) {
     // TODO: should we use a more optimized Codec, e.g. Pulsing (or write custom)?
     // The taxonomy has a unique structure, where each term is associated with one document
  
+    // :Post-Release-Update-Version.LUCENE_XY:
     // Make sure we use a MergePolicy which always merges adjacent segments and thus
     // keeps the doc IDs ordered as well (this is crucial for the taxonomy index).
     return new IndexWriterConfig(Version.LUCENE_50, null).setOpenMode(openMode).setMergePolicy(
diff --git a/lucene/dev/trunk/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java b/lucene/dev/trunk/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
index 9f5b6fe6..eaa71db5 100644
--- a/lucene/dev/trunk/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
+++ b/lucene/dev/trunk/lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser.java
@@ -65,7 +65,7 @@ public static void beforeClass() throws Exception {
     BufferedReader d = new BufferedReader(new InputStreamReader(
         TestParser.class.getResourceAsStream("reuters21578.txt"), "US-ASCII"));
     dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(Version.LUCENE_40, analyzer));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer));
     String line = d.readLine();
     while (line != null) {
       int endOfDate = line.indexOf('\t');
diff --git a/lucene/dev/trunk/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java b/lucene/dev/trunk/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
index 797acaea..e901ef7f 100644
--- a/lucene/dev/trunk/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
+++ b/lucene/dev/trunk/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FreeTextSuggester.java
@@ -301,7 +301,7 @@ public void build(InputIterator iterator, double ramBufferSizeMB) throws IOExcep
 
     Directory dir = FSDirectory.open(tempIndexPath);
 
-    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_46, indexAnalyzer);
+    IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_CURRENT, indexAnalyzer);
     iwc.setOpenMode(IndexWriterConfig.OpenMode.CREATE);
     iwc.setRAMBufferSizeMB(ramBufferSizeMB);
     IndexWriter writer = new IndexWriter(dir, iwc);
diff --git a/lucene/dev/trunk/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java b/lucene/dev/trunk/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
index eb12f54e..862a9f45 100644
--- a/lucene/dev/trunk/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
+++ b/lucene/dev/trunk/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
@@ -228,6 +228,7 @@
   // for all suites ever since.
   // -----------------------------------------------------------------
 
+  // :Post-Release-Update-Version.LUCENE_XY:
   /** 
    * Use this constant when creating Analyzers and any other version-dependent stuff.
    * <p><b>NOTE:</b> Change this when development starts for new Lucene version:
diff --git a/lucene/dev/trunk/solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java b/lucene/dev/trunk/solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java
index 7c33a3dd..c1b2ce7c 100644
--- a/lucene/dev/trunk/solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java
+++ b/lucene/dev/trunk/solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField.java
@@ -187,8 +187,7 @@ else if (decomposition.equalsIgnoreCase("canonical"))
       rbc.setVariableTop(variableTop);
     }
 
-    // we use 4.0 because it ensures we just encode the pure byte[] keys.
-    analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_40, collator);
+    analyzer = new ICUCollationKeyAnalyzer(Version.LUCENE_CURRENT, collator);
   }
   
   /**
diff --git a/lucene/dev/trunk/solr/core/src/java/org/apache/solr/schema/CollationField.java b/lucene/dev/trunk/solr/core/src/java/org/apache/solr/schema/CollationField.java
index 5b46159b..891e6736 100644
--- a/lucene/dev/trunk/solr/core/src/java/org/apache/solr/schema/CollationField.java
+++ b/lucene/dev/trunk/solr/core/src/java/org/apache/solr/schema/CollationField.java
@@ -147,8 +147,7 @@ else if (decomposition.equalsIgnoreCase("full"))
       else
         throw new SolrException(ErrorCode.SERVER_ERROR, "Invalid decomposition: " + decomposition);
     }
-    // we use 4.0 because it ensures we just encode the pure byte[] keys.
-    analyzer = new CollationKeyAnalyzer(Version.LUCENE_40, collator);
+    analyzer = new CollationKeyAnalyzer(Version.LUCENE_CURRENT, collator);
   }
   
   /**
diff --git a/lucene/dev/trunk/solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java b/lucene/dev/trunk/solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java
index e07b5ed6..9051bf29 100644
--- a/lucene/dev/trunk/solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java
+++ b/lucene/dev/trunk/solr/core/src/test/org/apache/solr/core/SolrCoreCheckLockOnStartupTest.java
@@ -43,7 +43,7 @@ public void setUp() throws Exception {
     //explicitly creates the temp dataDir so we know where the index will be located
     createTempDir();
 
-    IndexWriterConfig indexWriterConfig = new IndexWriterConfig(Version.LUCENE_40, null);
+    IndexWriterConfig indexWriterConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, null);
     Directory directory = newFSDirectory(new File(dataDir, "index"));
     //creates a new index on the known location
     new IndexWriter(
@@ -58,7 +58,7 @@ public void testSimpleLockErrorOnStartup() throws Exception {
 
     Directory directory = newFSDirectory(new File(dataDir, "index"), new SimpleFSLockFactory());
     //creates a new IndexWriter without releasing the lock yet
-    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(Version.LUCENE_40, null));
+    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, null));
 
     ignoreException("locked");
     try {
@@ -84,7 +84,7 @@ public void testNativeLockErrorOnStartup() throws Exception {
     log.info("Acquiring lock on {}", indexDir.getAbsolutePath());
     Directory directory = newFSDirectory(indexDir, new NativeFSLockFactory());
     //creates a new IndexWriter without releasing the lock yet
-    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(Version.LUCENE_40, null));
+    IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, null));
 
     ignoreException("locked");
     try {
diff --git a/lucene/dev/trunk/solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java b/lucene/dev/trunk/solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
index d16456ef..567b1bec 100644
--- a/lucene/dev/trunk/solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
+++ b/lucene/dev/trunk/solr/core/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
@@ -118,7 +118,7 @@ public void testLoadNewIndexDir() throws IOException, ParserConfigurationExcepti
     Directory dir = newFSDirectory(newDir);
     IndexWriter iw = new IndexWriter(
         dir,
-        new IndexWriterConfig(Version.LUCENE_40, new StandardAnalyzer(Version.LUCENE_40))
+        new IndexWriterConfig(TEST_VERSION_CURRENT, new StandardAnalyzer(TEST_VERSION_CURRENT))
     );
     Document doc = new Document();
     doc.add(new TextField("id", "2", Field.Store.YES));
diff --git a/lucene/dev/trunk/solr/core/src/test/org/apache/solr/search/TestStressLucene.java b/lucene/dev/trunk/solr/core/src/test/org/apache/solr/search/TestStressLucene.java
index 38809f56..f27e363d 100644
--- a/lucene/dev/trunk/solr/core/src/test/org/apache/solr/search/TestStressLucene.java
+++ b/lucene/dev/trunk/solr/core/src/test/org/apache/solr/search/TestStressLucene.java
@@ -101,7 +101,7 @@ public void testStressLuceneNRT() throws Exception {
 
 
     // RAMDirectory dir = new RAMDirectory();
-    // final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(Version.LUCENE_40, new WhitespaceAnalyzer(Version.LUCENE_40)));
+    // final IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)));
 
     Directory dir = newDirectory();
 
diff --git a/lucene/dev/trunk/solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java b/lucene/dev/trunk/solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
index 15ec62f6..69d70ab6 100644
--- a/lucene/dev/trunk/solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
+++ b/lucene/dev/trunk/solr/core/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
@@ -25,7 +25,7 @@
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-import org.apache.lucene.util.Version;
+import org.apache.lucene.util.LuceneTestCase;
 
 import java.util.Collection;
 import java.util.HashSet;
@@ -41,7 +41,7 @@
   @Override
   public Collection<Token> convert(String origQuery) {
     Collection<Token> result = new HashSet<Token>();
-    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);
+    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(LuceneTestCase.TEST_VERSION_CURRENT);
     
     try (TokenStream ts = analyzer.tokenStream("", origQuery)) {
       // TODO: support custom attributes
