diff --git a/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy.java b/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy.java
index 1c5345e8..91e91367 100644
--- a/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy.java
+++ b/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy.java
@@ -21,12 +21,14 @@
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.Future;
 
 import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.store.Directory;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.impl.HttpSolrServer;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
@@ -43,6 +45,7 @@
 import org.apache.solr.common.params.UpdateParams;
 import org.apache.solr.core.CoreContainer;
 import org.apache.solr.core.CoreDescriptor;
+import org.apache.solr.core.DirectoryFactory.DirContext;
 import org.apache.solr.core.RequestHandlers.LazyRequestHandlerWrapper;
 import org.apache.solr.core.SolrCore;
 import org.apache.solr.handler.ReplicationHandler;
@@ -163,6 +166,7 @@ private void replicate(String nodeName, SolrCore core, ZkNodeProps leaderprops)
         RefCounted<SolrIndexSearcher> searchHolder = core
             .getNewestSearcher(false);
         SolrIndexSearcher searcher = searchHolder.get();
+        Directory dir = core.getDirectoryFactory().get(core.getIndexDir(), DirContext.META_DATA, null);
         try {
           log.debug(core.getCoreDescriptor().getCoreContainer()
               .getZkController().getNodeName()
@@ -172,8 +176,12 @@ private void replicate(String nodeName, SolrCore core, ZkNodeProps leaderprops)
               + leaderUrl
               + " gen:"
               + core.getDeletionPolicy().getLatestCommit().getGeneration()
-              + " data:" + core.getDataDir());
+              + " data:" + core.getDataDir()
+              + " index:" + core.getIndexDir()
+              + " newIndex:" + core.getNewIndexDir()
+              + " files:" + Arrays.asList(dir.listAll()));
         } finally {
+          core.getDirectoryFactory().release(dir);
           searchHolder.decref();
         }
       } catch (Exception e) {
diff --git a/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/handler/SnapPuller.java b/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/handler/SnapPuller.java
index 2ed2ff48..836cfed4 100644
--- a/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/handler/SnapPuller.java
+++ b/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/handler/SnapPuller.java
@@ -16,6 +16,7 @@
  */
 package org.apache.solr.handler;
 
+import static org.apache.lucene.util.IOUtils.CHARSET_UTF_8;
 import static org.apache.solr.handler.ReplicationHandler.ALIAS;
 import static org.apache.solr.handler.ReplicationHandler.CHECKSUM;
 import static org.apache.solr.handler.ReplicationHandler.CMD_DETAILS;
@@ -47,6 +48,7 @@
 import java.nio.channels.FileChannel;
 import java.text.SimpleDateFormat;
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Date;
@@ -75,9 +77,6 @@
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
-
-import static org.apache.lucene.util.IOUtils.CHARSET_UTF_8;
-
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.impl.HttpClientUtil;
 import org.apache.solr.client.solrj.impl.HttpSolrServer;
@@ -104,6 +103,7 @@
 import org.apache.solr.util.PropertiesInputStream;
 import org.apache.solr.util.PropertiesOutputStream;
 import org.apache.solr.util.RefCounted;
+import org.eclipse.jetty.util.log.Log;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -388,8 +388,8 @@ boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws I
       fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory("fsyncService"));
       // use a synchronized list because the list is read by other threads (to show details)
       filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());
-      // if the generateion of master is older than that of the slave , it means they are not compatible to be copied
-      // then a new index direcory to be created and all the files need to be copied
+      // if the generation of master is older than that of the slave , it means they are not compatible to be copied
+      // then a new index directory to be created and all the files need to be copied
       boolean isFullCopyNeeded = IndexDeletionPolicyWrapper
           .getCommitTimestamp(commit) >= latestVersion
           || commit.getGeneration() >= latestGeneration || forceReplication;
@@ -408,26 +408,32 @@ boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws I
         if (isIndexStale(indexDir)) {
           isFullCopyNeeded = true;
         }
-        LOG.info("Starting download to " + tmpIndexDir + " fullCopy=" + isFullCopyNeeded);
+        
+        if (!isFullCopyNeeded) {
+          // rollback - and do it before we download any files
+          // so we don't remove files we thought we didn't need
+          // to download later
+          solrCore.getUpdateHandler().getSolrCoreState()
+          .closeIndexWriter(core, true);
+        }
+        try {
+          LOG.info("Starting download to " + tmpIndexDir + " fullCopy="
+              + isFullCopyNeeded);
         successfulInstall = false;
         
-        downloadIndexFiles(isFullCopyNeeded, tmpIndexDir, latestGeneration);
-        LOG.info("Total time taken for download : " + ((System.currentTimeMillis() - replicationStartTime) / 1000) + " secs");
-        Collection<Map<String, Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);
+          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir,
+              latestGeneration);
+          LOG.info("Total time taken for download : "
+              + ((System.currentTimeMillis() - replicationStartTime) / 1000)
+              + " secs");
+          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);
         if (!modifiedConfFiles.isEmpty()) {
           downloadConfFiles(confFilesToDownload, latestGeneration);
           if (isFullCopyNeeded) {
             successfulInstall = modifyIndexProps(tmpIdxDirName);
             deleteTmpIdxDir  =  false;
           } else {
-            solrCore.getUpdateHandler().getSolrCoreState()
-                .closeIndexWriter(core, true);
-            try {
               successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);
-            } finally {
-              solrCore.getUpdateHandler().getSolrCoreState()
-                  .openIndexWriter(core);
-            }
           }
           if (successfulInstall) {
             if (isFullCopyNeeded) {
@@ -441,7 +447,9 @@ boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws I
             }
             
             LOG.info("Configuration files are modified, core will be reloaded");
-            logReplicationTimeAndConfFiles(modifiedConfFiles, successfulInstall);//write to a file time of replication and conf files.
+              logReplicationTimeAndConfFiles(modifiedConfFiles,
+                  successfulInstall);// write to a file time of replication and
+                                     // conf files.
             reloadCore();
           }
         } else {
@@ -450,15 +458,16 @@ boolean fetchLatestIndex(final SolrCore core, boolean forceReplication) throws I
             successfulInstall = modifyIndexProps(tmpIdxDirName);
             deleteTmpIdxDir =  false;
           } else {
-            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);
-            try {
               successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);
-            } finally {
-              solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);
-            }
           }
           if (successfulInstall) {
-            logReplicationTimeAndConfFiles(modifiedConfFiles, successfulInstall);
+              logReplicationTimeAndConfFiles(modifiedConfFiles,
+                  successfulInstall);
+            }
+          }
+        } finally {
+          if (!isFullCopyNeeded) {
+            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);
           }
         }
 
@@ -733,28 +742,27 @@ private void downloadConfFiles(List<Map<String, Object>> confFilesToDownload, lo
    *
    * @param downloadCompleteIndex is it a fresh index copy
    * @param tmpIndexDir               the directory to which files need to be downloadeed to
+   * @param indexDir                 the indexDir to be merged to
    * @param latestGeneration         the version number
    */
   private void downloadIndexFiles(boolean downloadCompleteIndex,
-      Directory tmpIndexDir, long latestGeneration) throws Exception {
-    String indexDir = solrCore.getIndexDir();
-    
-    // it's okay to use null for lock factory since we know this dir will exist
-    Directory dir = solrCore.getDirectoryFactory().get(indexDir, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);
-    try {
+      Directory indexDir, Directory tmpIndexDir, long latestGeneration)
+      throws Exception {
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Download files to dir: " + Arrays.asList(indexDir.listAll()));
+    }
       for (Map<String,Object> file : filesToDownload) {
-        if (!dir.fileExists((String) file.get(NAME)) || downloadCompleteIndex) {
+      if (!indexDir.fileExists((String) file.get(NAME))
+          || downloadCompleteIndex) {
           dirFileFetcher = new DirectoryFileFetcher(tmpIndexDir, file,
               (String) file.get(NAME), false, latestGeneration);
           currentFile = file;
           dirFileFetcher.fetchFile();
           filesDownloaded.add(new HashMap<String,Object>(file));
         } else {
-          LOG.info("Skipping download for " + file.get(NAME) + " because it already exists");
-        }
+        LOG.info("Skipping download for " + file.get(NAME)
+            + " because it already exists");
       }
-    } finally {
-      solrCore.getDirectoryFactory().release(dir);
     }
   }
 
@@ -782,6 +790,7 @@ private boolean isIndexStale(Directory dir) throws IOException {
    * <p/>
    */
   private boolean moveAFile(Directory tmpIdxDir, Directory indexDir, String fname, List<String> copiedfiles) {
+    LOG.debug("Moving file: {}", fname);
     boolean success = false;
     try {
       if (indexDir.fileExists(fname)) {
@@ -805,6 +814,14 @@ private boolean moveAFile(Directory tmpIdxDir, Directory indexDir, String fname,
    * Copy all index files from the temp index dir to the actual index. The segments_N file is copied last.
    */
   private boolean moveIndexFiles(Directory tmpIdxDir, Directory indexDir) {
+    if (LOG.isDebugEnabled()) {
+      try {
+        LOG.info("From dir files:" + Arrays.asList(tmpIdxDir.listAll()));
+        LOG.info("To dir files:" + Arrays.asList(indexDir.listAll()));
+      } catch (IOException e) {
+        throw new RuntimeException(e);
+      }
+    }
     String segmentsFile = null;
     List<String> movedfiles = new ArrayList<String>();
     for (Map<String, Object> f : filesDownloaded) {
diff --git a/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java b/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
index 9e7f0d14..643fe494 100644
--- a/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
+++ b/lucene/dev/branches/lucene_solr_4_6/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
@@ -17,10 +17,22 @@
  * limitations under the License.
  */
 
-import org.apache.http.client.HttpClient;
+import static org.apache.solr.update.processor.DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Set;
+import java.util.concurrent.ExecutorService;
+
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRef;
-import org.apache.solr.client.solrj.impl.HttpClientUtil;
 import org.apache.solr.client.solrj.impl.HttpSolrServer;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.RequestRecovery;
 import org.apache.solr.cloud.CloudDescriptor;
@@ -45,9 +57,7 @@
 import org.apache.solr.common.util.Hash;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.core.CoreDescriptor;
-import org.apache.solr.handler.component.HttpShardHandlerFactory;
 import org.apache.solr.handler.component.RealTimeGetComponent;
-import org.apache.solr.handler.component.ShardHandler;
 import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.request.SolrRequestInfo;
 import org.apache.solr.response.SolrQueryResponse;
@@ -69,20 +79,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Set;
-import java.util.concurrent.ExecutorService;
-
-import static org.apache.solr.update.processor.DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM;
-
 // NOT mt-safe... create a new processor for each add thread
 // TODO: we really should not wait for distrib after local? unless a certain replication factor is asked for
 public class DistributedUpdateProcessor extends UpdateRequestProcessor {
@@ -112,17 +108,6 @@ public static DistribPhase parseParam(final String param) {
     }
   }
   
-  private final HttpClient client;
-  {
-    ModifiableSolrParams params = new ModifiableSolrParams();
-    params.set(HttpClientUtil.PROP_MAX_CONNECTIONS, 10000);
-    params.set(HttpClientUtil.PROP_MAX_CONNECTIONS_PER_HOST, 20);
-    params.set(HttpClientUtil.PROP_CONNECTION_TIMEOUT, 15000);
-    params.set(HttpClientUtil.PROP_SO_TIMEOUT, 60000);
-    params.set(HttpClientUtil.PROP_USE_RETRY, false);
-    client = HttpClientUtil.createClient(params);
-  }
-
   public static final String COMMIT_END_POINT = "commit_end_point";
   public static final String LOG_REPLAY = "log_replay";
   
