diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
index eb8d197f..011cb1bd 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/config/DatabaseDescriptor.java
@@ -47,7 +47,6 @@
 public class DatabaseDescriptor
 {
     private static Logger logger_ = Logger.getLogger(DatabaseDescriptor.class);
-    public static final String STREAMING_SUBDIR = "stream";
 
     // don't capitalize these; we need them to match what's in the config file for CLS.valueOf to parse
     public static enum CommitLogSync {
@@ -712,7 +711,9 @@ public static void createAllDirectories() throws IOException
             {
                 String oneDir = dataFile + File.separator + table;
                 FileUtils.createDirectory(oneDir);
-                File streamingDir = new File(oneDir, STREAMING_SUBDIR);
+
+                // remove the deprecated streaming directory.
+                File streamingDir = new File(oneDir, "stream");
                 if (streamingDir.exists())
                     FileUtils.deleteDir(streamingDir);
             }
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CompactionManager.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CompactionManager.java
index 2ba964b4..ee6cf6b1 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CompactionManager.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CompactionManager.java
@@ -343,13 +343,8 @@ int doCompaction(ColumnFamilyStore cfs, Collection<SSTableReader> sstables, int
         {
             throw new UnsupportedOperationException("disk full");
         }
-        if (target != null)
-        {
-            // compacting for streaming: send to subdirectory
-            compactionFileLocation = compactionFileLocation + File.separator + DatabaseDescriptor.STREAMING_SUBDIR;
-        }
-        List<SSTableReader> results = new ArrayList<SSTableReader>();
 
+        List<SSTableReader> results = new ArrayList<SSTableReader>();
         long startTime = System.currentTimeMillis();
         long totalkeysWritten = 0;
 
@@ -389,7 +384,7 @@ int doCompaction(ColumnFamilyStore cfs, Collection<SSTableReader> sstables, int
 
         if (writer != null)
         {
-            results.add(writer.closeAndOpenReader(DatabaseDescriptor.getKeysCachedFraction(table.name, cfs.getColumnFamilyName())));
+            results.add(writer.closeAndOpenReader(DatabaseDescriptor.getKeysCachedFraction(table.name, cfs.getColumnFamilyName()), target != null));
             String format = "AntiCompacted to %s.  %d/%d bytes for %d keys.  Time: %dms.";
             long dTime = System.currentTimeMillis() - startTime;
             logger.info(String.format(format, writer.getFilename(), SSTable.getTotalBytes(sstables), results.get(0).length(), totalkeysWritten, dTime));
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SSTableWriter.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SSTableWriter.java
index 93245517..341174df 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SSTableWriter.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SSTableWriter.java
@@ -128,10 +128,15 @@ public void append(DecoratedKey decoratedKey, byte[] value) throws IOException
         afterAppend(decoratedKey, currentPosition, value.length);
     }
 
+    public SSTableReader closeAndOpenReader(double cacheFraction) throws IOException
+    {
+        return closeAndOpenReader(cacheFraction, false);
+    }
+
     /**
      * Renames temporary SSTable files to valid data, index, and bloom filter files
      */
-    public SSTableReader closeAndOpenReader(double cacheFraction) throws IOException
+    public SSTableReader closeAndOpenReader(double cacheFraction, boolean temporary) throws IOException
     {
         // bloom filter
         FileOutputStream fos = new FileOutputStream(filterFilename());
@@ -148,9 +153,12 @@ public SSTableReader closeAndOpenReader(double cacheFraction) throws IOException
         // main data
         dataFile.close(); // calls force
 
+        if (!temporary)
+        {
         rename(indexFilename());
         rename(filterFilename());
         path = rename(path); // important to do this last since index & filter file names are derived from it
+        }
 
         InstrumentedCache<DecoratedKey, PositionSize> keyCache = SSTableReader.createKeyCache((int)(cacheFraction * keysWritten));
         return new SSTableReader(path, partitioner, indexPositions, spannedIndexDataPositions, bf, keyCache);
