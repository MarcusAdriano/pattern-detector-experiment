diff --git a/db/derby/code/branches/10.4/java/engine/org/apache/derby/impl/sql/execute/AlterTableConstantAction.java b/db/derby/code/branches/10.4/java/engine/org/apache/derby/impl/sql/execute/AlterTableConstantAction.java
index 81adbc61..d86ec825 100644
--- a/db/derby/code/branches/10.4/java/engine/org/apache/derby/impl/sql/execute/AlterTableConstantAction.java
+++ b/db/derby/code/branches/10.4/java/engine/org/apache/derby/impl/sql/execute/AlterTableConstantAction.java
@@ -1645,6 +1645,12 @@ private void updateIndex(
 			properties.put(
                 "nUniqueColumns", Integer.toString(indexRowLength));
 		}
+		if(cd.getIndexDescriptor().isUniqueWithDuplicateNulls())
+		{
+			properties.put(
+                    "uniqueWithDuplicateNulls", Boolean.toString(true));
+		}
+
 		properties.put(
             "rowLocationColumn", Integer.toString(indexRowLength - 1));
 		properties.put(
diff --git a/db/derby/code/branches/10.4/java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java b/db/derby/code/branches/10.4/java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java
index 70d02c51..88461172 100644
--- a/db/derby/code/branches/10.4/java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java
+++ b/db/derby/code/branches/10.4/java/engine/org/apache/derby/impl/sql/execute/InsertResultSet.java
@@ -1852,6 +1852,11 @@ private void updateAllIndexes(long newHeapConglom,
 				properties.put("nUniqueColumns", 
 							   Integer.toString(indexRowLength));
 			}
+			if(cd.getIndexDescriptor().isUniqueWithDuplicateNulls())
+			{
+				properties.put(
+	                    "uniqueWithDuplicateNulls", Boolean.toString(true));
+			}
 			properties.put("rowLocationColumn", 
 							Integer.toString(indexRowLength - 1));
 			properties.put("nKeyFields", Integer.toString(indexRowLength));
@@ -2326,6 +2331,11 @@ private void emptyIndexes(long newHeapConglom,
 				properties.put("nUniqueColumns", 
 							   Integer.toString(indexRowLength));
 			}
+			if(cd.getIndexDescriptor().isUniqueWithDuplicateNulls())
+			{
+				properties.put(
+	                    "uniqueWithDuplicateNulls", Boolean.toString(true));
+			}
 			properties.put("rowLocationColumn", 
 							Integer.toString(indexRowLength - 1));
 			properties.put("nKeyFields", Integer.toString(indexRowLength));
diff --git a/db/derby/code/branches/10.4/java/testing/org/apache/derbyTesting/functionTests/tests/lang/NullableUniqueConstraintTest.java b/db/derby/code/branches/10.4/java/testing/org/apache/derbyTesting/functionTests/tests/lang/NullableUniqueConstraintTest.java
index 4753dae1..84ec8ba6 100644
--- a/db/derby/code/branches/10.4/java/testing/org/apache/derbyTesting/functionTests/tests/lang/NullableUniqueConstraintTest.java
+++ b/db/derby/code/branches/10.4/java/testing/org/apache/derbyTesting/functionTests/tests/lang/NullableUniqueConstraintTest.java
@@ -21,6 +21,7 @@
 
 package org.apache.derbyTesting.functionTests.tests.lang;
 
+import java.sql.CallableStatement;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
@@ -36,6 +37,7 @@
 import junit.framework.TestSuite;
 
 import org.apache.derbyTesting.junit.BaseJDBCTestCase;
+import org.apache.derbyTesting.junit.SupportFilesSetup;
 import org.apache.derbyTesting.junit.TestConfiguration;
 
 /**
@@ -146,6 +148,30 @@ public void testSingleKeyPartUniqueConstraint() throws SQLException {
         ps.close();
     }
     
+    /**
+     * Compress table should recreate the indexes correctly rather
+     * than ignoring the unique nullable property of the index
+     * @throws SQLException
+     */
+    public void testDerby4677CompressTable() throws SQLException {
+        Connection con = getConnection();
+        Statement stmt = con.createStatement();
+        stmt.executeUpdate("CREATE TABLE TABLE1(NAME1 INT UNIQUE, "+
+        		"name2 int unique not null, name3 int primary key)");
+        stmt.execute("call syscs_util.syscs_compress_table('APP','TABLE1',1)");
+        stmt.executeUpdate("INSERT INTO TABLE1 VALUES(1,11,111)");
+        //following should run into problem because of constraint on name1
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(1,22,222)");
+        //following should run into problem because of constraint on name2
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(3,11,333)");
+        //following should run into problem because of constraint on name3
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(4,44,111)");
+        stmt.executeUpdate("DROP TABLE TABLE1");    
+    }
+    
     /**
      * Basic test of Unique Constraint using multipart part key.
      * @throws SQLException
diff --git a/db/derby/code/branches/10.4/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java b/db/derby/code/branches/10.4/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java
index 3721c6d6..127b77a3 100644
--- a/db/derby/code/branches/10.4/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java
+++ b/db/derby/code/branches/10.4/java/testing/org/apache/derbyTesting/functionTests/tests/tools/ImportExportBinaryDataTest.java
@@ -21,6 +21,7 @@ Licensed to the Apache Software Foundation (ASF) under one or more
  */
 package org.apache.derbyTesting.functionTests.tests.tools;
 
+import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
 import java.sql.SQLException;
@@ -125,6 +126,79 @@ public void testImportTableExportTable()
         verifyData(" * ");
     }
 
+    /**
+     * Bulk insert into a table should recreate the indexes correctly rather
+     * than ignoring the unique nullable property of the index.
+     * In the following test case, we have an empty table in which we are
+     * 	trying to do an import from a file with one row worth's data.
+     * 	This combination used to cause bulk insert functionality to 
+     * 	recreate index incorrectly for unique nullable index. This allowed
+     * 	duplicate rows for unique nullable index. Fix for DERBY-4677 resolves
+     * 	the issue.
+     * @throws SQLException
+     */
+    public void testDerby4677BulkInsertIntoEmptyTable() throws SQLException {
+        Connection con = getConnection();
+        Statement stmt = con.createStatement();
+        stmt.executeUpdate("CREATE TABLE TABLE1(NAME1 INT UNIQUE, "+
+        		"name2 int unique not null, name3 int primary key)");
+        stmt.executeUpdate("INSERT INTO TABLE1 VALUES(1,11,111)");
+        String dataFileName =
+            (SupportFilesSetup.getReadWrite("data_file.dat")).getPath();
+        doExportTable("APP", "TABLE1", dataFileName, null, null, "UTF-16");
+        stmt.executeUpdate("DELETE FROM TABLE1");
+        commit();
+        doImportTable("APP", "TABLE1", dataFileName, null, null, "UTF-16",0);
+        //following should run into problem because of constraint on name1
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(1,22,222)");
+        //following should run into problem because of constraint on name2
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(3,11,333)");
+        //following should run into problem because of constraint on name3
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(4,44,111)");
+        stmt.executeUpdate("DROP TABLE TABLE1");    
+    	SupportFilesSetup.deleteFile(dataFileName);
+    }
+    
+    /**
+     * Bulk insert into a table should recreate the indexes correctly rather
+     * than ignoring the unique nullable property of the index.
+     * In the following test case, we have an empty table in which we are
+     * 	trying to do an import from an empty file with the REPLACE option.
+     * 	This combination used to cause bulk insert functionality to 
+     * 	recreate index incorrectly for unique nullable index. This allowed
+     * 	duplicate rows for unique nullable index. Fix for DERBY-4677 resolves
+     * 	the issue.
+     * @throws SQLException
+     */
+    public void testDerby4677BulkInsertWithReplace() throws SQLException {
+        Connection con = getConnection();
+        Statement stmt = con.createStatement();
+        stmt.executeUpdate("CREATE TABLE TABLE1(NAME1 INT UNIQUE, "+
+        		"name2 int unique not null, name3 int primary key)");
+        String emptyFileName =
+            (SupportFilesSetup.getReadWrite("empty_file.dat")).getPath();
+        //there is no data in TABLE1 so empty_file.dat will be empty 
+        //after export. Using following to just create an empty file
+        doExportTable("APP", "TABLE1", emptyFileName, null, null, "UTF-16");
+        commit();
+        doImportTable("APP", "TABLE1", emptyFileName, null, null, "UTF-16",1);
+        stmt.executeUpdate("INSERT INTO TABLE1 VALUES(1,11,111)");
+        //following should run into problem because of constraint on name1
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(1,22,222)");
+        //following should run into problem because of constraint on name2
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(3,11,333)");
+        //following should run into problem because of constraint on name3
+        assertStatementError("23505", stmt,
+        		"INSERT INTO TABLE1 VALUES(4,44,111)");
+        stmt.executeUpdate("DROP TABLE TABLE1");    
+    	SupportFilesSetup.deleteFile(emptyFileName);
+    }
+
     
     /*
      * Test import/export of all the columns using 
