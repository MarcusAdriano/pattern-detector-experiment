diff --git a/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/DirectoryReader.java b/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/DirectoryReader.java
index 64f77e05..803c29cd 100644
--- a/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/DirectoryReader.java
+++ b/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/DirectoryReader.java
@@ -320,7 +320,10 @@ public String toString() {
     }
     buffer.append(getClass().getSimpleName());
     buffer.append('(');
-    buffer.append(segmentInfos.getCurrentSegmentFileName());
+    final String segmentsFile = segmentInfos.getCurrentSegmentFileName();
+    if (segmentsFile != null) {
+      buffer.append(segmentsFile);
+    }
     if (writer != null) {
       buffer.append(":nrt");
     }
diff --git a/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java b/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
index 31fdaa80..943ae6bb 100644
--- a/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
+++ b/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/DocumentsWriter.java
@@ -545,7 +545,7 @@ synchronized void abort() throws IOException {
       aborting = false;
       notifyAll();
       if (infoStream != null) {
-        message("docWriter: done abort");
+        message("docWriter: done abort; abortedFiles=" + abortedFiles);
       }
     }
   }
@@ -677,6 +677,10 @@ synchronized int flush(boolean closeDocStore) throws IOException {
     return flushState.numDocs;
   }
 
+  Collection<String> getFlushedFiles() {
+    return flushState.flushedFiles;
+  }
+
   /** Build compound file for the segment we just flushed */
   void createCompoundFile(String segment) throws IOException {
     
diff --git a/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/IndexWriter.java
index 909318ef..81a74bde 100644
--- a/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/IndexWriter.java
@@ -403,20 +403,20 @@ IndexReader getReader() throws IOException {
     // this method is called:
     poolReaders = true;
 
-    flush(true, true, false);
-
     // Prevent segmentInfos from changing while opening the
     // reader; in theory we could do similar retry logic,
     // just like we do when loading segments_N
+    IndexReader r;
     synchronized(this) {
-      applyDeletes();
-      final IndexReader r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs);
+      flush(false, true, true);
+      r = new DirectoryReader(this, segmentInfos, config.getReaderTermsIndexDivisor(), codecs);
       if (infoStream != null) {
         message("return reader version=" + r.getVersion() + " reader=" + r);
       }
-      return r;
     }
+    maybeMerge();
 
+    return r;
   }
 
   /** Holds shared SegmentReader instances. IndexWriter uses
@@ -1816,6 +1816,10 @@ private void closeInternal(boolean waitForMerges) throws CorruptIndexException,
    */
   private synchronized boolean flushDocStores() throws IOException {
 
+    if (infoStream != null) {
+      message("flushDocStores segment=" + docWriter.getDocStoreSegment());
+    }
+
     boolean useCompoundDocStore = false;
 
     String docStoreSegment;
@@ -1830,6 +1834,10 @@ private synchronized boolean flushDocStores() throws IOException {
       }
     }
 
+    if (infoStream != null) {
+      message("flushDocStores files=" + docWriter.closedFiles());
+    }
+
     useCompoundDocStore = mergePolicy.useCompoundDocStore(segmentInfos);
       
     if (useCompoundDocStore && docStoreSegment != null && docWriter.closedFiles().size() != 0) {
@@ -2903,7 +2911,7 @@ public void addIndexes(Directory... dirs) throws CorruptIndexException, IOExcept
       List<SegmentInfo> infos = new ArrayList<SegmentInfo>();
       for (Directory dir : dirs) {
         if (infoStream != null) {
-          message("process directory " + dir);
+          message("addIndexes: process directory " + dir);
         }
         SegmentInfos sis = new SegmentInfos(codecs); // read infos from dir
         sis.read(dir, codecs);
@@ -2911,13 +2919,14 @@ public void addIndexes(Directory... dirs) throws CorruptIndexException, IOExcept
         for (SegmentInfo info : sis) {
           assert !infos.contains(info): "dup info dir=" + info.dir + " name=" + info.name;
 
-          if (infoStream != null) {
-            message("process segment=" + info.name);
-          }
           docCount += info.docCount;
           String newSegName = newSegmentName();
           String dsName = info.getDocStoreSegment();
 
+          if (infoStream != null) {
+            message("addIndexes: process segment origName=" + info.name + " newName=" + newSegName + " dsName=" + dsName);
+          }
+
           // Determine if the doc store of this segment needs to be copied. It's
           // only relevant for segments who share doc store with others, because
           // the DS might have been copied already, in which case we just want
@@ -3354,6 +3363,9 @@ private synchronized final boolean doFlushInternal(boolean flushDocStores, boole
 
         try {
           flushedDocCount = docWriter.flush(flushDocStores);
+          if (infoStream != null) {
+            message("flushedFiles=" + docWriter.getFlushedFiles());
+          }
           success = true;
         } finally {
           if (!success) {
@@ -3847,6 +3859,13 @@ else if (next != si.getDocStoreOffset())
       }
     }
 
+    // if a mergedSegmentWarmer is installed, we must merge
+    // the doc stores because we will open a full
+    // SegmentReader on the merged segment:
+    if (!mergeDocStores && mergedSegmentWarmer != null && currentDocStoreSegment != null && lastDocStoreSegment != null && lastDocStoreSegment.equals(currentDocStoreSegment)) {
+      mergeDocStores = true;
+    }
+
     final int docStoreOffset;
     final String docStoreSegment;
     final boolean docStoreIsCompoundFile;
@@ -4107,7 +4126,14 @@ final private int mergeMiddle(MergePolicy.OneMerge merge)
         deleter.incRef(merge.mergeFiles);
       }
 
-      if (poolReaders && mergedSegmentWarmer != null) {
+      final String currentDocStoreSegment = docWriter.getDocStoreSegment();
+      
+      // if the merged segment warmer was not installed when
+      // this merge was started, causing us to not force
+      // the docStores to close, we can't warm it now
+      final boolean canWarm = merge.info.getDocStoreSegment() == null || currentDocStoreSegment == null || !merge.info.getDocStoreSegment().equals(currentDocStoreSegment);
+
+      if (poolReaders && mergedSegmentWarmer != null && canWarm) {
         // Load terms index & doc stores so the segment
         // warmer can run searches, load documents/term
         // vectors
diff --git a/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java b/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
index f9abfabb..c3a4ae0e 100644
--- a/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
+++ b/lucene/dev/trunk/lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriter.java
@@ -50,6 +50,13 @@ public TermsHashConsumerPerThread addThread(TermsHashPerThread termsHashPerThrea
   @Override
   synchronized void flush(Map<TermsHashConsumerPerThread,Collection<TermsHashConsumerPerField>> threadsAndFields, final SegmentWriteState state) throws IOException {
 
+    if (state.numDocsInStore > 0) {
+      // It's possible that all documents seen in this segment
+      // hit non-aborting exceptions, in which case we will
+      // not have yet init'd the TermVectorsWriter:
+      initTermVectorsWriter();
+    }
+
     if (tvx != null) {
 
       if (state.numDocsInStore > 0)
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
index d1b0df9a..52e8a89a 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
@@ -771,19 +771,34 @@ public CommitAndAddIndexes3(int numCopy) throws Throwable {
     void doBody(int j, Directory[] dirs) throws Throwable {
       switch(j%5) {
       case 0:
+        if (VERBOSE) {
+          System.out.println("TEST: " + Thread.currentThread().getName() + ": addIndexes + optimize");
+        }
         writer2.addIndexes(dirs);
         writer2.optimize();
         break;
       case 1:
+        if (VERBOSE) {
+          System.out.println("TEST: " + Thread.currentThread().getName() + ": addIndexes");
+        }
         writer2.addIndexes(dirs);
         break;
       case 2:
+        if (VERBOSE) {
+          System.out.println("TEST: " + Thread.currentThread().getName() + ": addIndexes(IR[])");
+        }
         writer2.addIndexes(readers);
         break;
       case 3:
+        if (VERBOSE) {
+          System.out.println("TEST: " + Thread.currentThread().getName() + ": optimize");
+        }
         writer2.optimize();
         break;
       case 4:
+        if (VERBOSE) {
+          System.out.println("TEST: " + Thread.currentThread().getName() + ": commit");
+        }
         writer2.commit();
       }
     }
@@ -814,15 +829,24 @@ public void testAddIndexesWithCloseNoWait() throws Throwable {
 
     final int NUM_COPY = 50;
     CommitAndAddIndexes3 c = new CommitAndAddIndexes3(NUM_COPY);
+    if (VERBOSE) {
+      c.writer2.setInfoStream(System.out);
+    }
     c.launchThreads(-1);
 
     Thread.sleep(500);
 
     // Close w/o first stopping/joining the threads
+    if (VERBOSE) {
+      System.out.println("TEST: now close(false)");
+    }
     c.close(false);
 
     c.joinThreads();
 
+    if (VERBOSE) {
+      System.out.println("TEST: done join threads");
+    }
     _TestUtil.checkIndex(c.dir2);
 
     c.closeDir();
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
index c549261a..76797124 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
@@ -46,16 +46,24 @@ public void clearDoFail() {
     public void eval(MockDirectoryWrapper dir)  throws IOException {
       if (doFail && (Thread.currentThread().getName().equals("main") 
           || Thread.currentThread().getName().equals("Main Thread"))) {
+        boolean isDoFlush = false;
+        boolean isClose = false;
         StackTraceElement[] trace = new Exception().getStackTrace();
         for (int i = 0; i < trace.length; i++) {
           if ("doFlush".equals(trace[i].getMethodName())) {
+            isDoFlush = true;
+          }
+          if ("close".equals(trace[i].getMethodName())) {
+            isClose = true;
+          }
+        }
+        if (isDoFlush && !isClose) {
             hitExc = true;
             throw new IOException("now failing during flush");
           }
         }
       }
     }
-  }
 
   // Make sure running BG merges still work fine even when
   // we are hitting exceptions during flushing.
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
index 5b2687f7..03d5a958 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
@@ -21,7 +21,6 @@
 import java.io.File;
 import java.io.IOException;
 import java.io.PrintStream;
-import java.io.Reader;
 import java.io.StringReader;
 import java.util.List;
 import java.util.ArrayList;
@@ -36,12 +35,8 @@
 import java.util.concurrent.atomic.AtomicBoolean;
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.CachingTokenFilter;
 import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.analysis.MockTokenFilter;
 import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
@@ -53,7 +48,6 @@
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.Field.TermVector;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
-import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.PhraseQuery;
@@ -64,7 +58,6 @@
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FSDirectory;
-import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.store.Lock;
 import org.apache.lucene.store.LockFactory;
@@ -76,7 +69,6 @@
 import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.ThreadInterruptedException;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.Bits;
 
 public class TestIndexWriter extends LuceneTestCase {
 
@@ -2342,6 +2334,11 @@ public void testCommitThreadSafety() throws Throwable {
     final Directory dir = newDirectory();
     final IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( 
         TEST_VERSION_CURRENT, new MockAnalyzer()));
+    LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();
+    if (lmp.getMergeFactor() > 5) {
+      // reduce risk of too many open files
+      lmp.setMergeFactor(5);
+    }
     w.commit();
     final AtomicBoolean failed = new AtomicBoolean();
     Thread[] threads = new Thread[NUM_THREADS];
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java
index f8850abb..c987aafe 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java
@@ -22,6 +22,7 @@
 import java.util.Collections;
 import java.util.List;
 import java.util.Random;
+import java.util.concurrent.atomic.AtomicBoolean;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -38,7 +39,6 @@
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.ThreadInterruptedException;
@@ -838,6 +838,7 @@ public void testEmptyIndex() throws Exception {
 
   public void testSegmentWarmer() throws Exception {
     Directory dir = newDirectory();
+    final AtomicBoolean didWarm = new AtomicBoolean();
     IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
                                     .setMaxBufferedDocs(2).setReaderPooling(true));
     ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);
@@ -846,6 +847,7 @@ public void warm(IndexReader r) throws IOException {
           final IndexSearcher s = new IndexSearcher(r);
           final TopDocs hits = s.search(new TermQuery(new Term("foo", "bar")), 10);
           assertEquals(20, hits.totalHits);
+          didWarm.set(true);
         }
       });
     
@@ -857,5 +859,6 @@ public void warm(IndexReader r) throws IOException {
     w.waitForMerges();
     w.close();
     dir.close();
+    assertTrue(didWarm.get());
   }
 }
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
index c34b8b95..a9abba28 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
@@ -298,9 +298,18 @@ public FailOnlyOnAbortOrFlush(boolean onlyOnce) {
     public void eval(MockDirectoryWrapper dir)  throws IOException {
       if (doFail) {
         StackTraceElement[] trace = new Exception().getStackTrace();
+        boolean sawAbortOrFlushDoc = false;
+        boolean sawClose = false;
         for (int i = 0; i < trace.length; i++) {
           if ("abort".equals(trace[i].getMethodName()) ||
               "flushDocument".equals(trace[i].getMethodName())) {
+            sawAbortOrFlushDoc = true;
+          }
+          if ("close".equals(trace[i].getMethodName())) {
+            sawClose = true;
+          }
+        }
+        if (sawAbortOrFlushDoc && !sawClose) {
             if (onlyOnce)
               doFail = false;
             //System.out.println(Thread.currentThread().getName() + ": now fail");
@@ -310,7 +319,6 @@ public void eval(MockDirectoryWrapper dir)  throws IOException {
         }
       }
     }
-  }
 
 
 
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
index 5c82159a..f335d406 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/BaseTestRangeFilter.java
@@ -20,18 +20,20 @@
 import java.io.IOException;
 import java.util.Random;
 
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util._TestUtil;
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
+import org.apache.lucene.index.LogMergePolicy;
+import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util._TestUtil;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
+
 import static org.junit.Assert.*;
 
 public class BaseTestRangeFilter extends LuceneTestCase {
@@ -118,6 +120,12 @@ private static IndexReader build(Random random, TestIndex index) throws IOExcept
         newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer())
     .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(_TestUtil.nextInt(random, 50, 1000)));
     
+    LogMergePolicy lmp = (LogMergePolicy) writer.w.getMergePolicy();
+    if (lmp.getMergeFactor() > 5) {
+      // reduce risk of too many open files
+      lmp.setMergeFactor(5);
+    }
+    
     Document doc = new Document();
     Field idField = newField(random, "id", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
     Field randField = newField(random, "rand", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java
index 8c98218b..c8f426b1 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java
@@ -19,14 +19,15 @@
 
 import java.io.IOException;
 
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LogMergePolicy;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.index.SerialMergeScheduler;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -36,6 +37,8 @@ public void testEnforceDeletions() throws Exception {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir,
                                                      newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));
+    // asserts below requires no unexpected merges:
+    ((LogMergePolicy) writer.w.getMergePolicy()).setMergeFactor(10);
 
     // NOTE: cannot use writer.getReader because RIW (on
     // flipping a coin) may give us a newly opened reader,
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
index d3b49674..ce43b068 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
@@ -19,14 +19,15 @@
 
 import java.io.IOException;
 
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.Term;
+import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.index.SerialMergeScheduler;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LogMergePolicy;
 import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.SerialMergeScheduler;
 import org.apache.lucene.index.SlowMultiReaderWrapper;
+import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.OpenBitSet;
@@ -154,6 +155,8 @@ public void testEnforceDeletions() throws Exception {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random, dir,
                                                      newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));
+    // asserts below requires no unexpected merges:
+    ((LogMergePolicy) writer.w.getMergePolicy()).setMergeFactor(10);
 
     // NOTE: cannot use writer.getReader because RIW (on
     // flipping a coin) may give us a newly opened reader,
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockDirectoryWrapper.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockDirectoryWrapper.java
index 8c93a749..3fc6ec09 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockDirectoryWrapper.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockDirectoryWrapper.java
@@ -49,12 +49,12 @@
   boolean trackDiskUsage = false;
   private Set<String> unSyncedFiles;
   private Set<String> createdFiles;
+  Set<String> openFilesForWrite = new HashSet<String>();
   volatile boolean crashed;
 
   // use this for tracking files for crash.
   // additionally: provides debugging information in case you leave one open
-  Map<Closeable,Exception> files
-   = Collections.synchronizedMap(new IdentityHashMap<Closeable,Exception>());
+  Map<Closeable,Exception> openFileHandles = Collections.synchronizedMap(new IdentityHashMap<Closeable,Exception>());
   
   // NOTE: we cannot initialize the Map here due to the
   // order in which our constructor actually does this
@@ -62,9 +62,16 @@
   // like super is called, then our members are initialized:
   Map<String,Integer> openFiles;
 
+  // Only tracked if noDeleteOpenFile is true: if an attempt
+  // is made to delete an open file, we enroll it here.
+  Set<String> openFilesDeleted;
+
   private synchronized void init() {
-    if (openFiles == null)
+    if (openFiles == null) {
       openFiles = new HashMap<String,Integer>();
+      openFilesDeleted = new HashSet<String>();
+    }
+
     if (createdFiles == null)
       createdFiles = new HashSet<String>();
     if (unSyncedFiles == null)
@@ -128,11 +135,13 @@ public synchronized final long sizeInBytes() throws IOException {
   public synchronized void crash() throws IOException {
     crashed = true;
     openFiles = new HashMap<String,Integer>();
+    openFilesForWrite = new HashSet<String>();
+    openFilesDeleted = new HashSet<String>();
     Iterator<String> it = unSyncedFiles.iterator();
     unSyncedFiles = new HashSet<String>();
     // first force-close all files, so we can corrupt on windows etc.
     // clone the file map, as these guys want to remove themselves on close.
-    Map<Closeable,Exception> m = new IdentityHashMap<Closeable,Exception>(files);
+    Map<Closeable,Exception> m = new IdentityHashMap<Closeable,Exception>(openFileHandles);
     for (Closeable f : m.keySet())
       try {
         f.close();
@@ -227,6 +236,21 @@ public synchronized void deleteFile(String name) throws IOException {
     deleteFile(name, false);
   }
 
+  // sets the cause of the incoming ioe to be the stack
+  // trace when the offending file name was opened
+  private synchronized IOException fillOpenTrace(IOException ioe, String name, boolean input) {
+    for(Map.Entry<Closeable,Exception> ent : openFileHandles.entrySet()) {
+      if (input && ent.getKey() instanceof MockIndexInputWrapper && ((MockIndexInputWrapper) ent.getKey()).name.equals(name)) {
+        ioe.initCause(ent.getValue());
+        break;
+      } else if (!input && ent.getKey() instanceof MockIndexOutputWrapper && ((MockIndexOutputWrapper) ent.getKey()).name.equals(name)) {
+        ioe.initCause(ent.getValue());
+        break;
+      }
+    }
+    return ioe;
+  }
+
   private synchronized void deleteFile(String name, boolean forced) throws IOException {
 
     maybeThrowDeterministicException();
@@ -236,14 +260,21 @@ private synchronized void deleteFile(String name, boolean forced) throws IOExcep
 
     if (unSyncedFiles.contains(name))
       unSyncedFiles.remove(name);
-    if (!forced) {
-      if (noDeleteOpenFile && openFiles.containsKey(name)) {
-        throw new IOException("MockDirectoryWrapper: file \"" + name + "\" is still open: cannot delete");
+    if (!forced && noDeleteOpenFile) {
+      if (openFiles.containsKey(name)) {
+        openFilesDeleted.add(name);
+        throw fillOpenTrace(new IOException("MockDirectoryWrapper: file \"" + name + "\" is still open: cannot delete"), name, true);
+      } else {
+        openFilesDeleted.remove(name);
       }
     }
     delegate.deleteFile(name);
   }
 
+  public synchronized Set<String> getOpenDeletedFiles() {
+    return new HashSet<String>(openFilesDeleted);
+  }
+
   @Override
   public synchronized IndexOutput createOutput(String name) throws IOException {
     if (crashed)
@@ -277,8 +308,10 @@ public synchronized IndexOutput createOutput(String name) throws IOException {
         ramdir.fileMap.put(name, file);
       }
     }
+    //System.out.println(Thread.currentThread().getName() + ": MDW: create " + name);
     IndexOutput io = new MockIndexOutputWrapper(this, delegate.createOutput(name), name);
-    files.put(io, new RuntimeException("unclosed IndexOutput"));
+    openFileHandles.put(io, new RuntimeException("unclosed IndexOutput"));
+    openFilesForWrite.add(name);
     return io;
   }
 
@@ -286,7 +319,13 @@ public synchronized IndexOutput createOutput(String name) throws IOException {
   public synchronized IndexInput openInput(String name) throws IOException {
     if (!delegate.fileExists(name))
       throw new FileNotFoundException(name);
-    else {
+
+    // cannot open a file for input if it's still open for
+    // output, except for segments.gen and segments_N
+    if (openFilesForWrite.contains(name) && !name.startsWith("segments")) {
+      throw fillOpenTrace(new IOException("MockDirectoryWrapper: file \"" + name + "\" is still open for writing"), name, false);
+    }
+
       if (openFiles.containsKey(name)) {
         Integer v =  openFiles.get(name);
         v = Integer.valueOf(v.intValue()+1);
@@ -294,10 +333,9 @@ public synchronized IndexInput openInput(String name) throws IOException {
       } else {
          openFiles.put(name, Integer.valueOf(1));
       }
-    }
 
     IndexInput ii = new MockIndexInputWrapper(this, name, delegate.openInput(name));
-    files.put(ii, new RuntimeException("unclosed IndexInput"));
+    openFileHandles.put(ii, new RuntimeException("unclosed IndexInput"));
     return ii;
   }
 
@@ -331,11 +369,12 @@ public final synchronized long getRecomputedActualSizeInBytes() throws IOExcepti
   public synchronized void close() throws IOException {
     if (openFiles == null) {
       openFiles = new HashMap<String,Integer>();
+      openFilesDeleted = new HashSet<String>();
     }
     if (noDeleteOpenFile && openFiles.size() > 0) {
       // print the first one as its very verbose otherwise
       Exception cause = null;
-      Iterator<Exception> stacktraces = files.values().iterator();
+      Iterator<Exception> stacktraces = openFileHandles.values().iterator();
       if (stacktraces.hasNext())
         cause = stacktraces.next();
       // RuntimeException instead of IOException because
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockIndexInputWrapper.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockIndexInputWrapper.java
index 724ca84b..7b3a7a0c 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockIndexInputWrapper.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockIndexInputWrapper.java
@@ -27,7 +27,7 @@
 
 public class MockIndexInputWrapper extends IndexInput {
   private MockDirectoryWrapper dir;
-  private String name;
+  final String name;
   private IndexInput delegate;
   private boolean isClone;
 
@@ -52,12 +52,13 @@ public void close() throws IOException {
         if (v != null) {
           if (v.intValue() == 1) {
             dir.openFiles.remove(name);
+            dir.openFilesDeleted.remove(name);
           } else {
             v = Integer.valueOf(v.intValue()-1);
             dir.openFiles.put(name, v);
           }
         }
-        dir.files.remove(this);
+        dir.openFileHandles.remove(this);
       }
     }
   }
diff --git a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockIndexOutputWrapper.java b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockIndexOutputWrapper.java
index b5c9eb37..9ae960d3 100644
--- a/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockIndexOutputWrapper.java
+++ b/lucene/dev/trunk/lucene/src/test/org/apache/lucene/store/MockIndexOutputWrapper.java
@@ -30,7 +30,7 @@
   private MockDirectoryWrapper dir;
   private final IndexOutput delegate;
   private boolean first=true;
-  private final String name;
+  final String name;
   
   byte[] singleByte = new byte[1];
 
@@ -53,7 +53,10 @@ public void close() throws IOException {
         dir.maxUsedSize = size;
       }
     }
-    dir.files.remove(this);
+    synchronized(dir) {
+      dir.openFileHandles.remove(this);
+      dir.openFilesForWrite.remove(name);
+    }
   }
 
   @Override
