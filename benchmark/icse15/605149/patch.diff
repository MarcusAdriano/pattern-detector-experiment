diff --git a/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordAnalyzer.java b/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordAnalyzer.java
index ede2713c..aaf4b033 100644
--- a/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordAnalyzer.java
+++ b/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordAnalyzer.java
@@ -17,6 +17,7 @@
  * limitations under the License.
  */
 
+import java.io.IOException;
 import java.io.Reader;
 
 /**
@@ -29,12 +30,13 @@ public TokenStream tokenStream(String fieldName,
     return new KeywordTokenizer(reader);
   }
   public TokenStream reusableTokenStream(String fieldName,
-                                         final Reader reader) {
+                                         final Reader reader) throws IOException {
     Tokenizer tokenizer = (Tokenizer) getPreviousTokenStream();
     if (tokenizer == null) {
       tokenizer = new KeywordTokenizer(reader);
       setPreviousTokenStream(tokenizer);
-    }
+    } else
+      	tokenizer.reset(reader);
     return tokenizer;
   }
 }
diff --git a/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordTokenizer.java b/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordTokenizer.java
index 1bcb2818..f1a23ccc 100644
--- a/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordTokenizer.java
+++ b/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordTokenizer.java
@@ -55,4 +55,9 @@ public Token next(Token result) throws IOException {
     }
     return null;
   }
+
+  public void reset(Reader input) throws IOException {
+    super.reset(input);
+    this.done = false;
+  }
 }
diff --git a/lucene/java/trunk/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java b/lucene/java/trunk/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java
index 00ddea90..cfa552b4 100644
--- a/lucene/java/trunk/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java
+++ b/lucene/java/trunk/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java
@@ -18,7 +18,10 @@
  */
 
 import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.TermDocs;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -61,4 +64,22 @@ public void testPerFieldAnalyzer() throws Exception {
               "+partnum:Q36 +space", query.toString("description"));
     assertEquals("doc found!", 1, hits.length());
   }
+
+  public void testMutipleDocument() throws Exception {
+    RAMDirectory dir = new RAMDirectory();
+    IndexWriter writer = new IndexWriter(dir,new KeywordAnalyzer(), true);
+    Document doc = new Document();
+    doc.add(new Field("partnum", "Q36", Field.Store.YES, Field.Index.TOKENIZED));
+    writer.addDocument(doc);
+    doc = new Document();
+    doc.add(new Field("partnum", "Q37", Field.Store.YES, Field.Index.TOKENIZED));
+    writer.addDocument(doc);
+    writer.close();
+
+    IndexReader reader = IndexReader.open(dir);
+    TermDocs td = reader.termDocs(new Term("partnum", "Q36"));
+    assertTrue(td.next());
+    td = reader.termDocs(new Term("partnum", "Q37"));
+    assertTrue(td.next());
+  }
 }
