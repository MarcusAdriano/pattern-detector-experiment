diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFields.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFields.java
index 9487fc9e..7d94bfc5 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFields.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFields.java
@@ -24,7 +24,6 @@
  *  core. */
 class LegacyFields extends Fields {
   private final IndexReader r;
-  private TermEnum terms;
 
   public LegacyFields(IndexReader r) throws IOException {
     this.r = r;
@@ -37,7 +36,6 @@ public FieldsEnum iterator() throws IOException {
 
   @Override
   public Terms terms(String field) throws IOException {
-    // nocommit
     return new LegacyTerms(r, field);
   }
 }
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFieldsEnum.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFieldsEnum.java
index 1088becb..63ff4df5 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFieldsEnum.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFieldsEnum.java
@@ -65,6 +65,7 @@ public TermsEnum terms() throws IOException {
     private final String field;
     private TermEnum terms;
     private TermRef current;
+    private final TermRef tr = new TermRef();
 
     LegacyTermsEnum(IndexReader r, String field) throws IOException {
       this.r = r;
@@ -81,23 +82,26 @@ public TermsEnum terms() throws IOException {
     @Override
     public SeekStatus seek(TermRef text) throws IOException {
 
-      // nocommit: too slow?
+      // nocommit -- should we optimize for "silly seek"
+      // cases, here?  ie seek to term you're already on, to
+      // very next term , etc.
       terms.close();
       terms = r.terms(new Term(field, text.toString()));
+
       final Term t = terms.term();
       if (t == null) {
         current = null;
         return SeekStatus.END;
-      } else {
-        final TermRef tr = new TermRef(t.text());
-        if (text.termEquals(tr)) {
+      } else if (t.field() == field) {
+        tr.copy(t.text());
           current = tr;
+        if (text.termEquals(tr)) {
           return SeekStatus.FOUND;
         } else {
-          // nocommit reuse TermRef instance
-          current = tr;
           return SeekStatus.NOT_FOUND;
         }
+      } else {
+        return SeekStatus.END;
       }
     }
 
@@ -114,8 +118,12 @@ public long ord() throws IOException {
     @Override
     public TermRef next() throws IOException {
       if (terms.next()) {
-        // nocommit -- reuse TermRef instance
-        current = new TermRef(terms.term().text());
+        if (terms.term().field == field) {
+          tr.copy(terms.term().text());
+          current = tr;
+        } else {
+          current = null;
+        }
         return current;
       } else {
         current = null;
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyTerms.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyTerms.java
index 5d8f3599..9cef0174 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyTerms.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyTerms.java
@@ -18,9 +18,10 @@
  * limitations under the License.
  */
 
-
 import java.io.IOException;
 
+import org.apache.lucene.util.StringHelper;
+
 /** Implements flex API (FieldsEnum/TermsEnum) on top of
  *  pre-flex API.  Used only for IndexReader impls outside
  *  Lucene's core. */
@@ -31,7 +32,7 @@
 
   LegacyTerms(IndexReader r, String field) {
     this.r = r;
-    this.field = field;
+    this.field = StringHelper.intern(field);
   }
 
   @Override
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/SegmentReader.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/SegmentReader.java
index 048626d6..67b4ba72 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/SegmentReader.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/SegmentReader.java
@@ -38,8 +38,6 @@
 import org.apache.lucene.util.BitVector;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.CloseableThreadLocal;
-import org.apache.lucene.util.cache.Cache;
-import org.apache.lucene.util.cache.SimpleLRUCache;
 import org.apache.lucene.index.codecs.Codecs;
 import org.apache.lucene.index.codecs.Codec;
 import org.apache.lucene.index.codecs.preflex.PreFlexFields;
@@ -923,31 +921,6 @@ public TermPositions termPositions() throws IOException {
       return new LegacyTermPositions();
   }
 
-  private final CloseableThreadLocal perThread = new CloseableThreadLocal();
-
-  // nocommit -- move term vectors under here
-  private static final class PerThread {
-    LegacyTermEnum terms;
-    
-    // Used for caching the least recently looked-up Terms
-    Cache termsCache;
-  }
-
-  private final static int DEFAULT_TERMS_CACHE_SIZE = 1024;
-
-  private PerThread getPerThread() throws IOException {
-    PerThread resources = (PerThread) perThread.get();
-    if (resources == null) {
-      resources = new PerThread();
-      resources.terms = new LegacyTermEnum(null);
-      // Cache does not have to be thread-safe, it is only used by one thread at the same time
-      resources.termsCache = new SimpleLRUCache(DEFAULT_TERMS_CACHE_SIZE);
-      perThread.set(resources);
-    }
-    return resources;
-  }
-
-  
   @Override
   public int docFreq(Term t) throws IOException {
     ensureOpen();
@@ -1354,13 +1327,14 @@ public int getTermInfosIndexDivisor() {
     TermRef currentTerm;
 
     public LegacyTermEnum(Term t) throws IOException {
-      //System.out.println("sr.lte.init: term=" + t);
+      // System.out.println("sr.lte.init: term=" + t);
       fields = core.fields.iterator();
       currentField = fields.next();
       if (currentField == null) {
+        // no fields
         done = true;
       } else if (t != null) {
-        // Pre-seek
+        // Pre-seek to this term
 
         // nocommit -- inefficient; do we need
         // FieldsEnum.seek? (but this is slow only for
@@ -1375,29 +1349,43 @@ public LegacyTermEnum(Term t) throws IOException {
         }
 
         if (!done) {
-          if (currentField == t.field) {
-            // Field matches -- get terms
+          // We found some field -- get its terms:
             terms = fields.terms();
+
+          if (currentField.equals(t.field)) {
+            // We found exactly the requested field; now
+            // seek the term text:
             String text = t.text();
             TermRef tr;
+
             // this is a hack only for backwards compatibility.
             // previously you could supply a term ending with a lead surrogate,
             // and it would return the next Term.
             // if someone does this, tack on the lowest possible trail surrogate.
             // this emulates the old behavior, and forms "valid UTF-8" unicode.
             if (text.length() > 0 
-                && Character.isHighSurrogate(text.charAt(text.length() - 1)))
+                && Character.isHighSurrogate(text.charAt(text.length() - 1))) {
               tr = new TermRef(t.text() + "\uDC00");
-            else
+            } else {
               tr = new TermRef(t.text());
+            }
             TermsEnum.SeekStatus status = terms.seek(tr);
             if (status == TermsEnum.SeekStatus.END) {
-              // leave currentTerm null
+              // Rollover to the next field
+              terms = null;
+              next();
             } else if (status == TermsEnum.SeekStatus.FOUND) {
+              // Found exactly the term
               currentTerm = tr;
             } else {
+              // Found another term, in this same field
               currentTerm = terms.term();
             }
+          } else {
+            // We didn't find exact field (we found the
+            // following field); advance to first term in
+            // this field
+            next();
           }
         }
       } else {
@@ -1433,7 +1421,8 @@ public boolean next() throws IOException {
           // This field still has terms
           return true;
         } else {
-          // Done producing terms from this field
+          // Done producing terms from this field; advance
+          // to next field
           terms = null;
         }
       }
@@ -1441,11 +1430,9 @@ public boolean next() throws IOException {
 
     @Override
     public Term term() {
-      if (terms != null && !done) {
-        if (currentTerm != null) {
+      if (!done && terms != null && currentTerm != null) {
           return new Term(currentField, currentTerm.toString());
         }
-      }
       return null;
     }
 
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
index 5eaf428d..2c2fda95 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
@@ -58,6 +58,7 @@
   private final int readBufferSize;
   private Directory cfsReader;
 
+  // nocommit -- we need the legacy terms cache back in here
   PreFlexFields(Directory dir, FieldInfos fieldInfos, SegmentInfo info, int readBufferSize, int indexDivisor)
     throws IOException {
 
@@ -364,6 +365,7 @@ public int docFreq() {
 
     @Override
     public DocsEnum docs(Bits skipDocs) throws IOException {
+      // nocommit -- reuse?
       return new PreDocsEnum(skipDocs, terms);
     }
   }
diff --git a/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestFlex.java b/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestFlex.java
index e69de29b..38f779e5 100644
--- a/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestFlex.java
+++ b/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestFlex.java
@@ -0,0 +1,60 @@
+package org.apache.lucene.index;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.*;
+import java.util.*;
+import org.apache.lucene.store.*;
+import org.apache.lucene.search.*;
+import org.apache.lucene.analysis.*;
+import org.apache.lucene.document.*;
+import org.apache.lucene.util.*;
+
+public class TestFlex extends LuceneTestCase {
+
+  // Test non-flex API emulated on flex index
+  public void testNonFlex() throws Exception {
+    Directory d = new MockRAMDirectory();
+
+    final int DOC_COUNT = 177;
+
+    IndexWriter w = new IndexWriter(d, new WhitespaceAnalyzer(),
+                                    IndexWriter.MaxFieldLength.UNLIMITED);
+    w.setMaxBufferedDocs(7);
+    Document doc = new Document();
+    doc.add(new Field("field1", "this is field1", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field2", "this is field2", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field3", "aaa", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field4", "bbb", Field.Store.NO, Field.Index.ANALYZED));
+    for(int i=0;i<DOC_COUNT;i++) {
+      w.addDocument(doc);
+    }
+
+    IndexReader r = w.getReader();
+
+    TermEnum terms = r.terms(new Term("field3", "bbb"));
+    // pre-flex API should seek to the next field
+    assertNotNull(terms.term());
+    assertEquals("field4", terms.term().field());
+
+    r.close();
+    w.close();
+    d.close();
+  }
+}
+
diff --git a/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestFlexExternalReader.java b/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestFlexExternalReader.java
index e69de29b..70d9f133 100644
--- a/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestFlexExternalReader.java
+++ b/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestFlexExternalReader.java
@@ -0,0 +1,182 @@
+package org.apache.lucene.index;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.*;
+import java.util.*;
+import org.apache.lucene.store.*;
+import org.apache.lucene.search.*;
+import org.apache.lucene.analysis.*;
+import org.apache.lucene.document.*;
+import org.apache.lucene.util.*;
+
+public class TestFlexExternalReader extends LuceneTestCase {
+
+  // Delegates to a "normal" IndexReader, making it look
+  // "external", to force testing of the "flex API on
+  // external reader" layer
+  private final static class ExternalReader extends IndexReader {
+    private final IndexReader r;
+    public ExternalReader(IndexReader r) {
+      this.r = r;
+    }
+
+    public TermFreqVector[] getTermFreqVectors(int docNumber) throws IOException {
+      return r.getTermFreqVectors(docNumber);
+    }
+
+    public TermFreqVector getTermFreqVector(int docNumber, String field) throws IOException {
+      return r.getTermFreqVector(docNumber, field);
+    }
+
+    public void getTermFreqVector(int docNumber, String field, TermVectorMapper mapper) throws IOException {
+      r.getTermFreqVector(docNumber, field, mapper);
+    }
+
+    public void getTermFreqVector(int docNumber, TermVectorMapper mapper) throws IOException {
+      r.getTermFreqVector(docNumber, mapper);
+    }
+
+    public int numDocs() {
+      return r.numDocs();
+    }
+
+    public int maxDoc() {
+      return r.maxDoc();
+    }
+
+    public Document document(int n, FieldSelector fieldSelector) throws CorruptIndexException, IOException {
+      return r.document(n, fieldSelector);
+    }
+
+    public boolean isDeleted(int n) {
+      return r.isDeleted(n);
+    }
+
+    public boolean hasDeletions() {
+      return r.hasDeletions();
+    }
+
+    public byte[] norms(String field) throws IOException {
+      return r.norms(field);
+    }
+
+    public void norms(String field, byte[] bytes, int offset) 
+      throws IOException {
+      r.norms(field, bytes, offset);
+    }
+    
+    protected  void doSetNorm(int doc, String field, byte value)
+      throws CorruptIndexException, IOException {
+      r.doSetNorm(doc, field, value);
+    }
+
+    public TermEnum terms() throws IOException {
+      return r.terms();
+    }
+
+    public TermEnum terms(Term t) throws IOException {
+      return r.terms(t);
+    }
+
+    public int docFreq(Term t) throws IOException {
+      return r.docFreq(t);
+    }
+
+    public TermDocs termDocs() throws IOException {
+      return r.termDocs();
+    }
+
+    public TermPositions termPositions() throws IOException {
+      return r.termPositions();
+    }
+
+    public void doDelete(int docID) throws IOException {
+      r.doDelete(docID);
+    }
+
+    public void doUndeleteAll() throws IOException {
+      r.doUndeleteAll();
+    }
+
+    protected void doCommit(Map<String, String> commitUserData) throws IOException {
+      r.doCommit(commitUserData);
+    }
+
+    protected void doClose() throws IOException {
+      r.doClose();
+    }
+
+    public Collection<String> getFieldNames(FieldOption fldOption) {
+      return r.getFieldNames(fldOption);
+    }
+  }
+
+  public void testExternalReader() throws Exception {
+    Directory d = new MockRAMDirectory();
+
+    final int DOC_COUNT = 177;
+
+    IndexWriter w = new IndexWriter(d, new WhitespaceAnalyzer(),
+                                    IndexWriter.MaxFieldLength.UNLIMITED);
+    w.setMaxBufferedDocs(7);
+    Document doc = new Document();
+    doc.add(new Field("field1", "this is field1", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field2", "this is field2", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field3", "aaa", Field.Store.NO, Field.Index.ANALYZED));
+    doc.add(new Field("field4", "bbb", Field.Store.NO, Field.Index.ANALYZED));
+    for(int i=0;i<DOC_COUNT;i++) {
+      w.addDocument(doc);
+    }
+
+    IndexReader r = new ExternalReader(w.getReader());
+
+    TermRef field1Term = new TermRef("field1");
+    TermRef field2Term = new TermRef("field2");
+
+    assertEquals(DOC_COUNT, r.maxDoc());
+    assertEquals(DOC_COUNT, r.numDocs());
+    assertEquals(DOC_COUNT, r.docFreq(new Term("field1", "field1")));
+    assertEquals(DOC_COUNT, r.docFreq("field1", field1Term));
+
+    Fields fields = r.fields();
+    Terms terms = fields.terms("field1");
+    TermsEnum termsEnum = terms.iterator();
+    assertEquals(TermsEnum.SeekStatus.FOUND, termsEnum.seek(field1Term));
+
+    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, termsEnum.seek(field2Term));
+    assertTrue(new TermRef("is").termEquals(termsEnum.term()));
+
+    terms = fields.terms("field2");
+    termsEnum = terms.iterator();
+    assertEquals(TermsEnum.SeekStatus.NOT_FOUND, termsEnum.seek(field1Term));
+    assertTrue(termsEnum.term().termEquals(field2Term));
+
+    assertEquals(TermsEnum.SeekStatus.FOUND, termsEnum.seek(field2Term));
+
+    termsEnum = fields.terms("field3").iterator();
+    assertEquals(TermsEnum.SeekStatus.END, termsEnum.seek(new TermRef("bbb")));
+
+    assertEquals(TermsEnum.SeekStatus.FOUND, termsEnum.seek(new TermRef("aaa")));
+    assertNull(termsEnum.next());
+
+    r.close();
+    w.close();
+    d.close();
+  }
+}
diff --git a/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestStressIndexing2.java b/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestStressIndexing2.java
index badacad6..f696401e 100644
--- a/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestStressIndexing2.java
+++ b/lucene/java/branches/flex_1458/src/test/org/apache/lucene/index/TestStressIndexing2.java
@@ -29,6 +29,8 @@
 
 import junit.framework.TestCase;
 
+// nocommit -- cut test over to flex API, but not too soon
+// (it catches bugs in emulation)
 public class TestStressIndexing2 extends LuceneTestCase {
   static int maxFields=4;
   static int bigFieldSize=10;
