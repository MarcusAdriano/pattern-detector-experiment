diff --git a/lucene/java/trunk/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/java/trunk/src/java/org/apache/lucene/index/IndexWriter.java
index 809df3c9..c193431f 100644
--- a/lucene/java/trunk/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/lucene/java/trunk/src/java/org/apache/lucene/index/IndexWriter.java
@@ -2602,11 +2602,8 @@ synchronized private boolean commitMerge(MergePolicy.OneMerge merge) throws IOEx
     // file that current segments does not reference), we
     // abort this merge
     if (merge.isAborted()) {
-
-      if (infoStream != null) {
-        if (merge.isAborted())
+      if (infoStream != null)
           message("commitMerge: skipping merge " + merge.segString(directory) + ": it was aborted");
-      }
 
       assert merge.increfDone;
       decrefMergeSegments(merge);
@@ -2866,9 +2863,8 @@ final synchronized boolean registerMerge(MergePolicy.OneMerge merge) {
    *  the synchronized lock on IndexWriter instance. */
   final synchronized void mergeInit(MergePolicy.OneMerge merge) throws IOException {
 
-    // Bind a new segment name here so even with
-    // ConcurrentMergePolicy we keep deterministic segment
-    // names.
+    if (merge.isAborted())
+      throw new IOException("merge is aborted");
 
     assert merge.registerDone;
 
@@ -2982,6 +2978,10 @@ else if (next != si.getDocStoreOffset())
     merge.increfDone = true;
 
     merge.mergeDocStores = mergeDocStores;
+
+    // Bind a new segment name here so even with
+    // ConcurrentMergePolicy we keep deterministic segment
+    // names.
     merge.info = new SegmentInfo(newSegmentName(), 0,
                                  directory, false, true,
                                  docStoreOffset,
@@ -3033,6 +3033,7 @@ final private int mergeMiddle(MergePolicy.OneMerge merge)
 
     try {
       int totDocCount = 0;
+
       for (int i = 0; i < numSegments; i++) {
         SegmentInfo si = sourceSegmentsClone.info(i);
         IndexReader reader = SegmentReader.get(si, MERGE_READ_BUFFER_SIZE, merge.mergeDocStores); // no need to set deleter (yet)
@@ -3043,6 +3044,9 @@ final private int mergeMiddle(MergePolicy.OneMerge merge)
         message("merge: total "+totDocCount+" docs");
       }
 
+      if (merge.isAborted())
+        throw new IOException("merge is aborted");
+
       mergedDocCount = merge.info.docCount = merger.merge(merge.mergeDocStores);
 
       assert mergedDocCount == totDocCount;
diff --git a/lucene/java/trunk/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java b/lucene/java/trunk/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
index 5364cf65..2661673c 100644
--- a/lucene/java/trunk/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
+++ b/lucene/java/trunk/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
@@ -19,19 +19,14 @@
 
 import org.apache.lucene.analysis.SimpleAnalyzer;
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.FSDirectory;
 import org.apache.lucene.store.MockRAMDirectory;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.util._TestUtil;
-import org.apache.lucene.util.English;
 
 import org.apache.lucene.util.LuceneTestCase;
 
 import java.io.IOException;
-import java.io.File;
 
 public class TestConcurrentMergeScheduler extends LuceneTestCase {
   
@@ -193,6 +188,7 @@ public void testNoWaitClose() throws IOException {
         ConcurrentMergeScheduler cms = new ConcurrentMergeScheduler();
         writer.setMergeScheduler(cms);
         writer.setMaxBufferedDocs(2);
+        writer.setMergeFactor(100);
 
         for(int j=0;j<201;j++) {
           idField.setValue(Integer.toString(iter*201+j));
@@ -205,10 +201,16 @@ public void testNoWaitClose() throws IOException {
           delID += 5;
         }
 
+        // Force a bunch of merge threads to kick off so we
+        // stress out aborting them on close:
+        writer.setMergeFactor(3);
+        writer.addDocument(doc);
+        writer.flush();
+
         writer.close(false);
 
         IndexReader reader = IndexReader.open(directory);
-        assertEquals((1+iter)*181, reader.numDocs());
+        assertEquals((1+iter)*182, reader.numDocs());
         reader.close();
 
         // Reopen
diff --git a/lucene/java/trunk/src/test/org/apache/lucene/store/MockRAMDirectory.java b/lucene/java/trunk/src/test/org/apache/lucene/store/MockRAMDirectory.java
index 9d335422..f1b75626 100644
--- a/lucene/java/trunk/src/test/org/apache/lucene/store/MockRAMDirectory.java
+++ b/lucene/java/trunk/src/test/org/apache/lucene/store/MockRAMDirectory.java
@@ -146,12 +146,18 @@ public IndexOutput createOutput(String name) throws IOException {
     RAMFile file = new RAMFile(this);
     synchronized (this) {
       RAMFile existing = (RAMFile)fileMap.get(name);
+      // Enforce write once:
+      if (existing!=null && !name.equals("segments.gen"))
+        throw new IOException("file " + name + " already exists");
+      else {
       if (existing!=null) {
         sizeInBytes -= existing.sizeInBytes;
         existing.directory = null;
       }
+
       fileMap.put(name, file);
     }
+    }
 
     return new MockRAMOutputStream(this, file);
   }
