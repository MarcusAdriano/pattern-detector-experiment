diff --git a/db/derby/code/branches/10.1/java/engine/org/apache/derby/iapi/store/access/DiskHashtable.java b/db/derby/code/branches/10.1/java/engine/org/apache/derby/iapi/store/access/DiskHashtable.java
index 5ea3950d..ca1d03c9 100644
--- a/db/derby/code/branches/10.1/java/engine/org/apache/derby/iapi/store/access/DiskHashtable.java
+++ b/db/derby/code/branches/10.1/java/engine/org/apache/derby/iapi/store/access/DiskHashtable.java
@@ -28,17 +28,18 @@
 import org.apache.derby.iapi.services.io.FormatableBitSet;
 import org.apache.derby.iapi.types.DataValueDescriptor;
 import org.apache.derby.iapi.types.SQLInteger;
-import org.apache.derby.impl.store.access.heap.HeapRowLocation;
 import org.apache.derby.iapi.types.RowLocation;
 import org.apache.derby.iapi.services.context.ContextService;
 import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
+import org.apache.derby.iapi.services.sanity.SanityManager;
 
 /**
- * This class is used by BackingStoreHashtable when the BackingStoreHashtable must spill to disk.
- * It implements the methods of a hash table: put, get, remove, elements, however it is not implemented
- * as a hash table. In order to minimize the amount of unique code it is implemented using a Btree and a heap
- * conglomerate. The Btree indexes the hash code of the row key. The actual key may be too long for
- * our Btree implementation.
+ * This class is used by BackingStoreHashtable when the BackingStoreHashtable 
+ * must spill to disk.  It implements the methods of a hash table: put, get, 
+ * remove, elements, however it is not implemented as a hash table. In order to
+ * minimize the amount of unique code it is implemented using a Btree and a 
+ * heap conglomerate. The Btree indexes the hash code of the row key. The 
+ * actual key may be too long for our Btree implementation.
  *
  * Created: Fri Jan 28 13:58:03 2005
  *
@@ -65,12 +66,16 @@
      * Creates a new <code>DiskHashtable</code> instance.
      *
      * @param tc
-     * @param template An array of DataValueDescriptors that serves as a template for the rows.
+     * @param template              An array of DataValueDescriptors that 
+     *                              serves as a template for the rows.
      * @param key_column_numbers The indexes of the key columns (0 based)
-     * @param remove_duplicates If true then rows with duplicate keys are removed
-     * @param keepAfterCommit If true then the hash table is kept after a commit
+     * @param remove_duplicates     If true then rows with duplicate keys are 
+     *                              removed.
+     * @param keepAfterCommit       If true then the hash table is kept after 
+     *                              a commit
      */
-    public DiskHashtable( TransactionController tc,
+    public DiskHashtable( 
+    TransactionController   tc,
                           DataValueDescriptor[] template,
                           int[] key_column_numbers,
                           boolean remove_duplicates,
@@ -81,44 +86,89 @@ public DiskHashtable( TransactionController tc,
         this.key_column_numbers = key_column_numbers;
         this.remove_duplicates = remove_duplicates;
         LanguageConnectionContext lcc = (LanguageConnectionContext)
-				ContextService.getContextOrNull(LanguageConnectionContext.CONTEXT_ID);
+            ContextService.getContextOrNull(
+                LanguageConnectionContext.CONTEXT_ID);
+
         keepStatistics = (lcc != null) && lcc.getRunTimeStatisticsMode();
-        row = new DataValueDescriptor[ template.length];
+
+        // Create template row used for creating the conglomerate and 
+        // fetching rows.
+        row = new DataValueDescriptor[template.length];
         for( int i = 0; i < row.length; i++)
+        {
             row[i] = template[i].getNewNull();
-        int tempFlags = keepAfterCommit ? (TransactionController.IS_TEMPORARY | TransactionController.IS_KEPT)
-          : TransactionController.IS_TEMPORARY;
         
-        rowConglomerateId = tc.createConglomerate( "heap",
+            if (SanityManager.DEBUG)
+            {
+                // must have an object template for all cols in hash overflow.
+                SanityManager.ASSERT(
+                    row[i] != null, 
+                    "Template for the hash table must have non-null object");
+            }
+        }
+
+        int tempFlags = 
+            keepAfterCommit ? 
+            (TransactionController.IS_TEMPORARY | 
+             TransactionController.IS_KEPT) : 
+            TransactionController.IS_TEMPORARY;
+        
+        // create the "base" table of the hash overflow.
+        rowConglomerateId = 
+            tc.createConglomerate( 
+                "heap",
                                                    template,
                                                    (ColumnOrdering[]) null,
                                                    (Properties) null,
                                                    tempFlags);
-        rowConglomerate = tc.openConglomerate( rowConglomerateId,
+
+        // open the "base" table of the hash overflow.
+        rowConglomerate = 
+            tc.openConglomerate( 
+                rowConglomerateId,
                                                keepAfterCommit,
                                                TransactionController.OPENMODE_FORUPDATE,
                                                TransactionController.MODE_TABLE,
-                                               TransactionController.ISOLATION_NOLOCK /* Single thread only */ );
+                TransactionController.ISOLATION_NOLOCK/* Single thread only */);
+
+        // create the index on the "hash" base table.  The key of the index
+        // is the hash code of the row key.  The second column is the 
+        // RowLocation of the row in the "base" table of the hash overflow.
+        btreeRow = 
+            new DataValueDescriptor[] 
+                { new SQLInteger(), rowConglomerate.newRowLocationTemplate()};
 
-        btreeRow = new DataValueDescriptor[] { new SQLInteger(), rowConglomerate.newRowLocationTemplate()};
         Properties btreeProps = new Properties();
-        btreeProps.put( "baseConglomerateId", String.valueOf( rowConglomerateId));
-        btreeProps.put( "rowLocationColumn", "1");
-        btreeProps.put( "allowDuplicates", "false"); // Because the row location is part of the key
-        btreeProps.put( "nKeyFields", "2"); // Include the row location column
-        btreeProps.put( "nUniqueColumns", "2"); // Include the row location column
-        btreeProps.put( "maintainParentLinks", "false");
-        btreeConglomerateId = tc.createConglomerate( "BTREE",
+
+        btreeProps.put("baseConglomerateId", 
+                String.valueOf(rowConglomerateId));
+        btreeProps.put("rowLocationColumn",  
+                "1");
+        btreeProps.put("allowDuplicates",    
+                "false"); // Because the row location is part of the key
+        btreeProps.put("nKeyFields",         
+                "2"); // Include the row location column
+        btreeProps.put("nUniqueColumns",     
+                "2"); // Include the row location column
+        btreeProps.put("maintainParentLinks", 
+                "false");
+        btreeConglomerateId = 
+            tc.createConglomerate( 
+                "BTREE",
                                                      btreeRow,
                                                      (ColumnOrdering[]) null,
                                                      btreeProps,
                                                      tempFlags);
 
-        btreeConglomerate = tc.openConglomerate( btreeConglomerateId,
+        // open the "index" of the hash overflow.
+        btreeConglomerate = 
+            tc.openConglomerate( 
+                btreeConglomerateId,
                                                  keepAfterCommit,
                                                  TransactionController.OPENMODE_FORUPDATE,
                                                  TransactionController.MODE_TABLE,
-                                                 TransactionController.ISOLATION_NOLOCK /* Single thread only */ );
+                TransactionController.ISOLATION_NOLOCK /*Single thread only*/ );
+
     } // end of constructor
 
     public void close() throws StandardException
@@ -135,48 +185,59 @@ public void close() throws StandardException
      * @param row The row to be inserted.
      *
      * @return true if the row was added,
-     *         false if it was not added (because it was a duplicate and we are eliminating duplicates).
+     *         false if it was not added (because it was a duplicate and we 
+     *               are eliminating duplicates).
      *
      * @exception StandardException standard error policy
      */
-    public boolean put( Object key, Object[] row)
+    public boolean put(Object key, Object[] row)
         throws StandardException
     {
         boolean isDuplicate = false;
-        if( remove_duplicates || keepStatistics)
+        if (remove_duplicates || keepStatistics)
         {
             // Go to the work of finding out whether it is a duplicate
-            isDuplicate = (getRemove( key, false, true) != null);
-            if( remove_duplicates && isDuplicate)
+            isDuplicate = (getRemove(key, false, true) != null);
+            if (remove_duplicates && isDuplicate)
                 return false;
         }
-        rowConglomerate.insertAndFetchLocation( (DataValueDescriptor[]) row, (RowLocation) btreeRow[1]);
+
+        // insert the row into the "base" conglomerate.
+        rowConglomerate.insertAndFetchLocation( 
+            (DataValueDescriptor[]) row, (RowLocation) btreeRow[1]);
+
+        // create index row from hashcode and rowlocation just inserted, and
+        // insert index row into index.
         btreeRow[0].setValue( key.hashCode());
         btreeConglomerate.insert( btreeRow);
-        if( keepStatistics && !isDuplicate)
+
+        if (keepStatistics && !isDuplicate)
             size++;
+
         return true;
+
     } // end of put
 
     /**
      * Get a row from the overflow structure.
      *
-     * @param key If the rows only have one key column then the key value. If there is more than one
-     *            key column then a KeyHasher
+     * @param key If the rows only have one key column then the key value. 
+     *            If there is more than one key column then a KeyHasher
      *
      * @return null if there is no corresponding row,
-     *         the row (DataValueDescriptor[]) if there is exactly one row with the key
+     *         the row (DataValueDescriptor[]) if there is exactly one row 
+     *         with the key, or
      *         a Vector of all the rows with the key if there is more than one.
      *
      * @exception StandardException
      */
-    public Object get( Object key)
+    public Object get(Object key)
         throws StandardException
     {
-        return getRemove( key, false, false);
+        return getRemove(key, false, false);
     }
 
-    private Object getRemove( Object key, boolean remove, boolean existenceOnly)
+    private Object getRemove(Object key, boolean remove, boolean existenceOnly)
         throws StandardException
     {
         int hashCode = key.hashCode();
@@ -184,7 +245,9 @@ private Object getRemove( Object key, boolean remove, boolean existenceOnly)
         Object retValue = null;
 
         scanKey[0].setValue( hashCode);
-        ScanController scan = tc.openScan( btreeConglomerateId,
+        ScanController scan = 
+            tc.openScan( 
+                btreeConglomerateId,
                                            false, // do not hold
                                            remove ? TransactionController.OPENMODE_FORUPDATE : 0,
                                            TransactionController.MODE_TABLE,
@@ -197,9 +260,12 @@ private Object getRemove( Object key, boolean remove, boolean existenceOnly)
                                            ScanController.GT);
         try
         {
-            while( scan.fetchNext( btreeRow))
+            while (scan.fetchNext(btreeRow))
             {
-                if( rowConglomerate.fetch( (RowLocation) btreeRow[1], row, (FormatableBitSet) null /* all columns */)
+                if (rowConglomerate.fetch(
+                        (RowLocation) btreeRow[1], 
+                        row, 
+                        (FormatableBitSet) null /* all columns */)
                     && rowMatches( row, key))
                 {
                     if( existenceOnly)
@@ -207,18 +273,29 @@ private Object getRemove( Object key, boolean remove, boolean existenceOnly)
 
                     rowCount++;
                     if( rowCount == 1)
+                    {
+                        // if there is only one matching row just return row. 
                         retValue = BackingStoreHashtable.cloneRow( row);
+                    }
                     else 
                     {
+                        // if there is more than one row, return a vector of
+                        // the rows.
+                        //
                         Vector v;
                         if( rowCount == 2)
                         {
+                            // convert the "single" row retrieved from the
+                            // first trip in the loop, to a vector with the
+                            // first two rows.
                             v = new Vector( 2);
                             v.add( retValue);
                             retValue = v;
                         }
                         else
+                        {
                             v = (Vector) retValue;
+                        }
                         v.add( BackingStoreHashtable.cloneRow( row));
                     }
                     if( remove)
@@ -241,7 +318,8 @@ private Object getRemove( Object key, boolean remove, boolean existenceOnly)
     } // end of getRemove
 
 
-    private boolean rowMatches( DataValueDescriptor[] row,
+    private boolean rowMatches( 
+    DataValueDescriptor[] row,
                                 Object key)
     {
         if( key_column_numbers.length == 1)
