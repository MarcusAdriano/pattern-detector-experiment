diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/analytics/AnalyticsContext.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/analytics/AnalyticsContext.java
index c8889127..945ee3c4 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/analytics/AnalyticsContext.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/analytics/AnalyticsContext.java
@@ -527,7 +527,7 @@ private void timerEvent() throws IOException
 		{
 			Collection<IAnalyticsSource> myUpdaters;
 
-			// we dont need to synchronize as there will not be any
+			// we don't need to synchronize as there will not be any
 			// addition or removal of listeners
 			myUpdaters = new ArrayList<IAnalyticsSource>(updaters);
 
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/cli/CliOptions.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/cli/CliOptions.java
index 177aa8c4..c24bd0bb 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/cli/CliOptions.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/cli/CliOptions.java
@@ -43,7 +43,7 @@
     private static void printUsage()
     {
         System.err.println("");
-        System.err.println("Usage: cascli --host hostname [--port <portname>]");
+        System.err.println("Usage: cassandra-cli --host hostname [--port <portname>]");
         System.err.println("");
     }
 
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/cql/common/SuperColumnRangeQueryRSD.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/cql/common/SuperColumnRangeQueryRSD.java
index 40c3ce54..3423f1d1 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/cql/common/SuperColumnRangeQueryRSD.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/cql/common/SuperColumnRangeQueryRSD.java
@@ -33,7 +33,7 @@
 import org.apache.log4j.Logger;
 
 /**
- * A Row Source Defintion (RSD) for doing a super column range query on a Super Column Family.
+ * A Row Source Definition (RSD) for doing a super column range query on a Super Column Family.
  */
 public class SuperColumnRangeQueryRSD extends RowSourceDef
 {
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
index 0b893f2d..ddaaf91b 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
@@ -536,7 +536,7 @@ public ColumnFamily getColumnFamily(String key, String columnFamilyColumn, IFilt
 
     /**
      * Fetch from disk files and go in sorted order  to be efficient
-     * This fn exits as soon as the required data is found.
+     * This function exits as soon as the required data is found.
      *
      * @param key
      * @param cf
@@ -866,7 +866,7 @@ void doMajorCompaction(long skip) throws IOException
 
     /*
      * Compact all the files irrespective of the size.
-     * skip : is the ammount in Gb of the files to be skipped
+     * skip : is the amount in GB of the files to be skipped
      * all files greater than skip GB are skipped for this compaction.
      * Except if skip is 0 , in that case this is ignored and all files are taken.
      */
@@ -1019,7 +1019,7 @@ boolean doFileAntiCompaction(List<String> files, List<Range> ranges, EndPoint ta
         IPartitioner p = StorageService.getPartitioner();
         // Calculate the expected compacted filesize
         long expectedRangeFileSize = getExpectedCompactedFileSize(files);
-        /* in the worst case a node will be giving out alf of its data so we take a chance */
+        /* in the worst case a node will be giving out half of its data so we take a chance */
         expectedRangeFileSize = expectedRangeFileSize / 2;
         rangeFileLocation = DatabaseDescriptor.getCompactionFileLocation(expectedRangeFileSize);
         // If the compaction file path is null that means we have no space left for this compaction.
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CompactSerializerInvocationHandler.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CompactSerializerInvocationHandler.java
index 9fda1069..e2484a9f 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CompactSerializerInvocationHandler.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CompactSerializerInvocationHandler.java
@@ -25,7 +25,7 @@
 
 
 /*
- * This is the abstraction that pre-processes calls to implmentations
+ * This is the abstraction that pre-processes calls to implementations
  * of the ICompactSerializer2 serialize() via dynamic proxies.
  * Author : Avinash Lakshman ( alakshman@facebook.com) & Prashant Malik ( pmalik@facebook.com )
  */
@@ -40,11 +40,11 @@ public CompactSerializerInvocationHandler(ICompactSerializer2<T> serializer)
     }
 
     /*
-     * This dynamic runtime proxy adds the indexes before the actual coumns are serialized.
+     * This dynamic runtime proxy adds the indexes before the actual columns are serialized.
     */
     public Object invoke(Object proxy, Method m, Object[] args) throws Throwable
     {
-        /* Do the preprocessing here. */
+        /* Do the pre-processing here. */
     	ColumnFamily cf = (ColumnFamily)args[0];
     	DataOutputBuffer bufOut = (DataOutputBuffer)args[1];
     	ColumnIndexer.serialize(cf, bufOut);
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/HintedHandOffManager.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/HintedHandOffManager.java
index 6a765ea2..26c55c78 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/HintedHandOffManager.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/HintedHandOffManager.java
@@ -151,12 +151,12 @@ private static void deliverAllHints(ColumnFamilyStore hintStore) throws DigestMi
           logger_.debug("Started deliverAllHints");
 
         // 1. Scan through all the keys that we need to handoff
-        // 2. For each key read the list of recepients and send
-        // 3. Delete that recepient from the key if write was successful
+        // 2. For each key read the list of recipients and send
+        // 3. Delete that recipient from the key if write was successful
         // 4. If all writes were success for a given key we can even delete the key .
         // 5. Now force a flush
         // 6. Do major compaction to clean up all deletes etc.
-        // 7. I guess we r done
+        // 7. I guess we are done
         for (String tableName : DatabaseDescriptor.getTables())
         {
             ColumnFamily hintColumnFamily = ColumnFamilyStore.removeDeleted(hintStore.getColumnFamily(tableName, HINTS_CF, new IdentityFilter()), Integer.MAX_VALUE);
@@ -197,8 +197,8 @@ private static void deliverHintsToEndpoint(EndPoint endPoint) throws IOException
           logger_.debug("Started hinted handoff for endPoint " + endPoint.getHost());
 
         // 1. Scan through all the keys that we need to handoff
-        // 2. For each key read the list of recepients if teh endpoint matches send
-        // 3. Delete that recepient from the key if write was successful
+        // 2. For each key read the list of recipients if the endpoint matches send
+        // 3. Delete that recipient from the key if write was successful
         Table systemTable = Table.open(Table.SYSTEM_TABLE);
         for (String tableName : DatabaseDescriptor.getTables())
         {
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ReadResponse.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ReadResponse.java
index 2b1061cc..7908705e 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ReadResponse.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ReadResponse.java
@@ -32,7 +32,7 @@
 
 /*
  * The read response message is sent by the server when reading data 
- * this encapsulates the tablename and teh row that has been read.
+ * this encapsulates the tablename and the row that has been read.
  * The table name is needed so that we can use it to create repairs.
  * Author : Avinash Lakshman ( alakshman@facebook.com) & Prashant Malik ( pmalik@facebook.com )
  */
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Row.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Row.java
index 2baf00bf..ee32eba7 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Row.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Row.java
@@ -113,7 +113,7 @@ public boolean isEmpty()
     /*
      * This function will repair the current row with the input row
      * what that means is that if there are any differences between the 2 rows then
-     * this fn will make the current row take the latest changes .
+     * this function will make the current row take the latest changes.
      */
     public void repair(Row rowOther)
     {
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/RowMutation.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/RowMutation.java
index 5594ebfd..a2eae948 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/RowMutation.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/RowMutation.java
@@ -144,12 +144,12 @@ public void add(ColumnFamily columnFamily)
      * the column. Column name is specified as <column family>:column.
      * This will result in a ColumnFamily associated with
      * <column family> as name and a Column with <column>
-     * as name. The columan can be further broken up
+     * as name. The column can be further broken up
      * as super column name : columnname  in case of super columns
      *
      * param @ cf - column name as <column family>:<column>
      * param @ value - value associated with the column
-     * param @ timestamp - ts associated with this data.
+     * param @ timestamp - timestamp associated with this data.
     */
     public void add(String cf, byte[] value, long timestamp)
     {
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Table.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Table.java
index b2dbfac6..ca4ab57e 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Table.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Table.java
@@ -721,7 +721,7 @@ void load(Row row) throws IOException
         List<Iterator<String>> iterators = new ArrayList<Iterator<String>>();
         ColumnFamilyStore cfs = getColumnFamilyStore(columnFamily);
 
-        // we iterate through memtables with a priorityqueue to avoid more sorting than necessary.
+        // we iterate through memtables with a priority queue to avoid more sorting than necessary.
         // this predicate throws out the keys before the start of our range.
         Predicate p = new Predicate()
         {
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/TimeFilter.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/TimeFilter.java
index b5a4a1ab..b86f9253 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/TimeFilter.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/TimeFilter.java
@@ -27,7 +27,7 @@
 
 
 /**
- * This class provides a filter for fitering out columns
+ * This class provides a filter for filtering out columns
  * that are older than a specific time.
  *
  * @author pmalik
@@ -67,8 +67,8 @@ else if (values.length == 2 && columnFamily.isSuper())
         {
             /*
                 * TODO : For super columns we need to re-visit this issue.
-                * For now this fn will set done to true if we are done with
-                * atleast one super column
+                * For now this function will set done to true if we are done with
+                * at least one super column
                 */
             Collection<IColumn> columns = columnFamily.getAllColumns();
             for (IColumn column : columns)
@@ -104,7 +104,7 @@ public IColumn filter(IColumn column, DataInputStream dis) throws IOException
         /*
            * If its a column instance we need the timestamp to verify if
            * it should be filtered , but at this instance the timestamp is not read
-           * so we read the timestamp and set the buffer back so that the rest of desrialization
+           * so we read the timestamp and set the buffer back so that the rest of deserialization
            * logic does not change.
            */
         if (column instanceof Column)
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/WriteResponse.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/WriteResponse.java
index 66433389..96737b15 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/WriteResponse.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/WriteResponse.java
@@ -34,7 +34,7 @@
 
 /*
  * This message is sent back the row mutation verb handler 
- * and basically specifes if the write succeeded or not for a particular 
+ * and basically specifies if the write succeeded or not for a particular 
  * key in a table
  * Author : Avinash Lakshman ( alakshman@facebook.com) & Prashant Malik ( pmalik@facebook.com )
  */
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/dht/BootStrapper.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/dht/BootStrapper.java
index d82d3436..592c6157 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/dht/BootStrapper.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/dht/BootStrapper.java
@@ -35,7 +35,7 @@
 
 
 /**
- * This class handles the boostrapping responsibilities for
+ * This class handles the bootstrapping responsibilities for
  * any new endpoint.
 */
 public class BootStrapper implements Runnable
@@ -43,7 +43,7 @@
     private static Logger logger_ = Logger.getLogger(BootStrapper.class);
     /* endpoints that need to be bootstrapped */
     protected EndPoint[] targets_ = new EndPoint[0];
-    /* tokens of the nodes being bootstapped. */
+    /* tokens of the nodes being bootstrapped. */
     protected final Token[] tokens_;
     protected TokenMetadata tokenMetadata_ = null;
     private List<EndPoint> filters_ = new ArrayList<EndPoint>();
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/dht/LeaveJoinProtocolImpl.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/dht/LeaveJoinProtocolImpl.java
index 2967d9bb..1b3874cf 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/dht/LeaveJoinProtocolImpl.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/dht/LeaveJoinProtocolImpl.java
@@ -36,7 +36,7 @@
 
 /**
  * This class performs the exact opposite of the
- * operations of the Bootstrapper class. Given 
+ * operations of the BootStrapper class. Given 
  * a bunch of nodes that need to move it determines 
  * who they need to hand off data in terms of ranges.
 */
@@ -209,7 +209,7 @@ private void removeExpandedRangesFromNewConfiguration(Map<Range, List<EndPoint>>
     /**
      * Here we are removing the nodes that need to leave the
      * ring and trying to calculate what the ranges would look
-     * like w/o them. For eg if we remove two nodes A and D from
+     * like w/o them. e.g. if we remove two nodes A and D from
      * the ring and the order of nodes on the ring is A, B, C
      * and D. When B is removed the range of C is the old range 
      * of C and the old range of B. We want a mapping from old
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/ApplicationState.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/ApplicationState.java
index fc14a431..e1c57ff0 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/ApplicationState.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/ApplicationState.java
@@ -31,12 +31,12 @@
 /**
  * This abstraction represents the state associated with a particular node which an
  * application wants to make available to the rest of the nodes in the cluster. 
- * Whenever a peice of state needs to be disseminated to the rest of cluster wrap
+ * Whenever a piece of state needs to be disseminated to the rest of cluster wrap
  * the state in an instance of <i>ApplicationState</i> and add it to the Gossiper.
  *  
- * For eg. if we want to disseminate load information for node A do the following:
+ * e.g. if we want to disseminate load information for node A do the following:
  * 
- *      ApplicationState loadState = new ApplicationState(<string reprensentation of load>);
+ *      ApplicationState loadState = new ApplicationState(<string representation of load>);
  *      Gossiper.instance().addApplicationState("LOAD STATE", loadState);
  *  
  * Author : Avinash Lakshman ( alakshman@facebook.com) & Prashant Malik ( pmalik@facebook.com )
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/FailureDetector.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/FailureDetector.java
index ede0020b..d8d69bcc 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/FailureDetector.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/FailureDetector.java
@@ -49,7 +49,7 @@
     private static final int sampleSize_ = 1000;
     private static final int phiSuspectThreshold_ = 5;
     private static final int phiConvictThreshold_ = 8;
-    /* The Failure Detector has to have been up for atleast 1 min. */
+    /* The Failure Detector has to have been up for at least 1 min. */
     private static final long uptimeThreshold_ = 60000;
     private static IFailureDetector failureDetector_;
     /* Used to lock the factory for creation of FailureDetector instance */
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/Gossiper.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/Gossiper.java
index 6a806c69..12d361f5 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/Gossiper.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/Gossiper.java
@@ -205,7 +205,7 @@ public void convict(EndPoint endpoint)
             {
                 /*
                  * just to be sure - is invoked just to make sure that
-                 * it was called atleast once.
+                 * it was called at least once.
                 */
                 if ( liveEndpoints_.contains(endpoint) )
                 {
@@ -870,7 +870,7 @@ synchronized void examineGossiper(List<GossipDigest> gDigestList, List<GossipDig
             }
             else
             {
-                /* We are here since we have no data for this endpoint locally so request everthing. */
+                /* We are here since we have no data for this endpoint locally so request everything. */
                 requestAll(gDigest, deltaGossipDigestList, remoteGeneration);
             }
         }
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/IEndPointStateChangeSubscriber.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/IEndPointStateChangeSubscriber.java
index 8b8709dd..2e0a12b2 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/IEndPointStateChangeSubscriber.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/gms/IEndPointStateChangeSubscriber.java
@@ -37,7 +37,7 @@
      * Use to inform interested parties about the change in the state
      * for specified endpoint
      * 
-     * @param endpoint endpoint for which the state change occured.
+     * @param endpoint endpoint for which the state change occurred.
      * @param epState state that actually changed for the above endpoint.
      */
     public void onChange(EndPoint endpoint, EndPointState epState);
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/IndexHelper.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/IndexHelper.java
index b6c7b6cb..28a76be5 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/IndexHelper.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/IndexHelper.java
@@ -272,8 +272,8 @@ static ColumnRange getColumnRangeFromTimeIndex(IndexHelper.TimeRange timeRange,
         int numColumns = 0;      
        
         /*
-         *  Time indicies are sorted in descending order. So
-         *  we need to apply a reverse compartor for the 
+         *  Time indices are sorted in descending order. So
+         *  we need to apply a reverse comparator for the 
          *  binary search.        
         */        
         Comparator<IndexHelper.ColumnIndexInfo> comparator = Collections.reverseOrder(); 
@@ -297,7 +297,7 @@ static ColumnRange getColumnRangeFromTimeIndex(IndexHelper.TimeRange timeRange,
          * lower timestamp in the time range.      
         */
         start = (index == 0) ? 0 : columnIndexList.get(index - 1).position();
-        /* add the number of colunms in the first chunk. */
+        /* add the number of columns in the first chunk. */
         numColumns += (index ==0) ? columnIndexList.get(0).count() : columnIndexList.get(index - 1).count(); 
         if( index < size )
         {            
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SequenceFile.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SequenceFile.java
index 15902d44..0b38fdcc 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SequenceFile.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/io/SequenceFile.java
@@ -31,7 +31,7 @@
 import org.apache.log4j.Logger;
 
 /**
- * This class writes key/value pairs seqeuntially to disk. It is
+ * This class writes key/value pairs sequentially to disk. It is
  * also used to read sequentially from disk. However one could
  * jump to random positions to read data from the file. This class
  * also has many implementations of the IFileWriter and IFileReader
@@ -544,7 +544,7 @@ private void readTimeRange(String key, DataOutputBuffer bufOut, String columnFam
             int bytesSkipped = IndexHelper.skipBloomFilter(file_);
             /*
              * read the correct number of bytes for the column family and
-             * write data into buffer. Substract from dataSize the bloom
+             * write data into buffer. Subtract from dataSize the bloom
              * filter size.
             */
             dataSize -= bytesSkipped;
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/IMessagingService.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/IMessagingService.java
index 7b66967c..8fd9b816 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/IMessagingService.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/IMessagingService.java
@@ -94,8 +94,8 @@
      * @param message message to be sent.
      * @param to endpoint to which the message needs to be sent
      * @param cb callback interface which is used to pass the responses or
-     *           suggest that a timeout occured to the invoker of the send().
-     *           suggest that a timeout occured to the invoker of the send().
+     *           suggest that a timeout occurred to the invoker of the send().
+     *           suggest that a timeout occurred to the invoker of the send().
      * @return an reference to message id used to match with the result
      */
     public String sendRR(Message message, EndPoint to, IAsyncCallback cb);
@@ -163,9 +163,9 @@
      * Stream a file from source to destination. This is highly optimized
      * to not hold any of the contents of the file in memory.
      * @param file name of file to stream.
-     * param start position inside the file
-     * param total number of bytes to stream
-     * param to endpoint to which we need to stream the file.
+     * @param startPosition position inside the file
+     * @param total number of bytes to stream
+     * @param to endpoint to which we need to stream the file.
     */
     public void stream(String file, long startPosition, long total, EndPoint from, EndPoint to);
 
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/SelectorManager.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/SelectorManager.java
index bffba9ae..388d5a0e 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/SelectorManager.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/SelectorManager.java
@@ -60,10 +60,10 @@ private SelectorManager(String name)
     /**
      * Registers a new channel with the selector, and attaches the given
      * SelectionKeyHandler as the handler for the newly created key. Operations
-     * which the hanlder is interested in will be called as available.
+     * which the handler is interested in will be called as available.
      * 
      * @param channel
-     *            The channel to regster with the selector
+     *            The channel to register with the selector
      * @param handler
      *            The handler to use for the callbacks
      * @param ops
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/TcpConnection.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/TcpConnection.java
index 3ea8de75..cfeb3cd0 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/TcpConnection.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/net/TcpConnection.java
@@ -497,7 +497,7 @@ private void handleException(Throwable th)
         {
             logger_.warn("Problem reading from socket connected to : " + socketChannel_);
             logger_.warn(LogUtil.throwableToString(th));
-            // This is to fix the wierd Linux bug with NIO.
+            // This is to fix the weird Linux bug with NIO.
             errorClose();
         }
     }
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/MultiQuorumResponseHandler.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/MultiQuorumResponseHandler.java
index 37ab3a4c..f9ad796e 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/MultiQuorumResponseHandler.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/MultiQuorumResponseHandler.java
@@ -111,7 +111,7 @@ private void onCompletion() throws IOException
             {
                 /* 
                  * The DigestMismatchException has the key for which the mismatch
-                 * occured bundled in it as context 
+                 * occurred bundled in it as context 
                 */
                 String key = ex.getMessage();
                 onDigestMismatch(key);
@@ -123,7 +123,7 @@ private void onCompletion() throws IOException
          * in order to retrieve the appropriate data message that needs
          * to be sent out to the replicas. 
          * 
-         * @param key for which the mismatch occured.
+         * @param key for which the mismatch occurred.
         */
         private void onDigestMismatch(String key) throws IOException
         {
@@ -211,7 +211,7 @@ void onCompleteResponse(Row row)
      * The handler of the response message that has been
      * sent by one of the replicas for one of the keys.
      * 
-     * @param message the reponse message for one of the
+     * @param message the response message for one of the
      *        message that we sent out.
      */
     public void response(Message message)
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/ReadRepairManager.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/ReadRepairManager.java
index a24509d4..8ad2cc23 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/ReadRepairManager.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/ReadRepairManager.java
@@ -45,8 +45,8 @@
  * it basically uses the cache table construct to schedule writes that have to be 
  * made for read repairs. 
  * A cachetable is created which wakes up every n  milliseconds specified by 
- * expirationTimeInMillis and calls a global hook fn on pending entries 
- * This fn basically sends the message to the appropriate servers to update them
+ * expirationTimeInMillis and calls a global hook function on pending entries 
+ * This function basically sends the message to the appropriate servers to update them
  * with the latest changes.
  * Author : Avinash Lakshman ( alakshman@facebook.com) & Prashant Malik ( pmalik@facebook.com )
  */
@@ -59,13 +59,13 @@
 
 	/*
 	 * This is the internal class which actually
-	 * implements the global hook fn called by the readrepair manager
+	 * implements the global hook function called by the read repair manager
 	 */
 	static class ReadRepairPerformer implements
 			ICacheExpungeHook<String, Message>
 	{
 		/*
-		 * The hook fn which takes the end point and the row mutation that 
+		 * The hook function which takes the end point and the row mutation that 
 		 * needs to be sent to the end point in order 
 		 * to perform read repair.
 		 */
@@ -106,7 +106,7 @@ public  static ReadRepairManager instance()
 
 	/*
 	 * Schedules a read repair.
-	 * @param target endpoint on whcih the read repair should happen
+	 * @param target endpoint on which the read repair should happen
 	 * @param rowMutationMessage the row mutation message that has the repaired row.
 	 */
 	public void schedule(EndPoint target, RowMutationMessage rowMutationMessage)
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/ReadResponseResolver.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/ReadResponseResolver.java
index a4938db2..7d13af79 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/ReadResponseResolver.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/ReadResponseResolver.java
@@ -39,8 +39,8 @@
 
 /**
  * This class is used by all read functions and is called by the Quorum 
- * when atleast a few of the servers ( few is specified in Quorum)
- * have sent the response . The resolve fn then schedules read repair 
+ * when at least a few of the servers (few is specified in Quorum)
+ * have sent the response . The resolve function then schedules read repair 
  * and resolution of read data from the various servers.
  * Author : Avinash Lakshman ( alakshman@facebook.com) & Prashant Malik ( pmalik@facebook.com )
  */
@@ -129,7 +129,7 @@ public Row resolve(List<Message> responses) throws DigestMismatchException
 		}
 
         // At  this point  we have the return row .
-		// Now we need to calculate the differnce 
+		// Now we need to calculate the difference 
 		// so that we can schedule read repairs 
 		for (int i = 0 ; i < rowList.size(); i++)
 		{
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageLoadBalancer.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageLoadBalancer.java
index 676e705f..a45b7128 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageLoadBalancer.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageLoadBalancer.java
@@ -51,7 +51,7 @@
  * This class keeps track of load information across the system.
  * It registers itself with the Gossiper for ApplicationState namely
  * load information i.e number of requests processed w.r.t distinct
- * keys at an Endpoint. Monitor load infomation for a 5 minute
+ * keys at an Endpoint. Monitor load information for a 5 minute
  * interval and then do load balancing operations if necessary.
  * 
  * Author : Avinash Lakshman ( alakshman@facebook.com) & Prashant Malik ( pmalik@facebook.com )
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageProxy.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageProxy.java
index ce376f10..db238500 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageProxy.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageProxy.java
@@ -371,10 +371,10 @@ public static Row readProtocol(ReadCommand command, StorageService.ConsistencyLe
         // 1. Get the N nodes from storage service where the data needs to be
         // replicated
         // 2. Construct a message for read\write
-         * 3. Set one of teh messages to get teh data and teh rest to get teh digest
+         * 3. Set one of the messages to get the data and the rest to get the digest
         // 4. SendRR ( to all the nodes above )
-        // 5. Wait for a response from atleast X nodes where X <= N and teh data node
-         * 6. If the digest matches return teh data.
+        // 5. Wait for a response from at least X nodes where X <= N and the data node
+         * 6. If the digest matches return the data.
          * 7. else carry out read repair by getting data from all the nodes.
         // 5. return success
      */
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java
index 1e419ad0..1bdc37a9 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java
@@ -520,7 +520,7 @@ public void updateToken(Token token) throws IOException
      * This method removes the state associated with this endpoint
      * from the TokenMetadata instance.
      * 
-     *  param@ endpoint remove the token state associated with this 
+     *  @param endpoint remove the token state associated with this 
      *         endpoint.
      */
     public void removeTokenState(EndPoint endpoint) 
@@ -845,8 +845,8 @@ public Range getPrimaryRangeForEndPoint(EndPoint ep)
      * This method returns the endpoint that is responsible for storing the
      * specified key.
      *
-     * param @ key - key for which we need to find the endpoint
-     * return value - the endpoint responsible for this key
+     * @param key - key for which we need to find the endpoint
+     * @return value - the endpoint responsible for this key
      */
     public EndPoint getPrimary(String key)
     {
@@ -894,7 +894,7 @@ public boolean isPrimary(String key)
      * This method returns the N endpoints that are responsible for storing the
      * specified key i.e for replication.
      *
-     * param @ key - key for which we need to find the endpoint return value -
+     * @param key - key for which we need to find the endpoint return value -
      * the endpoint responsible for this key
      */
     public EndPoint[] getNStorageEndPoint(String key)
@@ -912,7 +912,7 @@ public boolean isPrimary(String key)
      * This method attempts to return N endpoints that are responsible for storing the
      * specified key i.e for replication.
      *
-     * param @ key - key for which we need to find the endpoint return value -
+     * @param key - key for which we need to find the endpoint return value -
      * the endpoint responsible for this key
      */
     public List<EndPoint> getNLiveStorageEndPoint(String key)
@@ -933,7 +933,7 @@ public boolean isPrimary(String key)
      * This method returns the N endpoints that are responsible for storing the
      * specified key i.e for replication.
      *
-     * param @ key - key for which we need to find the endpoint return value -
+     * @param key - key for which we need to find the endpoint return value -
      * the endpoint responsible for this key
      */
     public Map<EndPoint, EndPoint> getNStorageEndPointMap(String key)
@@ -945,7 +945,7 @@ public boolean isPrimary(String key)
      * This method returns the N endpoints that are responsible for storing the
      * specified token i.e for replication.
      *
-     * param @ token - position on the ring
+     * @param token - position on the ring
      */
     public EndPoint[] getNStorageEndPoint(Token token)
     {
@@ -957,8 +957,8 @@ public boolean isPrimary(String key)
      * specified token i.e for replication and are based on the token to endpoint 
      * mapping that is passed in.
      *
-     * param @ token - position on the ring
-     * param @ tokens - w/o the following tokens in the token list
+     * @param token - position on the ring
+     * @param tokens - w/o the following tokens in the token list
      */
     protected EndPoint[] getNStorageEndPoint(Token token, Map<Token, EndPoint> tokenToEndPointMap)
     {
@@ -987,9 +987,9 @@ public EndPoint findSuitableEndPoint(String key) throws IOException
 				return endpoints[j];
 			}
 		}
-		// We have tried to be really nice but looks like theer are no servers 
+		// We have tried to be really nice but looks like there are no servers 
 		// in the local data center that are alive and can service this request so 
-		// just send it to teh first alive guy and see if we get anything.
+		// just send it to the first alive guy and see if we get anything.
 		j = 0;
 		for ( ; j < endpoints.length; ++j )
 		{
@@ -1041,7 +1041,7 @@ public EndPoint findSuitableEndPoint(String key) throws IOException
 			if ( moveOn )
 				continue;
 			
-			// We have tried to be really nice but looks like theer are no servers 
+			// We have tried to be really nice but looks like there are no servers 
 			// in the local data center that are alive and can service this request so 
 			// just send it to the first alive guy and see if we get anything.
 			j = 0;
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageServiceMBean.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageServiceMBean.java
index 8ba3eecd..8c7f1845 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageServiceMBean.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/StorageServiceMBean.java
@@ -61,7 +61,7 @@
      * node being bootstrapped. This is used in case of normal
      * bootstrap failure. Use a tool to re-calculate the cardinality
      * at a later point at the destination.
-     * @param sources colon separated list of directories from where 
+     * @param directories colon separated list of directories from where 
      *                files need to be picked up.
      * @param target endpoint receiving data.
     */
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/WriteResponseResolver.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/WriteResponseResolver.java
index 1a173cae..746fb264 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/WriteResponseResolver.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/service/WriteResponseResolver.java
@@ -37,8 +37,8 @@
 
 	/*
 	 * The resolve function for the Write looks at all the responses if all the
-	 * respones returned are false then we have a problem since that means the
-	 * key wa not written to any of the servers we want to notify the client of
+	 * responses returned are false then we have a problem since that means the
+	 * key was not written to any of the servers we want to notify the client of
 	 * this so in that case we should return a false saying that the write
 	 * failed.
 	 * 
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/KeyChecker.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/KeyChecker.java
index 76a1bd71..d844561f 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/KeyChecker.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/KeyChecker.java
@@ -36,7 +36,7 @@
     private static final int bufSize_ = 128*1024*1024;
     /*
      * This function checks if the local storage endpoint 
-     * is reponsible for storing this key .
+     * is responsible for storing this key .
      */
     private static boolean checkIfProcessKey(String key)
     {
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/ThreadListBuilder.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/ThreadListBuilder.java
index 05e80400..940c1332 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/ThreadListBuilder.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/ThreadListBuilder.java
@@ -39,7 +39,7 @@ public static void main(String[] args) throws Throwable
     {
         if ( args.length != 2 )
         {
-            System.out.println("Usage : java com.facebook.infrastructure.tools.ThreadListBuilder <directory containing files to be processed> <directory to dump the bloom filter in.>");
+            System.out.println("Usage : java org.apache.cassandra.tools.ThreadListBuilder <directory containing files to be processed> <directory to dump the bloom filter in.>");
             System.exit(1);
         }
         
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/TokenUpdateVerbHandler.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/TokenUpdateVerbHandler.java
index 7b3445d4..c91058a5 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/TokenUpdateVerbHandler.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/TokenUpdateVerbHandler.java
@@ -72,7 +72,7 @@ public void doVerb(Message message)
                 if (logger_.isDebugEnabled())
                   logger_.debug("Processing node " + node);
                 byte[] bytes = headers.remove(node);
-                /* Send a message to this node to update its token to the one retreived. */
+                /* Send a message to this node to update its token to the one retrieved. */
                 EndPoint target = new EndPoint(node, DatabaseDescriptor.getStoragePort());
                 token = p.getTokenFactory().fromByteArray(bytes);
                 
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/TokenUpdater.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/TokenUpdater.java
index 1cb95676..378e2645 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/TokenUpdater.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/tools/TokenUpdater.java
@@ -41,7 +41,7 @@ public static void main(String[] args) throws Throwable
     {
         if ( args.length != 3 )
         {
-            System.out.println("Usage : java com.facebook.infrastructure.tools.TokenUpdater <ip:port> <token> <file containing node token info>");
+            System.out.println("Usage : java org.apache.cassandra.tools.TokenUpdater <ip:port> <token> <file containing node token info>");
             System.exit(1);
         }
         
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomCalculations.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomCalculations.java
index 22e91e66..6fdb1ea9 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomCalculations.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomCalculations.java
@@ -99,7 +99,7 @@ public BloomSpecification(int k, int bucketsPerElement) {
      * but minimize the number of buckets per element and the number of hash
      * functions used.  Because bandwidth (and therefore total bitvector size)
      * is considered more expensive than computing power, preference is given
-     * to minimizing buckets per element rather than number of hash funtions.
+     * to minimizing buckets per element rather than number of hash functions.
      *
      * @param maxFalsePosProb The maximum tolerable false positive rate.
      * @return A Bloom Specification which would result in a false positive rate
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomFilter.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomFilter.java
index d3032db7..3b790185 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomFilter.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomFilter.java
@@ -86,7 +86,7 @@ public boolean isPresent(String key)
     }
 
     /*
-     param@ key -- value whose hash is used to fill
+     @param key -- value whose hash is used to fill
      the filter_.
      This is a general purpose API.
      */
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java
index c1ee105c..694e4abe 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/FBUtilities.java
@@ -267,7 +267,7 @@ public static boolean isEqual(byte[] digestA, byte[] digestB)
         return MessageDigest.isEqual(digestA, digestB);
     }
 
-    // The given bytearray is compressed onto the specifed stream.
+    // The given byte array is compressed onto the specified stream.
     // The method does not close the stream. The caller will have to do it.
     public static void compressToStream(byte[] input, ByteArrayOutputStream bos) throws IOException
     {
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/FastObjectHash.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/FastObjectHash.java
index a2bf08d4..127c9ab7 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/FastObjectHash.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/FastObjectHash.java
@@ -256,7 +256,7 @@ else if (cur != REMOVED && cur.equals(obj))
                 return (cur != FREE) ? -index - 1 : firstRemoved;
             }
             // if it's full, the key is already stored
-            // NOTE: cur cannot equal REMOVE here (would have retuned already
+            // NOTE: cur cannot equal REMOVE here (would have returned already
             // (see above)
             return (cur != FREE) ? -index - 1 : index;
         }
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/Filter.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/Filter.java
index 3f5ef48e..b5b19186 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/Filter.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/Filter.java
@@ -62,8 +62,8 @@ int getHashCount()
         }
     }
 
-    // murmur is faster than a sha-based approach and provides as-good collision
-    // resistance.  the combinatorial generation approach described in
+    // Murmur is faster than an SHA-based approach and provides as-good collision
+    // resistance.  The combinatorial generation approach described in
     // http://www.eecs.harvard.edu/~kirsch/pubs/bbbf/esa06.pdf
     // does prove to work in actual tests, and is obviously faster
     // than performing further iterations of murmur.
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/Log4jLogger.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/Log4jLogger.java
index f4415e7b..ca52498c 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/Log4jLogger.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/utils/Log4jLogger.java
@@ -20,7 +20,7 @@
 
 /**
  * Log4j configurations may change while the application is running, 
- * potentially invalidating a logger's appender(s).  This is a convinience
+ * potentially invalidating a logger's appender(s).  This is a convenience
  * class to wrap logger calls so that a logger is always explicitly 
  * invoked.
  */
