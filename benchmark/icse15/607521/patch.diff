diff --git a/lucene/java/trunk/src/java/org/apache/lucene/analysis/CharTokenizer.java b/lucene/java/trunk/src/java/org/apache/lucene/analysis/CharTokenizer.java
index c394f76d..9ae8fc2a 100644
--- a/lucene/java/trunk/src/java/org/apache/lucene/analysis/CharTokenizer.java
+++ b/lucene/java/trunk/src/java/org/apache/lucene/analysis/CharTokenizer.java
@@ -45,6 +45,7 @@ protected char normalize(char c) {
   }
 
   public final Token next(Token token) throws IOException {
+    token.clear();
     int length = 0;
     int start = bufferIndex;
     char[] buffer = token.termBuffer();
diff --git a/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordTokenizer.java b/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordTokenizer.java
index f1a23ccc..d2192ea3 100644
--- a/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordTokenizer.java
+++ b/lucene/java/trunk/src/java/org/apache/lucene/analysis/KeywordTokenizer.java
@@ -42,6 +42,7 @@ public Token next(Token result) throws IOException {
     if (!done) {
       done = true;
       int upto = 0;
+      result.clear();
       char[] buffer = result.termBuffer();
       while (true) {
         final int length = input.read(buffer, upto, buffer.length-upto);
diff --git a/lucene/java/trunk/src/java/org/apache/lucene/analysis/TokenStream.java b/lucene/java/trunk/src/java/org/apache/lucene/analysis/TokenStream.java
index 6f0dd90c..775a2183 100644
--- a/lucene/java/trunk/src/java/org/apache/lucene/analysis/TokenStream.java
+++ b/lucene/java/trunk/src/java/org/apache/lucene/analysis/TokenStream.java
@@ -59,13 +59,22 @@ public Token next() throws IOException {
    *  returned Token (this gives fastest tokenization
    *  performance), but this is not required and a new Token
    *  may be returned.  Callers may re-use a single Token
-   *  instance for successive calls to this method and must
-   *  therefore fully consume the previously returned Token
-   *  before calling this method again.
-   *  @param result a Token that may or may not be used to
-   *   return
-   *  @return next token in the stream or null if
-   *   end-of-stream was hit*/
+   *  instance for successive calls to this method.
+   *  <p>
+   *  This implicitly defines a "contract" between 
+   *  consumers (callers of this method) and 
+   *  producers (implementations of this method 
+   *  that are the source for tokens):
+   *  <ul>
+   *   <li>A consumer must fully consume the previously 
+   *       returned Token before calling this method again.</li>
+   *   <li>A producer must call {@link Token#clear()}
+   *       before setting the fields in it & returning it</li>
+   *  </ul>
+   *  Note that a {@link TokenFilter} is considered a consumer.
+   *  @param result a Token that may or may not be used to return
+   *  @return next token in the stream or null if end-of-stream was hit
+   */
   public Token next(Token result) throws IOException {
     return next();
   }
diff --git a/lucene/java/trunk/src/java/org/apache/lucene/analysis/Tokenizer.java b/lucene/java/trunk/src/java/org/apache/lucene/analysis/Tokenizer.java
index 7208ed9b..234ad09a 100644
--- a/lucene/java/trunk/src/java/org/apache/lucene/analysis/Tokenizer.java
+++ b/lucene/java/trunk/src/java/org/apache/lucene/analysis/Tokenizer.java
@@ -23,8 +23,12 @@
 /** A Tokenizer is a TokenStream whose input is a Reader.
   <p>
   This is an abstract class.
+  <p>
   NOTE: subclasses must override at least one of {@link
   #next()} or {@link #next(Token)}.
+  <p>
+  NOTE: subclasses overriding {@link #next(Token)} must  
+  call {@link Token#clear()}.
  */
 
 public abstract class Tokenizer extends TokenStream {
diff --git a/lucene/java/trunk/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java b/lucene/java/trunk/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
index 4fdaee3b..8efde277 100644
--- a/lucene/java/trunk/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
+++ b/lucene/java/trunk/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
@@ -92,6 +92,7 @@ public Token next(Token result) throws IOException {
 	    return null;
 	}
 
+        result.clear();
         scanner.getText(result);
         final int start = scanner.yychar();
         result.setStartOffset(start);
diff --git a/lucene/java/trunk/src/java/org/apache/lucene/index/DocumentsWriter.java b/lucene/java/trunk/src/java/org/apache/lucene/index/DocumentsWriter.java
index 49557077..8113f0f5 100644
--- a/lucene/java/trunk/src/java/org/apache/lucene/index/DocumentsWriter.java
+++ b/lucene/java/trunk/src/java/org/apache/lucene/index/DocumentsWriter.java
@@ -1373,7 +1373,6 @@ public void invertField(Fieldable field, Analyzer analyzer, final int maxFieldLe
             offsetEnd = offset-1;
             Token token;
             for(;;) {
-              localToken.clear();
               token = stream.next(localToken);
               if (token == null) break;
               position += (token.getPositionIncrement() - 1);
