diff --git a/cassandra/trunk/src/java/org/apache/cassandra/db/RowIteratorFactory.java b/cassandra/trunk/src/java/org/apache/cassandra/db/RowIteratorFactory.java
index 87d1d7f2..ccf1f686 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/db/RowIteratorFactory.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/db/RowIteratorFactory.java
@@ -25,7 +25,6 @@
 
 import org.apache.cassandra.db.columniterator.IColumnIterator;
 import org.apache.cassandra.db.filter.QueryFilter;
-import org.apache.cassandra.db.marshal.AbstractType;
 import org.apache.cassandra.io.sstable.SSTableReader;
 import org.apache.cassandra.io.sstable.SSTableScanner;
 import org.apache.cassandra.utils.CloseableIterator;
@@ -34,8 +33,6 @@
 public class RowIteratorFactory
 {
 
-    private static final int RANGE_FILE_BUFFER_SIZE = 256 * 1024;
-
     private static final Comparator<IColumnIterator> COMPARE_BY_KEY = new Comparator<IColumnIterator>()
     {
         public int compare(IColumnIterator o1, IColumnIterator o2)
@@ -53,7 +50,7 @@ public int compare(IColumnIterator o1, IColumnIterator o2)
      * @param startWith Start at this key
      * @param stopAt Stop and this key
      * @param filter Used to decide which columns to pull out
-     * @param comparator
+     * @param cfs
      * @return A row iterator following all the given restrictions
      */
     public static CloseableIterator<Row> getIterator(final Iterable<Memtable> memtables,
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLogSegment.java b/cassandra/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLogSegment.java
index bcd13fdd..9537e6ba 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLogSegment.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLogSegment.java
@@ -36,12 +36,12 @@
 import org.slf4j.LoggerFactory;
 
 import org.apache.cassandra.config.CFMetaData;
+import org.apache.cassandra.config.DatabaseDescriptor;
 import org.apache.cassandra.config.Schema;
+import org.apache.cassandra.db.ColumnFamily;
+import org.apache.cassandra.db.RowMutation;
 import org.apache.cassandra.io.util.FileUtils;
 import org.apache.cassandra.net.MessagingService;
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.db.RowMutation;
-import org.apache.cassandra.db.ColumnFamily;
 
 /*
  * A single commit log file on disk. Manages creation of the file and writing row mutations to disk,
@@ -64,7 +64,7 @@
 
     public final long id;
 
-    private File logFile;
+    private final File logFile;
     private RandomAccessFile logFileAccessor;
 
     private boolean needsSync = false;
@@ -116,7 +116,7 @@ public static CommitLogSegment freshSegment()
             // Map the segment, extending or truncating it to the standard segment size
             logFileAccessor.setLength(CommitLog.SEGMENT_SIZE);
 
-            buffer = logFileAccessor.getChannel().map(FileChannel.MapMode.READ_WRITE, (long) 0, (long) CommitLog.SEGMENT_SIZE);
+            buffer = logFileAccessor.getChannel().map(FileChannel.MapMode.READ_WRITE, 0, CommitLog.SEGMENT_SIZE);
             buffer.putInt(CommitLog.END_OF_SEGMENT_MARKER);
             buffer.position(0);
 
@@ -132,7 +132,7 @@ public static CommitLogSegment freshSegment()
      * Extracts the commit log ID from filename
      *
      * @param   filename  the filename of the commit log file
-     * @returns the extracted commit log ID
+     * @return the extracted commit log ID
      */
     public static long idFromFilename(String filename)
     {
@@ -152,7 +152,7 @@ public static long idFromFilename(String filename)
 
     /**
      * @param   filename  the filename to check
-     * @returns true if filename could be a commit log based on it's filename
+     * @return true if filename could be a commit log based on it's filename
      */
     public static boolean possibleCommitLogFile(String filename)
     {
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java b/cassandra/trunk/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java
index 3093c155..dccc8504 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/locator/AbstractReplicationStrategy.java
@@ -87,7 +87,7 @@ public void clearEndpointCache()
      * get the (possibly cached) endpoints that should store the given Token.
      * Note that while the endpoints are conceptually a Set (no duplicates will be included),
      * we return a List to avoid an extra allocation when sorting by proximity later
-     * @param searchToken the token the natural endpoints are requested for
+     * @param searchPosition the position the natural endpoints are requested for
      * @return a copy of the natural endpoints for the given token
      */
     public ArrayList<InetAddress> getNaturalEndpoints(RingPosition searchPosition)
@@ -109,7 +109,7 @@ public void clearEndpointCache()
     /**
      * calculate the natural endpoints for the given token
      *
-     * @see #getNaturalEndpoints(org.apache.cassandra.dht.Token)
+     * @see #getNaturalEndpoints(org.apache.cassandra.dht.RingPosition)
      *
      * @param searchToken the token the natural endpoints are requested for
      * @return a copy of the natural endpoints for the given token
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/scheduler/IRequestScheduler.java b/cassandra/trunk/src/java/org/apache/cassandra/scheduler/IRequestScheduler.java
index 3a2f456c..8f89bd0d 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/scheduler/IRequestScheduler.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/scheduler/IRequestScheduler.java
@@ -32,7 +32,7 @@
      * 
      * @param t Thread handing the request
      * @param id    Scheduling parameter, an id to distinguish profiles (users/keyspace)
-     * @param timeout   The max time in milliseconds to spend blocking for a slot
+     * @param timeoutMS   The max time in milliseconds to spend blocking for a slot
      */
     public void queue(Thread t, String id, long timeoutMS) throws TimeoutException;
 
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/service/CassandraDaemon.java b/cassandra/trunk/src/java/org/apache/cassandra/service/CassandraDaemon.java
index 3522cff3..b316d16f 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/service/CassandraDaemon.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/service/CassandraDaemon.java
@@ -43,7 +43,7 @@
     
     /**
      * Start the Cassandra Daemon, assuming that it has already been
-     * initialized, via either {@link #init(String[])} or
+     * initialized, via either {@link CassandraDaemon#init(String[])} or
      * {@link #load(String[])}.
      * 
      * @throws IOException
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java b/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java
index 6eca30e0..df96594b 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/service/StorageService.java
@@ -69,7 +69,7 @@
 import org.apache.cassandra.utils.Pair;
 import org.apache.cassandra.utils.WrappedRunnable;
 
-/*
+/**
  * This abstraction contains the token/identifier of this node
  * on the identifier space. This token gets gossiped around.
  * This class will also maintain histograms of the load information
@@ -204,7 +204,7 @@ public static IPartitioner getPartitioner()
         return getPrimaryRangeForEndpoint(FBUtilities.getBroadcastAddress());
     }
 
-    private Set<InetAddress> replicatingNodes = Collections.synchronizedSet(new HashSet<InetAddress>());
+    private final Set<InetAddress> replicatingNodes = Collections.synchronizedSet(new HashSet<InetAddress>());
     private CassandraDaemon daemon;
 
     private InetAddress removingNode;
@@ -223,7 +223,7 @@ public static IPartitioner getPartitioner()
     private static enum Mode { NORMAL, CLIENT, JOINING, LEAVING, DECOMMISSIONED, MOVING, DRAINING, DRAINED }
     private Mode operationMode;
 
-    private MigrationManager migrationManager = new MigrationManager();
+    private final MigrationManager migrationManager = new MigrationManager();
 
     /* Used for tracking drain progress */
     private volatile int totalCFs, remainingCFs;
@@ -285,7 +285,7 @@ public StorageService()
         MessagingService.instance().registerVerbHandlers(Verb.TRUNCATE, new TruncateVerbHandler());
         MessagingService.instance().registerVerbHandlers(Verb.SCHEMA_CHECK, new SchemaCheckVerbHandler());
 
-        // spin up the streaming serivice so it is available for jmx tools.
+        // spin up the streaming service so it is available for jmx tools.
         if (StreamingService.instance == null)
             throw new RuntimeException("Streaming service is unavailable.");
     }
@@ -441,6 +441,7 @@ public synchronized void initServer(int delay) throws IOException, Configuration
         // daemon threads, like our executors', continue to run while shutdown hooks are invoked
         Thread drainOnShutdown = new Thread(new WrappedRunnable()
         {
+            @Override
             public void runMayThrow() throws ExecutionException, InterruptedException, IOException
             {
                 ThreadPoolExecutor mutationStage = StageManager.getStage(Stage.MUTATION);
@@ -1958,8 +1959,8 @@ public InetAddress getSuccessor(InetAddress ep)
      *
      * @param table keyspace name also known as table
      * @param cf Column family name
-     * @param key - key for which we need to find the endpoint return value -
-     * the endpoint responsible for this key
+     * @param key key for which we need to find the endpoint 
+     * @return the endpoint responsible for this key
      */
     public List<InetAddress> getNaturalEndpoints(String table, String cf, String key)
     {
@@ -1976,8 +1977,9 @@ public InetAddress getSuccessor(InetAddress ep)
      * This method returns the N endpoints that are responsible for storing the
      * specified key i.e for replication.
      *
-     * @param position - position for which we need to find the endpoint return value -
-     * the endpoint responsible for this token
+     * @param table keyspace name also known as table
+     * @param pos position for which we need to find the endpoint 
+     * @return the endpoint responsible for this token
      */
     public List<InetAddress> getNaturalEndpoints(String table, RingPosition pos)
     {
@@ -1988,8 +1990,9 @@ public InetAddress getSuccessor(InetAddress ep)
      * This method attempts to return N endpoints that are responsible for storing the
      * specified key i.e for replication.
      *
-     * @param key - key for which we need to find the endpoint return value -
-     * the endpoint responsible for this key
+     * @param table keyspace name also known as table
+     * @param key key for which we need to find the endpoint 
+     * @return the endpoint responsible for this key
      */
     public List<InetAddress> getLiveNaturalEndpoints(String table, ByteBuffer key)
     {
@@ -2806,6 +2809,7 @@ public void bulkLoad(String directory)
 
         SSTableLoader.Client client = new SSTableLoader.Client()
         {
+            @Override
             public void init(String keyspace)
             {
                 for (Map.Entry<Range<Token>, List<InetAddress>> entry : StorageService.instance.getRangeToAddressMap(keyspace).entrySet())
@@ -2816,6 +2820,7 @@ public void init(String keyspace)
                 }
             }
 
+            @Override
             public boolean validateColumnFamily(String keyspace, String cfName)
             {
                 return Schema.instance.getCFMetaData(keyspace, cfName) != null;
diff --git a/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomFilterSerializer.java b/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomFilterSerializer.java
index d6f59ea5..7625b166 100644
--- a/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomFilterSerializer.java
+++ b/cassandra/trunk/src/java/org/apache/cassandra/utils/BloomFilterSerializer.java
@@ -68,7 +68,7 @@ public BloomFilter deserialize(DataInput dis) throws IOException
 
     /**
      * Calculates a serialized size of the given Bloom Filter
-     * @see this.serialize(BloomFilter, DataOutput)
+     * @see BloomFilterSerializer#serialize(BloomFilter, DataOutput)
      *
      * @param bf Bloom filter to calculate serialized size
      *
