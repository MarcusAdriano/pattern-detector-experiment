diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFieldsEnum.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFieldsEnum.java
index aa829b57..c13e8948 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFieldsEnum.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/LegacyFieldsEnum.java
@@ -48,9 +48,10 @@ public boolean seek(String field) throws IOException {
 
   public String next() throws IOException {
 
+    if (field != null) {
     final Term seekTo = new Term(field, "\uFFFF");
-
     doSeek(seekTo);
+    }
     if (terms.term() != null) {
       String newField = terms.term().field;
       assert !newField.equals(field);
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/TermRef.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/TermRef.java
index 5d4b382e..73809516 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/TermRef.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/TermRef.java
@@ -115,18 +115,19 @@ public int hashCode() {
   }
   
   private int hash(byte a[]) {
-    if (a == null)
+    if (a == null) {
         return 0;
+    }
     int result = 1;
     int upTo = offset;
-    for(int i = 0; i < length; i++)
+    for(int i = 0; i < length; i++) {
         result = 31 * result + bytes[upTo++];
+    }
     return result;
-}
+  }
 
   @Override
   public boolean equals(Object other) {
-
     return this.termEquals((TermRef) other);
   }
 
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/DocsProducer.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/DocsProducer.java
index 31def0c7..48dab8ff 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/DocsProducer.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/DocsProducer.java
@@ -24,6 +24,9 @@
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Bits;
 
+// nocommit -- circular, not clean
+import org.apache.lucene.index.codecs.standard.StandardTermsDictReader.CacheEntry;
+
 
 // nocommit -- this is tied to StandarTermsDictWriter;
 // shouldn't it be named StandardDocsProducer?  hmm, though,
@@ -38,7 +41,6 @@
 public abstract class DocsProducer {
   
   public abstract class Reader {
-    public class State {}
     
     public abstract void readTerm(int docFreq, boolean isIndexTerm) throws IOException;
 
@@ -46,9 +48,9 @@
     public abstract DocsEnum docs(Bits deletedDocs) throws IOException;
     
     // nocommit: fooling around with reusable
-    public abstract State captureState(State reusableState);
+    public abstract CacheEntry captureState(CacheEntry reusableState);
     
-    public abstract void setState(State state) throws IOException;
+    public abstract void setState(CacheEntry state, int docFreq) throws IOException;
     
     public boolean canCaptureState() {
       return false;
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/pulsing/PulsingDocsReader.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/pulsing/PulsingDocsReader.java
index 144c369e..0fca5743 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/pulsing/PulsingDocsReader.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/pulsing/PulsingDocsReader.java
@@ -26,6 +26,7 @@
 import org.apache.lucene.index.codecs.Codec;
 import org.apache.lucene.index.codecs.DocsProducer;
 import org.apache.lucene.index.codecs.pulsing.PulsingDocsWriter.Document;
+import org.apache.lucene.index.codecs.standard.StandardTermsDictReader.CacheEntry;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.ArrayUtil;
@@ -297,13 +298,13 @@ public int advance(int target) throws IOException {
     }
 
     @Override
-    public State captureState(State reusableState) {
+    public CacheEntry captureState(CacheEntry reusableState) {
       // TODO Auto-generated method stub
       return null;
     }
 
     @Override
-    public void setState(State state) throws IOException {
+    public void setState(CacheEntry state, int docFreq) throws IOException {
       // TODO Auto-generated method stub
       
     }
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/sep/SepDocsReader.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/sep/SepDocsReader.java
index b1a7a31d..35b7d888 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/sep/SepDocsReader.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/sep/SepDocsReader.java
@@ -30,6 +30,7 @@
 import org.apache.lucene.index.PositionsEnum;
 import org.apache.lucene.index.IndexFileNames;
 import org.apache.lucene.index.codecs.Codec;
+import org.apache.lucene.index.codecs.standard.StandardTermsDictReader.CacheEntry;
 
 /** Concrete class that reads the current doc/freq/skip
  *  postings format */
@@ -519,15 +520,14 @@ public int advance(int target) throws IOException {
     }
 
     @Override
-    public State captureState(State reusableState) {
+    public CacheEntry captureState(CacheEntry reusableState) {
       // TODO Auto-generated method stub
       return null;
     }
 
     @Override
-    public void setState(State state) throws IOException {
+    public void setState(CacheEntry state, int docFreq) throws IOException {
       // TODO Auto-generated method stub
-      
     }
   }
 }
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexReader.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexReader.java
index 7d153011..e2ef86ab 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexReader.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/SimpleStandardTermsIndexReader.java
@@ -130,6 +130,8 @@ public SimpleStandardTermsIndexReader(Directory dir, FieldInfos fieldInfos, Stri
   int blockUpto;
   int blockOffset;
 
+  // nocommit -- is this big enough, given max allowed term
+  // size (measured in chars!!) ?
   private static final int BYTE_BLOCK_SHIFT = 15;
   private static final int BYTE_BLOCK_SIZE = 1 << BYTE_BLOCK_SHIFT;
   private static final int BYTE_BLOCK_MASK = BYTE_BLOCK_SIZE - 1;
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardDocsReader.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardDocsReader.java
index 156dbba0..5156fe58 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardDocsReader.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardDocsReader.java
@@ -30,6 +30,7 @@
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.index.codecs.DocsProducer;
+import org.apache.lucene.index.codecs.standard.StandardTermsDictReader.CacheEntry;
 
 /** Concrete class that reads the current doc/freq/skip
  *  postings format */
@@ -114,7 +115,7 @@ public void close() throws IOException {
     final IndexInput termsIn;
     final FieldInfo fieldInfo;
     long freqOffset;
-    long skipOffset;
+    int skipOffset;
     int docFreq;
 
     // TODO: abstraction violation (we are storing this with
@@ -152,7 +153,7 @@ public void readTerm(int docFreq, boolean isIndexTerm) throws IOException {
       }
 
       if (docFreq >= skipInterval) {
-        skipOffset = termsIn.readVLong();
+        skipOffset = termsIn.readVInt();
       } else {
         skipOffset = 0;
       }
@@ -162,54 +163,45 @@ public void readTerm(int docFreq, boolean isIndexTerm) throws IOException {
       }
     }
     
-    public class TermDictsReaderState extends State {
-      long termsInPos;
+    public class TermDictsReaderState extends CacheEntry {
       long freqOffset;
-      long skipOffset;
-      long freqInPos;
-      int freq;
-      long proxPos;
-      public long proxOffset;
+      int skipOffset;
+      long proxOffset;
     }
     
     @Override
-    public State captureState(State reusableState) {
+    public CacheEntry captureState(CacheEntry reusableState) {
       TermDictsReaderState state;
-      if(reusableState == null) {
+      if (reusableState == null) {
         state = new TermDictsReaderState();
       } else {
         state = (TermDictsReaderState) reusableState;
-        state.proxPos = 0;
-        state.proxOffset = 0;
-      }
-      if(posReader != null) {
-        if(posReader.positions != null) {
-          state.proxPos = posReader.positions.proxIn.getFilePointer();
         }
+      if (posReader != null) {
         state.proxOffset = posReader.proxOffset;
+      } else {
+        state.proxOffset = 0;
       }
-      state.termsInPos = termsIn.getFilePointer();
       state.freqOffset = freqOffset;
-      state.freqInPos = freqIn.getFilePointer();
-      state.freq = docFreq;
       state.skipOffset = skipOffset;
       return state;
     }
 
     @Override
-    public void setState(State state) throws IOException {
-      TermDictsReaderState readerState = (TermDictsReaderState)state;
+    public void setState(CacheEntry state, int docFreq) throws IOException {
+      TermDictsReaderState readerState = (TermDictsReaderState) state;
       skipOffset = readerState.skipOffset;
-      termsIn.seek(readerState.termsInPos);
       freqOffset = readerState.freqOffset;
-      freqIn.seek(readerState.freqInPos);
-      docFreq = readerState.freq;
       
-      if(posReader != null) {
-        if(posReader.positions != null) {
-          posReader.positions.proxIn.seek(readerState.proxPos);
-        }
+      this.docFreq = docFreq;
+      
+      if (posReader != null) {
         posReader.proxOffset = readerState.proxOffset;
+        if (posReader.positions != null) {
+          posReader.positions.seekPending = true;
+          posReader.positions.skipOffset = posReader.proxOffset;
+          posReader.positions.skipPosCount = 0;
+        }
       }
     }
     
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardDocsWriter.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardDocsWriter.java
index 2aefd6b4..04a86cf7 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardDocsWriter.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardDocsWriter.java
@@ -83,8 +83,9 @@ public void start(IndexOutput termsOut) throws IOException {
 
   public void startTerm() {
     freqStart = out.getFilePointer();
-    if (!omitTermFreqAndPositions)
+    if (!omitTermFreqAndPositions) {
       posWriter.startTerm();
+    }
     skipListWriter.resetSkip();
   }
 
@@ -178,7 +179,7 @@ public void finishTerm(int docCount, boolean isIndexTerm) throws IOException {
       if (Codec.DEBUG) {
         System.out.println(Thread.currentThread().getName() + ":  writeSkip @ freqFP=" + out.getFilePointer() + " freqStartFP=" + freqStart);
       }
-      termsOut.writeVLong(skipListWriter.writeSkip(out)-freqStart);
+      termsOut.writeVInt((int) (skipListWriter.writeSkip(out)-freqStart));
     }
      
     if (!omitTermFreqAndPositions) {
@@ -194,8 +195,9 @@ public void finishTerm(int docCount, boolean isIndexTerm) throws IOException {
   }
 
   public void close() throws IOException {
-    if (Codec.DEBUG)
+    if (Codec.DEBUG) {
       System.out.println("docs writer close pointer=" + out.getFilePointer());
+    }
     try {
       out.close();
     } finally {
diff --git a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader.java b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader.java
index 94adba77..2cd471cc 100644
--- a/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader.java
+++ b/lucene/java/branches/flex_1458/src/java/org/apache/lucene/index/codecs/standard/StandardTermsDictReader.java
@@ -39,7 +39,6 @@
 import org.apache.lucene.index.codecs.Codec;
 import org.apache.lucene.index.codecs.DocsProducer;
 import org.apache.lucene.index.codecs.FieldsProducer;
-import org.apache.lucene.index.codecs.DocsProducer.Reader.State;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Bits;
@@ -103,6 +102,7 @@ public StandardTermsDictReader(StandardTermsIndexReader indexReader, Directory d
           fieldIndexReader = null;
         }
         if (numTerms > 0) {
+          assert !fields.containsKey(fieldInfo.name);
           fields.put(fieldInfo.name, new FieldReader(fieldIndexReader, fieldInfo, numTerms, termsStartPointer));
         }
       }
@@ -191,8 +191,9 @@ public TermsEnum terms() throws IOException {
   
   private class FieldReader extends Terms {
     private final CloseableThreadLocal threadResources = new CloseableThreadLocal();
+    // nocommit: not needed?
     // nocommit: check placement
-    Collection<ThreadResources> threadResourceSet = new HashSet<ThreadResources>();
+    //Collection<ThreadResources> threadResourceSet = new HashSet<ThreadResources>();
     final long numTerms;
     final FieldInfo fieldInfo;
     final long termsStartPointer;
@@ -206,20 +207,31 @@ public TermsEnum terms() throws IOException {
       this.indexReader = fieldIndexReader;
     }
 
+    public int docFreq(TermRef text) throws IOException {
+      ThreadResources resources = getThreadResources();
+      if (resources.termsEnum.seek(text) == TermsEnum.SeekStatus.FOUND) {
+        return resources.termsEnum.docFreq();
+      } else {
+        return 0;
+      }
+    }
+
     public void close() {
       threadResources.close();
+      // nocommit should not be needed?
+      /*
       for(ThreadResources threadResource : threadResourceSet) {
         threadResource.termInfoCache = null;
       }
+      */
     }
     
-    private ThreadResources getThreadResources() {
-      ThreadResources resources = (ThreadResources)threadResources.get();
+    private ThreadResources getThreadResources() throws IOException {
+      ThreadResources resources = (ThreadResources) threadResources.get();
       if (resources == null) {
-        resources = new ThreadResources();
         // Cache does not have to be thread-safe, it is only used by one thread at the same time
-        resources.termInfoCache = new ReuseLRUCache(1024);
-        threadResourceSet.add(resources);
+        resources = new ThreadResources(new SegmentTermsEnum(), numTerms);
+        //threadResourceSet.add(resources);
         threadResources.set(resources);
       }
       return resources;
@@ -232,7 +244,7 @@ public TermsEnum iterator() throws IOException {
     public long getUniqueTermCount() {
       return numTerms;
     }
-    ThreadResources resources = getThreadResources();
+
     // Iterates through terms in this field
     private class SegmentTermsEnum extends TermsEnum {
       private final IndexInput in;
@@ -243,7 +255,6 @@ public long getUniqueTermCount() {
       private int docFreq;
       private final StandardTermsIndexReader.TermsIndexResult indexResult = new StandardTermsIndexReader.TermsIndexResult();
 
-      
       SegmentTermsEnum() throws IOException {
         if (Codec.DEBUG) {
           System.out.println("tdr " + this + ": CREATE TermsEnum field=" + fieldInfo.name + " startPos=" + termsStartPointer + " seg=" + segment);
@@ -266,15 +277,17 @@ public SeekStatus seek(TermRef term) throws IOException {
         CacheEntry entry = null;
 
         if (docs.canCaptureState()) {
-          cache = resources.termInfoCache;
+          final ThreadResources resources = getThreadResources();
+          cache = resources.cache;
 
           entry = (CacheEntry) cache.get(term);
           if (entry != null) {
             docFreq = entry.freq;
-            bytesReader.term = (TermRef) entry.term.clone();
-            docs.setState(entry.state);
+            bytesReader.term.copy(entry.term);
+            docs.setState(entry, docFreq);
             termUpto = entry.termUpTo;
-
+            // nocommit -- would be better to do this lazy?
+            in.seek(entry.filePointer);
             return SeekStatus.FOUND;
           } 
         }
@@ -290,6 +303,7 @@ public SeekStatus seek(TermRef term) throws IOException {
           if (Codec.DEBUG) {
             System.out.println(Thread.currentThread().getName() + ":  already here!");
           }
+          // nocommit -- cache this
           return SeekStatus.FOUND;
         }
 
@@ -331,19 +345,23 @@ public SeekStatus seek(TermRef term) throws IOException {
               //new Throwable().printStackTrace(System.out);
             }
         
-            if(docs.canCaptureState() && scanCnt > 1) {
-             if(cache.eldest != null) {
+            // nocommit -- why scanCnt > 1?
+            //if (docs.canCaptureState() && scanCnt > 1) {
+
+            if (docs.canCaptureState()) {
+              // Store in cache
+              if (cache.eldest != null) {
                entry = (CacheEntry) cache.eldest;
                cache.eldest = null;
-               entry.state = docs.captureState(entry.state);
+                docs.captureState(entry);
+                entry.term.copy((TermRef) bytesReader.term);
               } else {
-                entry = new CacheEntry();
-                entry.state = docs.captureState(null);
+                entry = docs.captureState(null);
+                entry.term = (TermRef) bytesReader.term.clone();
               }
               entry.freq = docFreq;
               entry.termUpTo = termUpto;
-            
-              entry.term = (TermRef) bytesReader.term.clone();
+              entry.filePointer = in.getFilePointer();
              
               cache.put(entry.term, entry);
             }
@@ -461,22 +479,42 @@ public DocsEnum docs(Bits skipDocs) throws IOException {
     }
   }
 
-  private class CacheEntry {
+  // nocommit -- scrutinize API
+  public static class CacheEntry {
     int termUpTo;
     int freq;
-    State state;
+    long filePointer;
     TermRef term;
   }
   
+  private static final int MAX_CACHE_SIZE = 1024;
+  
   /**
    * Per-thread resources managed by ThreadLocal
    */
-  private final class ThreadResources {
+  private static final class ThreadResources {
     // Used for caching the least recently looked-up Terms
-    ReuseLRUCache termInfoCache;
+    final ReuseLRUCache cache;
+    final TermsEnum termsEnum;
+
+    ThreadResources(TermsEnum termsEnum, long numTerms) {
+      final int cacheSize;
+      if (numTerms >= MAX_CACHE_SIZE) {
+        cacheSize = MAX_CACHE_SIZE;
+      } else if (numTerms < 1) {
+        cacheSize = 1;
+      } else {
+        cacheSize = (int) numTerms;
   }
   
-  private class ReuseLRUCache extends LinkedHashMap {
+      cache = new ReuseLRUCache(cacheSize);
+      this.termsEnum = termsEnum;
+    }
+  }
+
+  // nocommit -- wonder if simple double-barrel LRU cache
+  // would be better
+  private static class ReuseLRUCache extends LinkedHashMap {
     
     private final static float LOADFACTOR = 0.75f;
     private int cacheSize;
@@ -486,18 +524,25 @@ public DocsEnum docs(Bits skipDocs) throws IOException {
      * Creates a last-recently-used cache with the specified size. 
      */
     public ReuseLRUCache(int cacheSize) {
+      // nocommit -- we should not init cache w/ full
+      // capacity?  init it at 0, and only start evicting
+      // once #entries is over our max
       super((int) Math.ceil(cacheSize/ LOADFACTOR) + 1, LOADFACTOR, true);
       this.cacheSize = cacheSize;
     }
     
     protected boolean removeEldestEntry(Map.Entry eldest) {
       boolean remove = size() > ReuseLRUCache.this.cacheSize;
-      if(remove) {
+      if (remove) {
         this.eldest = eldest.getValue();
       } 
       return remove;
     }
     
+    // nocommit -- not needed?  we don't need to sync since
+    // only one thread works with this?
+
+    /*
     @Override
     public synchronized Object put(Object key, Object value) {
       // TODO Auto-generated method stub
@@ -509,6 +554,7 @@ public synchronized Object get(Object key) {
       // TODO Auto-generated method stub
       return super.get(key);
     }
+    */
   }
 
 }
