diff --git a/mahout/trunk/core/src/test/java/org/apache/mahout/common/DummyRecordWriter.java b/mahout/trunk/core/src/test/java/org/apache/mahout/common/DummyRecordWriter.java
index 3db6846c..a0e912f7 100644
--- a/mahout/trunk/core/src/test/java/org/apache/mahout/common/DummyRecordWriter.java
+++ b/mahout/trunk/core/src/test/java/org/apache/mahout/common/DummyRecordWriter.java
@@ -18,15 +18,10 @@
 package org.apache.mahout.common;
 
 import com.google.common.collect.Lists;
-
-import java.lang.reflect.Constructor;
-import java.lang.reflect.Method;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.TreeMap;
-
+import com.google.common.collect.Maps;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.io.NullWritable;
+import org.apache.hadoop.io.Writable;
 import org.apache.hadoop.mapreduce.MapContext;
 import org.apache.hadoop.mapreduce.Mapper;
 import org.apache.hadoop.mapreduce.RecordWriter;
@@ -34,13 +29,47 @@
 import org.apache.hadoop.mapreduce.Reducer;
 import org.apache.hadoop.mapreduce.TaskAttemptContext;
 import org.apache.hadoop.mapreduce.TaskAttemptID;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.DataInputStream;
+import java.io.DataOutputStream;
+import java.io.IOException;
+import java.lang.reflect.Constructor;
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+public final class DummyRecordWriter<K extends Writable, V extends Writable> extends RecordWriter<K, V> {
 
-public final class DummyRecordWriter<K, V> extends RecordWriter<K, V> {
+  private static final Logger log = LoggerFactory.getLogger(DummyRecordWriter.class);
 
-  private final Map<K, List<V>> data = new TreeMap<K, List<V>>();
+  private final Map<K, List<V>> data = Maps.newHashMap();
 
   @Override
   public void write(K key, V value) {
+    // if the user reuses the same writable class, we need to create a new one
+    // otherwise the Map content will be modified after the insert
+    try {
+      if (!(key instanceof NullWritable)) {
+        K newKey = (K) key.getClass().newInstance();
+        cloneWritable(key, newKey);
+        key = newKey;
+      }
+      V newValue = (V) value.getClass().newInstance();
+      cloneWritable(value, newValue);
+      value = newValue;
+    } catch (InstantiationException e) {
+      log.error(e.getMessage());
+    } catch (IllegalAccessException e) {
+      log.error(e.getMessage());
+    } catch (IOException e) {
+      log.error(e.getMessage());
+    }
+
     List<V> points = data.get(key);
     if (points == null) {
       points = Lists.newArrayList();
@@ -49,6 +78,16 @@ public void write(K key, V value) {
     points.add(value);
   }
 
+  private void cloneWritable(Writable from, Writable to) throws IOException {
+    ByteArrayOutputStream baos = new ByteArrayOutputStream();
+    DataOutputStream dos = new DataOutputStream(baos);
+    from.write(dos);
+    dos.close();
+    ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());
+    DataInputStream dis = new DataInputStream(bais);
+    to.readFields(dis);
+  }
+
   @Override
   public void close(TaskAttemptContext context) {
   }
@@ -101,7 +140,7 @@ public void close(TaskAttemptContext context) {
     }
   }
 
-  @SuppressWarnings({ "unchecked", "rawtypes" })
+  @SuppressWarnings({"unchecked", "rawtypes"})
   private static <K1, V1, K2, V2> Mapper<K1, V1, K2, V2>.Context buildNewMapperContext(
       Configuration configuration, RecordWriter<K2, V2> output) throws Exception {
     Class<?> mapContextImplClass = Class.forName("org.apache.hadoop.mapreduce.task.MapContextImpl");
@@ -115,7 +154,7 @@ public void close(TaskAttemptContext context) {
     return (Mapper.Context) getMapContext.invoke(wrappedMapper, mapContextImpl);
   }
 
-  @SuppressWarnings({ "unchecked", "rawtypes" })
+  @SuppressWarnings({"unchecked", "rawtypes"})
   private static <K1, V1, K2, V2> Mapper<K1, V1, K2, V2>.Context buildOldMapperContext(
       Mapper<K1, V1, K2, V2> mapper, Configuration configuration,
       RecordWriter<K2, V2> output) throws Exception {
@@ -125,7 +164,7 @@ public void close(TaskAttemptContext context) {
         new TaskAttemptID(), null, output, null, new DummyStatusReporter(), null);
   }
 
-  @SuppressWarnings({ "unchecked", "rawtypes" })
+  @SuppressWarnings({"unchecked", "rawtypes"})
   private static <K1, V1, K2, V2> Reducer<K1, V1, K2, V2>.Context buildNewReducerContext(
       Configuration configuration, RecordWriter<K2, V2> output, Class<K1> keyClass,
       Class<V1> valueClass) throws Exception {
@@ -149,7 +188,7 @@ public void close(TaskAttemptContext context) {
     return (Reducer.Context) getReducerContext.invoke(wrappedReducer, reduceContextImpl);
   }
   
-  @SuppressWarnings({ "unchecked", "rawtypes" })
+  @SuppressWarnings({"unchecked", "rawtypes"})
   private static <K1, V1, K2, V2> Reducer<K1, V1, K2, V2>.Context buildOldReducerContext(
       Reducer<K1, V1, K2, V2> reducer, Configuration configuration,
       RecordWriter<K2, V2> output, Class<K1> keyClass,
diff --git a/mahout/trunk/core/src/test/java/org/apache/mahout/common/DummyRecordWriterTest.java b/mahout/trunk/core/src/test/java/org/apache/mahout/common/DummyRecordWriterTest.java
index e69de29b..6b254487 100644
--- a/mahout/trunk/core/src/test/java/org/apache/mahout/common/DummyRecordWriterTest.java
+++ b/mahout/trunk/core/src/test/java/org/apache/mahout/common/DummyRecordWriterTest.java
@@ -0,0 +1,45 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.mahout.common;
+
+import org.apache.hadoop.io.IntWritable;
+import org.apache.mahout.math.DenseVector;
+import org.apache.mahout.math.VectorWritable;
+import org.junit.Assert;
+import org.junit.Test;
+
+public class DummyRecordWriterTest {
+
+  @Test
+  public void testWrite() {
+    DummyRecordWriter<IntWritable, VectorWritable> writer = 
+        new DummyRecordWriter<IntWritable, VectorWritable>();
+    IntWritable reusableIntWritable = new IntWritable();
+    VectorWritable reusableVectorWritable = new VectorWritable();
+    reusableIntWritable.set(0);
+    reusableVectorWritable.set(new DenseVector(new double[] { 1, 2, 3 }));
+    writer.write(reusableIntWritable, reusableVectorWritable);
+    reusableIntWritable.set(1);
+    reusableVectorWritable.set(new DenseVector(new double[] { 4, 5, 6 }));
+    writer.write(reusableIntWritable, reusableVectorWritable);
+
+    Assert.assertEquals(
+        "The writer must remember the two keys that is written to it", 2,
+        writer.getKeys().size());
+  }
+}
