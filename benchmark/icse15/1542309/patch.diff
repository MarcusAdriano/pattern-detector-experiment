diff --git a/lucene/dev/branches/branch_4x/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java b/lucene/dev/branches/branch_4x/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java
index e721efd6..588c0f54 100644
--- a/lucene/dev/branches/branch_4x/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java
+++ b/lucene/dev/branches/branch_4x/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsReader.java
@@ -373,6 +373,10 @@ CompressionMode getCompressionMode() {
     return compressionMode;
   }
 
+  int getChunkSize() {
+    return chunkSize;
+  }
+
   ChunkIterator chunkIterator(int startDocID) throws IOException {
     ensureOpen();
     fieldsStream.seek(indexReader.getStartPointer(startDocID));
diff --git a/lucene/dev/branches/branch_4x/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java b/lucene/dev/branches/branch_4x/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
index a250308d..88b09eaf 100644
--- a/lucene/dev/branches/branch_4x/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
+++ b/lucene/dev/branches/branch_4x/lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter.java
@@ -337,7 +337,9 @@ public int merge(MergeState mergeState) throws IOException {
       final Bits liveDocs = reader.getLiveDocs();
 
       if (matchingFieldsReader == null
-          || matchingFieldsReader.getVersion() != VERSION_CURRENT) { // means reader version is not the same as the writer version
+          || matchingFieldsReader.getVersion() != VERSION_CURRENT // means reader version is not the same as the writer version
+          || matchingFieldsReader.getCompressionMode() != compressionMode
+          || matchingFieldsReader.getChunkSize() != chunkSize) { // the way data is decompressed depends on the chunk size
         // naive merge...
         for (int i = nextLiveDoc(0, liveDocs, maxDoc); i < maxDoc; i = nextLiveDoc(i + 1, liveDocs, maxDoc)) {
           Document doc = reader.document(i);
@@ -362,8 +364,7 @@ public int merge(MergeState mergeState) throws IOException {
               startOffsets[i] = startOffsets[i - 1] + it.lengths[i - 1];
             }
 
-            if (compressionMode == matchingFieldsReader.getCompressionMode() // same compression mode
-                && numBufferedDocs == 0 // starting a new chunk
+            if (numBufferedDocs == 0 // starting a new chunk
                 && startOffsets[it.chunkDocs - 1] < chunkSize // chunk is small enough
                 && startOffsets[it.chunkDocs - 1] + it.lengths[it.chunkDocs - 1] >= chunkSize // chunk is large enough
                 && nextDeletedDoc(it.docBase, liveDocs, it.docBase + it.chunkDocs) == it.docBase + it.chunkDocs) { // no deletion in the chunk
