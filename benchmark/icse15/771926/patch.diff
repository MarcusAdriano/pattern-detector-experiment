diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
index 8fa145bc..68f4a4db 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/ColumnFamilyStore.java
@@ -402,11 +402,9 @@ String getTempFileName( List<String> files)
      * by having a thread per log file present for recovery. Re-visit at that
      * time.
      */
-    void switchMemtable(String key, ColumnFamily columnFamily, CommitLog.CommitLogContext cLogCtx) throws IOException
+    void switchMemtable()
     {
-        memtable_.set( new Memtable(table_, columnFamily_) );
-        if(!key.equals(Memtable.flushKey_))
-        	memtable_.get().put(key, columnFamily, cLogCtx);
+        memtable_.set(new Memtable(table_, columnFamily_));
         
         if (memtableSwitchCount == Integer.MAX_VALUE)
         {
@@ -429,7 +427,7 @@ void switchBinaryMemtable(String key, byte[] buffer) throws IOException
 
     void forceFlush() throws IOException
     {
-        memtable_.get().forceflush(this);
+        memtable_.get().forceflush();
     }
 
     void forceBlockingFlush() throws IOException, ExecutionException, InterruptedException
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CommitLog.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CommitLog.java
index 380143e2..635ee56f 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CommitLog.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/CommitLog.java
@@ -436,6 +436,11 @@ private void updateHeader(Row row) throws IOException
         }
     }
 
+    CommitLogContext getContext() throws IOException
+    {
+        return new CommitLogContext(logFile_, logWriter_.getCurrentPosition());
+    }
+
     /*
      * Adds the specified row to the commit log. This method will reset the
      * file offset to what it is before the start of the operation in case
diff --git a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Memtable.java b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Memtable.java
index 256baed8..c0187804 100644
--- a/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Memtable.java
+++ b/incubator/cassandra/trunk/src/java/org/apache/cassandra/db/Memtable.java
@@ -18,39 +18,24 @@
 
 package org.apache.cassandra.db;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
-import java.util.Comparator;
-import java.util.Iterator;
-import java.util.PriorityQueue;
-import java.util.Arrays;
-import java.util.concurrent.Callable;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.FutureTask;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReentrantLock;
-
-import org.apache.log4j.Logger;
-
 import org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor;
-import org.apache.cassandra.concurrent.ThreadFactoryImpl;
 import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.io.DataOutputBuffer;
 import org.apache.cassandra.io.SSTable;
-import org.apache.cassandra.utils.BloomFilter;
-import org.apache.cassandra.utils.LogUtil;
-import org.apache.cassandra.dht.IPartitioner;
 import org.apache.cassandra.service.StorageService;
-import org.cliffc.high_scale_lib.NonBlockingHashSet;
+import org.apache.cassandra.utils.BloomFilter;
 import org.apache.cassandra.utils.DestructivePQIterator;
+import org.apache.log4j.Logger;
+import org.cliffc.high_scale_lib.NonBlockingHashSet;
+
+import java.io.IOException;
+import java.util.*;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.FutureTask;
+import java.util.concurrent.atomic.AtomicInteger;
 
 /**
  * Author : Avinash Lakshman ( alakshman@facebook.com) & Prashant Malik ( pmalik@facebook.com )
@@ -60,7 +45,7 @@
 {
 	private static Logger logger_ = Logger.getLogger( Memtable.class );
     private static Set<ExecutorService> runningExecutorServices_ = new NonBlockingHashSet<ExecutorService>();
-    public static final String flushKey_ = "FlushKey";
+    private boolean isFrozen_;
 
     public static void shutdown()
     {
@@ -82,10 +67,8 @@ public static void shutdown()
     private String cfName_;
     /* Creation time of this Memtable */
     private long creationTime_;
-    private volatile boolean isFrozen_ = false;
     private Map<String, ColumnFamily> columnFamilies_ = new HashMap<String, ColumnFamily>();
     /* Lock and Condition for notifying new clients about Memtable switches */
-    Lock lock_ = new ReentrantLock();
 
     Memtable(String table, String cfName)
     {
@@ -176,16 +159,9 @@ void resolveCount(int oldCount, int newCount)
         currentObjectCount_.addAndGet(newCount - oldCount);
     }
 
-    boolean isThresholdViolated(String key)
-    {
-    	boolean bVal = false;//isLifetimeViolated();
-        if (currentSize_.get() >= threshold_ ||  currentObjectCount_.get() >= thresholdCount_ || bVal || key.equals(flushKey_))
+    boolean isThresholdViolated()
         {
-        	if ( bVal )
-        		logger_.info("Memtable's lifetime for " + cfName_ + " has been violated.");
-        	return true;
-        }
-        return false;
+        return currentSize_.get() >= threshold_ ||  currentObjectCount_.get() >= thresholdCount_;
     }
 
     String getColumnFamily()
@@ -198,41 +174,29 @@ int getPendingTasks()
     	return (int)(executor_.getTaskCount() - executor_.getCompletedTaskCount());
     }
 
-    /*
-     * This version is used by the external clients to put data into
-     * the memtable. This version will respect the threshold and flush
-     * the memtable to disk when the size exceeds the threshold.
-    */
-    void put(String key, ColumnFamily columnFamily, final CommitLog.CommitLogContext cLogCtx) throws IOException
-    {
-        if (isThresholdViolated(key) )
+    private synchronized void enqueueFlush(CommitLog.CommitLogContext cLogCtx)
         {
-            lock_.lock();
-            try
-            {
-                final ColumnFamilyStore cfStore = Table.open(table_).getColumnFamilyStore(cfName_);
                 if (!isFrozen_)
                 {
                     isFrozen_ = true;
-                    cfStore.switchMemtable(key, columnFamily, cLogCtx);
+            ColumnFamilyStore cfStore = Table.open(table_).getColumnFamilyStore(cfName_);
+            cfStore.switchMemtable();
                     executor_.flushWhenTerminated(cLogCtx);
                     executor_.shutdown();
                 }
-                else
-                {
-                    // retry the put on the new memtable
-                    cfStore.apply(key, columnFamily, cLogCtx);
-                }
             }
-            finally
+
+    /*
+     * This version is used by the external clients to put data into
+     * the memtable. This version will respect the threshold and flush
+     * the memtable to disk when the size exceeds the threshold.
+    */
+    void put(String key, ColumnFamily columnFamily, CommitLog.CommitLogContext cLogCtx) throws IOException
             {
-                lock_.unlock();
-            }
-        }
-        else
+        executor_.submit(new Putter(key, columnFamily));
+        if (isThresholdViolated())
         {
-        	Runnable putter = new Putter(key, columnFamily);
-        	executor_.submit(putter);
+            enqueueFlush(cLogCtx);
         }
     }
 
@@ -241,19 +205,11 @@ void put(String key, ColumnFamily columnFamily, final CommitLog.CommitLogContext
      * Flushing is still done in a separate executor -- forceFlush only blocks
      * until the flush runnable is queued.
     */
-    public void forceflush(ColumnFamilyStore cfStore) throws IOException
+    public void forceflush()
     {
-        RowMutation rm = new RowMutation(DatabaseDescriptor.getTables().get(0), flushKey_);
-
         try
         {
-            if (cfStore.isSuper())
-            {
-                rm.add(cfStore.getColumnFamilyName() + ":SC1:Column", "0".getBytes(), 0);
-            } else {
-                rm.add(cfStore.getColumnFamilyName() + ":Column", "0".getBytes(), 0);
-            }
-            rm.apply();
+            enqueueFlush(CommitLog.open(table_).getContext());
             executor_.flushQueuer.get();
         }
         catch (Exception ex)
@@ -296,7 +252,6 @@ private void resolve(String key, ColumnFamily columnFamily)
     */
     void putOnRecovery(String key, ColumnFamily columnFamily)
     {
-        if(!key.equals(Memtable.flushKey_))
         	resolve(key, columnFamily);
     }
 
