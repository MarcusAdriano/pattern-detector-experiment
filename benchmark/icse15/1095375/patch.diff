diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
index 56e78250..e452bf84 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
@@ -198,6 +198,11 @@ public final String getBestFragment(TokenStream tokenStream, String text)
 	    tokenStream.reset();
 	    
 		TextFragment currentFrag =	new TextFragment(newText,newText.length(), docFrags.size());
+		
+    if (fragmentScorer instanceof QueryScorer) {
+      ((QueryScorer) fragmentScorer).setMaxDocCharsToAnalyze(maxDocCharsToAnalyze);
+    }
+    
 		TokenStream newStream = fragmentScorer.init(tokenStream);
 		if(newStream != null) {
 		  tokenStream = newStream;
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/OffsetLimitTokenFilter.java b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/OffsetLimitTokenFilter.java
index e69de29b..839c7cd5 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/OffsetLimitTokenFilter.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/OffsetLimitTokenFilter.java
@@ -0,0 +1 @@
+package org.apache.lucene.search.highlight;/** * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */import java.io.IOException;import org.apache.lucene.analysis.TokenFilter;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;/** * This TokenFilter limits the number of tokens while indexing by adding up the * current offset. */public final class OffsetLimitTokenFilter extends TokenFilter {    private int offsetCount;  private OffsetAttribute offsetAttrib = getAttribute(OffsetAttribute.class);  private int offsetLimit;    public OffsetLimitTokenFilter(TokenStream input, int offsetLimit) {    super(input);    this.offsetLimit = offsetLimit;  }    @Override  public boolean incrementToken() throws IOException {    if (offsetCount < offsetLimit && input.incrementToken()) {      int offsetLength = offsetAttrib.endOffset() - offsetAttrib.startOffset();      offsetCount += offsetLength;      return true;    }    return false;  }    @Override  public void reset() throws IOException {    super.reset();    offsetCount = 0;  }  }
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryScorer.java b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryScorer.java
index e0b76a4a..706fb891 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryScorer.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryScorer.java
@@ -54,6 +54,7 @@
   private IndexReader reader;
   private boolean skipInitExtractor;
   private boolean wrapToCaching = true;
+  private int maxCharsToAnalyze;
 
   /**
    * @param query Query to use for highlighting
@@ -209,7 +210,7 @@ private void init(Query query, String field, IndexReader reader, boolean expandM
   private TokenStream initExtractor(TokenStream tokenStream) throws IOException {
     WeightedSpanTermExtractor qse = defaultField == null ? new WeightedSpanTermExtractor()
         : new WeightedSpanTermExtractor(defaultField);
-
+    qse.setMaxDocCharsToAnalyze(maxCharsToAnalyze);
     qse.setExpandMultiTermQuery(expandMultiTermQuery);
     qse.setWrapIfNotCachingTokenFilter(wrapToCaching);
     if (reader == null) {
@@ -265,4 +266,8 @@ public void setExpandMultiTermQuery(boolean expandMultiTermQuery) {
   public void setWrapIfNotCachingTokenFilter(boolean wrap) {
     this.wrapToCaching = wrap;
   }
+
+  public void setMaxDocCharsToAnalyze(int maxDocCharsToAnalyze) {
+    this.maxCharsToAnalyze = maxDocCharsToAnalyze;
+  }
 }
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
index 490c236b..c81390c3 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
@@ -57,6 +57,7 @@
   private boolean expandMultiTermQuery;
   private boolean cachedTokenStream;
   private boolean wrapToCaching = true;
+  private int maxDocCharsToAnalyze;
 
   public WeightedSpanTermExtractor() {
   }
@@ -323,13 +324,13 @@ private boolean fieldNameComparator(String fieldNameToCheck) {
 
   private IndexReader getReaderForField(String field) throws IOException {
     if(wrapToCaching && !cachedTokenStream && !(tokenStream instanceof CachingTokenFilter)) {
-      tokenStream = new CachingTokenFilter(tokenStream);
+      tokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));
       cachedTokenStream = true;
     }
     IndexReader reader = readers.get(field);
     if (reader == null) {
       MemoryIndex indexer = new MemoryIndex();
-      indexer.addField(field, tokenStream);
+      indexer.addField(field, new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));
       tokenStream.reset();
       IndexSearcher searcher = indexer.createSearcher();
       reader = searcher.getIndexReader();
@@ -575,4 +576,8 @@ public TermEnum terms(final Term t) throws IOException {
 
   }
 
+  protected final void setMaxDocCharsToAnalyze(int maxDocCharsToAnalyze) {
+    this.maxDocCharsToAnalyze = maxDocCharsToAnalyze;
+  }
+
 }
diff --git a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/OffsetLimitTokenFilterTest.java b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/OffsetLimitTokenFilterTest.java
index e69de29b..1715ef77 100644
--- a/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/OffsetLimitTokenFilterTest.java
+++ b/lucene/dev/branches/branch_3x/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/OffsetLimitTokenFilterTest.java
@@ -0,0 +1 @@
+package org.apache.lucene.search.highlight;/** * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the "License"); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */import java.io.Reader;import java.io.StringReader;import org.apache.lucene.analysis.Analyzer;import org.apache.lucene.analysis.BaseTokenStreamTestCase;import org.apache.lucene.analysis.WhitespaceAnalyzer;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.util.Version;public class OffsetLimitTokenFilterTest extends BaseTokenStreamTestCase {    public void testFilter() throws Exception {    TokenStream stream = new WhitespaceAnalyzer(Version.LUCENE_CURRENT)        .tokenStream("field", new StringReader(            "short toolong evenmuchlongertext a ab toolong foo"));          OffsetLimitTokenFilter filter = new OffsetLimitTokenFilter(stream, 10);    assertTokenStreamContents(filter, new String[] {"short", "toolong"});        stream = new WhitespaceAnalyzer(Version.LUCENE_CURRENT).tokenStream("field", new StringReader(        "short toolong evenmuchlongertext a ab toolong foo"));    filter = new OffsetLimitTokenFilter(stream, 12);    assertTokenStreamContents(filter, new String[] {"short", "toolong"});      stream = new WhitespaceAnalyzer(Version.LUCENE_CURRENT).tokenStream(        "field", new StringReader(            "short toolong evenmuchlongertext a ab toolong foo"));    filter = new OffsetLimitTokenFilter(stream, 30);    assertTokenStreamContents(filter, new String[] {"short", "toolong",        "evenmuchlongertext"});            checkOneTermReuse(new Analyzer() {            @Override      public TokenStream tokenStream(String fieldName, Reader reader) {        return new WhitespaceAnalyzer(Version.LUCENE_CURRENT).tokenStream(fieldName, reader);      }    }, "llenges", "llenges");  }}
diff --git a/lucene/dev/branches/branch_3x/solr/src/java/org/apache/solr/highlight/DefaultSolrHighlighter.java b/lucene/dev/branches/branch_3x/solr/src/java/org/apache/solr/highlight/DefaultSolrHighlighter.java
index b4a83e91..fa0a01b9 100644
--- a/lucene/dev/branches/branch_3x/solr/src/java/org/apache/solr/highlight/DefaultSolrHighlighter.java
+++ b/lucene/dev/branches/branch_3x/solr/src/java/org/apache/solr/highlight/DefaultSolrHighlighter.java
@@ -432,11 +432,19 @@ private void doHighlightingByHighlighter( Query query, SolrQueryRequest req, Nam
         tstream = createAnalyzerTStream(schema, fieldName, docTexts[j]);
       }
                    
+      int maxCharsToAnalyze = params.getFieldInt(fieldName,
+          HighlightParams.MAX_CHARS,
+          Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);
+      
       Highlighter highlighter;
       if (Boolean.valueOf(req.getParams().get(HighlightParams.USE_PHRASE_HIGHLIGHTER, "true"))) {
         // TODO: this is not always necessary - eventually we would like to avoid this wrap
         //       when it is not needed.
+        if (maxCharsToAnalyze < 0) {
         tstream = new CachingTokenFilter(tstream);
+        } else {
+          tstream = new CachingTokenFilter(new OffsetLimitTokenFilter(tstream, maxCharsToAnalyze));
+        }
         
         // get highlighter
         highlighter = getPhraseHighlighter(query, fieldName, req, (CachingTokenFilter) tstream);
@@ -449,9 +457,6 @@ private void doHighlightingByHighlighter( Query query, SolrQueryRequest req, Nam
         highlighter = getHighlighter(query, fieldName, req);
       }
       
-      int maxCharsToAnalyze = params.getFieldInt(fieldName,
-          HighlightParams.MAX_CHARS,
-          Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);
       if (maxCharsToAnalyze < 0) {
         highlighter.setMaxDocCharsToAnalyze(docTexts[j].length());
       } else {
